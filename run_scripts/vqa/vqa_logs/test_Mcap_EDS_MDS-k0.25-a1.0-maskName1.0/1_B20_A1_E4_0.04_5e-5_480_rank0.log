2022-10-13 09:47:47 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-13 09:47:47 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-13 09:47:47 - utils.py[line:261] - INFO: Start init
2022-10-13 09:47:47 - utils.py[line:261] - INFO: Start init
2022-10-13 09:47:48 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-13 09:47:48 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-13 09:47:48 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-13 09:47:48 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-13 09:47:54 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 4, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=4, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-13 09:47:54 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-13 09:47:54 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-10-13 09:47:58 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-13 09:47:58 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-13 09:47:58 - train.py[line:119] - INFO: model: OFAModel
2022-10-13 09:47:58 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-13 09:47:58 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-13 09:47:58 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-13 09:47:58 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-13 09:47:59 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-13 09:47:59 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-13 09:47:59 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-13 09:47:59 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-13 09:47:59 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-13 09:47:59 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-13 09:47:59 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-10-13 09:47:59 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt
2022-10-13 09:48:22 - trainer.py[line:605] - INFO: Loading EMA from checkpoint
2022-10-13 09:48:22 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-10-13 09:48:22 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-10-13 09:48:22 - trainer.py[line:612] - INFO: Loading EMA fp32 params from checkpoint
2022-10-13 09:48:23 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt (epoch 8 @ 0 updates)
2022-10-13 09:48:23 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 1 row count 578200 total row count 1156400
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 0 row count 578200 total row count 1156400
2022-10-13 09:48:23 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 115640, warmup steps 4625, warmup_factor 0.00021621621621621621
Total steps 115640, warmup steps 4625, warmup_factor 0.00021621621621621621
2022-10-13 09:48:24 - trainer.py[line:707] - INFO: begin training epoch 1
2022-10-13 09:48:24 - train.py[line:312] - INFO: Start iterating over samples
2022-10-13 09:48:42 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 28910 loss=0.835, loss_v1=0, loss_v2=0, nll_loss=0.747, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=91.6, ups=0.83, wpb=110.8, bsz=40, num_updates=10, lr=1.08108e-07, gnorm=2.402, clip=100, loss_scale=128, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=43
2022-10-13 09:48:54 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 28910 loss=0.892, loss_v1=0, loss_v2=0, nll_loss=0.805, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.75, wps=93.6, ups=0.85, wpb=109.6, bsz=40, num_updates=20, lr=2.16216e-07, gnorm=2.524, clip=100, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=55
2022-10-13 09:49:05 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 28910 loss=0.86, loss_v1=0, loss_v2=0, nll_loss=0.776, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=97.8, ups=0.88, wpb=111.1, bsz=40, num_updates=30, lr=3.24324e-07, gnorm=2.587, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=66
2022-10-13 09:49:16 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 28910 loss=0.825, loss_v1=0, loss_v2=0, nll_loss=0.732, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.66, wps=99.1, ups=0.89, wpb=111.6, bsz=40, num_updates=40, lr=4.32432e-07, gnorm=2.342, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=77
2022-10-13 09:49:28 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 28910 loss=0.833, loss_v1=0, loss_v2=0, nll_loss=0.744, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=95.3, ups=0.87, wpb=109.4, bsz=40, num_updates=50, lr=5.40541e-07, gnorm=2.57, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=89
2022-10-13 09:49:39 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 28910 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.687, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=94.2, ups=0.85, wpb=111.1, bsz=40, num_updates=60, lr=6.48649e-07, gnorm=2.222, clip=100, loss_scale=128, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=101
2022-10-13 09:49:51 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 28910 loss=0.772, loss_v1=0, loss_v2=0, nll_loss=0.684, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=94.9, ups=0.86, wpb=109.8, bsz=40, num_updates=70, lr=7.56757e-07, gnorm=2.23, clip=100, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=112
2022-10-13 09:50:02 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 28910 loss=0.75, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=101.8, ups=0.93, wpb=110, bsz=40, num_updates=80, lr=8.64865e-07, gnorm=1.926, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=123
2022-10-13 09:50:13 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 28910 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.655, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=95.8, ups=0.86, wpb=111, bsz=40, num_updates=90, lr=9.72973e-07, gnorm=1.723, clip=90, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=135
2022-10-13 09:50:25 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 28910 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=95.3, ups=0.87, wpb=110.1, bsz=40, num_updates=100, lr=1.08108e-06, gnorm=1.723, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=146
2022-10-13 09:50:36 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 28910 loss=0.757, loss_v1=0, loss_v2=0, nll_loss=0.686, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=101.2, ups=0.92, wpb=110, bsz=40, num_updates=110, lr=1.18919e-06, gnorm=1.533, clip=90, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=157
2022-10-13 09:50:47 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 28910 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.609, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99, ups=0.89, wpb=111.2, bsz=40, num_updates=120, lr=1.2973e-06, gnorm=1.211, clip=70, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=168
2022-10-13 09:50:59 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 28910 loss=0.731, loss_v1=0, loss_v2=0, nll_loss=0.668, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=97.9, ups=0.88, wpb=110.8, bsz=40, num_updates=130, lr=1.40541e-06, gnorm=1.141, clip=70, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=180
2022-10-13 09:51:10 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 28910 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.5, ups=0.89, wpb=110.9, bsz=40, num_updates=140, lr=1.51351e-06, gnorm=0.806, clip=40, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=191
2022-10-13 09:51:21 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 28910 loss=0.652, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=150, lr=1.62162e-06, gnorm=0.696, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=202
2022-10-13 09:51:32 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 28910 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.628, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=101, ups=0.91, wpb=110.5, bsz=40, num_updates=160, lr=1.72973e-06, gnorm=0.681, clip=20, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=213
2022-10-13 09:51:43 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 28910 loss=0.707, loss_v1=0, loss_v2=0, nll_loss=0.652, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=170, lr=1.83784e-06, gnorm=0.636, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=224
2022-10-13 09:51:54 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 28910 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.565, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99.2, ups=0.89, wpb=111.4, bsz=40, num_updates=180, lr=1.94595e-06, gnorm=0.623, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=235
2022-10-13 09:52:05 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 28910 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.5, ups=0.9, wpb=111.8, bsz=40, num_updates=190, lr=2.05405e-06, gnorm=0.533, clip=0, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=247
2022-10-13 09:52:17 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 28910 loss=0.713, loss_v1=0, loss_v2=0, nll_loss=0.659, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=200, lr=2.16216e-06, gnorm=0.621, clip=0, loss_scale=128, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=258
2022-10-13 09:52:28 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 28910 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.601, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.3, ups=0.89, wpb=110.7, bsz=40, num_updates=210, lr=2.27027e-06, gnorm=0.561, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=269
2022-10-13 09:52:39 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 28910 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.571, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=101.5, ups=0.92, wpb=109.8, bsz=40, num_updates=220, lr=2.37838e-06, gnorm=0.569, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=280
2022-10-13 09:52:50 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 28910 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=230, lr=2.48649e-06, gnorm=0.563, clip=0, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=291
2022-10-13 09:53:01 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.5, ups=0.9, wpb=111.4, bsz=40, num_updates=240, lr=2.59459e-06, gnorm=0.578, clip=10, loss_scale=128, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=302
2022-10-13 09:53:12 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 28910 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=250, lr=2.7027e-06, gnorm=0.596, clip=10, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=313
2022-10-13 09:53:23 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 28910 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=102.7, ups=0.93, wpb=110.5, bsz=40, num_updates=260, lr=2.81081e-06, gnorm=0.631, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=324
2022-10-13 09:53:34 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 28910 loss=0.73, loss_v1=0, loss_v2=0, nll_loss=0.667, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=98.6, ups=0.91, wpb=108.9, bsz=40, num_updates=270, lr=2.91892e-06, gnorm=0.815, clip=20, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=335
2022-10-13 09:53:45 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 28910 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.603, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=280, lr=3.02703e-06, gnorm=0.684, clip=0, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=346
2022-10-13 09:53:56 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 28910 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.3, ups=0.9, wpb=110, bsz=40, num_updates=290, lr=3.13514e-06, gnorm=0.7, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=357
2022-10-13 09:54:07 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 28910 loss=0.649, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=97.3, ups=0.89, wpb=109.8, bsz=40, num_updates=300, lr=3.24324e-06, gnorm=0.638, clip=10, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=369
2022-10-13 09:54:19 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 28910 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=310, lr=3.35135e-06, gnorm=0.649, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=380
2022-10-13 09:54:30 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 28910 loss=0.634, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=103.3, ups=0.93, wpb=111.3, bsz=40, num_updates=320, lr=3.45946e-06, gnorm=0.618, clip=0, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=391
2022-10-13 09:54:41 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 28910 loss=0.688, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=330, lr=3.56757e-06, gnorm=0.721, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=402
2022-10-13 09:54:51 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 28910 loss=0.663, loss_v1=0, loss_v2=0, nll_loss=0.606, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=102.8, ups=0.92, wpb=111.2, bsz=40, num_updates=340, lr=3.67568e-06, gnorm=0.665, clip=0, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=413
2022-10-13 09:55:03 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 28910 loss=0.612, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.9, ups=0.9, wpb=111.8, bsz=40, num_updates=350, lr=3.78378e-06, gnorm=0.628, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=424
2022-10-13 09:55:14 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 28910 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.587, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=360, lr=3.89189e-06, gnorm=0.661, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=435
2022-10-13 09:55:25 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 28910 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.596, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=101.3, ups=0.92, wpb=110.4, bsz=40, num_updates=370, lr=4e-06, gnorm=0.665, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=446
2022-10-13 09:55:36 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 28910 loss=0.667, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=380, lr=4.10811e-06, gnorm=0.645, clip=0, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=457
2022-10-13 09:55:47 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 28910 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.547, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=390, lr=4.21622e-06, gnorm=0.704, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=468
2022-10-13 09:55:58 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 28910 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.563, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=400, lr=4.32432e-06, gnorm=0.753, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=479
2022-10-13 09:56:09 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 28910 loss=0.618, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=410, lr=4.43243e-06, gnorm=0.821, clip=20, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=491
2022-10-13 09:56:20 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 28910 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=420, lr=4.54054e-06, gnorm=0.89, clip=20, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=501
2022-10-13 09:56:31 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 28910 loss=0.627, loss_v1=0, loss_v2=0, nll_loss=0.556, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=100.4, ups=0.9, wpb=111.3, bsz=40, num_updates=430, lr=4.64865e-06, gnorm=0.999, clip=50, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=513
2022-10-13 09:56:43 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 28910 loss=0.679, loss_v1=0, loss_v2=0, nll_loss=0.608, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.7, ups=0.9, wpb=109.6, bsz=40, num_updates=440, lr=4.75676e-06, gnorm=1.093, clip=50, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=524
2022-10-13 09:56:54 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 28910 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.3, ups=0.88, wpb=110.8, bsz=40, num_updates=450, lr=4.86486e-06, gnorm=1.065, clip=70, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=535
2022-10-13 09:57:05 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 28910 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=460, lr=4.97297e-06, gnorm=1.28, clip=80, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=546
2022-10-13 09:57:17 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 28910 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=470, lr=5.08108e-06, gnorm=1.03, clip=50, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=558
2022-10-13 09:57:28 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 28910 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.6, ups=0.89, wpb=109.2, bsz=40, num_updates=480, lr=5.18919e-06, gnorm=1.075, clip=60, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=569
2022-10-13 09:57:39 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 28910 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=490, lr=5.2973e-06, gnorm=1.014, clip=40, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=580
2022-10-13 09:57:50 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 28910 loss=0.626, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.5, ups=0.87, wpb=110, bsz=40, num_updates=500, lr=5.40541e-06, gnorm=0.993, clip=30, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=592
2022-10-13 09:58:02 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 28910 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.9, ups=0.9, wpb=108.7, bsz=40, num_updates=510, lr=5.51351e-06, gnorm=1.024, clip=40, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=603
2022-10-13 09:58:13 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.9, ups=0.89, wpb=111.5, bsz=40, num_updates=520, lr=5.62162e-06, gnorm=0.989, clip=40, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=614
2022-10-13 09:58:24 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 28910 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=101.5, ups=0.91, wpb=111, bsz=40, num_updates=530, lr=5.72973e-06, gnorm=1.067, clip=50, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=625
2022-10-13 09:58:35 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 28910 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99, ups=0.9, wpb=110.1, bsz=40, num_updates=540, lr=5.83784e-06, gnorm=0.947, clip=30, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=636
2022-10-13 09:58:46 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 28910 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=550, lr=5.94595e-06, gnorm=1.088, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=647
2022-10-13 09:58:57 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 28910 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=101.6, ups=0.92, wpb=110.1, bsz=40, num_updates=560, lr=6.05405e-06, gnorm=0.97, clip=30, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=658
2022-10-13 09:59:08 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 28910 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.9, ups=0.89, wpb=110.1, bsz=40, num_updates=570, lr=6.16216e-06, gnorm=0.957, clip=20, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=669
2022-10-13 09:59:19 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 28910 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.53, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.8, ups=0.89, wpb=111.1, bsz=40, num_updates=580, lr=6.27027e-06, gnorm=1.006, clip=50, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=681
2022-10-13 09:59:31 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 28910 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=101, ups=0.9, wpb=112.1, bsz=40, num_updates=590, lr=6.37838e-06, gnorm=1.212, clip=80, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=692
2022-10-13 09:59:42 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 28910 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=95.1, ups=0.86, wpb=110.4, bsz=40, num_updates=600, lr=6.48649e-06, gnorm=1.147, clip=80, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=703
2022-10-13 09:59:54 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.532, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.9, ups=0.88, wpb=109.4, bsz=40, num_updates=610, lr=6.59459e-06, gnorm=1.075, clip=80, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=715
2022-10-13 10:00:05 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 28910 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.9, ups=0.91, wpb=109.6, bsz=40, num_updates=620, lr=6.7027e-06, gnorm=1.133, clip=80, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=726
2022-10-13 10:00:16 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 28910 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.5, ups=0.9, wpb=111.7, bsz=40, num_updates=630, lr=6.81081e-06, gnorm=1.025, clip=60, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=737
2022-10-13 10:00:27 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 28910 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.6, ups=0.87, wpb=109.8, bsz=40, num_updates=640, lr=6.91892e-06, gnorm=1.126, clip=60, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=748
2022-10-13 10:00:39 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 28910 loss=0.622, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.7, ups=0.88, wpb=110.1, bsz=40, num_updates=650, lr=7.02703e-06, gnorm=1.057, clip=60, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=760
2022-10-13 10:00:50 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 28910 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.9, ups=0.87, wpb=110.6, bsz=40, num_updates=660, lr=7.13514e-06, gnorm=0.919, clip=30, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=771
2022-10-13 10:01:01 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 28910 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.3, ups=0.9, wpb=109.8, bsz=40, num_updates=670, lr=7.24324e-06, gnorm=0.997, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=782
2022-10-13 10:01:12 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 28910 loss=0.669, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=680, lr=7.35135e-06, gnorm=1.234, clip=70, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=794
2022-10-13 10:01:23 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 28910 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.9, ups=0.93, wpb=109.9, bsz=40, num_updates=690, lr=7.45946e-06, gnorm=1.008, clip=50, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=804
2022-10-13 10:01:34 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 28910 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=105.8, ups=0.94, wpb=112.4, bsz=40, num_updates=700, lr=7.56757e-06, gnorm=1.01, clip=30, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=815
2022-10-13 10:01:45 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 28910 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.6, ups=0.88, wpb=110, bsz=40, num_updates=710, lr=7.67568e-06, gnorm=1.131, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=826
2022-10-13 10:01:57 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 28910 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.9, ups=0.88, wpb=110.5, bsz=40, num_updates=720, lr=7.78378e-06, gnorm=1.16, clip=70, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=838
2022-10-13 10:02:08 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 28910 loss=0.62, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.1, ups=0.88, wpb=110.5, bsz=40, num_updates=730, lr=7.89189e-06, gnorm=1.02, clip=40, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=849
2022-10-13 10:02:19 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 28910 loss=0.642, loss_v1=0, loss_v2=0, nll_loss=0.568, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99, ups=0.9, wpb=109.9, bsz=40, num_updates=740, lr=8e-06, gnorm=1.006, clip=60, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=860
2022-10-13 10:02:31 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98, ups=0.88, wpb=111.6, bsz=40, num_updates=750, lr=8.10811e-06, gnorm=0.913, clip=20, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=872
2022-10-13 10:02:41 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 28910 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.542, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=101.3, ups=0.93, wpb=109.4, bsz=40, num_updates=760, lr=8.21622e-06, gnorm=1.205, clip=80, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=883
2022-10-13 10:02:53 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.9, ups=0.88, wpb=111.8, bsz=40, num_updates=770, lr=8.32432e-06, gnorm=1.025, clip=50, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=894
2022-10-13 10:03:04 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.8, ups=0.89, wpb=111.6, bsz=40, num_updates=780, lr=8.43243e-06, gnorm=1.064, clip=40, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=905
2022-10-13 10:03:15 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 28910 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=790, lr=8.54054e-06, gnorm=1.136, clip=60, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=916
2022-10-13 10:03:26 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 28910 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.7, ups=0.9, wpb=108.7, bsz=40, num_updates=800, lr=8.64865e-06, gnorm=1.042, clip=60, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=928
2022-10-13 10:03:37 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 28910 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.8, ups=0.92, wpb=110.1, bsz=40, num_updates=810, lr=8.75676e-06, gnorm=0.914, clip=30, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=938
2022-10-13 10:03:48 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 28910 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=106.5, ups=0.97, wpb=110.3, bsz=40, num_updates=820, lr=8.86486e-06, gnorm=0.935, clip=40, loss_scale=256, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=949
2022-10-13 10:03:59 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 28910 loss=0.623, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.6, ups=0.9, wpb=111.5, bsz=40, num_updates=830, lr=8.97297e-06, gnorm=1.085, clip=70, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=960
2022-10-13 10:04:10 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 28910 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=840, lr=9.08108e-06, gnorm=1.022, clip=40, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=971
2022-10-13 10:04:22 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.7, ups=0.86, wpb=109.9, bsz=40, num_updates=850, lr=9.18919e-06, gnorm=1.021, clip=40, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=983
2022-10-13 10:04:33 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 28910 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=860, lr=9.2973e-06, gnorm=1.114, clip=70, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=994
2022-10-13 10:04:44 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 28910 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=870, lr=9.40541e-06, gnorm=1.152, clip=70, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1005
2022-10-13 10:04:55 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 28910 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=880, lr=9.51351e-06, gnorm=1.009, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1017
2022-10-13 10:05:07 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 28910 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.8, ups=0.89, wpb=112.1, bsz=40, num_updates=890, lr=9.62162e-06, gnorm=0.906, clip=10, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1028
2022-10-13 10:05:18 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.4, ups=0.91, wpb=110.2, bsz=40, num_updates=900, lr=9.72973e-06, gnorm=0.957, clip=50, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1039
2022-10-13 10:05:29 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.2, ups=0.89, wpb=110.6, bsz=40, num_updates=910, lr=9.83784e-06, gnorm=1.012, clip=40, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1050
2022-10-13 10:05:40 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 28910 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=920, lr=9.94595e-06, gnorm=0.927, clip=10, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1061
2022-10-13 10:05:52 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 28910 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.5, ups=0.88, wpb=111.3, bsz=40, num_updates=930, lr=1.00541e-05, gnorm=0.814, clip=10, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1073
2022-10-13 10:06:03 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.2, ups=0.9, wpb=110.7, bsz=40, num_updates=940, lr=1.01622e-05, gnorm=0.935, clip=20, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=1084
2022-10-13 10:06:14 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 28910 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98.8, ups=0.9, wpb=109.8, bsz=40, num_updates=950, lr=1.02703e-05, gnorm=1.003, clip=30, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1095
2022-10-13 10:06:25 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 28910 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.5, ups=0.88, wpb=109, bsz=40, num_updates=960, lr=1.03784e-05, gnorm=0.93, clip=30, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=1106
2022-10-13 10:06:37 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 28910 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.6, ups=0.87, wpb=110.6, bsz=40, num_updates=970, lr=1.04865e-05, gnorm=1.028, clip=50, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1118
2022-10-13 10:06:48 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.2, ups=0.88, wpb=109.6, bsz=40, num_updates=980, lr=1.05946e-05, gnorm=0.975, clip=50, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1129
2022-10-13 10:06:59 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=102, ups=0.92, wpb=111.3, bsz=40, num_updates=990, lr=1.07027e-05, gnorm=0.998, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1140
2022-10-13 10:07:10 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101, ups=0.9, wpb=112.1, bsz=40, num_updates=1000, lr=1.08108e-05, gnorm=0.947, clip=20, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1151
2022-10-13 10:07:10 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 10:07:10 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-13 10:07:12 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 10:07:12 - train.py[line:551] - INFO: load:1.24 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 10:09:47 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 10:09:47 - train.py[line:551] - INFO: load:1.26 valid_run:155.12 task_valid:151.76 collect_output:2.07
2022-10-13 10:12:17 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 10:12:17 - train.py[line:551] - INFO: load:1.29 valid_run:304.89 task_valid:296.37 collect_output:6.11
2022-10-13 10:14:50 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 10:14:50 - train.py[line:551] - INFO: load:1.32 valid_run:458.46 task_valid:440.62 collect_output:14.24
2022-10-13 10:17:21 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 10:17:21 - train.py[line:551] - INFO: load:1.34 valid_run:608.50 task_valid:586.95 collect_output:16.82
2022-10-13 10:19:54 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 10:19:54 - train.py[line:551] - INFO: load:1.37 valid_run:761.58 task_valid:735.50 collect_output:20.26
2022-10-13 10:22:26 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 10:22:26 - train.py[line:551] - INFO: load:1.39 valid_run:914.10 task_valid:882.35 collect_output:24.83
2022-10-13 10:25:00 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 10:25:00 - train.py[line:551] - INFO: load:1.42 valid_run:1067.63 task_valid:1029.86 collect_output:29.68
2022-10-13 10:27:31 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 10:27:31 - train.py[line:551] - INFO: load:1.45 valid_run:1219.20 task_valid:1172.29 collect_output:37.74
2022-10-13 10:30:02 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 10:30:02 - train.py[line:551] - INFO: load:1.48 valid_run:1369.42 task_valid:1318.05 collect_output:41.17
2022-10-13 10:32:31 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 10:32:31 - train.py[line:551] - INFO: load:1.50 valid_run:1518.52 task_valid:1462.31 collect_output:44.93
2022-10-13 10:35:01 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 10:35:01 - train.py[line:551] - INFO: load:1.53 valid_run:1669.00 task_valid:1608.26 collect_output:48.39
2022-10-13 10:37:32 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 10:37:32 - train.py[line:551] - INFO: load:1.55 valid_run:1819.52 task_valid:1754.26 collect_output:51.83
2022-10-13 10:40:02 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 10:40:02 - train.py[line:551] - INFO: load:1.57 valid_run:1969.77 task_valid:1897.03 collect_output:58.26
2022-10-13 10:42:33 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 10:42:33 - train.py[line:551] - INFO: load:1.60 valid_run:2120.71 task_valid:2043.33 collect_output:61.85
2022-10-13 10:45:04 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 10:45:04 - train.py[line:551] - INFO: load:1.62 valid_run:2271.56 task_valid:2190.78 collect_output:64.18
2022-10-13 10:47:35 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 10:47:35 - train.py[line:551] - INFO: load:1.65 valid_run:2422.29 task_valid:2335.83 collect_output:68.73
2022-10-13 10:50:07 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 10:50:07 - train.py[line:551] - INFO: load:1.67 valid_run:2573.95 task_valid:2482.33 collect_output:72.81
2022-10-13 10:52:38 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 10:52:38 - train.py[line:551] - INFO: load:1.70 valid_run:2725.21 task_valid:2630.42 collect_output:74.89
2022-10-13 10:55:07 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 10:55:07 - train.py[line:551] - INFO: load:1.72 valid_run:2874.13 task_valid:2773.15 collect_output:79.98
2022-10-13 10:57:38 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 10:57:38 - train.py[line:551] - INFO: load:1.75 valid_run:3024.78 task_valid:2919.35 collect_output:83.39
2022-10-13 11:00:10 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 11:00:10 - train.py[line:551] - INFO: load:1.77 valid_run:3176.50 task_valid:3064.85 collect_output:88.57
2022-10-13 11:02:40 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 11:02:40 - train.py[line:551] - INFO: load:1.80 valid_run:3326.43 task_valid:3210.41 collect_output:91.85
2022-10-13 11:05:11 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 11:05:11 - train.py[line:551] - INFO: load:1.82 valid_run:3478.09 task_valid:3357.75 collect_output:95.10
2022-10-13 11:07:43 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 11:07:43 - train.py[line:551] - INFO: load:1.85 valid_run:3630.20 task_valid:3505.51 collect_output:98.38

====================================================================================================
SGG eval:     R @ 50: 0.6385;     R @ 100: 0.6801;     R @ 500: 0.7097;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4284;    mR @ 100: 0.4822;    mR @ 500: 0.5250;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.3714) (eating:0.7353) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5323) (lying on:0.5000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9624) (says:0.0000) (sitting on:0.6774) (standing on:0.5113) (using:0.4500) (walking in:0.0000) (walking on:0.6216) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6385;     R @ 100: 0.6801;     R @ 500: 0.7097;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4284;    mR @ 100: 0.4822;    mR @ 500: 0.5250;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.3714) (eating:0.7353) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5323) (lying on:0.5000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9624) (says:0.0000) (sitting on:0.6774) (standing on:0.5113) (using:0.4500) (walking in:0.0000) (walking on:0.6216) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2022-10-13 11:10:15 - train.py[line:487] - INFO: 0.6801467787114845
2022-10-13 11:10:16 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 11:10:16 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.32 | loss_v1 0 | loss_v2 0 | nll_loss 0.198 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.680147 | ppl 1.15 | vqa_score 0.4764 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 1000
2022-10-13 11:10:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1000 updates
2022-10-13 11:10:16 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-13 11:10:22 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-13 11:10:27 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 0.6801467787114845) (writing took 10.951272557955235 seconds)
2022-10-13 11:10:37 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 28910 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=0.3, ups=0, wpb=109.3, bsz=40, num_updates=1010, lr=1.09189e-05, gnorm=1.114, clip=60, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4958
2022-10-13 11:10:49 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 28910 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.536, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.6, ups=0.87, wpb=110.6, bsz=40, num_updates=1020, lr=1.1027e-05, gnorm=1.027, clip=50, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=4970
2022-10-13 11:11:00 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=1030, lr=1.11351e-05, gnorm=1.049, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4981
2022-10-13 11:11:11 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.4, ups=0.88, wpb=110.8, bsz=40, num_updates=1040, lr=1.12432e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4992
2022-10-13 11:11:23 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 28910 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.9, ups=0.88, wpb=111.2, bsz=40, num_updates=1050, lr=1.13514e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5004
2022-10-13 11:11:34 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 28910 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.4, ups=0.91, wpb=108.6, bsz=40, num_updates=1060, lr=1.14595e-05, gnorm=1.004, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5015
2022-10-13 11:11:45 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 28910 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.6, ups=0.87, wpb=111, bsz=40, num_updates=1070, lr=1.15676e-05, gnorm=1.082, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5026
2022-10-13 11:11:57 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.9, ups=0.87, wpb=110.8, bsz=40, num_updates=1080, lr=1.16757e-05, gnorm=1.02, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5038
2022-10-13 11:12:08 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 28910 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.8, ups=0.9, wpb=109.7, bsz=40, num_updates=1090, lr=1.17838e-05, gnorm=1.02, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5049
2022-10-13 11:12:19 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 28910 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=1100, lr=1.18919e-05, gnorm=1.009, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5060
2022-10-13 11:12:31 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 28910 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.548, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.5, ups=0.87, wpb=110.4, bsz=40, num_updates=1110, lr=1.2e-05, gnorm=1.144, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5072
2022-10-13 11:12:42 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.4, ups=0.89, wpb=110, bsz=40, num_updates=1120, lr=1.21081e-05, gnorm=0.941, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5083
2022-10-13 11:12:53 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=102.5, ups=0.93, wpb=110.7, bsz=40, num_updates=1130, lr=1.22162e-05, gnorm=0.909, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5094
2022-10-13 11:13:04 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 28910 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=1140, lr=1.23243e-05, gnorm=0.863, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5105
2022-10-13 11:13:15 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 28910 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=1150, lr=1.24324e-05, gnorm=1.106, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5116
2022-10-13 11:13:26 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.5, ups=0.92, wpb=110, bsz=40, num_updates=1160, lr=1.25405e-05, gnorm=0.927, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5127
2022-10-13 11:13:38 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 28910 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=1170, lr=1.26486e-05, gnorm=0.984, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5139
2022-10-13 11:13:49 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 28910 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.4, ups=0.88, wpb=110.3, bsz=40, num_updates=1180, lr=1.27568e-05, gnorm=0.994, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5150
2022-10-13 11:14:01 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 28910 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=93.4, ups=0.86, wpb=108.9, bsz=40, num_updates=1190, lr=1.28649e-05, gnorm=1.007, clip=50, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5162
2022-10-13 11:14:12 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 28910 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.5, ups=0.9, wpb=109.8, bsz=40, num_updates=1200, lr=1.2973e-05, gnorm=0.999, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5173
2022-10-13 11:14:23 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 28910 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.3, ups=0.89, wpb=109.1, bsz=40, num_updates=1210, lr=1.30811e-05, gnorm=0.995, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5184
2022-10-13 11:14:34 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 28910 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=1220, lr=1.31892e-05, gnorm=0.944, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5195
2022-10-13 11:14:45 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.9, ups=0.89, wpb=111.3, bsz=40, num_updates=1230, lr=1.32973e-05, gnorm=0.984, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5207
2022-10-13 11:14:57 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 28910 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.5, ups=0.9, wpb=108.6, bsz=40, num_updates=1240, lr=1.34054e-05, gnorm=1.041, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5218
2022-10-13 11:15:08 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 28910 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94.7, ups=0.87, wpb=108.5, bsz=40, num_updates=1250, lr=1.35135e-05, gnorm=0.958, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5229
2022-10-13 11:15:20 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=95, ups=0.87, wpb=109.5, bsz=40, num_updates=1260, lr=1.36216e-05, gnorm=1.095, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5241
2022-10-13 11:15:31 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.9, ups=0.91, wpb=110.2, bsz=40, num_updates=1270, lr=1.37297e-05, gnorm=1.007, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5252
2022-10-13 11:15:42 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 28910 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.534, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=1280, lr=1.38378e-05, gnorm=0.883, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5263
2022-10-13 11:15:53 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97, ups=0.89, wpb=109.4, bsz=40, num_updates=1290, lr=1.39459e-05, gnorm=1.126, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5274
2022-10-13 11:16:05 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97, ups=0.87, wpb=111.9, bsz=40, num_updates=1300, lr=1.40541e-05, gnorm=0.925, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5286
2022-10-13 11:16:16 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.1, ups=0.89, wpb=110.4, bsz=40, num_updates=1310, lr=1.41622e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5297
2022-10-13 11:16:27 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 28910 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=1320, lr=1.42703e-05, gnorm=1.1, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5308
2022-10-13 11:16:39 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.9, ups=0.87, wpb=110.8, bsz=40, num_updates=1330, lr=1.43784e-05, gnorm=0.964, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5320
2022-10-13 11:16:50 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.3, ups=0.9, wpb=112.1, bsz=40, num_updates=1340, lr=1.44865e-05, gnorm=0.863, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5331
2022-10-13 11:17:02 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 28910 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.7, ups=0.87, wpb=110.5, bsz=40, num_updates=1350, lr=1.45946e-05, gnorm=0.956, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5343
2022-10-13 11:17:12 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 28910 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=102.8, ups=0.93, wpb=111, bsz=40, num_updates=1360, lr=1.47027e-05, gnorm=1.018, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5353
2022-10-13 11:17:24 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 28910 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.7, ups=0.89, wpb=109.7, bsz=40, num_updates=1370, lr=1.48108e-05, gnorm=0.95, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5365
2022-10-13 11:17:34 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 28910 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=103.1, ups=0.94, wpb=110.2, bsz=40, num_updates=1380, lr=1.49189e-05, gnorm=0.926, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5375
2022-10-13 11:17:45 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 28910 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.6, ups=0.9, wpb=109.7, bsz=40, num_updates=1390, lr=1.5027e-05, gnorm=0.907, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5387
2022-10-13 11:17:57 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 28910 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.2, ups=0.89, wpb=109.3, bsz=40, num_updates=1400, lr=1.51351e-05, gnorm=0.989, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5398
2022-10-13 11:18:08 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.8, ups=0.9, wpb=110.9, bsz=40, num_updates=1410, lr=1.52432e-05, gnorm=0.935, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5409
2022-10-13 11:18:19 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 28910 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.3, ups=0.91, wpb=110.2, bsz=40, num_updates=1420, lr=1.53514e-05, gnorm=0.906, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5420
2022-10-13 11:18:30 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.6, ups=0.91, wpb=109.8, bsz=40, num_updates=1430, lr=1.54595e-05, gnorm=1.037, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5431
2022-10-13 11:18:41 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.6, ups=0.89, wpb=108.6, bsz=40, num_updates=1440, lr=1.55676e-05, gnorm=1.048, clip=40, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=5442
2022-10-13 11:18:53 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.4, ups=0.89, wpb=110.9, bsz=40, num_updates=1450, lr=1.56757e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5454
2022-10-13 11:19:04 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 28910 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.1, ups=0.89, wpb=109.1, bsz=40, num_updates=1460, lr=1.57838e-05, gnorm=0.972, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5465
2022-10-13 11:19:15 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.4, ups=0.89, wpb=110.7, bsz=40, num_updates=1470, lr=1.58919e-05, gnorm=0.894, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5476
2022-10-13 11:19:27 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 28910 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=1480, lr=1.6e-05, gnorm=0.975, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5488
2022-10-13 11:19:37 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 28910 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=102.1, ups=0.92, wpb=110.8, bsz=40, num_updates=1490, lr=1.61081e-05, gnorm=0.909, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5499
2022-10-13 11:19:49 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.8, ups=0.87, wpb=111.8, bsz=40, num_updates=1500, lr=1.62162e-05, gnorm=0.855, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5510
2022-10-13 11:20:00 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 28910 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=1510, lr=1.63243e-05, gnorm=1.049, clip=50, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5521
2022-10-13 11:20:11 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 28910 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=1520, lr=1.64324e-05, gnorm=0.966, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5533
2022-10-13 11:20:23 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 28910 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.7, ups=0.9, wpb=111.6, bsz=40, num_updates=1530, lr=1.65405e-05, gnorm=0.977, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5544
2022-10-13 11:20:34 - progress_bar.py[line:274] - INFO: epoch 001:   1540 / 28910 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.498, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95, ups=0.86, wpb=110.2, bsz=40, num_updates=1540, lr=1.66486e-05, gnorm=0.938, clip=20, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=5555
2022-10-13 11:20:45 - progress_bar.py[line:274] - INFO: epoch 001:   1550 / 28910 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101, ups=0.91, wpb=111, bsz=40, num_updates=1550, lr=1.67568e-05, gnorm=0.917, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5566
2022-10-13 11:20:57 - progress_bar.py[line:274] - INFO: epoch 001:   1560 / 28910 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97, ups=0.89, wpb=109.6, bsz=40, num_updates=1560, lr=1.68649e-05, gnorm=0.928, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5578
2022-10-13 11:21:08 - progress_bar.py[line:274] - INFO: epoch 001:   1570 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.5, ups=0.9, wpb=109.7, bsz=40, num_updates=1570, lr=1.6973e-05, gnorm=0.935, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5589
2022-10-13 11:21:19 - progress_bar.py[line:274] - INFO: epoch 001:   1580 / 28910 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.2, ups=0.89, wpb=110.9, bsz=40, num_updates=1580, lr=1.70811e-05, gnorm=0.936, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5600
2022-10-13 11:21:30 - progress_bar.py[line:274] - INFO: epoch 001:   1590 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.7, ups=0.91, wpb=111.3, bsz=40, num_updates=1590, lr=1.71892e-05, gnorm=0.851, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5611
2022-10-13 11:21:41 - progress_bar.py[line:274] - INFO: epoch 001:   1600 / 28910 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.5, ups=0.88, wpb=111.1, bsz=40, num_updates=1600, lr=1.72973e-05, gnorm=0.859, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5623
2022-10-13 11:21:45 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 11:21:54 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=88.7, ups=0.8, wpb=110.2, bsz=40, num_updates=1610, lr=1.74054e-05, gnorm=0.944, clip=40, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=5635
2022-10-13 11:22:05 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 28910 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.1, ups=0.9, wpb=110, bsz=40, num_updates=1620, lr=1.75135e-05, gnorm=1.069, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5646
2022-10-13 11:22:16 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=1630, lr=1.76216e-05, gnorm=0.891, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5657
2022-10-13 11:22:27 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 28910 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.511, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.5, ups=0.9, wpb=110.6, bsz=40, num_updates=1640, lr=1.77297e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5669
2022-10-13 11:22:38 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=1650, lr=1.78378e-05, gnorm=0.981, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5680
2022-10-13 11:22:50 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 28910 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97, ups=0.88, wpb=110.8, bsz=40, num_updates=1660, lr=1.79459e-05, gnorm=0.888, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5691
2022-10-13 11:23:01 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 28910 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.51, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101, ups=0.91, wpb=110.6, bsz=40, num_updates=1670, lr=1.80541e-05, gnorm=0.881, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5702
2022-10-13 11:23:12 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.5, ups=0.88, wpb=109.6, bsz=40, num_updates=1680, lr=1.81622e-05, gnorm=1.02, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5713
2022-10-13 11:23:24 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 28910 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.7, ups=0.89, wpb=110.2, bsz=40, num_updates=1690, lr=1.82703e-05, gnorm=0.981, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5725
2022-10-13 11:23:35 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.1, ups=0.91, wpb=109.2, bsz=40, num_updates=1700, lr=1.83784e-05, gnorm=0.956, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5736
2022-10-13 11:23:46 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 28910 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.7, ups=0.9, wpb=109.8, bsz=40, num_updates=1710, lr=1.84865e-05, gnorm=1.144, clip=70, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5747
2022-10-13 11:23:57 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102.9, ups=0.93, wpb=110.6, bsz=40, num_updates=1720, lr=1.85946e-05, gnorm=0.802, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5758
2022-10-13 11:24:08 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=1730, lr=1.87027e-05, gnorm=0.901, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5769
2022-10-13 11:24:19 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 28910 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.7, ups=0.89, wpb=110.1, bsz=40, num_updates=1740, lr=1.88108e-05, gnorm=0.869, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5780
2022-10-13 11:24:31 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=1750, lr=1.89189e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5792
2022-10-13 11:24:42 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 28910 loss=0.551, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=1760, lr=1.9027e-05, gnorm=0.919, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5803
2022-10-13 11:24:53 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.9, wpb=110.3, bsz=40, num_updates=1770, lr=1.91351e-05, gnorm=0.891, clip=30, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5814
2022-10-13 11:25:05 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 28910 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=94, ups=0.85, wpb=110.6, bsz=40, num_updates=1780, lr=1.92432e-05, gnorm=1.118, clip=60, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=5826
2022-10-13 11:25:16 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 28910 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100, ups=0.9, wpb=111.2, bsz=40, num_updates=1790, lr=1.93514e-05, gnorm=0.908, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5837
2022-10-13 11:25:28 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.2, ups=0.87, wpb=109.6, bsz=40, num_updates=1800, lr=1.94595e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5849
2022-10-13 11:25:39 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 28910 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.5, ups=0.89, wpb=108.4, bsz=40, num_updates=1810, lr=1.95676e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5860
2022-10-13 11:25:50 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 28910 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99, ups=0.9, wpb=110.3, bsz=40, num_updates=1820, lr=1.96757e-05, gnorm=0.921, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5871
2022-10-13 11:26:01 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 28910 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.48, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.4, ups=0.9, wpb=108.3, bsz=40, num_updates=1830, lr=1.97838e-05, gnorm=0.976, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5882
2022-10-13 11:26:13 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 28910 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.4, ups=0.86, wpb=110.4, bsz=40, num_updates=1840, lr=1.98919e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=5894
2022-10-13 11:26:24 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 28910 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=103.5, ups=0.93, wpb=111.9, bsz=40, num_updates=1850, lr=2e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5905
2022-10-13 11:26:35 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.1, ups=0.91, wpb=109, bsz=40, num_updates=1860, lr=2.01081e-05, gnorm=1.017, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5916
2022-10-13 11:26:46 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.5, ups=0.89, wpb=111.8, bsz=40, num_updates=1870, lr=2.02162e-05, gnorm=1.069, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5927
2022-10-13 11:26:57 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.8, ups=0.91, wpb=110.4, bsz=40, num_updates=1880, lr=2.03243e-05, gnorm=0.89, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5938
2022-10-13 11:27:08 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.2, ups=0.9, wpb=111.1, bsz=40, num_updates=1890, lr=2.04324e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5949
2022-10-13 11:27:19 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.1, ups=0.9, wpb=109.2, bsz=40, num_updates=1900, lr=2.05405e-05, gnorm=0.915, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5960
2022-10-13 11:27:31 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.8, ups=0.88, wpb=109.2, bsz=40, num_updates=1910, lr=2.06486e-05, gnorm=0.985, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5972
2022-10-13 11:27:42 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.3, ups=0.91, wpb=110.9, bsz=40, num_updates=1920, lr=2.07568e-05, gnorm=1.006, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5983
2022-10-13 11:27:53 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.4, ups=0.88, wpb=110, bsz=40, num_updates=1930, lr=2.08649e-05, gnorm=1.091, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5994
2022-10-13 11:28:04 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 28910 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=1940, lr=2.0973e-05, gnorm=0.883, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6006
2022-10-13 11:28:16 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.7, ups=0.9, wpb=110.2, bsz=40, num_updates=1950, lr=2.10811e-05, gnorm=0.908, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6017
2022-10-13 11:28:27 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.7, ups=0.92, wpb=108.9, bsz=40, num_updates=1960, lr=2.11892e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=6028
2022-10-13 11:28:38 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.9, ups=0.88, wpb=110.3, bsz=40, num_updates=1970, lr=2.12973e-05, gnorm=0.814, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6039
2022-10-13 11:28:49 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.2, ups=0.89, wpb=111.8, bsz=40, num_updates=1980, lr=2.14054e-05, gnorm=0.866, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6050
2022-10-13 11:29:01 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 28910 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100, ups=0.9, wpb=111.2, bsz=40, num_updates=1990, lr=2.15135e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6062
2022-10-13 11:29:12 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.2, ups=0.89, wpb=109.5, bsz=40, num_updates=2000, lr=2.16216e-05, gnorm=0.917, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6073
2022-10-13 11:29:12 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 11:29:13 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 11:29:13 - train.py[line:551] - INFO: load:1.13 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 11:29:15 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.51 GiB (GPU 0; 39.59 GiB total capacity; 8.50 GiB already allocated; 5.04 GiB free; 32.06 GiB reserved in total by PyTorch)
2022-10-13 11:29:15 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 8         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8701 MB |   14121 MB |     878 TB |     878 TB |
|       from large pool |    8556 MB |   13976 MB |     878 TB |     878 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8701 MB |   14121 MB |     878 TB |     878 TB |
|       from large pool |    8556 MB |   13976 MB |     878 TB |     878 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32834 MB |   36576 MB |  125022 MB |   92188 MB |
|       from large pool |   32688 MB |   36424 MB |  124766 MB |   92078 MB |
|       from small pool |     146 MB |     152 MB |     256 MB |     110 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24132 MB |   24132 MB |     907 TB |     907 TB |
|       from large pool |   24131 MB |   24131 MB |     907 TB |     907 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3668    |    3682    |   38502 K  |   38498 K  |
|       from large pool |     563    |     575    |   13269 K  |   13268 K  |
|       from small pool |    3105    |    3114    |   25232 K  |   25229 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3668    |    3682    |   38502 K  |   38498 K  |
|       from large pool |     563    |     575    |   13269 K  |   13268 K  |
|       from small pool |    3105    |    3114    |   25232 K  |   25229 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     198    |     212    |     462    |     264    |
|       from large pool |     125    |     136    |     334    |     209    |
|       from small pool |      73    |      76    |     128    |      55    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     130    |     140    |   25798 K  |   25798 K  |
|       from large pool |      95    |      99    |    5239 K  |    5239 K  |
|       from small pool |      35    |      48    |   20558 K  |   20558 K  |
|===========================================================================|

2022-10-13 11:29:15 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-13 11:29:15 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-13 11:31:48 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 11:31:48 - train.py[line:551] - INFO: load:1.16 valid_run:155.11 task_valid:150.25 collect_output:2.04
2022-10-13 11:34:18 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 11:34:18 - train.py[line:551] - INFO: load:1.18 valid_run:304.39 task_valid:295.00 collect_output:5.39
2022-10-13 11:36:51 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 11:36:51 - train.py[line:551] - INFO: load:1.21 valid_run:457.77 task_valid:440.06 collect_output:12.56
2022-10-13 11:39:22 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 11:39:22 - train.py[line:551] - INFO: load:1.24 valid_run:608.54 task_valid:587.04 collect_output:15.14
2022-10-13 11:41:56 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 11:41:56 - train.py[line:551] - INFO: load:1.27 valid_run:762.23 task_valid:736.31 collect_output:18.40
2022-10-13 11:44:28 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 11:44:28 - train.py[line:551] - INFO: load:1.30 valid_run:914.38 task_valid:882.71 collect_output:23.09
2022-10-13 11:47:02 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 11:47:02 - train.py[line:551] - INFO: load:1.32 valid_run:1067.82 task_valid:1029.73 collect_output:28.43
2022-10-13 11:49:33 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 11:49:33 - train.py[line:551] - INFO: load:1.35 valid_run:1219.38 task_valid:1171.56 collect_output:37.10
2022-10-13 11:52:03 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 11:52:03 - train.py[line:551] - INFO: load:1.37 valid_run:1369.42 task_valid:1317.19 collect_output:40.45
2022-10-13 11:54:32 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 11:54:32 - train.py[line:551] - INFO: load:1.40 valid_run:1518.39 task_valid:1461.28 collect_output:44.24
2022-10-13 11:57:03 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 11:57:03 - train.py[line:551] - INFO: load:1.42 valid_run:1668.84 task_valid:1607.21 collect_output:47.64
2022-10-13 11:59:33 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 11:59:33 - train.py[line:551] - INFO: load:1.45 valid_run:1819.03 task_valid:1752.88 collect_output:51.10
2022-10-13 12:02:03 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 12:02:03 - train.py[line:551] - INFO: load:1.47 valid_run:1969.00 task_valid:1895.35 collect_output:57.55
2022-10-13 12:04:34 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 12:04:34 - train.py[line:551] - INFO: load:1.50 valid_run:2120.00 task_valid:2041.53 collect_output:61.29
2022-10-13 12:07:05 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 12:07:05 - train.py[line:551] - INFO: load:1.52 valid_run:2270.50 task_valid:2188.52 collect_output:63.74
2022-10-13 12:09:35 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 12:09:35 - train.py[line:551] - INFO: load:1.55 valid_run:2420.81 task_valid:2333.37 collect_output:68.14
2022-10-13 12:12:07 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 12:12:07 - train.py[line:551] - INFO: load:1.57 valid_run:2572.50 task_valid:2479.78 collect_output:72.31
2022-10-13 12:14:38 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 12:14:38 - train.py[line:551] - INFO: load:1.60 valid_run:2723.40 task_valid:2627.27 collect_output:74.64
2022-10-13 12:17:06 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 12:17:06 - train.py[line:551] - INFO: load:1.62 valid_run:2872.02 task_valid:2769.85 collect_output:79.59
2022-10-13 12:19:37 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 12:19:37 - train.py[line:551] - INFO: load:1.65 valid_run:3022.69 task_valid:2916.04 collect_output:83.01
2022-10-13 12:22:09 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 12:22:09 - train.py[line:551] - INFO: load:1.67 valid_run:3174.70 task_valid:3061.51 collect_output:88.45
2022-10-13 12:24:39 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 12:24:39 - train.py[line:551] - INFO: load:1.70 valid_run:3324.53 task_valid:3206.97 collect_output:91.73
2022-10-13 12:27:12 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 12:27:12 - train.py[line:551] - INFO: load:1.73 valid_run:3476.98 task_valid:3355.34 collect_output:94.65
2022-10-13 12:29:44 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 12:29:44 - train.py[line:551] - INFO: load:1.75 valid_run:3629.69 task_valid:3503.79 collect_output:97.73

====================================================================================================
SGG eval:     R @ 50: 0.6525;     R @ 100: 0.6929;     R @ 500: 0.7247;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4397;    mR @ 100: 0.4967;    mR @ 500: 0.5260;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5625) (covering:0.5143) (eating:0.8235) (flying in:1.0000) (growing on:0.2500) (hanging from:0.5645) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7058) (standing on:0.4813) (using:0.5000) (walking in:0.0000) (walking on:0.6351) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6525;     R @ 100: 0.6929;     R @ 500: 0.7247;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4397;    mR @ 100: 0.4967;    mR @ 500: 0.5260;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5625) (covering:0.5143) (eating:0.8235) (flying in:1.0000) (growing on:0.2500) (hanging from:0.5645) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7058) (standing on:0.4813) (using:0.5000) (walking in:0.0000) (walking on:0.6351) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2022-10-13 12:32:17 - train.py[line:487] - INFO: 0.6929467787114846
2022-10-13 12:32:17 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 12:32:17 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.292 | loss_v1 0 | loss_v2 0 | nll_loss 0.156 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.692947 | ppl 1.11 | vqa_score 0.5056 | wps 118.5 | wpb 89.9 | bsz 30 | num_updates 2000 | best_R@100 0.692947
2022-10-13 12:32:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2022-10-13 12:32:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-13 12:32:23 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-13 12:32:29 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.6929467787114846) (writing took 11.115655238740146 seconds)
2022-10-13 12:32:40 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=2010, lr=2.17297e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=9881
2022-10-13 12:32:51 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 28910 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.2, ups=0.89, wpb=109.3, bsz=40, num_updates=2020, lr=2.18378e-05, gnorm=0.884, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=9892
2022-10-13 12:33:03 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.3, ups=0.87, wpb=110.3, bsz=40, num_updates=2030, lr=2.19459e-05, gnorm=0.897, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9904
2022-10-13 12:33:14 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.1, ups=0.91, wpb=109.7, bsz=40, num_updates=2040, lr=2.20541e-05, gnorm=0.883, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9915
2022-10-13 12:33:25 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.4, ups=0.9, wpb=109.7, bsz=40, num_updates=2050, lr=2.21622e-05, gnorm=0.937, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9926
2022-10-13 12:33:36 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.2, ups=0.89, wpb=110.7, bsz=40, num_updates=2060, lr=2.22703e-05, gnorm=0.897, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9937
2022-10-13 12:33:47 - progress_bar.py[line:274] - INFO: epoch 001:   2071 / 28910 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97, ups=0.89, wpb=108.5, bsz=40, num_updates=2070, lr=2.23784e-05, gnorm=0.899, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9948
2022-10-13 12:33:58 - progress_bar.py[line:274] - INFO: epoch 001:   2081 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=2080, lr=2.24865e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9960
2022-10-13 12:34:10 - progress_bar.py[line:274] - INFO: epoch 001:   2091 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.7, ups=0.9, wpb=109.8, bsz=40, num_updates=2090, lr=2.25946e-05, gnorm=0.951, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9971
2022-10-13 12:34:21 - progress_bar.py[line:274] - INFO: epoch 001:   2101 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.4, ups=0.9, wpb=111.1, bsz=40, num_updates=2100, lr=2.27027e-05, gnorm=0.876, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9982
2022-10-13 12:34:32 - progress_bar.py[line:274] - INFO: epoch 001:   2111 / 28910 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.5, ups=0.89, wpb=109.7, bsz=40, num_updates=2110, lr=2.28108e-05, gnorm=0.903, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=9993
2022-10-13 12:34:43 - progress_bar.py[line:274] - INFO: epoch 001:   2121 / 28910 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.507, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=95.3, ups=0.88, wpb=108.7, bsz=40, num_updates=2120, lr=2.29189e-05, gnorm=0.885, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10005
2022-10-13 12:34:55 - progress_bar.py[line:274] - INFO: epoch 001:   2131 / 28910 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.3, ups=0.9, wpb=108.8, bsz=40, num_updates=2130, lr=2.3027e-05, gnorm=0.879, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10016
2022-10-13 12:34:58 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 12:35:07 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=87.2, ups=0.8, wpb=109, bsz=40, num_updates=2140, lr=2.31351e-05, gnorm=1.039, clip=40, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=10028
2022-10-13 12:35:18 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 28910 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.8, ups=0.92, wpb=110.1, bsz=40, num_updates=2150, lr=2.32432e-05, gnorm=0.849, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10039
2022-10-13 12:35:29 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 28910 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.4, ups=0.9, wpb=110.2, bsz=40, num_updates=2160, lr=2.33514e-05, gnorm=1.033, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10050
2022-10-13 12:35:40 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.9, ups=0.92, wpb=109.2, bsz=40, num_updates=2170, lr=2.34595e-05, gnorm=0.937, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10061
2022-10-13 12:35:51 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 28910 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.9, ups=0.88, wpb=111.4, bsz=40, num_updates=2180, lr=2.35676e-05, gnorm=0.889, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10073
2022-10-13 12:36:03 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=2190, lr=2.36757e-05, gnorm=0.931, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10084
2022-10-13 12:36:14 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.9, wpb=109.4, bsz=40, num_updates=2200, lr=2.37838e-05, gnorm=0.982, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10095
2022-10-13 12:36:25 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=2210, lr=2.38919e-05, gnorm=0.986, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10106
2022-10-13 12:36:36 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=2220, lr=2.4e-05, gnorm=0.866, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10117
2022-10-13 12:36:48 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.1, ups=0.88, wpb=110.5, bsz=40, num_updates=2230, lr=2.41081e-05, gnorm=0.917, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10129
2022-10-13 12:36:59 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 28910 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=95.1, ups=0.87, wpb=109.2, bsz=40, num_updates=2240, lr=2.42162e-05, gnorm=1.024, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10140
2022-10-13 12:37:10 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 28910 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=2250, lr=2.43243e-05, gnorm=0.934, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10151
2022-10-13 12:37:22 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.5, ups=0.88, wpb=112, bsz=40, num_updates=2260, lr=2.44324e-05, gnorm=1.013, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10163
2022-10-13 12:37:33 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 28910 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.3, ups=0.9, wpb=111.1, bsz=40, num_updates=2270, lr=2.45405e-05, gnorm=0.812, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10174
2022-10-13 12:37:44 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.5, ups=0.89, wpb=111.1, bsz=40, num_updates=2280, lr=2.46486e-05, gnorm=0.878, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10185
2022-10-13 12:37:55 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 28910 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.1, ups=0.91, wpb=110.8, bsz=40, num_updates=2290, lr=2.47568e-05, gnorm=0.793, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10196
2022-10-13 12:38:06 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.5, ups=0.88, wpb=109.4, bsz=40, num_updates=2300, lr=2.48649e-05, gnorm=0.912, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10208
2022-10-13 12:38:17 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.7, ups=0.91, wpb=110.3, bsz=40, num_updates=2310, lr=2.4973e-05, gnorm=0.92, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10219
2022-10-13 12:38:29 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96, ups=0.88, wpb=108.9, bsz=40, num_updates=2320, lr=2.50811e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10230
2022-10-13 12:38:40 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.4, ups=0.89, wpb=109.3, bsz=40, num_updates=2330, lr=2.51892e-05, gnorm=0.999, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10241
2022-10-13 12:38:51 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.2, ups=0.93, wpb=110.4, bsz=40, num_updates=2340, lr=2.52973e-05, gnorm=0.852, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10252
2022-10-13 12:39:02 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.3, ups=0.86, wpb=110.2, bsz=40, num_updates=2350, lr=2.54054e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=10264
2022-10-13 12:39:14 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 28910 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.1, ups=0.88, wpb=109.6, bsz=40, num_updates=2360, lr=2.55135e-05, gnorm=0.886, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10275
2022-10-13 12:39:25 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.1, ups=0.89, wpb=111.2, bsz=40, num_updates=2370, lr=2.56216e-05, gnorm=0.826, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10286
2022-10-13 12:39:36 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.4, ups=0.9, wpb=111.1, bsz=40, num_updates=2380, lr=2.57297e-05, gnorm=0.789, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10297
2022-10-13 12:39:48 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.4, ups=0.88, wpb=110.1, bsz=40, num_updates=2390, lr=2.58378e-05, gnorm=0.997, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10309
2022-10-13 12:39:59 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.3, ups=0.89, wpb=109.5, bsz=40, num_updates=2400, lr=2.59459e-05, gnorm=0.956, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10320
2022-10-13 12:40:10 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 28910 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.1, ups=0.9, wpb=110.2, bsz=40, num_updates=2410, lr=2.60541e-05, gnorm=0.904, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10331
2022-10-13 12:40:21 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 28910 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.9, ups=0.92, wpb=110.2, bsz=40, num_updates=2420, lr=2.61622e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10342
2022-10-13 12:40:32 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=2430, lr=2.62703e-05, gnorm=0.843, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10353
2022-10-13 12:40:43 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 28910 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.9, ups=0.9, wpb=111.9, bsz=40, num_updates=2440, lr=2.63784e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10364
2022-10-13 12:40:54 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.2, ups=0.91, wpb=109.5, bsz=40, num_updates=2450, lr=2.64865e-05, gnorm=0.874, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10375
2022-10-13 12:41:05 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 28910 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102.8, ups=0.93, wpb=110.9, bsz=40, num_updates=2460, lr=2.65946e-05, gnorm=0.98, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10386
2022-10-13 12:41:16 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.2, ups=0.88, wpb=111.8, bsz=40, num_updates=2470, lr=2.67027e-05, gnorm=0.89, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10398
2022-10-13 12:41:28 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 28910 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.9, ups=0.88, wpb=109.5, bsz=40, num_updates=2480, lr=2.68108e-05, gnorm=0.872, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10409
2022-10-13 12:41:39 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 28910 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.8, ups=0.87, wpb=111.5, bsz=40, num_updates=2490, lr=2.69189e-05, gnorm=1.026, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10421
2022-10-13 12:41:51 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 28910 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=2500, lr=2.7027e-05, gnorm=0.852, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10432
2022-10-13 12:42:02 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 28910 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.9, wpb=110.3, bsz=40, num_updates=2510, lr=2.71351e-05, gnorm=0.917, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10443
2022-10-13 12:42:13 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 28910 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.3, ups=0.88, wpb=109.9, bsz=40, num_updates=2520, lr=2.72432e-05, gnorm=0.86, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10454
2022-10-13 12:42:25 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.9, ups=0.87, wpb=110.4, bsz=40, num_updates=2530, lr=2.73514e-05, gnorm=0.869, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10466
2022-10-13 12:42:36 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.4, ups=0.91, wpb=111, bsz=40, num_updates=2540, lr=2.74595e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10477
2022-10-13 12:42:47 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 28910 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.91, wpb=108.7, bsz=40, num_updates=2550, lr=2.75676e-05, gnorm=0.908, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10488
2022-10-13 12:42:58 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.2, ups=0.87, wpb=111.7, bsz=40, num_updates=2560, lr=2.76757e-05, gnorm=0.847, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10499
2022-10-13 12:43:09 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 28910 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=2570, lr=2.77838e-05, gnorm=0.88, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10510
2022-10-13 12:43:21 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.4, ups=0.87, wpb=110, bsz=40, num_updates=2580, lr=2.78919e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10522
2022-10-13 12:43:32 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.3, ups=0.89, wpb=109.8, bsz=40, num_updates=2590, lr=2.8e-05, gnorm=0.834, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10533
2022-10-13 12:43:44 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.3, ups=0.87, wpb=111.2, bsz=40, num_updates=2600, lr=2.81081e-05, gnorm=0.941, clip=50, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=10545
2022-10-13 12:43:55 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.3, ups=0.87, wpb=111.2, bsz=40, num_updates=2610, lr=2.82162e-05, gnorm=0.957, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10556
2022-10-13 12:44:07 - progress_bar.py[line:274] - INFO: epoch 001:   2622 / 28910 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.3, ups=0.88, wpb=111.9, bsz=40, num_updates=2620, lr=2.83243e-05, gnorm=0.876, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10568
2022-10-13 12:44:18 - progress_bar.py[line:274] - INFO: epoch 001:   2632 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=2630, lr=2.84324e-05, gnorm=0.861, clip=10, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=10579
2022-10-13 12:44:29 - progress_bar.py[line:274] - INFO: epoch 001:   2642 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=2640, lr=2.85405e-05, gnorm=0.877, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10590
2022-10-13 12:44:40 - progress_bar.py[line:274] - INFO: epoch 001:   2652 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98, ups=0.89, wpb=110.7, bsz=40, num_updates=2650, lr=2.86486e-05, gnorm=0.866, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10602
2022-10-13 12:44:52 - progress_bar.py[line:274] - INFO: epoch 001:   2662 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=2660, lr=2.87568e-05, gnorm=0.885, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10613
2022-10-13 12:45:02 - progress_bar.py[line:274] - INFO: epoch 001:   2672 / 28910 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.92, wpb=107.3, bsz=40, num_updates=2670, lr=2.88649e-05, gnorm=0.938, clip=40, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10624
2022-10-13 12:45:14 - progress_bar.py[line:274] - INFO: epoch 001:   2682 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.8, ups=0.88, wpb=110.4, bsz=40, num_updates=2680, lr=2.8973e-05, gnorm=0.858, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10635
2022-10-13 12:45:25 - progress_bar.py[line:274] - INFO: epoch 001:   2692 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=2690, lr=2.90811e-05, gnorm=0.974, clip=40, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10646
2022-10-13 12:45:36 - progress_bar.py[line:274] - INFO: epoch 001:   2702 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.5, ups=0.9, wpb=110.7, bsz=40, num_updates=2700, lr=2.91892e-05, gnorm=0.834, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10657
2022-10-13 12:45:48 - progress_bar.py[line:274] - INFO: epoch 001:   2712 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.5, ups=0.88, wpb=110, bsz=40, num_updates=2710, lr=2.92973e-05, gnorm=0.902, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10669
2022-10-13 12:45:52 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 12:46:00 - progress_bar.py[line:274] - INFO: epoch 001:   2723 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=91.2, ups=0.82, wpb=110.6, bsz=40, num_updates=2720, lr=2.94054e-05, gnorm=0.926, clip=40, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=10681
2022-10-13 12:46:12 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 28910 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=92.9, ups=0.86, wpb=108.2, bsz=40, num_updates=2730, lr=2.95135e-05, gnorm=1.057, clip=50, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=10693
2022-10-13 12:46:23 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.3, ups=0.9, wpb=110.5, bsz=40, num_updates=2740, lr=2.96216e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10704
2022-10-13 12:46:34 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 28910 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.9, ups=0.91, wpb=110.1, bsz=40, num_updates=2750, lr=2.97297e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10715
2022-10-13 12:46:45 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97, ups=0.89, wpb=109.6, bsz=40, num_updates=2760, lr=2.98378e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10726
2022-10-13 12:46:56 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=2770, lr=2.99459e-05, gnorm=0.811, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10737
2022-10-13 12:47:07 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=2780, lr=3.00541e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10748
2022-10-13 12:47:18 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.1, ups=0.9, wpb=111.8, bsz=40, num_updates=2790, lr=3.01622e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10759
2022-10-13 12:47:29 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.9, ups=0.9, wpb=111.5, bsz=40, num_updates=2800, lr=3.02703e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=11.5, ema_decay=0.9999, wall=10771
2022-10-13 12:47:41 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.1, ups=0.88, wpb=111.7, bsz=40, num_updates=2810, lr=3.03784e-05, gnorm=0.89, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10782
2022-10-13 12:47:52 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 28910 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.2, ups=0.91, wpb=111.1, bsz=40, num_updates=2820, lr=3.04865e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10793
2022-10-13 12:48:03 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.2, ups=0.9, wpb=110.1, bsz=40, num_updates=2830, lr=3.05946e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10804
2022-10-13 12:48:14 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=2840, lr=3.07027e-05, gnorm=0.947, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10815
2022-10-13 12:48:25 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.3, ups=0.92, wpb=110.4, bsz=40, num_updates=2850, lr=3.08108e-05, gnorm=0.961, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10826
2022-10-13 12:48:36 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.1, ups=0.89, wpb=109, bsz=40, num_updates=2860, lr=3.09189e-05, gnorm=1.04, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10837
2022-10-13 12:48:48 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 28910 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=2870, lr=3.1027e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10849
2022-10-13 12:48:59 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.7, ups=0.87, wpb=110.6, bsz=40, num_updates=2880, lr=3.11351e-05, gnorm=0.884, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10860
2022-10-13 12:49:10 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.89, wpb=109.6, bsz=40, num_updates=2890, lr=3.12432e-05, gnorm=1.135, clip=60, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10872
2022-10-13 12:49:22 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.6, ups=0.89, wpb=111.7, bsz=40, num_updates=2900, lr=3.13514e-05, gnorm=0.917, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10883
2022-10-13 12:49:33 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.8, ups=0.86, wpb=110.9, bsz=40, num_updates=2910, lr=3.14595e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=10894
2022-10-13 12:49:44 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101, ups=0.91, wpb=110.6, bsz=40, num_updates=2920, lr=3.15676e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10905
2022-10-13 12:49:55 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=2930, lr=3.16757e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10916
2022-10-13 12:50:07 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=2940, lr=3.17838e-05, gnorm=1.4, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10928
2022-10-13 12:50:18 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.9, ups=0.89, wpb=111.3, bsz=40, num_updates=2950, lr=3.18919e-05, gnorm=0.957, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10939
2022-10-13 12:50:29 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.4, ups=0.87, wpb=110.2, bsz=40, num_updates=2960, lr=3.2e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10950
2022-10-13 12:50:40 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.4, ups=0.9, wpb=109.3, bsz=40, num_updates=2970, lr=3.21081e-05, gnorm=0.896, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10961
2022-10-13 12:50:51 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 28910 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.1, ups=0.9, wpb=111.1, bsz=40, num_updates=2980, lr=3.22162e-05, gnorm=0.918, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10973
2022-10-13 12:51:03 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 28910 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=2990, lr=3.23243e-05, gnorm=0.794, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10984
2022-10-13 12:51:14 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=3000, lr=3.24324e-05, gnorm=0.91, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10995
2022-10-13 12:51:14 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 12:51:15 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 12:51:15 - train.py[line:551] - INFO: load:1.15 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 12:53:49 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 12:53:49 - train.py[line:551] - INFO: load:1.18 valid_run:154.16 task_valid:151.11 collect_output:1.80
2022-10-13 12:56:19 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 12:56:19 - train.py[line:551] - INFO: load:1.20 valid_run:303.63 task_valid:295.94 collect_output:5.29
2022-10-13 12:58:51 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 12:58:51 - train.py[line:551] - INFO: load:1.22 valid_run:456.10 task_valid:440.05 collect_output:12.57
2022-10-13 13:01:21 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 13:01:21 - train.py[line:551] - INFO: load:1.25 valid_run:605.83 task_valid:586.17 collect_output:15.11
2022-10-13 13:03:54 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 13:03:54 - train.py[line:551] - INFO: load:1.27 valid_run:758.75 task_valid:734.58 collect_output:18.57
2022-10-13 13:06:26 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 13:06:26 - train.py[line:551] - INFO: load:1.30 valid_run:910.96 task_valid:881.16 collect_output:23.11
2022-10-13 13:09:00 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 13:09:00 - train.py[line:551] - INFO: load:1.33 valid_run:1064.38 task_valid:1028.15 collect_output:28.45
2022-10-13 13:11:31 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 13:11:31 - train.py[line:551] - INFO: load:1.35 valid_run:1215.75 task_valid:1170.33 collect_output:36.56
2022-10-13 13:14:02 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 13:14:02 - train.py[line:551] - INFO: load:1.38 valid_run:1366.20 task_valid:1316.39 collect_output:39.85
2022-10-13 13:16:31 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 13:16:31 - train.py[line:551] - INFO: load:1.40 valid_run:1515.19 task_valid:1460.58 collect_output:43.60
2022-10-13 13:19:01 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 13:19:01 - train.py[line:551] - INFO: load:1.43 valid_run:1665.40 task_valid:1606.54 collect_output:46.79
2022-10-13 13:21:32 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 13:21:32 - train.py[line:551] - INFO: load:1.45 valid_run:1816.09 task_valid:1752.53 collect_output:50.40
2022-10-13 13:24:02 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 13:24:02 - train.py[line:551] - INFO: load:1.48 valid_run:1966.21 task_valid:1895.23 collect_output:56.72
2022-10-13 13:26:33 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 13:26:33 - train.py[line:551] - INFO: load:1.50 valid_run:2117.18 task_valid:2041.66 collect_output:60.19
2022-10-13 13:29:04 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 13:29:04 - train.py[line:551] - INFO: load:1.53 valid_run:2267.98 task_valid:2189.09 collect_output:62.47
2022-10-13 13:31:34 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 13:31:34 - train.py[line:551] - INFO: load:1.55 valid_run:2418.37 task_valid:2334.08 collect_output:66.83
2022-10-13 13:34:06 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 13:34:06 - train.py[line:551] - INFO: load:1.57 valid_run:2570.06 task_valid:2480.30 collect_output:71.25
2022-10-13 13:36:38 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 13:36:38 - train.py[line:551] - INFO: load:1.60 valid_run:2721.35 task_valid:2628.39 collect_output:73.38
2022-10-13 13:39:07 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 13:39:07 - train.py[line:551] - INFO: load:1.62 valid_run:2870.43 task_valid:2771.34 collect_output:78.35
2022-10-13 13:41:38 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 13:41:38 - train.py[line:551] - INFO: load:1.65 valid_run:3021.68 task_valid:2918.02 collect_output:81.74
2022-10-13 13:44:10 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 13:44:10 - train.py[line:551] - INFO: load:1.68 valid_run:3174.08 task_valid:3064.05 collect_output:86.92
2022-10-13 13:46:41 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 13:46:41 - train.py[line:551] - INFO: load:1.70 valid_run:3324.62 task_valid:3210.13 collect_output:90.21
2022-10-13 13:49:13 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 13:49:13 - train.py[line:551] - INFO: load:1.73 valid_run:3476.90 task_valid:3357.91 collect_output:93.50
2022-10-13 13:51:46 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 13:51:46 - train.py[line:551] - INFO: load:1.75 valid_run:3629.30 task_valid:3505.84 collect_output:96.80

====================================================================================================
SGG eval:     R @ 50: 0.6627;     R @ 100: 0.7004;     R @ 500: 0.7286;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4482;    mR @ 100: 0.4995;    mR @ 500: 0.5348;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.5143) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:1.0000) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7066) (standing on:0.5213) (using:0.5500) (walking in:0.0000) (walking on:0.6216) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6627;     R @ 100: 0.7004;     R @ 500: 0.7286;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4482;    mR @ 100: 0.4995;    mR @ 500: 0.5348;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.5143) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:1.0000) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7066) (standing on:0.5213) (using:0.5500) (walking in:0.0000) (walking on:0.6216) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2022-10-13 13:54:19 - train.py[line:487] - INFO: 0.7003831423478482
2022-10-13 13:54:19 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 13:54:19 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.419 | loss_v1 0 | loss_v2 0 | nll_loss 0.306 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.700383 | ppl 1.24 | vqa_score 0.5068 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 3000 | best_R@100 0.700383
2022-10-13 13:54:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3000 updates
2022-10-13 13:54:19 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-13 13:54:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-13 13:54:30 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 0.7003831423478482) (writing took 11.632307102903724 seconds)
2022-10-13 13:54:41 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=3010, lr=3.25405e-05, gnorm=1.002, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14802
2022-10-13 13:54:53 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=3020, lr=3.26486e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14814
2022-10-13 13:55:04 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.2, ups=0.91, wpb=111.5, bsz=40, num_updates=3030, lr=3.27568e-05, gnorm=0.913, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14825
2022-10-13 13:55:15 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 28910 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97, ups=0.89, wpb=109, bsz=40, num_updates=3040, lr=3.28649e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14836
2022-10-13 13:55:26 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.6, ups=0.91, wpb=110.5, bsz=40, num_updates=3050, lr=3.2973e-05, gnorm=0.902, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14847
2022-10-13 13:55:37 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.1, ups=0.89, wpb=111.4, bsz=40, num_updates=3060, lr=3.30811e-05, gnorm=0.952, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14858
2022-10-13 13:55:48 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.2, ups=0.91, wpb=109.5, bsz=40, num_updates=3070, lr=3.31892e-05, gnorm=1.097, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14869
2022-10-13 13:55:59 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=3080, lr=3.32973e-05, gnorm=1.017, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14880
2022-10-13 13:56:10 - progress_bar.py[line:274] - INFO: epoch 001:   3093 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.2, ups=0.9, wpb=110.1, bsz=40, num_updates=3090, lr=3.34054e-05, gnorm=0.837, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14891
2022-10-13 13:56:21 - progress_bar.py[line:274] - INFO: epoch 001:   3103 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.5, ups=0.9, wpb=109.7, bsz=40, num_updates=3100, lr=3.35135e-05, gnorm=1.006, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14903
2022-10-13 13:56:33 - progress_bar.py[line:274] - INFO: epoch 001:   3113 / 28910 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.2, ups=0.89, wpb=109, bsz=40, num_updates=3110, lr=3.36216e-05, gnorm=0.842, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=14914
2022-10-13 13:56:44 - progress_bar.py[line:274] - INFO: epoch 001:   3123 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.1, ups=0.86, wpb=111.1, bsz=40, num_updates=3120, lr=3.37297e-05, gnorm=0.936, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=14925
2022-10-13 13:56:55 - progress_bar.py[line:274] - INFO: epoch 001:   3133 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=103, ups=0.93, wpb=111.2, bsz=40, num_updates=3130, lr=3.38378e-05, gnorm=0.814, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14936
2022-10-13 13:57:06 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=3140, lr=3.39459e-05, gnorm=0.892, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14948
2022-10-13 13:57:17 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.6, ups=0.91, wpb=109.9, bsz=40, num_updates=3150, lr=3.40541e-05, gnorm=0.969, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14959
2022-10-13 13:57:29 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 28910 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.7, ups=0.87, wpb=109.5, bsz=40, num_updates=3160, lr=3.41622e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14970
2022-10-13 13:57:40 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.2, ups=0.9, wpb=110.2, bsz=40, num_updates=3170, lr=3.42703e-05, gnorm=0.948, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14981
2022-10-13 13:57:51 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=3180, lr=3.43784e-05, gnorm=0.979, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14993
2022-10-13 13:58:03 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=3190, lr=3.44865e-05, gnorm=1.005, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15004
2022-10-13 13:58:14 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.6, ups=0.91, wpb=109.6, bsz=40, num_updates=3200, lr=3.45946e-05, gnorm=0.981, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15015
2022-10-13 13:58:25 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 28910 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.9, ups=0.88, wpb=109.4, bsz=40, num_updates=3210, lr=3.47027e-05, gnorm=1.074, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15026
2022-10-13 13:58:36 - progress_bar.py[line:274] - INFO: epoch 001:   3223 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.2, ups=0.89, wpb=108.4, bsz=40, num_updates=3220, lr=3.48108e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15037
2022-10-13 13:58:47 - progress_bar.py[line:274] - INFO: epoch 001:   3233 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.6, ups=0.9, wpb=111.7, bsz=40, num_updates=3230, lr=3.49189e-05, gnorm=0.895, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15049
2022-10-13 13:58:59 - progress_bar.py[line:274] - INFO: epoch 001:   3243 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.3, ups=0.89, wpb=109.3, bsz=40, num_updates=3240, lr=3.5027e-05, gnorm=0.941, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15060
2022-10-13 13:59:10 - progress_bar.py[line:274] - INFO: epoch 001:   3253 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.8, ups=0.89, wpb=110.2, bsz=40, num_updates=3250, lr=3.51351e-05, gnorm=0.932, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15071
2022-10-13 13:59:21 - progress_bar.py[line:274] - INFO: epoch 001:   3263 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.8, ups=0.88, wpb=109.3, bsz=40, num_updates=3260, lr=3.52432e-05, gnorm=0.95, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15083
2022-10-13 13:59:32 - progress_bar.py[line:274] - INFO: epoch 001:   3273 / 28910 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100, ups=0.91, wpb=109.8, bsz=40, num_updates=3270, lr=3.53514e-05, gnorm=1.055, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15093
2022-10-13 13:59:44 - progress_bar.py[line:274] - INFO: epoch 001:   3283 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.6, ups=0.89, wpb=109.9, bsz=40, num_updates=3280, lr=3.54595e-05, gnorm=0.821, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15105
2022-10-13 13:59:54 - progress_bar.py[line:274] - INFO: epoch 001:   3293 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=103.2, ups=0.94, wpb=109.5, bsz=40, num_updates=3290, lr=3.55676e-05, gnorm=0.77, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15115
2022-10-13 14:00:05 - progress_bar.py[line:274] - INFO: epoch 001:   3303 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=3300, lr=3.56757e-05, gnorm=0.934, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15126
2022-10-13 14:00:16 - progress_bar.py[line:274] - INFO: epoch 001:   3313 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=3310, lr=3.57838e-05, gnorm=1.045, clip=60, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15138
2022-10-13 14:00:28 - progress_bar.py[line:274] - INFO: epoch 001:   3323 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.3, ups=0.89, wpb=110.7, bsz=40, num_updates=3320, lr=3.58919e-05, gnorm=0.853, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15149
2022-10-13 14:00:39 - progress_bar.py[line:274] - INFO: epoch 001:   3333 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.1, ups=0.9, wpb=111.1, bsz=40, num_updates=3330, lr=3.6e-05, gnorm=0.914, clip=30, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=15160
2022-10-13 14:00:50 - progress_bar.py[line:274] - INFO: epoch 001:   3343 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.9, ups=0.88, wpb=109.4, bsz=40, num_updates=3340, lr=3.61081e-05, gnorm=1.058, clip=70, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15171
2022-10-13 14:01:02 - progress_bar.py[line:274] - INFO: epoch 001:   3353 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.6, ups=0.87, wpb=111.3, bsz=40, num_updates=3350, lr=3.62162e-05, gnorm=1.02, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15183
2022-10-13 14:01:13 - progress_bar.py[line:274] - INFO: epoch 001:   3363 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.8, ups=0.9, wpb=111.5, bsz=40, num_updates=3360, lr=3.63243e-05, gnorm=1.019, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15194
2022-10-13 14:01:24 - progress_bar.py[line:274] - INFO: epoch 001:   3373 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=3370, lr=3.64324e-05, gnorm=0.856, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15205
2022-10-13 14:01:35 - progress_bar.py[line:274] - INFO: epoch 001:   3383 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.6, ups=0.9, wpb=108.6, bsz=40, num_updates=3380, lr=3.65405e-05, gnorm=0.974, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15216
2022-10-13 14:01:46 - progress_bar.py[line:274] - INFO: epoch 001:   3393 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.2, ups=0.89, wpb=111.4, bsz=40, num_updates=3390, lr=3.66486e-05, gnorm=0.819, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15227
2022-10-13 14:01:58 - progress_bar.py[line:274] - INFO: epoch 001:   3403 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.1, ups=0.89, wpb=109.6, bsz=40, num_updates=3400, lr=3.67568e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15239
2022-10-13 14:02:09 - progress_bar.py[line:274] - INFO: epoch 001:   3413 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.9, ups=0.9, wpb=111.9, bsz=40, num_updates=3410, lr=3.68649e-05, gnorm=0.995, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15250
2022-10-13 14:02:20 - progress_bar.py[line:274] - INFO: epoch 001:   3423 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.5, ups=0.89, wpb=109.5, bsz=40, num_updates=3420, lr=3.6973e-05, gnorm=0.973, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15261
2022-10-13 14:02:31 - progress_bar.py[line:274] - INFO: epoch 001:   3433 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=3430, lr=3.70811e-05, gnorm=0.871, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15272
2022-10-13 14:02:42 - progress_bar.py[line:274] - INFO: epoch 001:   3443 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=3440, lr=3.71892e-05, gnorm=0.919, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15283
2022-10-13 14:02:54 - progress_bar.py[line:274] - INFO: epoch 001:   3453 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.5, ups=0.87, wpb=109.5, bsz=40, num_updates=3450, lr=3.72973e-05, gnorm=0.892, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15295
2022-10-13 14:03:05 - progress_bar.py[line:274] - INFO: epoch 001:   3463 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101, ups=0.91, wpb=110.6, bsz=40, num_updates=3460, lr=3.74054e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15306
2022-10-13 14:03:16 - progress_bar.py[line:274] - INFO: epoch 001:   3473 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=3470, lr=3.75135e-05, gnorm=0.987, clip=40, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=15317
2022-10-13 14:03:27 - progress_bar.py[line:274] - INFO: epoch 001:   3483 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.1, ups=0.91, wpb=112.3, bsz=40, num_updates=3480, lr=3.76216e-05, gnorm=0.824, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15328
2022-10-13 14:03:39 - progress_bar.py[line:274] - INFO: epoch 001:   3493 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.1, ups=0.87, wpb=110.9, bsz=40, num_updates=3490, lr=3.77297e-05, gnorm=0.787, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15340
2022-10-13 14:03:50 - progress_bar.py[line:274] - INFO: epoch 001:   3503 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.2, ups=0.9, wpb=109.2, bsz=40, num_updates=3500, lr=3.78378e-05, gnorm=0.969, clip=60, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=15351
2022-10-13 14:04:01 - progress_bar.py[line:274] - INFO: epoch 001:   3513 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.2, ups=0.89, wpb=109.5, bsz=40, num_updates=3510, lr=3.79459e-05, gnorm=0.942, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15362
2022-10-13 14:04:12 - progress_bar.py[line:274] - INFO: epoch 001:   3523 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.5, ups=0.89, wpb=108.8, bsz=40, num_updates=3520, lr=3.80541e-05, gnorm=0.909, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15373
2022-10-13 14:04:23 - progress_bar.py[line:274] - INFO: epoch 001:   3533 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.7, ups=0.91, wpb=110.3, bsz=40, num_updates=3530, lr=3.81622e-05, gnorm=0.966, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15384
2022-10-13 14:04:29 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 14:04:35 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=89.4, ups=0.82, wpb=109.2, bsz=40, num_updates=3540, lr=3.82703e-05, gnorm=1.022, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=15397
2022-10-13 14:04:47 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.9, ups=0.87, wpb=110.8, bsz=40, num_updates=3550, lr=3.83784e-05, gnorm=1.119, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15408
2022-10-13 14:04:58 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.9, wpb=110.5, bsz=40, num_updates=3560, lr=3.84865e-05, gnorm=0.886, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15419
2022-10-13 14:05:09 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.6, ups=0.88, wpb=111.2, bsz=40, num_updates=3570, lr=3.85946e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15431
2022-10-13 14:05:21 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=3580, lr=3.87027e-05, gnorm=0.88, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15442
2022-10-13 14:05:32 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=3590, lr=3.88108e-05, gnorm=1.007, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15453
2022-10-13 14:05:44 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=94.9, ups=0.86, wpb=109.9, bsz=40, num_updates=3600, lr=3.89189e-05, gnorm=0.925, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=15465
2022-10-13 14:05:55 - progress_bar.py[line:274] - INFO: epoch 001:   3614 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.1, ups=0.9, wpb=110.1, bsz=40, num_updates=3610, lr=3.9027e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15476
2022-10-13 14:06:06 - progress_bar.py[line:274] - INFO: epoch 001:   3624 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.5, ups=0.88, wpb=109, bsz=40, num_updates=3620, lr=3.91351e-05, gnorm=0.915, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15487
2022-10-13 14:06:17 - progress_bar.py[line:274] - INFO: epoch 001:   3634 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=3630, lr=3.92432e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15498
2022-10-13 14:06:29 - progress_bar.py[line:274] - INFO: epoch 001:   3644 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.8, ups=0.87, wpb=112.2, bsz=40, num_updates=3640, lr=3.93514e-05, gnorm=0.828, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15510
2022-10-13 14:06:40 - progress_bar.py[line:274] - INFO: epoch 001:   3654 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.6, ups=0.89, wpb=111.7, bsz=40, num_updates=3650, lr=3.94595e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15521
2022-10-13 14:06:51 - progress_bar.py[line:274] - INFO: epoch 001:   3664 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.6, ups=0.9, wpb=111.4, bsz=40, num_updates=3660, lr=3.95676e-05, gnorm=0.853, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15532
2022-10-13 14:07:02 - progress_bar.py[line:274] - INFO: epoch 001:   3674 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.9, ups=0.88, wpb=110.5, bsz=40, num_updates=3670, lr=3.96757e-05, gnorm=0.855, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15544
2022-10-13 14:07:14 - progress_bar.py[line:274] - INFO: epoch 001:   3684 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.1, ups=0.87, wpb=110, bsz=40, num_updates=3680, lr=3.97838e-05, gnorm=0.972, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15555
2022-10-13 14:07:25 - progress_bar.py[line:274] - INFO: epoch 001:   3694 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=3690, lr=3.98919e-05, gnorm=0.965, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15566
2022-10-13 14:07:36 - progress_bar.py[line:274] - INFO: epoch 001:   3704 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.3, ups=0.91, wpb=110.6, bsz=40, num_updates=3700, lr=4e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15577
2022-10-13 14:07:48 - progress_bar.py[line:274] - INFO: epoch 001:   3714 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.1, ups=0.87, wpb=110.6, bsz=40, num_updates=3710, lr=4.01081e-05, gnorm=0.857, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15589
2022-10-13 14:07:59 - progress_bar.py[line:274] - INFO: epoch 001:   3724 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=3720, lr=4.02162e-05, gnorm=0.809, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15600
2022-10-13 14:08:10 - progress_bar.py[line:274] - INFO: epoch 001:   3734 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.6, ups=0.89, wpb=110.3, bsz=40, num_updates=3730, lr=4.03243e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15611
2022-10-13 14:08:21 - progress_bar.py[line:274] - INFO: epoch 001:   3744 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.6, ups=0.91, wpb=111.1, bsz=40, num_updates=3740, lr=4.04324e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15622
2022-10-13 14:08:32 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.2, ups=0.89, wpb=110.7, bsz=40, num_updates=3750, lr=4.05405e-05, gnorm=0.811, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15633
2022-10-13 14:08:44 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.6, ups=0.87, wpb=109.6, bsz=40, num_updates=3760, lr=4.06486e-05, gnorm=0.838, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15645
2022-10-13 14:08:55 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=3770, lr=4.07568e-05, gnorm=0.842, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15656
2022-10-13 14:09:06 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=3780, lr=4.08649e-05, gnorm=0.978, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15667
2022-10-13 14:09:18 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=3790, lr=4.0973e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15679
2022-10-13 14:09:29 - progress_bar.py[line:274] - INFO: epoch 001:   3804 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.4, ups=0.91, wpb=111.2, bsz=40, num_updates=3800, lr=4.10811e-05, gnorm=0.824, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15690
2022-10-13 14:09:40 - progress_bar.py[line:274] - INFO: epoch 001:   3814 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.8, ups=0.88, wpb=109, bsz=40, num_updates=3810, lr=4.11892e-05, gnorm=1.083, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15701
2022-10-13 14:09:51 - progress_bar.py[line:274] - INFO: epoch 001:   3824 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.5, ups=0.93, wpb=110.8, bsz=40, num_updates=3820, lr=4.12973e-05, gnorm=1.008, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15712
2022-10-13 14:10:02 - progress_bar.py[line:274] - INFO: epoch 001:   3834 / 28910 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=3830, lr=4.14054e-05, gnorm=0.98, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15723
2022-10-13 14:10:14 - progress_bar.py[line:274] - INFO: epoch 001:   3844 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.7, ups=0.87, wpb=110.2, bsz=40, num_updates=3840, lr=4.15135e-05, gnorm=0.845, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15735
2022-10-13 14:10:25 - progress_bar.py[line:274] - INFO: epoch 001:   3854 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=3850, lr=4.16216e-05, gnorm=1.066, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15746
2022-10-13 14:10:36 - progress_bar.py[line:274] - INFO: epoch 001:   3864 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.4, ups=0.9, wpb=109.3, bsz=40, num_updates=3860, lr=4.17297e-05, gnorm=0.908, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15757
2022-10-13 14:10:47 - progress_bar.py[line:274] - INFO: epoch 001:   3874 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=3870, lr=4.18378e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15768
2022-10-13 14:10:58 - progress_bar.py[line:274] - INFO: epoch 001:   3884 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.4, ups=0.9, wpb=109.8, bsz=40, num_updates=3880, lr=4.19459e-05, gnorm=0.885, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15780
2022-10-13 14:11:10 - progress_bar.py[line:274] - INFO: epoch 001:   3894 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.5, ups=0.89, wpb=112.7, bsz=40, num_updates=3890, lr=4.20541e-05, gnorm=0.926, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15791
2022-10-13 14:11:21 - progress_bar.py[line:274] - INFO: epoch 001:   3904 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.9, ups=0.88, wpb=110.1, bsz=40, num_updates=3900, lr=4.21622e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15802
2022-10-13 14:11:32 - progress_bar.py[line:274] - INFO: epoch 001:   3914 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.6, ups=0.9, wpb=109.5, bsz=40, num_updates=3910, lr=4.22703e-05, gnorm=0.943, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15813
2022-10-13 14:11:43 - progress_bar.py[line:274] - INFO: epoch 001:   3924 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=102.7, ups=0.93, wpb=110.9, bsz=40, num_updates=3920, lr=4.23784e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15824
2022-10-13 14:11:54 - progress_bar.py[line:274] - INFO: epoch 001:   3934 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.6, ups=0.88, wpb=110, bsz=40, num_updates=3930, lr=4.24865e-05, gnorm=0.839, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15835
2022-10-13 14:12:05 - progress_bar.py[line:274] - INFO: epoch 001:   3944 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101, ups=0.9, wpb=112.1, bsz=40, num_updates=3940, lr=4.25946e-05, gnorm=0.787, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15847
2022-10-13 14:12:16 - progress_bar.py[line:274] - INFO: epoch 001:   3954 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.7, ups=0.93, wpb=110.9, bsz=40, num_updates=3950, lr=4.27027e-05, gnorm=0.961, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15857
2022-10-13 14:12:27 - progress_bar.py[line:274] - INFO: epoch 001:   3964 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.8, ups=0.94, wpb=109.2, bsz=40, num_updates=3960, lr=4.28108e-05, gnorm=0.936, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15868
2022-10-13 14:12:38 - progress_bar.py[line:274] - INFO: epoch 001:   3974 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=3970, lr=4.29189e-05, gnorm=0.969, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15879
2022-10-13 14:12:49 - progress_bar.py[line:274] - INFO: epoch 001:   3984 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.3, ups=0.89, wpb=108.7, bsz=40, num_updates=3980, lr=4.3027e-05, gnorm=0.855, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15891
2022-10-13 14:13:01 - progress_bar.py[line:274] - INFO: epoch 001:   3994 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.9, ups=0.89, wpb=110.5, bsz=40, num_updates=3990, lr=4.31351e-05, gnorm=0.949, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15902
2022-10-13 14:13:12 - progress_bar.py[line:274] - INFO: epoch 001:   4004 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.7, ups=0.93, wpb=109.8, bsz=40, num_updates=4000, lr=4.32432e-05, gnorm=0.911, clip=20, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=15913
2022-10-13 14:13:12 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 14:13:13 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 14:13:13 - train.py[line:551] - INFO: load:1.12 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 14:15:46 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 14:15:46 - train.py[line:551] - INFO: load:1.14 valid_run:152.93 task_valid:149.79 collect_output:2.08
2022-10-13 14:18:15 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 14:18:15 - train.py[line:551] - INFO: load:1.17 valid_run:301.83 task_valid:294.01 collect_output:5.66
2022-10-13 14:20:48 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 14:20:48 - train.py[line:551] - INFO: load:1.19 valid_run:454.55 task_valid:438.03 collect_output:13.29
2022-10-13 14:23:17 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 14:23:17 - train.py[line:551] - INFO: load:1.22 valid_run:604.13 task_valid:583.78 collect_output:16.07
2022-10-13 14:25:50 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 14:25:50 - train.py[line:551] - INFO: load:1.24 valid_run:757.19 task_valid:732.39 collect_output:19.41
2022-10-13 14:28:22 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 14:28:22 - train.py[line:551] - INFO: load:1.27 valid_run:909.01 task_valid:878.51 collect_output:24.08
2022-10-13 14:30:56 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 14:30:56 - train.py[line:551] - INFO: load:1.29 valid_run:1062.37 task_valid:1025.34 collect_output:29.56
2022-10-13 14:33:27 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 14:33:27 - train.py[line:551] - INFO: load:1.32 valid_run:1213.55 task_valid:1167.42 collect_output:37.61
2022-10-13 14:35:57 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 14:35:57 - train.py[line:551] - INFO: load:1.34 valid_run:1363.46 task_valid:1312.90 collect_output:40.99
2022-10-13 14:38:26 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 14:38:26 - train.py[line:551] - INFO: load:1.37 valid_run:1512.36 task_valid:1456.78 collect_output:44.94
2022-10-13 14:40:56 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 14:40:56 - train.py[line:551] - INFO: load:1.39 valid_run:1662.59 task_valid:1602.65 collect_output:48.23
2022-10-13 14:43:27 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 14:43:27 - train.py[line:551] - INFO: load:1.42 valid_run:1813.06 task_valid:1748.52 collect_output:51.74
2022-10-13 14:45:57 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 14:45:57 - train.py[line:551] - INFO: load:1.44 valid_run:1963.10 task_valid:1891.15 collect_output:58.06
2022-10-13 14:48:28 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 14:48:28 - train.py[line:551] - INFO: load:1.47 valid_run:2114.11 task_valid:2037.55 collect_output:61.57
2022-10-13 14:50:59 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 14:50:59 - train.py[line:551] - INFO: load:1.49 valid_run:2265.01 task_valid:2185.08 collect_output:63.89
2022-10-13 14:53:30 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 14:53:30 - train.py[line:551] - INFO: load:1.52 valid_run:2415.86 task_valid:2330.73 collect_output:67.97
2022-10-13 14:56:02 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 14:56:02 - train.py[line:551] - INFO: load:1.54 valid_run:2568.33 task_valid:2478.07 collect_output:71.89
2022-10-13 14:58:35 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 14:58:35 - train.py[line:551] - INFO: load:1.57 valid_run:2720.56 task_valid:2627.18 collect_output:73.80
2022-10-13 15:01:04 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 15:01:04 - train.py[line:551] - INFO: load:1.60 valid_run:2870.03 task_valid:2770.53 collect_output:78.69
2022-10-13 15:03:36 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 15:03:36 - train.py[line:551] - INFO: load:1.62 valid_run:3021.51 task_valid:2917.57 collect_output:81.87
2022-10-13 15:06:08 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 15:06:08 - train.py[line:551] - INFO: load:1.65 valid_run:3174.14 task_valid:3064.30 collect_output:86.59
2022-10-13 15:08:39 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 15:08:39 - train.py[line:551] - INFO: load:1.67 valid_run:3325.12 task_valid:3210.99 collect_output:89.61
2022-10-13 15:11:12 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 15:11:12 - train.py[line:551] - INFO: load:1.70 valid_run:3477.41 task_valid:3358.98 collect_output:92.76
2022-10-13 15:13:44 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 15:13:44 - train.py[line:551] - INFO: load:1.73 valid_run:3629.82 task_valid:3507.04 collect_output:95.98

====================================================================================================
SGG eval:     R @ 50: 0.6713;     R @ 100: 0.7041;     R @ 500: 0.7298;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4446;    mR @ 100: 0.4887;    mR @ 500: 0.5267;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.3714) (eating:0.7647) (flying in:0.8182) (growing on:0.2500) (hanging from:0.4355) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:1.0000) (playing:0.0000) (riding:0.9523) (says:0.0000) (sitting on:0.7372) (standing on:0.5263) (using:0.5500) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6713;     R @ 100: 0.7041;     R @ 500: 0.7298;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4446;    mR @ 100: 0.4887;    mR @ 500: 0.5267;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.3714) (eating:0.7647) (flying in:0.8182) (growing on:0.2500) (hanging from:0.4355) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:1.0000) (playing:0.0000) (riding:0.9523) (says:0.0000) (sitting on:0.7372) (standing on:0.5263) (using:0.5500) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-13 15:16:17 - train.py[line:487] - INFO: 0.7040528393175453
2022-10-13 15:16:17 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 15:16:17 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.372 | loss_v1 0 | loss_v2 0 | nll_loss 0.247 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.704053 | ppl 1.19 | vqa_score 0.5124 | wps 118.5 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.704053
2022-10-13 15:16:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2022-10-13 15:16:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-13 15:16:23 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-13 15:16:30 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.7040528393175453) (writing took 13.085651556961238 seconds)
2022-10-13 15:16:42 - progress_bar.py[line:274] - INFO: epoch 001:   4014 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=0.3, ups=0, wpb=109, bsz=40, num_updates=4010, lr=4.33514e-05, gnorm=0.944, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19723
2022-10-13 15:16:53 - progress_bar.py[line:274] - INFO: epoch 001:   4024 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.6, ups=0.9, wpb=110.7, bsz=40, num_updates=4020, lr=4.34595e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19734
2022-10-13 15:17:04 - progress_bar.py[line:274] - INFO: epoch 001:   4034 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.6, ups=0.9, wpb=111.4, bsz=40, num_updates=4030, lr=4.35676e-05, gnorm=1.027, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19745
2022-10-13 15:17:15 - progress_bar.py[line:274] - INFO: epoch 001:   4044 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.1, ups=0.87, wpb=111, bsz=40, num_updates=4040, lr=4.36757e-05, gnorm=0.814, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19756
2022-10-13 15:17:26 - progress_bar.py[line:274] - INFO: epoch 001:   4054 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=102.6, ups=0.92, wpb=111.2, bsz=40, num_updates=4050, lr=4.37838e-05, gnorm=0.81, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19767
2022-10-13 15:17:37 - progress_bar.py[line:274] - INFO: epoch 001:   4064 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.9, ups=0.91, wpb=109.8, bsz=40, num_updates=4060, lr=4.38919e-05, gnorm=0.871, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19778
2022-10-13 15:17:48 - progress_bar.py[line:274] - INFO: epoch 001:   4074 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=4070, lr=4.4e-05, gnorm=0.969, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19789
2022-10-13 15:17:59 - progress_bar.py[line:274] - INFO: epoch 001:   4084 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.1, ups=0.9, wpb=110.2, bsz=40, num_updates=4080, lr=4.41081e-05, gnorm=0.938, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19800
2022-10-13 15:18:11 - progress_bar.py[line:274] - INFO: epoch 001:   4094 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.5, ups=0.88, wpb=109.9, bsz=40, num_updates=4090, lr=4.42162e-05, gnorm=0.897, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19812
2022-10-13 15:18:22 - progress_bar.py[line:274] - INFO: epoch 001:   4104 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.9, ups=0.89, wpb=110.1, bsz=40, num_updates=4100, lr=4.43243e-05, gnorm=1.013, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19823
2022-10-13 15:18:33 - progress_bar.py[line:274] - INFO: epoch 001:   4114 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.6, ups=0.91, wpb=110, bsz=40, num_updates=4110, lr=4.44324e-05, gnorm=0.961, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19834
2022-10-13 15:18:44 - progress_bar.py[line:274] - INFO: epoch 001:   4124 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.6, ups=0.88, wpb=109.5, bsz=40, num_updates=4120, lr=4.45405e-05, gnorm=0.967, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=19845
2022-10-13 15:18:55 - progress_bar.py[line:274] - INFO: epoch 001:   4134 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=4130, lr=4.46486e-05, gnorm=0.931, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19857
2022-10-13 15:19:06 - progress_bar.py[line:274] - INFO: epoch 001:   4144 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=102.1, ups=0.93, wpb=110, bsz=40, num_updates=4140, lr=4.47568e-05, gnorm=0.884, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19867
2022-10-13 15:19:17 - progress_bar.py[line:274] - INFO: epoch 001:   4154 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.1, ups=0.91, wpb=110.7, bsz=40, num_updates=4150, lr=4.48649e-05, gnorm=0.867, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19878
2022-10-13 15:19:28 - progress_bar.py[line:274] - INFO: epoch 001:   4164 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=4160, lr=4.4973e-05, gnorm=1.014, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19889
2022-10-13 15:19:40 - progress_bar.py[line:274] - INFO: epoch 001:   4174 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97, ups=0.89, wpb=109.2, bsz=40, num_updates=4170, lr=4.50811e-05, gnorm=1.033, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19901
2022-10-13 15:19:51 - progress_bar.py[line:274] - INFO: epoch 001:   4184 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.4, ups=0.89, wpb=110, bsz=40, num_updates=4180, lr=4.51892e-05, gnorm=0.877, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19912
2022-10-13 15:20:02 - progress_bar.py[line:274] - INFO: epoch 001:   4194 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.1, ups=0.89, wpb=111.5, bsz=40, num_updates=4190, lr=4.52973e-05, gnorm=0.793, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19923
2022-10-13 15:20:13 - progress_bar.py[line:274] - INFO: epoch 001:   4204 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=4200, lr=4.54054e-05, gnorm=0.83, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19935
2022-10-13 15:20:21 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 15:20:26 - progress_bar.py[line:274] - INFO: epoch 001:   4215 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=89.8, ups=0.82, wpb=110, bsz=40, num_updates=4210, lr=4.55135e-05, gnorm=0.938, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19947
2022-10-13 15:20:37 - progress_bar.py[line:274] - INFO: epoch 001:   4225 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101, ups=0.91, wpb=110.9, bsz=40, num_updates=4220, lr=4.56216e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=19958
2022-10-13 15:20:48 - progress_bar.py[line:274] - INFO: epoch 001:   4235 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.1, ups=0.89, wpb=110.3, bsz=40, num_updates=4230, lr=4.57297e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19969
2022-10-13 15:20:59 - progress_bar.py[line:274] - INFO: epoch 001:   4245 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.9, wpb=111.3, bsz=40, num_updates=4240, lr=4.58378e-05, gnorm=0.902, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19980
2022-10-13 15:21:10 - progress_bar.py[line:274] - INFO: epoch 001:   4255 / 28910 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=4250, lr=4.59459e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19991
2022-10-13 15:21:21 - progress_bar.py[line:274] - INFO: epoch 001:   4265 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.4, ups=0.89, wpb=112, bsz=40, num_updates=4260, lr=4.60541e-05, gnorm=0.871, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20003
2022-10-13 15:21:33 - progress_bar.py[line:274] - INFO: epoch 001:   4275 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.7, ups=0.89, wpb=109.3, bsz=40, num_updates=4270, lr=4.61622e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20014
2022-10-13 15:21:44 - progress_bar.py[line:274] - INFO: epoch 001:   4285 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.8, ups=0.9, wpb=108.4, bsz=40, num_updates=4280, lr=4.62703e-05, gnorm=1.046, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20025
2022-10-13 15:21:54 - progress_bar.py[line:274] - INFO: epoch 001:   4295 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=103.8, ups=0.94, wpb=110.9, bsz=40, num_updates=4290, lr=4.63784e-05, gnorm=0.937, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20036
2022-10-13 15:22:06 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=4300, lr=4.64865e-05, gnorm=0.918, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20047
2022-10-13 15:22:17 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.1, ups=0.89, wpb=111.3, bsz=40, num_updates=4310, lr=4.65946e-05, gnorm=0.897, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20058
2022-10-13 15:22:28 - progress_bar.py[line:274] - INFO: epoch 001:   4325 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.7, ups=0.87, wpb=110.2, bsz=40, num_updates=4320, lr=4.67027e-05, gnorm=0.968, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20070
2022-10-13 15:22:40 - progress_bar.py[line:274] - INFO: epoch 001:   4335 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96, ups=0.88, wpb=109, bsz=40, num_updates=4330, lr=4.68108e-05, gnorm=0.901, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20081
2022-10-13 15:22:51 - progress_bar.py[line:274] - INFO: epoch 001:   4345 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.4, ups=0.88, wpb=110.9, bsz=40, num_updates=4340, lr=4.69189e-05, gnorm=1.138, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20092
2022-10-13 15:23:02 - progress_bar.py[line:274] - INFO: epoch 001:   4355 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101.9, ups=0.91, wpb=111.5, bsz=40, num_updates=4350, lr=4.7027e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20103
2022-10-13 15:23:13 - progress_bar.py[line:274] - INFO: epoch 001:   4365 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=4360, lr=4.71351e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20114
2022-10-13 15:23:24 - progress_bar.py[line:274] - INFO: epoch 001:   4375 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=4370, lr=4.72432e-05, gnorm=0.908, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20126
2022-10-13 15:23:36 - progress_bar.py[line:274] - INFO: epoch 001:   4385 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.6, ups=0.88, wpb=110.7, bsz=40, num_updates=4380, lr=4.73514e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20137
2022-10-13 15:23:47 - progress_bar.py[line:274] - INFO: epoch 001:   4395 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=4390, lr=4.74595e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=20148
2022-10-13 15:23:57 - progress_bar.py[line:274] - INFO: epoch 001:   4405 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=106.2, ups=0.96, wpb=110.9, bsz=40, num_updates=4400, lr=4.75676e-05, gnorm=0.885, clip=30, loss_scale=512, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=20159
2022-10-13 15:24:09 - progress_bar.py[line:274] - INFO: epoch 001:   4415 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=4410, lr=4.76757e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20170
2022-10-13 15:24:20 - progress_bar.py[line:274] - INFO: epoch 001:   4425 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.8, ups=0.89, wpb=112, bsz=40, num_updates=4420, lr=4.77838e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20181
2022-10-13 15:24:31 - progress_bar.py[line:274] - INFO: epoch 001:   4435 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.1, ups=0.88, wpb=110.6, bsz=40, num_updates=4430, lr=4.78919e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20192
2022-10-13 15:24:43 - progress_bar.py[line:274] - INFO: epoch 001:   4445 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=4440, lr=4.8e-05, gnorm=0.925, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20204
2022-10-13 15:24:53 - progress_bar.py[line:274] - INFO: epoch 001:   4455 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=102.5, ups=0.92, wpb=110.9, bsz=40, num_updates=4450, lr=4.81081e-05, gnorm=0.928, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=20215
2022-10-13 15:25:05 - progress_bar.py[line:274] - INFO: epoch 001:   4465 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=4460, lr=4.82162e-05, gnorm=0.852, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20226
2022-10-13 15:25:16 - progress_bar.py[line:274] - INFO: epoch 001:   4475 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.5, ups=0.93, wpb=109.6, bsz=40, num_updates=4470, lr=4.83243e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20237
2022-10-13 15:25:27 - progress_bar.py[line:274] - INFO: epoch 001:   4485 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=4480, lr=4.84324e-05, gnorm=0.938, clip=40, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=20248
2022-10-13 15:25:38 - progress_bar.py[line:274] - INFO: epoch 001:   4495 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.3, ups=0.88, wpb=109.6, bsz=40, num_updates=4490, lr=4.85405e-05, gnorm=1.005, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20259
2022-10-13 15:25:50 - progress_bar.py[line:274] - INFO: epoch 001:   4505 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.8, ups=0.89, wpb=109.5, bsz=40, num_updates=4500, lr=4.86486e-05, gnorm=0.793, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20271
2022-10-13 15:26:01 - progress_bar.py[line:274] - INFO: epoch 001:   4515 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.329, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=4510, lr=4.87568e-05, gnorm=0.906, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20282
2022-10-13 15:26:12 - progress_bar.py[line:274] - INFO: epoch 001:   4525 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=4520, lr=4.88649e-05, gnorm=0.938, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20293
2022-10-13 15:26:23 - progress_bar.py[line:274] - INFO: epoch 001:   4535 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.9, ups=0.91, wpb=108.4, bsz=40, num_updates=4530, lr=4.8973e-05, gnorm=0.993, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20304
2022-10-13 15:26:34 - progress_bar.py[line:274] - INFO: epoch 001:   4545 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.8, ups=0.89, wpb=109.9, bsz=40, num_updates=4540, lr=4.90811e-05, gnorm=0.841, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20315
2022-10-13 15:26:45 - progress_bar.py[line:274] - INFO: epoch 001:   4555 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98, ups=0.89, wpb=110.2, bsz=40, num_updates=4550, lr=4.91892e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20327
2022-10-13 15:26:57 - progress_bar.py[line:274] - INFO: epoch 001:   4565 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.2, ups=0.87, wpb=110.8, bsz=40, num_updates=4560, lr=4.92973e-05, gnorm=0.969, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20338
2022-10-13 15:27:08 - progress_bar.py[line:274] - INFO: epoch 001:   4575 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.7, ups=0.88, wpb=110.1, bsz=40, num_updates=4570, lr=4.94054e-05, gnorm=0.885, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20350
2022-10-13 15:27:20 - progress_bar.py[line:274] - INFO: epoch 001:   4585 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=4580, lr=4.95135e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=20361
2022-10-13 15:27:31 - progress_bar.py[line:274] - INFO: epoch 001:   4595 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=4590, lr=4.96216e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20372
2022-10-13 15:27:42 - progress_bar.py[line:274] - INFO: epoch 001:   4605 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.2, ups=0.9, wpb=108.6, bsz=40, num_updates=4600, lr=4.97297e-05, gnorm=1.001, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20383
2022-10-13 15:27:53 - progress_bar.py[line:274] - INFO: epoch 001:   4615 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.1, ups=0.88, wpb=110.6, bsz=40, num_updates=4610, lr=4.98378e-05, gnorm=0.919, clip=30, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=20394
2022-10-13 15:28:05 - progress_bar.py[line:274] - INFO: epoch 001:   4625 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.7, ups=0.89, wpb=108.6, bsz=40, num_updates=4620, lr=4.99459e-05, gnorm=0.968, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20406
2022-10-13 15:28:16 - progress_bar.py[line:274] - INFO: epoch 001:   4635 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.5, ups=0.9, wpb=109.3, bsz=40, num_updates=4630, lr=4.99977e-05, gnorm=0.868, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20417
2022-10-13 15:28:27 - progress_bar.py[line:274] - INFO: epoch 001:   4645 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.8, ups=0.91, wpb=109.4, bsz=40, num_updates=4640, lr=4.99932e-05, gnorm=0.856, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20428
2022-10-13 15:28:38 - progress_bar.py[line:274] - INFO: epoch 001:   4655 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=4650, lr=4.99887e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20439
2022-10-13 15:28:49 - progress_bar.py[line:274] - INFO: epoch 001:   4665 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97, ups=0.87, wpb=112.1, bsz=40, num_updates=4660, lr=4.99842e-05, gnorm=0.737, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=20451
2022-10-13 15:29:01 - progress_bar.py[line:274] - INFO: epoch 001:   4675 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.7, ups=0.89, wpb=111.6, bsz=40, num_updates=4670, lr=4.99797e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20462
2022-10-13 15:29:12 - progress_bar.py[line:274] - INFO: epoch 001:   4685 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.2, ups=0.89, wpb=110.6, bsz=40, num_updates=4680, lr=4.99752e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20473
2022-10-13 15:29:23 - progress_bar.py[line:274] - INFO: epoch 001:   4695 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.3, ups=0.88, wpb=109.6, bsz=40, num_updates=4690, lr=4.99707e-05, gnorm=0.881, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20484
2022-10-13 15:29:34 - progress_bar.py[line:274] - INFO: epoch 001:   4705 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=4700, lr=4.99662e-05, gnorm=0.857, clip=0, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=20496
2022-10-13 15:29:46 - progress_bar.py[line:274] - INFO: epoch 001:   4715 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.4, ups=0.88, wpb=111, bsz=40, num_updates=4710, lr=4.99617e-05, gnorm=0.821, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20507
2022-10-13 15:29:57 - progress_bar.py[line:274] - INFO: epoch 001:   4725 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.9, ups=0.87, wpb=110.5, bsz=40, num_updates=4720, lr=4.99572e-05, gnorm=0.848, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20519
2022-10-13 15:30:08 - progress_bar.py[line:274] - INFO: epoch 001:   4735 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.3, ups=0.9, wpb=110, bsz=40, num_updates=4730, lr=4.99527e-05, gnorm=0.897, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20530
2022-10-13 15:30:20 - progress_bar.py[line:274] - INFO: epoch 001:   4745 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.6, ups=0.89, wpb=111.1, bsz=40, num_updates=4740, lr=4.99482e-05, gnorm=0.925, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20541
2022-10-13 15:30:31 - progress_bar.py[line:274] - INFO: epoch 001:   4755 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=4750, lr=4.99437e-05, gnorm=0.888, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20552
2022-10-13 15:30:42 - progress_bar.py[line:274] - INFO: epoch 001:   4765 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.5, ups=0.91, wpb=111, bsz=40, num_updates=4760, lr=4.99392e-05, gnorm=0.94, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20563
2022-10-13 15:30:53 - progress_bar.py[line:274] - INFO: epoch 001:   4775 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.7, ups=0.92, wpb=110, bsz=40, num_updates=4770, lr=4.99347e-05, gnorm=0.9, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20574
2022-10-13 15:31:04 - progress_bar.py[line:274] - INFO: epoch 001:   4785 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.9, ups=0.89, wpb=108.7, bsz=40, num_updates=4780, lr=4.99302e-05, gnorm=0.819, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20585
2022-10-13 15:31:15 - progress_bar.py[line:274] - INFO: epoch 001:   4795 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.7, ups=0.89, wpb=112, bsz=40, num_updates=4790, lr=4.99257e-05, gnorm=0.954, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20596
2022-10-13 15:31:26 - progress_bar.py[line:274] - INFO: epoch 001:   4805 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=4800, lr=4.99212e-05, gnorm=0.928, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20608
2022-10-13 15:31:37 - progress_bar.py[line:274] - INFO: epoch 001:   4815 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.1, ups=0.91, wpb=109.9, bsz=40, num_updates=4810, lr=4.99167e-05, gnorm=0.821, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20619
2022-10-13 15:31:49 - progress_bar.py[line:274] - INFO: epoch 001:   4825 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.9, ups=0.9, wpb=109.4, bsz=40, num_updates=4820, lr=4.99122e-05, gnorm=0.957, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20630
2022-10-13 15:32:00 - progress_bar.py[line:274] - INFO: epoch 001:   4835 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.5, ups=0.9, wpb=109.5, bsz=40, num_updates=4830, lr=4.99077e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20641
2022-10-13 15:32:11 - progress_bar.py[line:274] - INFO: epoch 001:   4845 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=101, ups=0.89, wpb=112.9, bsz=40, num_updates=4840, lr=4.99032e-05, gnorm=0.782, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20652
2022-10-13 15:32:22 - progress_bar.py[line:274] - INFO: epoch 001:   4855 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=102.1, ups=0.93, wpb=110.3, bsz=40, num_updates=4850, lr=4.98987e-05, gnorm=0.828, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20663
2022-10-13 15:32:33 - progress_bar.py[line:274] - INFO: epoch 001:   4865 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98, ups=0.89, wpb=109.6, bsz=40, num_updates=4860, lr=4.98942e-05, gnorm=0.888, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20674
2022-10-13 15:32:44 - progress_bar.py[line:274] - INFO: epoch 001:   4875 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=4870, lr=4.98897e-05, gnorm=0.896, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20685
2022-10-13 15:32:55 - progress_bar.py[line:274] - INFO: epoch 001:   4885 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.5, ups=0.91, wpb=110.8, bsz=40, num_updates=4880, lr=4.98852e-05, gnorm=0.95, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20696
2022-10-13 15:33:06 - progress_bar.py[line:274] - INFO: epoch 001:   4895 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101.4, ups=0.91, wpb=111.2, bsz=40, num_updates=4890, lr=4.98806e-05, gnorm=0.927, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20707
2022-10-13 15:33:17 - progress_bar.py[line:274] - INFO: epoch 001:   4905 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=102.2, ups=0.92, wpb=110.6, bsz=40, num_updates=4900, lr=4.98761e-05, gnorm=0.963, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20718
2022-10-13 15:33:28 - progress_bar.py[line:274] - INFO: epoch 001:   4915 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=4910, lr=4.98716e-05, gnorm=0.834, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20729
2022-10-13 15:33:39 - progress_bar.py[line:274] - INFO: epoch 001:   4925 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=102.6, ups=0.91, wpb=112.5, bsz=40, num_updates=4920, lr=4.98671e-05, gnorm=0.715, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20740
2022-10-13 15:33:50 - progress_bar.py[line:274] - INFO: epoch 001:   4935 / 28910 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.3, ups=0.9, wpb=109.7, bsz=40, num_updates=4930, lr=4.98626e-05, gnorm=0.847, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20751
2022-10-13 15:34:01 - progress_bar.py[line:274] - INFO: epoch 001:   4945 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=4940, lr=4.98581e-05, gnorm=0.904, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20763
2022-10-13 15:34:13 - progress_bar.py[line:274] - INFO: epoch 001:   4955 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=4950, lr=4.98536e-05, gnorm=0.855, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=20774
2022-10-13 15:34:24 - progress_bar.py[line:274] - INFO: epoch 001:   4965 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=4960, lr=4.98491e-05, gnorm=0.818, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20785
2022-10-13 15:34:35 - progress_bar.py[line:274] - INFO: epoch 001:   4975 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=94.4, ups=0.87, wpb=108.2, bsz=40, num_updates=4970, lr=4.98446e-05, gnorm=0.869, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20796
2022-10-13 15:34:47 - progress_bar.py[line:274] - INFO: epoch 001:   4985 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=4980, lr=4.98401e-05, gnorm=0.795, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=20808
2022-10-13 15:34:57 - progress_bar.py[line:274] - INFO: epoch 001:   4995 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.4, ups=0.93, wpb=110, bsz=40, num_updates=4990, lr=4.98356e-05, gnorm=0.839, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20818
2022-10-13 15:35:08 - progress_bar.py[line:274] - INFO: epoch 001:   5005 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.7, ups=0.89, wpb=111.8, bsz=40, num_updates=5000, lr=4.98311e-05, gnorm=0.887, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20830
2022-10-13 15:35:08 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 15:35:10 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 15:35:10 - train.py[line:551] - INFO: load:1.20 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 15:37:42 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 15:37:42 - train.py[line:551] - INFO: load:1.22 valid_run:152.47 task_valid:149.35 collect_output:2.02
2022-10-13 15:40:11 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 15:40:11 - train.py[line:551] - INFO: load:1.24 valid_run:301.29 task_valid:293.28 collect_output:5.88
2022-10-13 15:42:44 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 15:42:44 - train.py[line:551] - INFO: load:1.27 valid_run:453.82 task_valid:437.33 collect_output:13.28
2022-10-13 15:45:14 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 15:45:14 - train.py[line:551] - INFO: load:1.29 valid_run:603.56 task_valid:583.42 collect_output:15.80
2022-10-13 15:47:47 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 15:47:47 - train.py[line:551] - INFO: load:1.32 valid_run:756.32 task_valid:731.79 collect_output:19.13
2022-10-13 15:50:19 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 15:50:19 - train.py[line:551] - INFO: load:1.35 valid_run:908.58 task_valid:878.29 collect_output:23.76
2022-10-13 15:52:52 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 15:52:52 - train.py[line:551] - INFO: load:1.37 valid_run:1062.03 task_valid:1025.40 collect_output:29.01
2022-10-13 15:55:24 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 15:55:24 - train.py[line:551] - INFO: load:1.40 valid_run:1213.59 task_valid:1167.78 collect_output:37.09
2022-10-13 15:57:54 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 15:57:54 - train.py[line:551] - INFO: load:1.42 valid_run:1363.70 task_valid:1313.45 collect_output:40.46
2022-10-13 16:00:23 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 16:00:23 - train.py[line:551] - INFO: load:1.45 valid_run:1512.72 task_valid:1457.69 collect_output:44.16
2022-10-13 16:02:54 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 16:02:54 - train.py[line:551] - INFO: load:1.47 valid_run:1662.99 task_valid:1603.68 collect_output:47.37
2022-10-13 16:05:24 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 16:05:24 - train.py[line:551] - INFO: load:1.50 valid_run:1813.44 task_valid:1749.75 collect_output:50.65
2022-10-13 16:07:55 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 16:07:55 - train.py[line:551] - INFO: load:1.52 valid_run:1963.95 task_valid:1892.70 collect_output:57.12
2022-10-13 16:10:26 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 16:10:26 - train.py[line:551] - INFO: load:1.57 valid_run:2115.11 task_valid:2039.31 collect_output:60.60
2022-10-13 16:12:57 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 16:12:57 - train.py[line:551] - INFO: load:1.59 valid_run:2266.02 task_valid:2186.84 collect_output:62.89
2022-10-13 16:15:28 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 16:15:28 - train.py[line:551] - INFO: load:1.62 valid_run:2416.84 task_valid:2332.23 collect_output:67.22
2022-10-13 16:18:01 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 16:18:01 - train.py[line:551] - INFO: load:1.65 valid_run:2569.56 task_valid:2479.75 collect_output:71.15
2022-10-13 16:20:33 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 16:20:33 - train.py[line:551] - INFO: load:1.68 valid_run:2721.89 task_valid:2628.80 collect_output:73.21
2022-10-13 16:23:02 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 16:23:02 - train.py[line:551] - INFO: load:1.70 valid_run:2871.10 task_valid:2771.99 collect_output:78.06
2022-10-13 16:25:33 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 16:25:33 - train.py[line:551] - INFO: load:1.73 valid_run:3022.23 task_valid:2918.83 collect_output:81.18
2022-10-13 16:28:06 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 16:28:06 - train.py[line:551] - INFO: load:1.76 valid_run:3174.84 task_valid:3065.38 collect_output:86.01
2022-10-13 16:30:37 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 16:30:37 - train.py[line:551] - INFO: load:1.78 valid_run:3325.54 task_valid:3211.75 collect_output:89.16
2022-10-13 16:33:09 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 16:33:09 - train.py[line:551] - INFO: load:1.81 valid_run:3477.71 task_valid:3359.66 collect_output:92.28
2022-10-13 16:35:42 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 16:35:42 - train.py[line:551] - INFO: load:1.83 valid_run:3630.17 task_valid:3507.89 collect_output:95.40

====================================================================================================
SGG eval:     R @ 50: 0.6711;     R @ 100: 0.7013;     R @ 500: 0.7225;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4274;    mR @ 100: 0.4799;    mR @ 500: 0.5131;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.7500) (covering:0.3714) (eating:0.8235) (flying in:0.7273) (growing on:0.1250) (hanging from:0.3839) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9533) (says:0.0000) (sitting on:0.7509) (standing on:0.5263) (using:0.5500) (walking in:0.0000) (walking on:0.6216) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6711;     R @ 100: 0.7013;     R @ 500: 0.7225;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4274;    mR @ 100: 0.4799;    mR @ 500: 0.5131;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.7500) (covering:0.3714) (eating:0.8235) (flying in:0.7273) (growing on:0.1250) (hanging from:0.3839) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9533) (says:0.0000) (sitting on:0.7509) (standing on:0.5263) (using:0.5500) (walking in:0.0000) (walking on:0.6216) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-13 16:38:15 - train.py[line:487] - INFO: 0.7013082505729564
2022-10-13 16:38:15 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 16:38:15 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.369 | loss_v1 0 | loss_v2 0 | nll_loss 0.231 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.701308 | ppl 1.17 | vqa_score 0.5113 | wps 118.5 | wpb 89.9 | bsz 30 | num_updates 5000 | best_R@100 0.704053
2022-10-13 16:38:15 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 5000 updates
2022-10-13 16:38:15 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-13 16:38:21 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-13 16:38:24 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 0.7013082505729564) (writing took 8.718654029071331 seconds)
2022-10-13 16:38:35 - progress_bar.py[line:274] - INFO: epoch 001:   5015 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=0.3, ups=0, wpb=110.1, bsz=40, num_updates=5010, lr=4.98266e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24636
2022-10-13 16:38:46 - progress_bar.py[line:274] - INFO: epoch 001:   5025 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97, ups=0.88, wpb=110.6, bsz=40, num_updates=5020, lr=4.98221e-05, gnorm=0.94, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24647
2022-10-13 16:38:58 - progress_bar.py[line:274] - INFO: epoch 001:   5035 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=5030, lr=4.98176e-05, gnorm=0.864, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24659
2022-10-13 16:39:09 - progress_bar.py[line:274] - INFO: epoch 001:   5045 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.7, ups=0.89, wpb=110.1, bsz=40, num_updates=5040, lr=4.98131e-05, gnorm=0.888, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24670
2022-10-13 16:39:20 - progress_bar.py[line:274] - INFO: epoch 001:   5055 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.9, ups=0.91, wpb=110.7, bsz=40, num_updates=5050, lr=4.98086e-05, gnorm=0.797, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24681
2022-10-13 16:39:29 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 16:39:32 - progress_bar.py[line:274] - INFO: epoch 001:   5066 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.4, ups=0.85, wpb=111.3, bsz=40, num_updates=5060, lr=4.98041e-05, gnorm=0.937, clip=40, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=24693
2022-10-13 16:39:43 - progress_bar.py[line:274] - INFO: epoch 001:   5076 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.6, ups=0.88, wpb=111.3, bsz=40, num_updates=5070, lr=4.97996e-05, gnorm=0.961, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24704
2022-10-13 16:39:54 - progress_bar.py[line:274] - INFO: epoch 001:   5086 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.8, ups=0.89, wpb=109.5, bsz=40, num_updates=5080, lr=4.97951e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24715
2022-10-13 16:40:05 - progress_bar.py[line:274] - INFO: epoch 001:   5096 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.7, ups=0.92, wpb=110.2, bsz=40, num_updates=5090, lr=4.97906e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24726
2022-10-13 16:40:16 - progress_bar.py[line:274] - INFO: epoch 001:   5106 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101.5, ups=0.91, wpb=111, bsz=40, num_updates=5100, lr=4.97861e-05, gnorm=0.857, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24737
2022-10-13 16:40:27 - progress_bar.py[line:274] - INFO: epoch 001:   5116 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.3, ups=0.9, wpb=110, bsz=40, num_updates=5110, lr=4.97816e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24748
2022-10-13 16:40:38 - progress_bar.py[line:274] - INFO: epoch 001:   5126 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=5120, lr=4.97771e-05, gnorm=0.851, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24760
2022-10-13 16:40:50 - progress_bar.py[line:274] - INFO: epoch 001:   5136 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=5130, lr=4.97726e-05, gnorm=0.88, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24771
2022-10-13 16:41:01 - progress_bar.py[line:274] - INFO: epoch 001:   5146 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.4, ups=0.91, wpb=109.1, bsz=40, num_updates=5140, lr=4.9768e-05, gnorm=0.909, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24782
2022-10-13 16:41:12 - progress_bar.py[line:274] - INFO: epoch 001:   5156 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.7, ups=0.89, wpb=109.9, bsz=40, num_updates=5150, lr=4.97635e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24793
2022-10-13 16:41:23 - progress_bar.py[line:274] - INFO: epoch 001:   5166 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99, ups=0.9, wpb=110.1, bsz=40, num_updates=5160, lr=4.9759e-05, gnorm=0.863, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24804
2022-10-13 16:41:34 - progress_bar.py[line:274] - INFO: epoch 001:   5176 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=5170, lr=4.97545e-05, gnorm=0.855, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24815
2022-10-13 16:41:45 - progress_bar.py[line:274] - INFO: epoch 001:   5186 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.4, ups=0.89, wpb=110.8, bsz=40, num_updates=5180, lr=4.975e-05, gnorm=1.002, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24827
2022-10-13 16:41:57 - progress_bar.py[line:274] - INFO: epoch 001:   5196 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=96.8, ups=0.88, wpb=109.7, bsz=40, num_updates=5190, lr=4.97455e-05, gnorm=0.871, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=24838
2022-10-13 16:42:08 - progress_bar.py[line:274] - INFO: epoch 001:   5206 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.7, ups=0.9, wpb=110, bsz=40, num_updates=5200, lr=4.9741e-05, gnorm=0.778, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24849
2022-10-13 16:42:19 - progress_bar.py[line:274] - INFO: epoch 001:   5216 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=102.2, ups=0.91, wpb=112, bsz=40, num_updates=5210, lr=4.97365e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24860
2022-10-13 16:42:30 - progress_bar.py[line:274] - INFO: epoch 001:   5226 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=5220, lr=4.9732e-05, gnorm=0.841, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=24871
2022-10-13 16:42:42 - progress_bar.py[line:274] - INFO: epoch 001:   5236 / 28910 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=5230, lr=4.97275e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24883
2022-10-13 16:42:53 - progress_bar.py[line:274] - INFO: epoch 001:   5246 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.1, ups=0.9, wpb=109, bsz=40, num_updates=5240, lr=4.9723e-05, gnorm=0.763, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=24894
2022-10-13 16:43:04 - progress_bar.py[line:274] - INFO: epoch 001:   5256 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.6, ups=0.9, wpb=109, bsz=40, num_updates=5250, lr=4.97185e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24905
2022-10-13 16:43:15 - progress_bar.py[line:274] - INFO: epoch 001:   5266 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=5260, lr=4.9714e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24916
2022-10-13 16:43:26 - progress_bar.py[line:274] - INFO: epoch 001:   5276 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.2, ups=0.88, wpb=109.6, bsz=40, num_updates=5270, lr=4.97095e-05, gnorm=0.827, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24927
2022-10-13 16:43:38 - progress_bar.py[line:274] - INFO: epoch 001:   5286 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=95.1, ups=0.88, wpb=108.5, bsz=40, num_updates=5280, lr=4.9705e-05, gnorm=0.829, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24939
2022-10-13 16:43:49 - progress_bar.py[line:274] - INFO: epoch 001:   5296 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99, ups=0.9, wpb=110.6, bsz=40, num_updates=5290, lr=4.97005e-05, gnorm=0.8, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24950
2022-10-13 16:44:00 - progress_bar.py[line:274] - INFO: epoch 001:   5306 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99, ups=0.9, wpb=109.7, bsz=40, num_updates=5300, lr=4.9696e-05, gnorm=0.775, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24961
2022-10-13 16:44:11 - progress_bar.py[line:274] - INFO: epoch 001:   5316 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.7, ups=0.9, wpb=108.9, bsz=40, num_updates=5310, lr=4.96915e-05, gnorm=0.838, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24972
2022-10-13 16:44:22 - progress_bar.py[line:274] - INFO: epoch 001:   5326 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=5320, lr=4.9687e-05, gnorm=0.794, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24983
2022-10-13 16:44:33 - progress_bar.py[line:274] - INFO: epoch 001:   5336 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.7, ups=0.9, wpb=110.3, bsz=40, num_updates=5330, lr=4.96825e-05, gnorm=0.85, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=24994
2022-10-13 16:44:44 - progress_bar.py[line:274] - INFO: epoch 001:   5346 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.9, ups=0.89, wpb=109.5, bsz=40, num_updates=5340, lr=4.9678e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25006
2022-10-13 16:44:56 - progress_bar.py[line:274] - INFO: epoch 001:   5356 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.8, ups=0.89, wpb=112.1, bsz=40, num_updates=5350, lr=4.96735e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25017
2022-10-13 16:45:07 - progress_bar.py[line:274] - INFO: epoch 001:   5366 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.5, ups=0.89, wpb=111.5, bsz=40, num_updates=5360, lr=4.9669e-05, gnorm=0.897, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25028
2022-10-13 16:45:18 - progress_bar.py[line:274] - INFO: epoch 001:   5376 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.7, ups=0.9, wpb=109.8, bsz=40, num_updates=5370, lr=4.96645e-05, gnorm=0.734, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25039
2022-10-13 16:45:29 - progress_bar.py[line:274] - INFO: epoch 001:   5386 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.1, ups=0.88, wpb=111.5, bsz=40, num_updates=5380, lr=4.966e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25051
2022-10-13 16:45:41 - progress_bar.py[line:274] - INFO: epoch 001:   5396 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.6, ups=0.87, wpb=110.2, bsz=40, num_updates=5390, lr=4.96555e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25062
2022-10-13 16:45:52 - progress_bar.py[line:274] - INFO: epoch 001:   5406 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.5, ups=0.88, wpb=110, bsz=40, num_updates=5400, lr=4.96509e-05, gnorm=0.9, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25073
2022-10-13 16:46:03 - progress_bar.py[line:274] - INFO: epoch 001:   5416 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.7, ups=0.9, wpb=109.1, bsz=40, num_updates=5410, lr=4.96464e-05, gnorm=0.882, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25085
2022-10-13 16:46:14 - progress_bar.py[line:274] - INFO: epoch 001:   5426 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=102.1, ups=0.92, wpb=111.4, bsz=40, num_updates=5420, lr=4.96419e-05, gnorm=0.844, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25095
2022-10-13 16:46:26 - progress_bar.py[line:274] - INFO: epoch 001:   5436 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=96.1, ups=0.88, wpb=109.5, bsz=40, num_updates=5430, lr=4.96374e-05, gnorm=0.894, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25107
2022-10-13 16:46:37 - progress_bar.py[line:274] - INFO: epoch 001:   5446 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=5440, lr=4.96329e-05, gnorm=0.859, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25118
2022-10-13 16:46:48 - progress_bar.py[line:274] - INFO: epoch 001:   5456 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.6, ups=0.93, wpb=109.5, bsz=40, num_updates=5450, lr=4.96284e-05, gnorm=0.746, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25129
2022-10-13 16:46:59 - progress_bar.py[line:274] - INFO: epoch 001:   5466 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=5460, lr=4.96239e-05, gnorm=0.953, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25140
2022-10-13 16:47:10 - progress_bar.py[line:274] - INFO: epoch 001:   5476 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=5470, lr=4.96194e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25151
2022-10-13 16:47:21 - progress_bar.py[line:274] - INFO: epoch 001:   5486 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.1, ups=0.92, wpb=109.4, bsz=40, num_updates=5480, lr=4.96149e-05, gnorm=0.868, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25162
2022-10-13 16:47:33 - progress_bar.py[line:274] - INFO: epoch 001:   5496 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.7, ups=0.88, wpb=111, bsz=40, num_updates=5490, lr=4.96104e-05, gnorm=0.896, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25174
2022-10-13 16:47:44 - progress_bar.py[line:274] - INFO: epoch 001:   5506 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=5500, lr=4.96059e-05, gnorm=0.833, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25185
2022-10-13 16:47:55 - progress_bar.py[line:274] - INFO: epoch 001:   5516 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97.2, ups=0.89, wpb=109.2, bsz=40, num_updates=5510, lr=4.96014e-05, gnorm=0.811, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25196
2022-10-13 16:48:06 - progress_bar.py[line:274] - INFO: epoch 001:   5526 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=5520, lr=4.95969e-05, gnorm=0.77, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25207
2022-10-13 16:48:18 - progress_bar.py[line:274] - INFO: epoch 001:   5536 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.5, ups=0.88, wpb=111, bsz=40, num_updates=5530, lr=4.95924e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25219
2022-10-13 16:48:29 - progress_bar.py[line:274] - INFO: epoch 001:   5546 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=5540, lr=4.95879e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25230
2022-10-13 16:48:40 - progress_bar.py[line:274] - INFO: epoch 001:   5556 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=5550, lr=4.95834e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25241
2022-10-13 16:48:52 - progress_bar.py[line:274] - INFO: epoch 001:   5566 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=5560, lr=4.95789e-05, gnorm=0.823, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25253
2022-10-13 16:49:03 - progress_bar.py[line:274] - INFO: epoch 001:   5576 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=5570, lr=4.95744e-05, gnorm=0.853, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25264
2022-10-13 16:49:14 - progress_bar.py[line:274] - INFO: epoch 001:   5586 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=5580, lr=4.95699e-05, gnorm=0.905, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25275
2022-10-13 16:49:25 - progress_bar.py[line:274] - INFO: epoch 001:   5596 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=101.7, ups=0.92, wpb=111.1, bsz=40, num_updates=5590, lr=4.95654e-05, gnorm=0.791, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25286
2022-10-13 16:49:36 - progress_bar.py[line:274] - INFO: epoch 001:   5606 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=5600, lr=4.95609e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25297
2022-10-13 16:49:47 - progress_bar.py[line:274] - INFO: epoch 001:   5616 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=5610, lr=4.95564e-05, gnorm=0.902, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25308
2022-10-13 16:49:59 - progress_bar.py[line:274] - INFO: epoch 001:   5626 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.7, ups=0.88, wpb=110.7, bsz=40, num_updates=5620, lr=4.95519e-05, gnorm=0.657, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25320
2022-10-13 16:50:09 - progress_bar.py[line:274] - INFO: epoch 001:   5636 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=102.2, ups=0.92, wpb=110.6, bsz=40, num_updates=5630, lr=4.95474e-05, gnorm=0.804, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25331
2022-10-13 16:50:21 - progress_bar.py[line:274] - INFO: epoch 001:   5646 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.9, ups=0.88, wpb=111.3, bsz=40, num_updates=5640, lr=4.95429e-05, gnorm=0.822, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25342
2022-10-13 16:50:32 - progress_bar.py[line:274] - INFO: epoch 001:   5656 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=5650, lr=4.95384e-05, gnorm=0.847, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25353
2022-10-13 16:50:43 - progress_bar.py[line:274] - INFO: epoch 001:   5666 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.8, ups=0.87, wpb=110.2, bsz=40, num_updates=5660, lr=4.95338e-05, gnorm=0.823, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25364
2022-10-13 16:50:54 - progress_bar.py[line:274] - INFO: epoch 001:   5676 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101.6, ups=0.91, wpb=111.2, bsz=40, num_updates=5670, lr=4.95293e-05, gnorm=0.707, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25375
2022-10-13 16:51:06 - progress_bar.py[line:274] - INFO: epoch 001:   5686 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.2, ups=0.88, wpb=109.9, bsz=40, num_updates=5680, lr=4.95248e-05, gnorm=0.835, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25387
2022-10-13 16:51:17 - progress_bar.py[line:274] - INFO: epoch 001:   5696 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.4, ups=0.88, wpb=111.9, bsz=40, num_updates=5690, lr=4.95203e-05, gnorm=0.822, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25398
2022-10-13 16:51:28 - progress_bar.py[line:274] - INFO: epoch 001:   5706 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=5700, lr=4.95158e-05, gnorm=0.704, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25409
2022-10-13 16:51:39 - progress_bar.py[line:274] - INFO: epoch 001:   5716 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=102.7, ups=0.93, wpb=110.3, bsz=40, num_updates=5710, lr=4.95113e-05, gnorm=0.893, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25420
2022-10-13 16:51:50 - progress_bar.py[line:274] - INFO: epoch 001:   5726 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.9, ups=0.89, wpb=110.2, bsz=40, num_updates=5720, lr=4.95068e-05, gnorm=0.792, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25431
2022-10-13 16:52:01 - progress_bar.py[line:274] - INFO: epoch 001:   5736 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=5730, lr=4.95023e-05, gnorm=0.76, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25443
2022-10-13 16:52:12 - progress_bar.py[line:274] - INFO: epoch 001:   5746 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=5740, lr=4.94978e-05, gnorm=0.772, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25454
2022-10-13 16:52:24 - progress_bar.py[line:274] - INFO: epoch 001:   5756 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.4, ups=0.87, wpb=109.8, bsz=40, num_updates=5750, lr=4.94933e-05, gnorm=0.839, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25465
2022-10-13 16:52:35 - progress_bar.py[line:274] - INFO: epoch 001:   5766 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=5760, lr=4.94888e-05, gnorm=0.848, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25476
2022-10-13 16:52:46 - progress_bar.py[line:274] - INFO: epoch 001:   5776 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=5770, lr=4.94843e-05, gnorm=0.817, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25488
2022-10-13 16:52:58 - progress_bar.py[line:274] - INFO: epoch 001:   5786 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.2, ups=0.88, wpb=109.2, bsz=40, num_updates=5780, lr=4.94798e-05, gnorm=0.875, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25499
2022-10-13 16:53:09 - progress_bar.py[line:274] - INFO: epoch 001:   5796 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.1, ups=0.87, wpb=111.1, bsz=40, num_updates=5790, lr=4.94753e-05, gnorm=0.756, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=25510
2022-10-13 16:53:20 - progress_bar.py[line:274] - INFO: epoch 001:   5806 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.3, ups=0.9, wpb=109, bsz=40, num_updates=5800, lr=4.94708e-05, gnorm=0.907, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25521
2022-10-13 16:53:31 - progress_bar.py[line:274] - INFO: epoch 001:   5816 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=5810, lr=4.94663e-05, gnorm=0.873, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25533
2022-10-13 16:53:42 - progress_bar.py[line:274] - INFO: epoch 001:   5826 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.1, ups=0.9, wpb=110.9, bsz=40, num_updates=5820, lr=4.94618e-05, gnorm=0.863, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25544
2022-10-13 16:53:54 - progress_bar.py[line:274] - INFO: epoch 001:   5836 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.8, ups=0.88, wpb=110, bsz=40, num_updates=5830, lr=4.94573e-05, gnorm=0.813, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25555
2022-10-13 16:54:05 - progress_bar.py[line:274] - INFO: epoch 001:   5846 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=101.6, ups=0.92, wpb=110.3, bsz=40, num_updates=5840, lr=4.94528e-05, gnorm=0.865, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25566
2022-10-13 16:54:16 - progress_bar.py[line:274] - INFO: epoch 001:   5856 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.6, ups=0.87, wpb=110, bsz=40, num_updates=5850, lr=4.94483e-05, gnorm=0.93, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25577
2022-10-13 16:54:27 - progress_bar.py[line:274] - INFO: epoch 001:   5866 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=5860, lr=4.94438e-05, gnorm=0.84, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25589
2022-10-13 16:54:38 - progress_bar.py[line:274] - INFO: epoch 001:   5876 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101, ups=0.91, wpb=110.4, bsz=40, num_updates=5870, lr=4.94393e-05, gnorm=0.832, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25600
2022-10-13 16:54:50 - progress_bar.py[line:274] - INFO: epoch 001:   5886 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=5880, lr=4.94348e-05, gnorm=0.78, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25611
2022-10-13 16:55:01 - progress_bar.py[line:274] - INFO: epoch 001:   5896 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=101.9, ups=0.92, wpb=111.2, bsz=40, num_updates=5890, lr=4.94303e-05, gnorm=0.791, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25622
2022-10-13 16:55:11 - progress_bar.py[line:274] - INFO: epoch 001:   5906 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.3, ups=0.91, wpb=109.7, bsz=40, num_updates=5900, lr=4.94258e-05, gnorm=0.846, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25633
2022-10-13 16:55:22 - progress_bar.py[line:274] - INFO: epoch 001:   5916 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=102, ups=0.91, wpb=111.8, bsz=40, num_updates=5910, lr=4.94212e-05, gnorm=0.827, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25644
2022-10-13 16:55:34 - progress_bar.py[line:274] - INFO: epoch 001:   5926 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.6, ups=0.9, wpb=111.3, bsz=40, num_updates=5920, lr=4.94167e-05, gnorm=0.887, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25655
2022-10-13 16:55:45 - progress_bar.py[line:274] - INFO: epoch 001:   5936 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.9, ups=0.9, wpb=109.9, bsz=40, num_updates=5930, lr=4.94122e-05, gnorm=0.808, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25666
2022-10-13 16:55:56 - progress_bar.py[line:274] - INFO: epoch 001:   5946 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=5940, lr=4.94077e-05, gnorm=0.876, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25677
2022-10-13 16:56:07 - progress_bar.py[line:274] - INFO: epoch 001:   5956 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.8, ups=0.87, wpb=110.3, bsz=40, num_updates=5950, lr=4.94032e-05, gnorm=0.783, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25689
2022-10-13 16:56:19 - progress_bar.py[line:274] - INFO: epoch 001:   5966 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.7, ups=0.89, wpb=108.5, bsz=40, num_updates=5960, lr=4.93987e-05, gnorm=0.782, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25700
2022-10-13 16:56:30 - progress_bar.py[line:274] - INFO: epoch 001:   5976 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=5970, lr=4.93942e-05, gnorm=0.952, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25711
2022-10-13 16:56:41 - progress_bar.py[line:274] - INFO: epoch 001:   5986 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.9, ups=0.88, wpb=109.1, bsz=40, num_updates=5980, lr=4.93897e-05, gnorm=0.728, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25722
2022-10-13 16:56:53 - progress_bar.py[line:274] - INFO: epoch 001:   5996 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.1, ups=0.88, wpb=110.6, bsz=40, num_updates=5990, lr=4.93852e-05, gnorm=0.806, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25734
2022-10-13 16:57:04 - progress_bar.py[line:274] - INFO: epoch 001:   6006 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.7, ups=0.9, wpb=109.5, bsz=40, num_updates=6000, lr=4.93807e-05, gnorm=0.865, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25745
2022-10-13 16:57:04 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 16:57:05 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 16:57:05 - train.py[line:551] - INFO: load:1.17 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 16:57:06 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.87 GiB already allocated; 2.72 GiB free; 34.39 GiB reserved in total by PyTorch)
2022-10-13 16:57:06 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-13 16:57:06 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 12        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9083 MB |   10307 MB |    3719 TB |    3719 TB |
|       from large pool |    8938 MB |   10162 MB |    3718 TB |    3718 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9083 MB |   10307 MB |    3719 TB |    3719 TB |
|       from large pool |    8938 MB |   10162 MB |    3718 TB |    3718 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   35216 MB |   37414 MB |  135816 MB |  100600 MB |
|       from large pool |   35070 MB |   37262 MB |  135552 MB |  100482 MB |
|       from small pool |     146 MB |     152 MB |     264 MB |     118 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   26132 MB |   26132 MB |    3680 TB |    3680 TB |
|       from large pool |   26131 MB |   26131 MB |    3679 TB |    3679 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  171190 K  |  171187 K  |
|       from large pool |     563    |     575    |   55526 K  |   55526 K  |
|       from small pool |    3095    |    3114    |  115664 K  |  115661 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  171190 K  |  171187 K  |
|       from large pool |     563    |     575    |   55526 K  |   55526 K  |
|       from small pool |    3095    |    3114    |  115664 K  |  115661 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     193    |     199    |     458    |     265    |
|       from large pool |     120    |     123    |     326    |     206    |
|       from small pool |      73    |      76    |     132    |      59    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     137    |     143    |  120372 K  |  120372 K  |
|       from large pool |      95    |      97    |   21074 K  |   21074 K  |
|       from small pool |      42    |      49    |   99297 K  |   99297 K  |
|===========================================================================|

2022-10-13 16:57:06 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-13 16:57:08 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.51 GiB (GPU 0; 39.59 GiB total capacity; 8.49 GiB already allocated; 1.13 GiB free; 35.97 GiB reserved in total by PyTorch)
2022-10-13 16:57:08 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 18        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8692 MB |   14111 MB |    3711 TB |    3711 TB |
|       from large pool |    8547 MB |   13966 MB |    3709 TB |    3709 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8692 MB |   14111 MB |    3711 TB |    3711 TB |
|       from large pool |    8547 MB |   13966 MB |    3709 TB |    3709 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36836 MB |   36854 MB |  228310 MB |  191474 MB |
|       from large pool |   36690 MB |   36702 MB |  228016 MB |  191326 MB |
|       from small pool |     146 MB |     152 MB |     294 MB |     148 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   28143 MB |   28143 MB |    4067 TB |    4067 TB |
|       from large pool |   28142 MB |   28142 MB |    4066 TB |    4066 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3668    |    3682    |  171209 K  |  171205 K  |
|       from large pool |     563    |     575    |   55531 K  |   55531 K  |
|       from small pool |    3105    |    3114    |  115677 K  |  115674 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3668    |    3682    |  171209 K  |  171205 K  |
|       from large pool |     563    |     575    |   55531 K  |   55531 K  |
|       from small pool |    3105    |    3114    |  115677 K  |  115674 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     167    |     171    |     551    |     384    |
|       from large pool |      94    |      95    |     404    |     310    |
|       from small pool |      73    |      76    |     147    |      74    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     107    |     122    |  119988 K  |  119988 K  |
|       from large pool |      74    |      79    |   20228 K  |   20228 K  |
|       from small pool |      33    |      47    |   99759 K  |   99759 K  |
|===========================================================================|

2022-10-13 16:57:08 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-13 16:57:08 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-13 16:59:39 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 16:59:39 - train.py[line:551] - INFO: load:1.19 valid_run:153.68 task_valid:148.44 collect_output:3.30
2022-10-13 17:02:08 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 17:02:08 - train.py[line:551] - INFO: load:1.22 valid_run:302.72 task_valid:292.55 collect_output:7.14
2022-10-13 17:04:41 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 17:04:41 - train.py[line:551] - INFO: load:1.24 valid_run:455.20 task_valid:436.47 collect_output:14.63
2022-10-13 17:07:10 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 17:07:10 - train.py[line:551] - INFO: load:1.27 valid_run:604.87 task_valid:582.37 collect_output:17.34
2022-10-13 17:09:43 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 17:09:43 - train.py[line:551] - INFO: load:1.29 valid_run:757.61 task_valid:730.45 collect_output:20.96
2022-10-13 17:12:15 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 17:12:15 - train.py[line:551] - INFO: load:1.32 valid_run:909.72 task_valid:876.87 collect_output:25.57
2022-10-13 17:14:49 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 17:14:49 - train.py[line:551] - INFO: load:1.34 valid_run:1063.18 task_valid:1023.77 collect_output:31.07
2022-10-13 17:17:20 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 17:17:20 - train.py[line:551] - INFO: load:1.37 valid_run:1214.61 task_valid:1165.78 collect_output:39.42
2022-10-13 17:19:50 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 17:19:50 - train.py[line:551] - INFO: load:1.39 valid_run:1364.75 task_valid:1311.58 collect_output:42.69
2022-10-13 17:22:19 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 17:22:19 - train.py[line:551] - INFO: load:1.42 valid_run:1513.67 task_valid:1455.65 collect_output:46.48
2022-10-13 17:24:50 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 17:24:50 - train.py[line:551] - INFO: load:1.44 valid_run:1664.46 task_valid:1601.79 collect_output:50.06
2022-10-13 17:27:21 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 17:27:21 - train.py[line:551] - INFO: load:1.47 valid_run:1815.40 task_valid:1747.72 collect_output:53.99
2022-10-13 17:29:53 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 17:29:53 - train.py[line:551] - INFO: load:1.49 valid_run:1966.63 task_valid:1890.65 collect_output:61.19
2022-10-13 17:32:24 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 17:32:24 - train.py[line:551] - INFO: load:1.52 valid_run:2117.97 task_valid:2036.85 collect_output:65.27
2022-10-13 17:34:55 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 17:34:55 - train.py[line:551] - INFO: load:1.54 valid_run:2269.16 task_valid:2184.83 collect_output:67.36
2022-10-13 17:37:26 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 17:37:26 - train.py[line:551] - INFO: load:1.57 valid_run:2420.36 task_valid:2330.77 collect_output:71.40
2022-10-13 17:39:59 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 17:39:59 - train.py[line:551] - INFO: load:1.59 valid_run:2572.71 task_valid:2477.80 collect_output:75.60
2022-10-13 17:42:31 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 17:42:31 - train.py[line:551] - INFO: load:1.62 valid_run:2724.82 task_valid:2626.46 collect_output:77.87
2022-10-13 17:45:01 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 17:45:01 - train.py[line:551] - INFO: load:1.65 valid_run:2874.83 task_valid:2770.81 collect_output:82.26
2022-10-13 17:47:33 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 17:47:33 - train.py[line:551] - INFO: load:1.68 valid_run:3026.76 task_valid:2918.57 collect_output:85.20
2022-10-13 17:50:06 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 17:50:06 - train.py[line:551] - INFO: load:1.72 valid_run:3179.29 task_valid:3065.20 collect_output:89.91
2022-10-13 17:52:36 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 17:52:36 - train.py[line:551] - INFO: load:1.75 valid_run:3329.84 task_valid:3211.61 collect_output:92.88
2022-10-13 17:55:09 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 17:55:09 - train.py[line:551] - INFO: load:1.77 valid_run:3482.20 task_valid:3359.80 collect_output:95.87
2022-10-13 17:57:41 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 17:57:41 - train.py[line:551] - INFO: load:1.80 valid_run:3634.74 task_valid:3508.21 collect_output:98.85

====================================================================================================
SGG eval:     R @ 50: 0.6664;     R @ 100: 0.6972;     R @ 500: 0.7180;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4350;    mR @ 100: 0.4763;    mR @ 500: 0.5016;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.7500) (covering:0.2857) (eating:0.8235) (flying in:0.8182) (growing on:0.1250) (hanging from:0.3452) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7611) (standing on:0.5147) (using:0.5500) (walking in:0.0000) (walking on:0.6216) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6664;     R @ 100: 0.6972;     R @ 500: 0.7180;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4350;    mR @ 100: 0.4763;    mR @ 500: 0.5016;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.7500) (covering:0.2857) (eating:0.8235) (flying in:0.8182) (growing on:0.1250) (hanging from:0.3452) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7611) (standing on:0.5147) (using:0.5500) (walking in:0.0000) (walking on:0.6216) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-13 18:00:15 - train.py[line:487] - INFO: 0.6972480774127834
2022-10-13 18:00:15 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 18:00:15 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.324 | loss_v1 0 | loss_v2 0 | nll_loss 0.176 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.697248 | ppl 1.13 | vqa_score 0.4966 | wps 118.4 | wpb 89.9 | bsz 30 | num_updates 6000 | best_R@100 0.704053
2022-10-13 18:00:15 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2022-10-13 18:00:15 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-13 18:00:21 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-13 18:00:23 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.6972480774127834) (writing took 8.651164073031396 seconds)
2022-10-13 18:00:35 - progress_bar.py[line:274] - INFO: epoch 001:   6016 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=0.3, ups=0, wpb=110, bsz=40, num_updates=6010, lr=4.93762e-05, gnorm=0.923, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=29556
2022-10-13 18:00:46 - progress_bar.py[line:274] - INFO: epoch 001:   6026 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.2, ups=0.9, wpb=110.6, bsz=40, num_updates=6020, lr=4.93717e-05, gnorm=0.783, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29567
2022-10-13 18:00:57 - progress_bar.py[line:274] - INFO: epoch 001:   6036 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=96.6, ups=0.88, wpb=109.6, bsz=40, num_updates=6030, lr=4.93672e-05, gnorm=0.822, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29578
2022-10-13 18:01:08 - progress_bar.py[line:274] - INFO: epoch 001:   6046 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=101.5, ups=0.91, wpb=111.7, bsz=40, num_updates=6040, lr=4.93627e-05, gnorm=0.859, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29589
2022-10-13 18:01:20 - progress_bar.py[line:274] - INFO: epoch 001:   6056 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.9, ups=0.9, wpb=110.3, bsz=40, num_updates=6050, lr=4.93582e-05, gnorm=0.863, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=29601
2022-10-13 18:01:30 - progress_bar.py[line:274] - INFO: epoch 001:   6066 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100, ups=0.91, wpb=109.5, bsz=40, num_updates=6060, lr=4.93537e-05, gnorm=0.821, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29612
2022-10-13 18:01:42 - progress_bar.py[line:274] - INFO: epoch 001:   6076 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.8, ups=0.88, wpb=109.4, bsz=40, num_updates=6070, lr=4.93492e-05, gnorm=0.918, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=29623
2022-10-13 18:01:53 - progress_bar.py[line:274] - INFO: epoch 001:   6086 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100, ups=0.9, wpb=111.3, bsz=40, num_updates=6080, lr=4.93447e-05, gnorm=0.854, clip=30, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=29634
2022-10-13 18:02:04 - progress_bar.py[line:274] - INFO: epoch 001:   6096 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.4, ups=0.9, wpb=111.2, bsz=40, num_updates=6090, lr=4.93402e-05, gnorm=0.793, clip=0, loss_scale=2048, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29645
2022-10-13 18:02:07 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-13 18:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   6107 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=92.2, ups=0.83, wpb=110.6, bsz=40, num_updates=6100, lr=4.93357e-05, gnorm=0.809, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=29657
2022-10-13 18:02:27 - progress_bar.py[line:274] - INFO: epoch 001:   6117 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=6110, lr=4.93312e-05, gnorm=0.965, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29669
2022-10-13 18:02:38 - progress_bar.py[line:274] - INFO: epoch 001:   6127 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=6120, lr=4.93267e-05, gnorm=1.078, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29680
2022-10-13 18:02:50 - progress_bar.py[line:274] - INFO: epoch 001:   6137 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.3, ups=0.9, wpb=111.6, bsz=40, num_updates=6130, lr=4.93222e-05, gnorm=0.735, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29691
2022-10-13 18:03:01 - progress_bar.py[line:274] - INFO: epoch 001:   6147 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=6140, lr=4.93177e-05, gnorm=0.732, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29702
2022-10-13 18:03:12 - progress_bar.py[line:274] - INFO: epoch 001:   6157 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=6150, lr=4.93132e-05, gnorm=0.822, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=29713
2022-10-13 18:03:23 - progress_bar.py[line:274] - INFO: epoch 001:   6167 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=103.5, ups=0.94, wpb=110.4, bsz=40, num_updates=6160, lr=4.93087e-05, gnorm=0.823, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=29724
2022-10-13 18:03:34 - progress_bar.py[line:274] - INFO: epoch 001:   6177 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.3, ups=0.87, wpb=110.2, bsz=40, num_updates=6170, lr=4.93041e-05, gnorm=0.892, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29735
2022-10-13 18:03:45 - progress_bar.py[line:274] - INFO: epoch 001:   6187 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.3, ups=0.89, wpb=110.8, bsz=40, num_updates=6180, lr=4.92996e-05, gnorm=0.811, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29747
2022-10-13 18:03:57 - progress_bar.py[line:274] - INFO: epoch 001:   6197 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96, ups=0.88, wpb=109.6, bsz=40, num_updates=6190, lr=4.92951e-05, gnorm=0.876, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29758
2022-10-13 18:04:08 - progress_bar.py[line:274] - INFO: epoch 001:   6207 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=6200, lr=4.92906e-05, gnorm=0.875, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29769
2022-10-13 18:04:20 - progress_bar.py[line:274] - INFO: epoch 001:   6217 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.4, ups=0.88, wpb=111, bsz=40, num_updates=6210, lr=4.92861e-05, gnorm=0.804, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=29781
2022-10-13 18:04:31 - progress_bar.py[line:274] - INFO: epoch 001:   6227 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.7, ups=0.91, wpb=109.8, bsz=40, num_updates=6220, lr=4.92816e-05, gnorm=0.742, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29792
2022-10-13 18:04:42 - progress_bar.py[line:274] - INFO: epoch 001:   6237 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.6, ups=0.89, wpb=109.6, bsz=40, num_updates=6230, lr=4.92771e-05, gnorm=0.844, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29803
2022-10-13 18:04:45 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 18:04:55 - progress_bar.py[line:274] - INFO: epoch 001:   6248 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=87, ups=0.79, wpb=110, bsz=40, num_updates=6240, lr=4.92726e-05, gnorm=0.812, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=29816
2022-10-13 18:05:06 - progress_bar.py[line:274] - INFO: epoch 001:   6258 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100, ups=0.91, wpb=109.5, bsz=40, num_updates=6250, lr=4.92681e-05, gnorm=0.936, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29827
2022-10-13 18:05:17 - progress_bar.py[line:274] - INFO: epoch 001:   6268 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.1, ups=0.87, wpb=109.4, bsz=40, num_updates=6260, lr=4.92636e-05, gnorm=0.883, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29838
2022-10-13 18:05:28 - progress_bar.py[line:274] - INFO: epoch 001:   6278 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.8, ups=0.9, wpb=111.2, bsz=40, num_updates=6270, lr=4.92591e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=29849
2022-10-13 18:05:40 - progress_bar.py[line:274] - INFO: epoch 001:   6288 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=6280, lr=4.92546e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29861
2022-10-13 18:05:51 - progress_bar.py[line:274] - INFO: epoch 001:   6298 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.6, ups=0.87, wpb=109.5, bsz=40, num_updates=6290, lr=4.92501e-05, gnorm=0.884, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29872
2022-10-13 18:06:03 - progress_bar.py[line:274] - INFO: epoch 001:   6308 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=94.8, ups=0.87, wpb=109.4, bsz=40, num_updates=6300, lr=4.92456e-05, gnorm=0.789, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29884
2022-10-13 18:06:14 - progress_bar.py[line:274] - INFO: epoch 001:   6318 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.2, ups=0.91, wpb=109.7, bsz=40, num_updates=6310, lr=4.92411e-05, gnorm=0.827, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=29895
2022-10-13 18:06:25 - progress_bar.py[line:274] - INFO: epoch 001:   6328 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=6320, lr=4.92366e-05, gnorm=0.831, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29906
2022-10-13 18:06:36 - progress_bar.py[line:274] - INFO: epoch 001:   6338 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=6330, lr=4.92321e-05, gnorm=0.834, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29917
2022-10-13 18:06:48 - progress_bar.py[line:274] - INFO: epoch 001:   6348 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=6340, lr=4.92276e-05, gnorm=0.741, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29929
2022-10-13 18:06:59 - progress_bar.py[line:274] - INFO: epoch 001:   6358 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.8, ups=0.91, wpb=109.1, bsz=40, num_updates=6350, lr=4.92231e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=29940
2022-10-13 18:07:10 - progress_bar.py[line:274] - INFO: epoch 001:   6368 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.4, ups=0.89, wpb=109.3, bsz=40, num_updates=6360, lr=4.92186e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29951
2022-10-13 18:07:21 - progress_bar.py[line:274] - INFO: epoch 001:   6378 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.6, ups=0.88, wpb=110.7, bsz=40, num_updates=6370, lr=4.92141e-05, gnorm=0.781, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29962
2022-10-13 18:07:32 - progress_bar.py[line:274] - INFO: epoch 001:   6388 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.6, ups=0.89, wpb=109.6, bsz=40, num_updates=6380, lr=4.92096e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29974
2022-10-13 18:07:43 - progress_bar.py[line:274] - INFO: epoch 001:   6398 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=102.3, ups=0.93, wpb=110.4, bsz=40, num_updates=6390, lr=4.92051e-05, gnorm=0.711, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29984
2022-10-13 18:07:55 - progress_bar.py[line:274] - INFO: epoch 001:   6408 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.6, ups=0.88, wpb=111.1, bsz=40, num_updates=6400, lr=4.92006e-05, gnorm=0.831, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29996
2022-10-13 18:08:06 - progress_bar.py[line:274] - INFO: epoch 001:   6418 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=6410, lr=4.91961e-05, gnorm=0.919, clip=40, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=30007
2022-10-13 18:08:17 - progress_bar.py[line:274] - INFO: epoch 001:   6428 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=6420, lr=4.91916e-05, gnorm=0.83, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30018
2022-10-13 18:08:28 - progress_bar.py[line:274] - INFO: epoch 001:   6438 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.8, ups=0.9, wpb=109.7, bsz=40, num_updates=6430, lr=4.9187e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30029
2022-10-13 18:08:39 - progress_bar.py[line:274] - INFO: epoch 001:   6448 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=101.4, ups=0.91, wpb=110.9, bsz=40, num_updates=6440, lr=4.91825e-05, gnorm=0.848, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30040
2022-10-13 18:08:50 - progress_bar.py[line:274] - INFO: epoch 001:   6458 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=94.3, ups=0.87, wpb=108.5, bsz=40, num_updates=6450, lr=4.9178e-05, gnorm=0.781, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30052
2022-10-13 18:09:01 - progress_bar.py[line:274] - INFO: epoch 001:   6468 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=102.1, ups=0.91, wpb=111.8, bsz=40, num_updates=6460, lr=4.91735e-05, gnorm=0.725, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30062
2022-10-13 18:09:13 - progress_bar.py[line:274] - INFO: epoch 001:   6478 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.4, ups=0.87, wpb=110, bsz=40, num_updates=6470, lr=4.9169e-05, gnorm=0.853, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30074
2022-10-13 18:09:24 - progress_bar.py[line:274] - INFO: epoch 001:   6488 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.1, ups=0.89, wpb=111.4, bsz=40, num_updates=6480, lr=4.91645e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30085
2022-10-13 18:09:35 - progress_bar.py[line:274] - INFO: epoch 001:   6498 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.3, ups=0.91, wpb=109.8, bsz=40, num_updates=6490, lr=4.916e-05, gnorm=0.828, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30096
2022-10-13 18:09:46 - progress_bar.py[line:274] - INFO: epoch 001:   6508 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=102.1, ups=0.93, wpb=110.2, bsz=40, num_updates=6500, lr=4.91555e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30107
2022-10-13 18:09:57 - progress_bar.py[line:274] - INFO: epoch 001:   6518 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=6510, lr=4.9151e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30118
2022-10-13 18:10:08 - progress_bar.py[line:274] - INFO: epoch 001:   6528 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.4, ups=0.9, wpb=110.4, bsz=40, num_updates=6520, lr=4.91465e-05, gnorm=0.849, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30129
2022-10-13 18:10:20 - progress_bar.py[line:274] - INFO: epoch 001:   6538 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=6530, lr=4.9142e-05, gnorm=0.938, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30141
2022-10-13 18:10:31 - progress_bar.py[line:274] - INFO: epoch 001:   6548 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.4, ups=0.89, wpb=109.7, bsz=40, num_updates=6540, lr=4.91375e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30152
2022-10-13 18:10:42 - progress_bar.py[line:274] - INFO: epoch 001:   6558 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.4, ups=0.88, wpb=110.8, bsz=40, num_updates=6550, lr=4.9133e-05, gnorm=0.693, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30163
2022-10-13 18:10:53 - progress_bar.py[line:274] - INFO: epoch 001:   6568 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.4, ups=0.9, wpb=109.2, bsz=40, num_updates=6560, lr=4.91285e-05, gnorm=0.807, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30174
2022-10-13 18:11:05 - progress_bar.py[line:274] - INFO: epoch 001:   6578 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=6570, lr=4.9124e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30186
2022-10-13 18:11:16 - progress_bar.py[line:274] - INFO: epoch 001:   6588 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.1, ups=0.9, wpb=110.1, bsz=40, num_updates=6580, lr=4.91195e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30197
2022-10-13 18:11:27 - progress_bar.py[line:274] - INFO: epoch 001:   6598 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.2, ups=0.91, wpb=109.4, bsz=40, num_updates=6590, lr=4.9115e-05, gnorm=0.855, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30208
2022-10-13 18:11:38 - progress_bar.py[line:274] - INFO: epoch 001:   6608 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=6600, lr=4.91105e-05, gnorm=0.815, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30219
2022-10-13 18:11:49 - progress_bar.py[line:274] - INFO: epoch 001:   6618 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=6610, lr=4.9106e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=30230
2022-10-13 18:12:00 - progress_bar.py[line:274] - INFO: epoch 001:   6628 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.4, ups=0.91, wpb=110.6, bsz=40, num_updates=6620, lr=4.91015e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30242
2022-10-13 18:12:12 - progress_bar.py[line:274] - INFO: epoch 001:   6638 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.5, ups=0.89, wpb=109.4, bsz=40, num_updates=6630, lr=4.9097e-05, gnorm=0.861, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30253
2022-10-13 18:12:23 - progress_bar.py[line:274] - INFO: epoch 001:   6648 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.6, ups=0.87, wpb=110.1, bsz=40, num_updates=6640, lr=4.90925e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30264
2022-10-13 18:12:34 - progress_bar.py[line:274] - INFO: epoch 001:   6658 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=6650, lr=4.9088e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30276
2022-10-13 18:12:45 - progress_bar.py[line:274] - INFO: epoch 001:   6668 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.5, ups=0.92, wpb=109.7, bsz=40, num_updates=6660, lr=4.90835e-05, gnorm=0.749, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30287
2022-10-13 18:12:56 - progress_bar.py[line:274] - INFO: epoch 001:   6678 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.5, ups=0.91, wpb=110.1, bsz=40, num_updates=6670, lr=4.9079e-05, gnorm=0.801, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30297
2022-10-13 18:13:07 - progress_bar.py[line:274] - INFO: epoch 001:   6688 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=6680, lr=4.90744e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30309
2022-10-13 18:13:19 - progress_bar.py[line:274] - INFO: epoch 001:   6698 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.8, ups=0.89, wpb=109.1, bsz=40, num_updates=6690, lr=4.90699e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30320
2022-10-13 18:13:30 - progress_bar.py[line:274] - INFO: epoch 001:   6708 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.9, ups=0.88, wpb=110.3, bsz=40, num_updates=6700, lr=4.90654e-05, gnorm=0.846, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30331
2022-10-13 18:13:41 - progress_bar.py[line:274] - INFO: epoch 001:   6718 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.1, ups=0.89, wpb=110.3, bsz=40, num_updates=6710, lr=4.90609e-05, gnorm=0.911, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30342
2022-10-13 18:13:52 - progress_bar.py[line:274] - INFO: epoch 001:   6728 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101.6, ups=0.91, wpb=111.2, bsz=40, num_updates=6720, lr=4.90564e-05, gnorm=0.744, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30353
2022-10-13 18:14:04 - progress_bar.py[line:274] - INFO: epoch 001:   6738 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.2, ups=0.88, wpb=109.4, bsz=40, num_updates=6730, lr=4.90519e-05, gnorm=0.818, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30365
2022-10-13 18:14:15 - progress_bar.py[line:274] - INFO: epoch 001:   6748 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.3, ups=0.87, wpb=110.4, bsz=40, num_updates=6740, lr=4.90474e-05, gnorm=0.792, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30376
2022-10-13 18:14:26 - progress_bar.py[line:274] - INFO: epoch 001:   6758 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=103.5, ups=0.94, wpb=109.9, bsz=40, num_updates=6750, lr=4.90429e-05, gnorm=0.854, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30387
2022-10-13 18:14:37 - progress_bar.py[line:274] - INFO: epoch 001:   6768 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=6760, lr=4.90384e-05, gnorm=0.737, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30398
2022-10-13 18:14:48 - progress_bar.py[line:274] - INFO: epoch 001:   6778 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=6770, lr=4.90339e-05, gnorm=0.784, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30409
2022-10-13 18:14:54 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 18:15:00 - progress_bar.py[line:274] - INFO: epoch 001:   6789 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=88.6, ups=0.82, wpb=108.5, bsz=40, num_updates=6780, lr=4.90294e-05, gnorm=0.855, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=30422
2022-10-13 18:15:12 - progress_bar.py[line:274] - INFO: epoch 001:   6799 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=6790, lr=4.90249e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30433
2022-10-13 18:15:23 - progress_bar.py[line:274] - INFO: epoch 001:   6809 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.2, ups=0.87, wpb=110.2, bsz=40, num_updates=6800, lr=4.90204e-05, gnorm=0.849, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30444
2022-10-13 18:15:34 - progress_bar.py[line:274] - INFO: epoch 001:   6819 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=6810, lr=4.90159e-05, gnorm=0.788, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30455
2022-10-13 18:15:45 - progress_bar.py[line:274] - INFO: epoch 001:   6829 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.1, ups=0.9, wpb=108.9, bsz=40, num_updates=6820, lr=4.90114e-05, gnorm=0.881, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30466
2022-10-13 18:15:56 - progress_bar.py[line:274] - INFO: epoch 001:   6839 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.7, ups=0.9, wpb=109.8, bsz=40, num_updates=6830, lr=4.90069e-05, gnorm=0.839, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30478
2022-10-13 18:16:08 - progress_bar.py[line:274] - INFO: epoch 001:   6849 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99, ups=0.9, wpb=110, bsz=40, num_updates=6840, lr=4.90024e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30489
2022-10-13 18:16:19 - progress_bar.py[line:274] - INFO: epoch 001:   6859 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.7, ups=0.91, wpb=110.3, bsz=40, num_updates=6850, lr=4.89979e-05, gnorm=0.865, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30500
2022-10-13 18:16:30 - progress_bar.py[line:274] - INFO: epoch 001:   6869 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=101.3, ups=0.91, wpb=110.8, bsz=40, num_updates=6860, lr=4.89934e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30511
2022-10-13 18:16:41 - progress_bar.py[line:274] - INFO: epoch 001:   6879 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.9, ups=0.88, wpb=110.1, bsz=40, num_updates=6870, lr=4.89889e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30522
2022-10-13 18:16:52 - progress_bar.py[line:274] - INFO: epoch 001:   6889 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.7, ups=0.88, wpb=111.3, bsz=40, num_updates=6880, lr=4.89844e-05, gnorm=0.699, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30533
2022-10-13 18:17:04 - progress_bar.py[line:274] - INFO: epoch 001:   6899 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.2, ups=0.87, wpb=110.8, bsz=40, num_updates=6890, lr=4.89799e-05, gnorm=0.883, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30545
2022-10-13 18:17:15 - progress_bar.py[line:274] - INFO: epoch 001:   6909 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=6900, lr=4.89754e-05, gnorm=0.744, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30556
2022-10-13 18:17:26 - progress_bar.py[line:274] - INFO: epoch 001:   6919 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.8, ups=0.91, wpb=110.4, bsz=40, num_updates=6910, lr=4.89709e-05, gnorm=0.895, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30567
2022-10-13 18:17:37 - progress_bar.py[line:274] - INFO: epoch 001:   6929 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=6920, lr=4.89664e-05, gnorm=0.931, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30578
2022-10-13 18:17:48 - progress_bar.py[line:274] - INFO: epoch 001:   6939 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.9, ups=0.9, wpb=110.8, bsz=40, num_updates=6930, lr=4.89619e-05, gnorm=0.827, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30589
2022-10-13 18:17:59 - progress_bar.py[line:274] - INFO: epoch 001:   6949 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.9, ups=0.9, wpb=110.6, bsz=40, num_updates=6940, lr=4.89573e-05, gnorm=0.826, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30600
2022-10-13 18:18:11 - progress_bar.py[line:274] - INFO: epoch 001:   6959 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.4, ups=0.86, wpb=110.4, bsz=40, num_updates=6950, lr=4.89528e-05, gnorm=0.783, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=30612
2022-10-13 18:18:22 - progress_bar.py[line:274] - INFO: epoch 001:   6969 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.8, ups=0.89, wpb=111.9, bsz=40, num_updates=6960, lr=4.89483e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30623
2022-10-13 18:18:33 - progress_bar.py[line:274] - INFO: epoch 001:   6979 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=6970, lr=4.89438e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30634
2022-10-13 18:18:44 - progress_bar.py[line:274] - INFO: epoch 001:   6989 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=6980, lr=4.89393e-05, gnorm=0.852, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30645
2022-10-13 18:18:55 - progress_bar.py[line:274] - INFO: epoch 001:   6999 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.3, ups=0.91, wpb=109.9, bsz=40, num_updates=6990, lr=4.89348e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30656
2022-10-13 18:19:06 - progress_bar.py[line:274] - INFO: epoch 001:   7009 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.3, ups=0.91, wpb=111, bsz=40, num_updates=7000, lr=4.89303e-05, gnorm=0.756, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30667
2022-10-13 18:19:06 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 18:19:08 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 18:19:08 - train.py[line:551] - INFO: load:1.26 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 18:21:41 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 18:21:41 - train.py[line:551] - INFO: load:1.28 valid_run:153.26 task_valid:149.86 collect_output:2.34
2022-10-13 18:24:10 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 18:24:10 - train.py[line:551] - INFO: load:1.31 valid_run:302.47 task_valid:293.97 collect_output:6.38
2022-10-13 18:26:43 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 18:26:43 - train.py[line:551] - INFO: load:1.33 valid_run:455.62 task_valid:438.16 collect_output:14.28
2022-10-13 18:29:13 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 18:29:13 - train.py[line:551] - INFO: load:1.36 valid_run:605.46 task_valid:584.33 collect_output:16.88
2022-10-13 18:31:46 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 18:31:46 - train.py[line:551] - INFO: load:1.38 valid_run:758.49 task_valid:732.72 collect_output:20.46
2022-10-13 18:34:19 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 18:34:19 - train.py[line:551] - INFO: load:1.41 valid_run:910.59 task_valid:879.13 collect_output:25.07
2022-10-13 18:36:52 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 18:36:52 - train.py[line:551] - INFO: load:1.43 valid_run:1064.19 task_valid:1026.37 collect_output:30.34
2022-10-13 18:39:24 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 18:39:24 - train.py[line:551] - INFO: load:1.46 valid_run:1215.67 task_valid:1168.34 collect_output:38.79
2022-10-13 18:41:54 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 18:41:54 - train.py[line:551] - INFO: load:1.48 valid_run:1365.65 task_valid:1313.86 collect_output:42.20
2022-10-13 18:44:23 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 18:44:23 - train.py[line:551] - INFO: load:1.51 valid_run:1514.39 task_valid:1457.75 collect_output:46.01
2022-10-13 18:46:53 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 18:46:53 - train.py[line:551] - INFO: load:1.53 valid_run:1664.63 task_valid:1603.67 collect_output:49.30
2022-10-13 18:49:24 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 18:49:24 - train.py[line:551] - INFO: load:1.56 valid_run:1815.45 task_valid:1749.88 collect_output:52.82
2022-10-13 18:51:55 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 18:51:55 - train.py[line:551] - INFO: load:1.58 valid_run:1966.20 task_valid:1893.33 collect_output:58.95
2022-10-13 18:54:26 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 18:54:26 - train.py[line:551] - INFO: load:1.61 valid_run:2117.74 task_valid:2040.21 collect_output:62.45
2022-10-13 18:56:58 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 18:56:58 - train.py[line:551] - INFO: load:1.63 valid_run:2269.06 task_valid:2188.09 collect_output:64.69
2022-10-13 18:59:28 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 18:59:28 - train.py[line:551] - INFO: load:1.66 valid_run:2419.74 task_valid:2333.38 collect_output:68.92
2022-10-13 19:02:01 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 19:02:01 - train.py[line:551] - INFO: load:1.70 valid_run:2572.16 task_valid:2480.48 collect_output:72.97
2022-10-13 19:04:33 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 19:04:33 - train.py[line:551] - INFO: load:1.72 valid_run:2723.89 task_valid:2628.85 collect_output:75.08
2022-10-13 19:07:02 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 19:07:02 - train.py[line:551] - INFO: load:1.75 valid_run:2873.22 task_valid:2772.02 collect_output:80.05
2022-10-13 19:09:34 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 19:09:34 - train.py[line:551] - INFO: load:1.77 valid_run:3024.59 task_valid:2918.92 collect_output:83.23
2022-10-13 19:12:06 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 19:12:06 - train.py[line:551] - INFO: load:1.81 valid_run:3177.10 task_valid:3065.22 collect_output:88.30
2022-10-13 19:14:36 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 19:14:36 - train.py[line:551] - INFO: load:1.83 valid_run:3327.35 task_valid:3211.19 collect_output:91.40
2022-10-13 19:17:09 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 19:17:09 - train.py[line:551] - INFO: load:1.86 valid_run:3479.71 task_valid:3359.16 collect_output:94.62
2022-10-13 19:19:41 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 19:19:41 - train.py[line:551] - INFO: load:1.89 valid_run:3631.87 task_valid:3506.97 collect_output:97.88

====================================================================================================
SGG eval:     R @ 50: 0.6671;     R @ 100: 0.6969;     R @ 500: 0.7131;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4340;    mR @ 100: 0.4790;    mR @ 500: 0.4939;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.7500) (covering:0.2857) (eating:0.8235) (flying in:1.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9167) (playing:0.0000) (riding:0.9500) (says:0.0000) (sitting on:0.7687) (standing on:0.5097) (using:0.5500) (walking in:0.0000) (walking on:0.6486) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-13 19:22:13 - train.py[line:487] - INFO: 0.6969420168067226

====================================================================================================
SGG eval:     R @ 50: 0.6671;     R @ 100: 0.6969;     R @ 500: 0.7131;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4340;    mR @ 100: 0.4790;    mR @ 500: 0.4939;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.7500) (covering:0.2857) (eating:0.8235) (flying in:1.0000) (growing on:0.1250) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9167) (playing:0.0000) (riding:0.9500) (says:0.0000) (sitting on:0.7687) (standing on:0.5097) (using:0.5500) (walking in:0.0000) (walking on:0.6486) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-13 19:22:13 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 19:22:13 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.331 | loss_v1 0 | loss_v2 0 | nll_loss 0.18 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.696942 | ppl 1.13 | vqa_score 0.4944 | wps 118.5 | wpb 89.9 | bsz 30 | num_updates 7000 | best_R@100 0.704053
2022-10-13 19:22:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 7000 updates
2022-10-13 19:22:13 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-13 19:22:19 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-13 19:22:22 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 0.6969420168067226) (writing took 8.442800279241055 seconds)
2022-10-13 19:22:33 - progress_bar.py[line:274] - INFO: epoch 001:   7019 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=0.3, ups=0, wpb=112, bsz=40, num_updates=7010, lr=4.89258e-05, gnorm=0.849, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34474
2022-10-13 19:22:44 - progress_bar.py[line:274] - INFO: epoch 001:   7029 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=7020, lr=4.89213e-05, gnorm=0.841, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34486
2022-10-13 19:22:56 - progress_bar.py[line:274] - INFO: epoch 001:   7039 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.1, ups=0.9, wpb=107.9, bsz=40, num_updates=7030, lr=4.89168e-05, gnorm=0.898, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34497
2022-10-13 19:23:07 - progress_bar.py[line:274] - INFO: epoch 001:   7049 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.2, ups=0.88, wpb=110.7, bsz=40, num_updates=7040, lr=4.89123e-05, gnorm=0.754, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=34508
2022-10-13 19:23:18 - progress_bar.py[line:274] - INFO: epoch 001:   7059 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=7050, lr=4.89078e-05, gnorm=0.756, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34519
2022-10-13 19:23:30 - progress_bar.py[line:274] - INFO: epoch 001:   7069 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=94.2, ups=0.86, wpb=109.9, bsz=40, num_updates=7060, lr=4.89033e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=34531
2022-10-13 19:23:41 - progress_bar.py[line:274] - INFO: epoch 001:   7079 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101.1, ups=0.9, wpb=112, bsz=40, num_updates=7070, lr=4.88988e-05, gnorm=0.766, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34542
2022-10-13 19:23:52 - progress_bar.py[line:274] - INFO: epoch 001:   7089 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=7080, lr=4.88943e-05, gnorm=0.748, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34553
2022-10-13 19:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   7099 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.8, ups=0.88, wpb=110.9, bsz=40, num_updates=7090, lr=4.88898e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34564
2022-10-13 19:24:15 - progress_bar.py[line:274] - INFO: epoch 001:   7109 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=7100, lr=4.88853e-05, gnorm=0.861, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34576
2022-10-13 19:24:25 - progress_bar.py[line:274] - INFO: epoch 001:   7119 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.7, ups=0.91, wpb=109.2, bsz=40, num_updates=7110, lr=4.88808e-05, gnorm=0.809, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34587
2022-10-13 19:24:37 - progress_bar.py[line:274] - INFO: epoch 001:   7129 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.4, ups=0.88, wpb=110.8, bsz=40, num_updates=7120, lr=4.88763e-05, gnorm=0.827, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34598
2022-10-13 19:24:48 - progress_bar.py[line:274] - INFO: epoch 001:   7139 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=7130, lr=4.88718e-05, gnorm=0.862, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34609
2022-10-13 19:24:59 - progress_bar.py[line:274] - INFO: epoch 001:   7149 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.6, ups=0.9, wpb=109.2, bsz=40, num_updates=7140, lr=4.88673e-05, gnorm=0.716, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34620
2022-10-13 19:25:10 - progress_bar.py[line:274] - INFO: epoch 001:   7159 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=102.7, ups=0.93, wpb=110.9, bsz=40, num_updates=7150, lr=4.88628e-05, gnorm=0.831, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34631
2022-10-13 19:25:21 - progress_bar.py[line:274] - INFO: epoch 001:   7169 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.7, ups=0.87, wpb=110.3, bsz=40, num_updates=7160, lr=4.88583e-05, gnorm=0.951, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34643
2022-10-13 19:25:33 - progress_bar.py[line:274] - INFO: epoch 001:   7179 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=7170, lr=4.88538e-05, gnorm=0.803, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34654
2022-10-13 19:25:44 - progress_bar.py[line:274] - INFO: epoch 001:   7189 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.3, ups=0.89, wpb=111.5, bsz=40, num_updates=7180, lr=4.88493e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=34665
2022-10-13 19:25:55 - progress_bar.py[line:274] - INFO: epoch 001:   7199 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.4, ups=0.87, wpb=111.1, bsz=40, num_updates=7190, lr=4.88448e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34677
2022-10-13 19:26:06 - progress_bar.py[line:274] - INFO: epoch 001:   7209 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.4, ups=0.91, wpb=109.5, bsz=40, num_updates=7200, lr=4.88402e-05, gnorm=0.828, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34688
2022-10-13 19:26:17 - progress_bar.py[line:274] - INFO: epoch 001:   7219 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=102.8, ups=0.93, wpb=111.1, bsz=40, num_updates=7210, lr=4.88357e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=34698
2022-10-13 19:26:28 - progress_bar.py[line:274] - INFO: epoch 001:   7229 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=101.2, ups=0.91, wpb=110.7, bsz=40, num_updates=7220, lr=4.88312e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34709
2022-10-13 19:26:39 - progress_bar.py[line:274] - INFO: epoch 001:   7239 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=7230, lr=4.88267e-05, gnorm=0.813, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34721
2022-10-13 19:26:50 - progress_bar.py[line:274] - INFO: epoch 001:   7249 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101.6, ups=0.91, wpb=111.1, bsz=40, num_updates=7240, lr=4.88222e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34731
2022-10-13 19:27:02 - progress_bar.py[line:274] - INFO: epoch 001:   7259 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.4, ups=0.88, wpb=111.1, bsz=40, num_updates=7250, lr=4.88177e-05, gnorm=0.674, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34743
2022-10-13 19:27:13 - progress_bar.py[line:274] - INFO: epoch 001:   7269 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=7260, lr=4.88132e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34754
2022-10-13 19:27:24 - progress_bar.py[line:274] - INFO: epoch 001:   7279 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=7270, lr=4.88087e-05, gnorm=0.827, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34765
2022-10-13 19:27:35 - progress_bar.py[line:274] - INFO: epoch 001:   7289 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.6, ups=0.9, wpb=109.2, bsz=40, num_updates=7280, lr=4.88042e-05, gnorm=0.769, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34776
2022-10-13 19:27:46 - progress_bar.py[line:274] - INFO: epoch 001:   7299 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=7290, lr=4.87997e-05, gnorm=0.778, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34788
2022-10-13 19:27:58 - progress_bar.py[line:274] - INFO: epoch 001:   7309 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.6, ups=0.88, wpb=110.9, bsz=40, num_updates=7300, lr=4.87952e-05, gnorm=0.735, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34799
2022-10-13 19:28:09 - progress_bar.py[line:274] - INFO: epoch 001:   7319 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.3, ups=0.91, wpb=109.7, bsz=40, num_updates=7310, lr=4.87907e-05, gnorm=0.801, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34810
2022-10-13 19:28:20 - progress_bar.py[line:274] - INFO: epoch 001:   7329 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.7, ups=0.89, wpb=111.8, bsz=40, num_updates=7320, lr=4.87862e-05, gnorm=0.754, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34821
2022-10-13 19:28:31 - progress_bar.py[line:274] - INFO: epoch 001:   7339 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.7, ups=0.9, wpb=111.5, bsz=40, num_updates=7330, lr=4.87817e-05, gnorm=0.823, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34832
2022-10-13 19:28:40 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 19:28:43 - progress_bar.py[line:274] - INFO: epoch 001:   7350 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=89.7, ups=0.81, wpb=111.3, bsz=40, num_updates=7340, lr=4.87772e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=34845
2022-10-13 19:28:55 - progress_bar.py[line:274] - INFO: epoch 001:   7360 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=7350, lr=4.87727e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34856
2022-10-13 19:29:06 - progress_bar.py[line:274] - INFO: epoch 001:   7370 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.7, ups=0.88, wpb=112.3, bsz=40, num_updates=7360, lr=4.87682e-05, gnorm=0.828, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34867
2022-10-13 19:29:17 - progress_bar.py[line:274] - INFO: epoch 001:   7380 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.9, ups=0.9, wpb=111.7, bsz=40, num_updates=7370, lr=4.87637e-05, gnorm=0.801, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34878
2022-10-13 19:29:28 - progress_bar.py[line:274] - INFO: epoch 001:   7390 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=7380, lr=4.87592e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=34890
2022-10-13 19:29:40 - progress_bar.py[line:274] - INFO: epoch 001:   7400 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.4, ups=0.87, wpb=110.8, bsz=40, num_updates=7390, lr=4.87547e-05, gnorm=0.795, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34901
2022-10-13 19:29:51 - progress_bar.py[line:274] - INFO: epoch 001:   7410 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=7400, lr=4.87502e-05, gnorm=0.773, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34912
2022-10-13 19:30:02 - progress_bar.py[line:274] - INFO: epoch 001:   7420 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=7410, lr=4.87457e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34923
2022-10-13 19:30:14 - progress_bar.py[line:274] - INFO: epoch 001:   7430 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.5, ups=0.87, wpb=109.9, bsz=40, num_updates=7420, lr=4.87412e-05, gnorm=0.813, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34935
2022-10-13 19:30:25 - progress_bar.py[line:274] - INFO: epoch 001:   7440 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=7430, lr=4.87367e-05, gnorm=0.796, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34946
2022-10-13 19:30:36 - progress_bar.py[line:274] - INFO: epoch 001:   7450 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.6, ups=0.9, wpb=109.3, bsz=40, num_updates=7440, lr=4.87322e-05, gnorm=0.858, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34957
2022-10-13 19:30:47 - progress_bar.py[line:274] - INFO: epoch 001:   7460 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=102.3, ups=0.93, wpb=110.3, bsz=40, num_updates=7450, lr=4.87276e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34968
2022-10-13 19:30:58 - progress_bar.py[line:274] - INFO: epoch 001:   7470 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=7460, lr=4.87231e-05, gnorm=0.826, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34979
2022-10-13 19:31:10 - progress_bar.py[line:274] - INFO: epoch 001:   7480 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=7470, lr=4.87186e-05, gnorm=0.735, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=34991
2022-10-13 19:31:21 - progress_bar.py[line:274] - INFO: epoch 001:   7490 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=7480, lr=4.87141e-05, gnorm=0.738, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35002
2022-10-13 19:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   7500 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=102.6, ups=0.93, wpb=110.9, bsz=40, num_updates=7490, lr=4.87096e-05, gnorm=0.703, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=35013
2022-10-13 19:31:43 - progress_bar.py[line:274] - INFO: epoch 001:   7510 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.5, ups=0.88, wpb=110, bsz=40, num_updates=7500, lr=4.87051e-05, gnorm=0.782, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35024
2022-10-13 19:31:54 - progress_bar.py[line:274] - INFO: epoch 001:   7520 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=7510, lr=4.87006e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35035
2022-10-13 19:32:05 - progress_bar.py[line:274] - INFO: epoch 001:   7530 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.7, ups=0.9, wpb=109.5, bsz=40, num_updates=7520, lr=4.86961e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35047
2022-10-13 19:32:17 - progress_bar.py[line:274] - INFO: epoch 001:   7540 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.4, ups=0.88, wpb=111.9, bsz=40, num_updates=7530, lr=4.86916e-05, gnorm=0.703, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35058
2022-10-13 19:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   7550 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=101.8, ups=0.93, wpb=109.5, bsz=40, num_updates=7540, lr=4.86871e-05, gnorm=0.769, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35069
2022-10-13 19:32:39 - progress_bar.py[line:274] - INFO: epoch 001:   7560 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.9, ups=0.89, wpb=108.7, bsz=40, num_updates=7550, lr=4.86826e-05, gnorm=0.786, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35080
2022-10-13 19:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   7570 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=101.4, ups=0.91, wpb=110.8, bsz=40, num_updates=7560, lr=4.86781e-05, gnorm=0.841, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35091
2022-10-13 19:33:01 - progress_bar.py[line:274] - INFO: epoch 001:   7580 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.6, ups=0.89, wpb=109.7, bsz=40, num_updates=7570, lr=4.86736e-05, gnorm=0.825, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35102
2022-10-13 19:33:12 - progress_bar.py[line:274] - INFO: epoch 001:   7590 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.3, ups=0.91, wpb=109.7, bsz=40, num_updates=7580, lr=4.86691e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35113
2022-10-13 19:33:23 - progress_bar.py[line:274] - INFO: epoch 001:   7600 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.2, ups=0.87, wpb=109.9, bsz=40, num_updates=7590, lr=4.86646e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=11.4, ema_decay=0.9999, wall=35125
2022-10-13 19:33:35 - progress_bar.py[line:274] - INFO: epoch 001:   7610 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=7600, lr=4.86601e-05, gnorm=0.74, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35136
2022-10-13 19:33:46 - progress_bar.py[line:274] - INFO: epoch 001:   7620 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=7610, lr=4.86556e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35147
2022-10-13 19:33:57 - progress_bar.py[line:274] - INFO: epoch 001:   7630 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.4, ups=0.91, wpb=109.9, bsz=40, num_updates=7620, lr=4.86511e-05, gnorm=0.841, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35158
2022-10-13 19:34:08 - progress_bar.py[line:274] - INFO: epoch 001:   7640 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.2, ups=0.89, wpb=111.5, bsz=40, num_updates=7630, lr=4.86466e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35169
2022-10-13 19:34:19 - progress_bar.py[line:274] - INFO: epoch 001:   7650 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.9, ups=0.9, wpb=111.9, bsz=40, num_updates=7640, lr=4.86421e-05, gnorm=0.82, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35180
2022-10-13 19:34:31 - progress_bar.py[line:274] - INFO: epoch 001:   7660 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.6, ups=0.87, wpb=109.3, bsz=40, num_updates=7650, lr=4.86376e-05, gnorm=0.753, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35192
2022-10-13 19:34:42 - progress_bar.py[line:274] - INFO: epoch 001:   7670 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=7660, lr=4.86331e-05, gnorm=0.755, clip=0, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=35203
2022-10-13 19:34:53 - progress_bar.py[line:274] - INFO: epoch 001:   7680 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=7670, lr=4.86286e-05, gnorm=0.822, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35214
2022-10-13 19:35:04 - progress_bar.py[line:274] - INFO: epoch 001:   7690 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=7680, lr=4.86241e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35226
2022-10-13 19:35:15 - progress_bar.py[line:274] - INFO: epoch 001:   7700 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=7690, lr=4.86196e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35237
2022-10-13 19:35:27 - progress_bar.py[line:274] - INFO: epoch 001:   7710 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.8, ups=0.87, wpb=109.7, bsz=40, num_updates=7700, lr=4.86151e-05, gnorm=0.769, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=35248
2022-10-13 19:35:38 - progress_bar.py[line:274] - INFO: epoch 001:   7720 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.4, ups=0.9, wpb=109.5, bsz=40, num_updates=7710, lr=4.86105e-05, gnorm=0.863, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35259
2022-10-13 19:35:50 - progress_bar.py[line:274] - INFO: epoch 001:   7730 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.7, ups=0.87, wpb=110.5, bsz=40, num_updates=7720, lr=4.8606e-05, gnorm=0.793, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=35271
2022-10-13 19:36:01 - progress_bar.py[line:274] - INFO: epoch 001:   7740 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=7730, lr=4.86015e-05, gnorm=0.811, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35282
2022-10-13 19:36:12 - progress_bar.py[line:274] - INFO: epoch 001:   7750 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99, ups=0.9, wpb=109.6, bsz=40, num_updates=7740, lr=4.8597e-05, gnorm=0.74, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=35293
2022-10-13 19:36:23 - progress_bar.py[line:274] - INFO: epoch 001:   7760 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=104.1, ups=0.93, wpb=112.1, bsz=40, num_updates=7750, lr=4.85925e-05, gnorm=0.835, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35304
2022-10-13 19:36:34 - progress_bar.py[line:274] - INFO: epoch 001:   7770 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.8, ups=0.89, wpb=111.9, bsz=40, num_updates=7760, lr=4.8588e-05, gnorm=0.82, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=35315
2022-10-13 19:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   7780 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.6, ups=0.88, wpb=108.7, bsz=40, num_updates=7770, lr=4.85835e-05, gnorm=0.863, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35326
2022-10-13 19:36:56 - progress_bar.py[line:274] - INFO: epoch 001:   7790 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.5, ups=0.88, wpb=109.9, bsz=40, num_updates=7780, lr=4.8579e-05, gnorm=0.898, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35338
2022-10-13 19:37:08 - progress_bar.py[line:274] - INFO: epoch 001:   7800 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=7790, lr=4.85745e-05, gnorm=0.761, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35349
2022-10-13 19:37:19 - progress_bar.py[line:274] - INFO: epoch 001:   7810 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=7800, lr=4.857e-05, gnorm=0.79, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35360
2022-10-13 19:37:30 - progress_bar.py[line:274] - INFO: epoch 001:   7820 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=7810, lr=4.85655e-05, gnorm=0.745, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35371
2022-10-13 19:37:41 - progress_bar.py[line:274] - INFO: epoch 001:   7830 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.2, ups=0.87, wpb=111.9, bsz=40, num_updates=7820, lr=4.8561e-05, gnorm=0.907, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=35382
2022-10-13 19:37:52 - progress_bar.py[line:274] - INFO: epoch 001:   7840 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=7830, lr=4.85565e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35394
2022-10-13 19:38:04 - progress_bar.py[line:274] - INFO: epoch 001:   7850 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=7840, lr=4.8552e-05, gnorm=0.891, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35405
2022-10-13 19:38:15 - progress_bar.py[line:274] - INFO: epoch 001:   7860 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.7, ups=0.9, wpb=109.5, bsz=40, num_updates=7850, lr=4.85475e-05, gnorm=0.885, clip=20, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=35416
2022-10-13 19:38:26 - progress_bar.py[line:274] - INFO: epoch 001:   7870 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.3, ups=0.88, wpb=109.5, bsz=40, num_updates=7860, lr=4.8543e-05, gnorm=0.811, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35427
2022-10-13 19:38:38 - progress_bar.py[line:274] - INFO: epoch 001:   7880 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.5, ups=0.89, wpb=108.4, bsz=40, num_updates=7870, lr=4.85385e-05, gnorm=0.834, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35439
2022-10-13 19:38:48 - progress_bar.py[line:274] - INFO: epoch 001:   7890 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=103.8, ups=0.94, wpb=110.7, bsz=40, num_updates=7880, lr=4.8534e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=35449
2022-10-13 19:39:00 - progress_bar.py[line:274] - INFO: epoch 001:   7900 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.6, ups=0.88, wpb=111, bsz=40, num_updates=7890, lr=4.85295e-05, gnorm=0.758, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35461
2022-10-13 19:39:11 - progress_bar.py[line:274] - INFO: epoch 001:   7910 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=7900, lr=4.8525e-05, gnorm=0.922, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35472
2022-10-13 19:39:22 - progress_bar.py[line:274] - INFO: epoch 001:   7920 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=102.5, ups=0.92, wpb=111.8, bsz=40, num_updates=7910, lr=4.85205e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35483
2022-10-13 19:39:33 - progress_bar.py[line:274] - INFO: epoch 001:   7930 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=7920, lr=4.8516e-05, gnorm=0.756, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35494
2022-10-13 19:39:44 - progress_bar.py[line:274] - INFO: epoch 001:   7940 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=7930, lr=4.85115e-05, gnorm=0.856, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35506
2022-10-13 19:39:56 - progress_bar.py[line:274] - INFO: epoch 001:   7950 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=7940, lr=4.8507e-05, gnorm=0.809, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35517
2022-10-13 19:40:07 - progress_bar.py[line:274] - INFO: epoch 001:   7960 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.1, ups=0.9, wpb=108.7, bsz=40, num_updates=7950, lr=4.85025e-05, gnorm=0.786, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35528
2022-10-13 19:40:18 - progress_bar.py[line:274] - INFO: epoch 001:   7970 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.1, ups=0.89, wpb=110.3, bsz=40, num_updates=7960, lr=4.8498e-05, gnorm=0.847, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35539
2022-10-13 19:40:29 - progress_bar.py[line:274] - INFO: epoch 001:   7980 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.1, ups=0.89, wpb=112.2, bsz=40, num_updates=7970, lr=4.84934e-05, gnorm=0.741, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35550
2022-10-13 19:40:40 - progress_bar.py[line:274] - INFO: epoch 001:   7990 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=102.7, ups=0.93, wpb=110.7, bsz=40, num_updates=7980, lr=4.84889e-05, gnorm=0.835, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35561
2022-10-13 19:40:51 - progress_bar.py[line:274] - INFO: epoch 001:   8000 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=7990, lr=4.84844e-05, gnorm=0.818, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35572
2022-10-13 19:41:01 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 19:41:03 - progress_bar.py[line:274] - INFO: epoch 001:   8011 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=90.7, ups=0.82, wpb=110, bsz=40, num_updates=8000, lr=4.84799e-05, gnorm=0.822, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=35585
2022-10-13 19:41:03 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 19:41:05 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 19:41:05 - train.py[line:551] - INFO: load:1.26 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 19:41:05 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.85 GiB already allocated; 3.35 GiB free; 33.76 GiB reserved in total by PyTorch)
2022-10-13 19:41:05 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-13 19:41:05 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 19        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9063 MB |   10289 MB |    5140 TB |    5139 TB |
|       from large pool |    8919 MB |   10143 MB |    5138 TB |    5138 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9063 MB |   10289 MB |    5140 TB |    5139 TB |
|       from large pool |    8919 MB |   10143 MB |    5138 TB |    5138 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34566 MB |   34572 MB |  193796 MB |  159230 MB |
|       from large pool |   34420 MB |   34420 MB |  193502 MB |  159082 MB |
|       from small pool |     146 MB |     152 MB |     294 MB |     148 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   25502 MB |   29931 MB |    5122 TB |    5122 TB |
|       from large pool |   25500 MB |   29929 MB |    5120 TB |    5120 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  237552 K  |  237548 K  |
|       from large pool |     563    |     575    |   76664 K  |   76663 K  |
|       from small pool |    3095    |    3114    |  160888 K  |  160885 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  237552 K  |  237548 K  |
|       from large pool |     563    |     575    |   76664 K  |   76663 K  |
|       from small pool |    3095    |    3114    |  160888 K  |  160885 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     169    |     172    |     526    |     357    |
|       from large pool |      96    |      96    |     379    |     283    |
|       from small pool |      73    |      76    |     147    |      74    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     108    |     112    |  169678 K  |  169678 K  |
|       from large pool |      68    |      68    |   30779 K  |   30779 K  |
|       from small pool |      40    |      47    |  138899 K  |  138899 K  |
|===========================================================================|

2022-10-13 19:41:05 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-13 19:43:38 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 19:43:38 - train.py[line:551] - INFO: load:1.28 valid_run:153.03 task_valid:148.94 collect_output:3.02
2022-10-13 19:46:07 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 19:46:07 - train.py[line:551] - INFO: load:1.31 valid_run:301.82 task_valid:292.68 collect_output:7.00
2022-10-13 19:48:39 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 19:48:39 - train.py[line:551] - INFO: load:1.33 valid_run:454.26 task_valid:436.63 collect_output:14.41
2022-10-13 19:51:09 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 19:51:09 - train.py[line:551] - INFO: load:1.36 valid_run:604.24 task_valid:582.71 collect_output:17.22
2022-10-13 19:53:43 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 19:53:43 - train.py[line:551] - INFO: load:1.38 valid_run:757.32 task_valid:731.08 collect_output:20.83
2022-10-13 19:56:15 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 19:56:15 - train.py[line:551] - INFO: load:1.41 valid_run:909.39 task_valid:877.50 collect_output:25.37
2022-10-13 19:58:48 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 19:58:48 - train.py[line:551] - INFO: load:1.43 valid_run:1062.95 task_valid:1024.46 collect_output:30.94
2022-10-13 20:01:20 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 20:01:20 - train.py[line:551] - INFO: load:1.46 valid_run:1214.69 task_valid:1166.63 collect_output:39.44
2022-10-13 20:03:51 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 20:03:51 - train.py[line:551] - INFO: load:1.48 valid_run:1365.42 task_valid:1312.84 collect_output:42.79
2022-10-13 20:06:21 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 20:06:21 - train.py[line:551] - INFO: load:1.52 valid_run:1515.20 task_valid:1457.63 collect_output:46.58
2022-10-13 20:08:52 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 20:08:52 - train.py[line:551] - INFO: load:1.55 valid_run:1665.96 task_valid:1604.00 collect_output:49.80
2022-10-13 20:11:23 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 20:11:23 - train.py[line:551] - INFO: load:1.57 valid_run:1817.14 task_valid:1750.39 collect_output:53.38
2022-10-13 20:13:54 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 20:13:54 - train.py[line:551] - INFO: load:1.60 valid_run:1967.83 task_valid:1893.59 collect_output:59.66
2022-10-13 20:16:26 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 20:16:26 - train.py[line:551] - INFO: load:1.63 valid_run:2119.82 task_valid:2040.96 collect_output:63.15
2022-10-13 20:18:57 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 20:18:57 - train.py[line:551] - INFO: load:1.65 valid_run:2271.50 task_valid:2189.18 collect_output:65.42
2022-10-13 20:21:29 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 20:21:29 - train.py[line:551] - INFO: load:1.68 valid_run:2422.58 task_valid:2334.87 collect_output:69.62
2022-10-13 20:24:01 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 20:24:01 - train.py[line:551] - INFO: load:1.71 valid_run:2575.08 task_valid:2482.04 collect_output:73.77
2022-10-13 20:26:33 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 20:26:33 - train.py[line:551] - INFO: load:1.74 valid_run:2727.04 task_valid:2630.80 collect_output:75.83
2022-10-13 20:29:02 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 20:29:02 - train.py[line:551] - INFO: load:1.77 valid_run:2876.22 task_valid:2774.13 collect_output:80.35
2022-10-13 20:31:34 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 20:31:34 - train.py[line:551] - INFO: load:1.80 valid_run:3027.72 task_valid:2921.09 collect_output:83.67
2022-10-13 20:34:06 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 20:34:06 - train.py[line:551] - INFO: load:1.82 valid_run:3179.80 task_valid:3066.83 collect_output:88.92
2022-10-13 20:36:36 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 20:36:36 - train.py[line:551] - INFO: load:1.85 valid_run:3329.72 task_valid:3212.31 collect_output:92.31
2022-10-13 20:39:08 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 20:39:08 - train.py[line:551] - INFO: load:1.87 valid_run:3481.39 task_valid:3359.45 collect_output:95.79
2022-10-13 20:41:40 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 20:41:40 - train.py[line:551] - INFO: load:1.90 valid_run:3633.28 task_valid:3506.93 collect_output:99.16

====================================================================================================
SGG eval:     R @ 50: 0.6570;     R @ 100: 0.6833;     R @ 500: 0.6955;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4209;    mR @ 100: 0.4465;    mR @ 500: 0.4605;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.7500) (covering:0.2857) (eating:0.8235) (flying in:0.5909) (growing on:0.1250) (hanging from:0.3710) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.9412) (says:0.0000) (sitting on:0.7704) (standing on:0.4663) (using:0.5500) (walking in:0.0000) (walking on:0.6486) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-13 20:44:11 - train.py[line:487] - INFO: 0.6833389865036924

====================================================================================================
SGG eval:     R @ 50: 0.6570;     R @ 100: 0.6833;     R @ 500: 0.6955;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4209;    mR @ 100: 0.4465;    mR @ 500: 0.4605;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.7500) (covering:0.2857) (eating:0.8235) (flying in:0.5909) (growing on:0.1250) (hanging from:0.3710) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9167) (playing:0.0000) (riding:0.9412) (says:0.0000) (sitting on:0.7704) (standing on:0.4663) (using:0.5500) (walking in:0.0000) (walking on:0.6486) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-13 20:44:11 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 20:44:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.34 | loss_v1 0 | loss_v2 0 | nll_loss 0.192 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.683339 | ppl 1.14 | vqa_score 0.4932 | wps 118.5 | wpb 89.9 | bsz 30 | num_updates 8000 | best_R@100 0.704053
2022-10-13 20:44:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2022-10-13 20:44:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-13 20:44:17 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-13 20:44:20 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.6833389865036924) (writing took 8.274076072033495 seconds)
2022-10-13 20:44:31 - progress_bar.py[line:274] - INFO: epoch 001:   8021 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=0.3, ups=0, wpb=110.9, bsz=40, num_updates=8010, lr=4.84754e-05, gnorm=0.773, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39392
2022-10-13 20:44:42 - progress_bar.py[line:274] - INFO: epoch 001:   8031 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.4, ups=0.88, wpb=108.3, bsz=40, num_updates=8020, lr=4.84709e-05, gnorm=0.867, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39404
2022-10-13 20:44:54 - progress_bar.py[line:274] - INFO: epoch 001:   8041 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=8030, lr=4.84664e-05, gnorm=0.763, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39415
2022-10-13 20:45:05 - progress_bar.py[line:274] - INFO: epoch 001:   8051 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.9, ups=0.89, wpb=112.1, bsz=40, num_updates=8040, lr=4.84619e-05, gnorm=0.804, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39426
2022-10-13 20:45:16 - progress_bar.py[line:274] - INFO: epoch 001:   8061 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96, ups=0.87, wpb=110.3, bsz=40, num_updates=8050, lr=4.84574e-05, gnorm=0.865, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39437
2022-10-13 20:45:28 - progress_bar.py[line:274] - INFO: epoch 001:   8071 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=8060, lr=4.84529e-05, gnorm=0.765, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39449
2022-10-13 20:45:39 - progress_bar.py[line:274] - INFO: epoch 001:   8081 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=8070, lr=4.84484e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39460
2022-10-13 20:45:50 - progress_bar.py[line:274] - INFO: epoch 001:   8091 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.7, ups=0.91, wpb=110.1, bsz=40, num_updates=8080, lr=4.84439e-05, gnorm=0.814, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39471
2022-10-13 20:46:01 - progress_bar.py[line:274] - INFO: epoch 001:   8101 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=8090, lr=4.84394e-05, gnorm=0.804, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39482
2022-10-13 20:46:12 - progress_bar.py[line:274] - INFO: epoch 001:   8111 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=103.9, ups=0.94, wpb=110.9, bsz=40, num_updates=8100, lr=4.84349e-05, gnorm=0.848, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39493
2022-10-13 20:46:23 - progress_bar.py[line:274] - INFO: epoch 001:   8121 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=101.1, ups=0.93, wpb=109.2, bsz=40, num_updates=8110, lr=4.84304e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39504
2022-10-13 20:46:34 - progress_bar.py[line:274] - INFO: epoch 001:   8131 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.9, ups=0.91, wpb=110.8, bsz=40, num_updates=8120, lr=4.84259e-05, gnorm=0.846, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39515
2022-10-13 20:46:45 - progress_bar.py[line:274] - INFO: epoch 001:   8141 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=8130, lr=4.84214e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39526
2022-10-13 20:46:56 - progress_bar.py[line:274] - INFO: epoch 001:   8151 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.9, ups=0.89, wpb=110.1, bsz=40, num_updates=8140, lr=4.84169e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39537
2022-10-13 20:47:07 - progress_bar.py[line:274] - INFO: epoch 001:   8161 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.6, ups=0.9, wpb=109.3, bsz=40, num_updates=8150, lr=4.84124e-05, gnorm=0.773, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39549
2022-10-13 20:47:19 - progress_bar.py[line:274] - INFO: epoch 001:   8171 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.9, ups=0.89, wpb=108.8, bsz=40, num_updates=8160, lr=4.84079e-05, gnorm=0.832, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39560
2022-10-13 20:47:30 - progress_bar.py[line:274] - INFO: epoch 001:   8181 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=8170, lr=4.84034e-05, gnorm=0.784, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39571
2022-10-13 20:47:41 - progress_bar.py[line:274] - INFO: epoch 001:   8191 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=8180, lr=4.83989e-05, gnorm=0.879, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39582
2022-10-13 20:47:52 - progress_bar.py[line:274] - INFO: epoch 001:   8201 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.8, ups=0.89, wpb=109.5, bsz=40, num_updates=8190, lr=4.83944e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39593
2022-10-13 20:48:03 - progress_bar.py[line:274] - INFO: epoch 001:   8211 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.8, ups=0.87, wpb=110, bsz=40, num_updates=8200, lr=4.83899e-05, gnorm=0.73, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39605
2022-10-13 20:48:15 - progress_bar.py[line:274] - INFO: epoch 001:   8221 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.9, ups=0.9, wpb=111.7, bsz=40, num_updates=8210, lr=4.83854e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39616
2022-10-13 20:48:26 - progress_bar.py[line:274] - INFO: epoch 001:   8231 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.7, ups=0.87, wpb=111.4, bsz=40, num_updates=8220, lr=4.83808e-05, gnorm=0.81, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39627
2022-10-13 20:48:37 - progress_bar.py[line:274] - INFO: epoch 001:   8241 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=8230, lr=4.83763e-05, gnorm=0.804, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39638
2022-10-13 20:48:49 - progress_bar.py[line:274] - INFO: epoch 001:   8251 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.1, ups=0.89, wpb=111.2, bsz=40, num_updates=8240, lr=4.83718e-05, gnorm=0.725, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39650
2022-10-13 20:49:00 - progress_bar.py[line:274] - INFO: epoch 001:   8261 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.2, ups=0.88, wpb=110.7, bsz=40, num_updates=8250, lr=4.83673e-05, gnorm=0.767, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39661
2022-10-13 20:49:11 - progress_bar.py[line:274] - INFO: epoch 001:   8271 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=8260, lr=4.83628e-05, gnorm=0.781, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39672
2022-10-13 20:49:22 - progress_bar.py[line:274] - INFO: epoch 001:   8281 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=8270, lr=4.83583e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39683
2022-10-13 20:49:34 - progress_bar.py[line:274] - INFO: epoch 001:   8291 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.3, ups=0.88, wpb=109.3, bsz=40, num_updates=8280, lr=4.83538e-05, gnorm=0.826, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39695
2022-10-13 20:49:45 - progress_bar.py[line:274] - INFO: epoch 001:   8301 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=8290, lr=4.83493e-05, gnorm=0.713, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39706
2022-10-13 20:49:56 - progress_bar.py[line:274] - INFO: epoch 001:   8311 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=103.2, ups=0.93, wpb=111.3, bsz=40, num_updates=8300, lr=4.83448e-05, gnorm=0.897, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39717
2022-10-13 20:50:07 - progress_bar.py[line:274] - INFO: epoch 001:   8321 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96, ups=0.88, wpb=109.1, bsz=40, num_updates=8310, lr=4.83403e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39728
2022-10-13 20:50:18 - progress_bar.py[line:274] - INFO: epoch 001:   8331 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.1, ups=0.87, wpb=110.2, bsz=40, num_updates=8320, lr=4.83358e-05, gnorm=0.724, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39740
2022-10-13 20:50:30 - progress_bar.py[line:274] - INFO: epoch 001:   8341 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=8330, lr=4.83313e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39751
2022-10-13 20:50:41 - progress_bar.py[line:274] - INFO: epoch 001:   8351 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.4, ups=0.9, wpb=111.4, bsz=40, num_updates=8340, lr=4.83268e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39762
2022-10-13 20:50:52 - progress_bar.py[line:274] - INFO: epoch 001:   8361 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.2, ups=0.89, wpb=111.6, bsz=40, num_updates=8350, lr=4.83223e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39773
2022-10-13 20:51:03 - progress_bar.py[line:274] - INFO: epoch 001:   8371 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.7, ups=0.9, wpb=109.3, bsz=40, num_updates=8360, lr=4.83178e-05, gnorm=0.8, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39784
2022-10-13 20:51:14 - progress_bar.py[line:274] - INFO: epoch 001:   8381 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=8370, lr=4.83133e-05, gnorm=0.793, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39796
2022-10-13 20:51:26 - progress_bar.py[line:274] - INFO: epoch 001:   8391 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=8380, lr=4.83088e-05, gnorm=0.803, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39807
2022-10-13 20:51:37 - progress_bar.py[line:274] - INFO: epoch 001:   8401 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.1, ups=0.92, wpb=108.3, bsz=40, num_updates=8390, lr=4.83043e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39818
2022-10-13 20:51:48 - progress_bar.py[line:274] - INFO: epoch 001:   8411 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.3, ups=0.91, wpb=109.7, bsz=40, num_updates=8400, lr=4.82998e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39829
2022-10-13 20:51:59 - progress_bar.py[line:274] - INFO: epoch 001:   8421 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=8410, lr=4.82953e-05, gnorm=0.898, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39840
2022-10-13 20:52:10 - progress_bar.py[line:274] - INFO: epoch 001:   8431 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.8, ups=0.92, wpb=110.1, bsz=40, num_updates=8420, lr=4.82908e-05, gnorm=0.737, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39851
2022-10-13 20:52:21 - progress_bar.py[line:274] - INFO: epoch 001:   8441 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.4, ups=0.89, wpb=109.1, bsz=40, num_updates=8430, lr=4.82863e-05, gnorm=0.826, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39862
2022-10-13 20:52:32 - progress_bar.py[line:274] - INFO: epoch 001:   8451 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=102.3, ups=0.91, wpb=111.9, bsz=40, num_updates=8440, lr=4.82818e-05, gnorm=0.774, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=39873
2022-10-13 20:52:43 - progress_bar.py[line:274] - INFO: epoch 001:   8461 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.8, ups=0.88, wpb=108.4, bsz=40, num_updates=8450, lr=4.82773e-05, gnorm=0.875, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39884
2022-10-13 20:52:55 - progress_bar.py[line:274] - INFO: epoch 001:   8471 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.8, ups=0.87, wpb=110.1, bsz=40, num_updates=8460, lr=4.82728e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39896
2022-10-13 20:53:06 - progress_bar.py[line:274] - INFO: epoch 001:   8481 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.4, ups=0.9, wpb=112.4, bsz=40, num_updates=8470, lr=4.82683e-05, gnorm=0.707, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39907
2022-10-13 20:53:17 - progress_bar.py[line:274] - INFO: epoch 001:   8491 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.1, ups=0.88, wpb=109.2, bsz=40, num_updates=8480, lr=4.82637e-05, gnorm=0.714, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39918
2022-10-13 20:53:29 - progress_bar.py[line:274] - INFO: epoch 001:   8501 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.8, ups=0.88, wpb=112.3, bsz=40, num_updates=8490, lr=4.82592e-05, gnorm=0.738, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39930
2022-10-13 20:53:40 - progress_bar.py[line:274] - INFO: epoch 001:   8511 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.5, ups=0.87, wpb=110.8, bsz=40, num_updates=8500, lr=4.82547e-05, gnorm=0.77, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39941
2022-10-13 20:53:51 - progress_bar.py[line:274] - INFO: epoch 001:   8521 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=103.5, ups=0.93, wpb=111.6, bsz=40, num_updates=8510, lr=4.82502e-05, gnorm=0.816, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39952
2022-10-13 20:54:02 - progress_bar.py[line:274] - INFO: epoch 001:   8531 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.5, ups=0.9, wpb=109.4, bsz=40, num_updates=8520, lr=4.82457e-05, gnorm=0.815, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39963
2022-10-13 20:54:13 - progress_bar.py[line:274] - INFO: epoch 001:   8541 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.6, ups=0.91, wpb=111.2, bsz=40, num_updates=8530, lr=4.82412e-05, gnorm=0.705, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39974
2022-10-13 20:54:24 - progress_bar.py[line:274] - INFO: epoch 001:   8551 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.5, ups=0.88, wpb=112, bsz=40, num_updates=8540, lr=4.82367e-05, gnorm=0.696, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39986
2022-10-13 20:54:36 - progress_bar.py[line:274] - INFO: epoch 001:   8561 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.4, ups=0.89, wpb=111.2, bsz=40, num_updates=8550, lr=4.82322e-05, gnorm=0.751, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39997
2022-10-13 20:54:47 - progress_bar.py[line:274] - INFO: epoch 001:   8571 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=8560, lr=4.82277e-05, gnorm=0.841, clip=10, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=40008
2022-10-13 20:54:58 - progress_bar.py[line:274] - INFO: epoch 001:   8581 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.7, ups=0.87, wpb=109.7, bsz=40, num_updates=8570, lr=4.82232e-05, gnorm=0.877, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40020
2022-10-13 20:55:09 - progress_bar.py[line:274] - INFO: epoch 001:   8591 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.9, ups=0.91, wpb=111.9, bsz=40, num_updates=8580, lr=4.82187e-05, gnorm=0.784, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40031
2022-10-13 20:55:21 - progress_bar.py[line:274] - INFO: epoch 001:   8601 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=8590, lr=4.82142e-05, gnorm=0.867, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40042
2022-10-13 20:55:32 - progress_bar.py[line:274] - INFO: epoch 001:   8611 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.2, ups=0.92, wpb=109.5, bsz=40, num_updates=8600, lr=4.82097e-05, gnorm=0.907, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=40053
2022-10-13 20:55:43 - progress_bar.py[line:274] - INFO: epoch 001:   8621 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.1, ups=0.88, wpb=110.6, bsz=40, num_updates=8610, lr=4.82052e-05, gnorm=0.838, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40064
2022-10-13 20:55:54 - progress_bar.py[line:274] - INFO: epoch 001:   8631 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=8620, lr=4.82007e-05, gnorm=0.889, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40076
2022-10-13 20:56:05 - progress_bar.py[line:274] - INFO: epoch 001:   8641 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.6, ups=0.91, wpb=110, bsz=40, num_updates=8630, lr=4.81962e-05, gnorm=0.8, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40086
2022-10-13 20:56:17 - progress_bar.py[line:274] - INFO: epoch 001:   8651 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=8640, lr=4.81917e-05, gnorm=0.725, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40098
2022-10-13 20:56:28 - progress_bar.py[line:274] - INFO: epoch 001:   8661 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=8650, lr=4.81872e-05, gnorm=0.774, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40109
2022-10-13 20:56:39 - progress_bar.py[line:274] - INFO: epoch 001:   8671 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.8, ups=0.91, wpb=109.8, bsz=40, num_updates=8660, lr=4.81827e-05, gnorm=0.784, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40120
2022-10-13 20:56:50 - progress_bar.py[line:274] - INFO: epoch 001:   8681 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=8670, lr=4.81782e-05, gnorm=0.713, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40131
2022-10-13 20:57:01 - progress_bar.py[line:274] - INFO: epoch 001:   8691 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101.1, ups=0.91, wpb=110.8, bsz=40, num_updates=8680, lr=4.81737e-05, gnorm=0.876, clip=10, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=40142
2022-10-13 20:57:02 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 20:57:13 - progress_bar.py[line:274] - INFO: epoch 001:   8702 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=89, ups=0.81, wpb=109.6, bsz=40, num_updates=8690, lr=4.81692e-05, gnorm=0.87, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=40154
2022-10-13 20:57:25 - progress_bar.py[line:274] - INFO: epoch 001:   8712 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.8, ups=0.88, wpb=108.5, bsz=40, num_updates=8700, lr=4.81647e-05, gnorm=0.788, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40166
2022-10-13 20:57:36 - progress_bar.py[line:274] - INFO: epoch 001:   8722 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=8710, lr=4.81602e-05, gnorm=0.802, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40177
2022-10-13 20:57:46 - progress_bar.py[line:274] - INFO: epoch 001:   8732 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=104.1, ups=0.95, wpb=109.3, bsz=40, num_updates=8720, lr=4.81557e-05, gnorm=0.907, clip=20, loss_scale=512, train_wall=10, gb_free=10.4, ema_decay=0.9999, wall=40188
2022-10-13 20:57:58 - progress_bar.py[line:274] - INFO: epoch 001:   8742 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.6, ups=0.89, wpb=111.7, bsz=40, num_updates=8730, lr=4.81512e-05, gnorm=0.925, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40199
2022-10-13 20:58:09 - progress_bar.py[line:274] - INFO: epoch 001:   8752 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.4, ups=0.89, wpb=109.3, bsz=40, num_updates=8740, lr=4.81466e-05, gnorm=0.863, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40210
2022-10-13 20:58:20 - progress_bar.py[line:274] - INFO: epoch 001:   8762 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=8750, lr=4.81421e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40221
2022-10-13 20:58:32 - progress_bar.py[line:274] - INFO: epoch 001:   8772 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.7, ups=0.88, wpb=109.8, bsz=40, num_updates=8760, lr=4.81376e-05, gnorm=0.823, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40233
2022-10-13 20:58:43 - progress_bar.py[line:274] - INFO: epoch 001:   8782 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96, ups=0.88, wpb=109, bsz=40, num_updates=8770, lr=4.81331e-05, gnorm=0.948, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40244
2022-10-13 20:58:54 - progress_bar.py[line:274] - INFO: epoch 001:   8792 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=8780, lr=4.81286e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40255
2022-10-13 20:59:05 - progress_bar.py[line:274] - INFO: epoch 001:   8802 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.7, ups=0.89, wpb=108.3, bsz=40, num_updates=8790, lr=4.81241e-05, gnorm=0.868, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40266
2022-10-13 20:59:17 - progress_bar.py[line:274] - INFO: epoch 001:   8812 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.8, ups=0.88, wpb=111, bsz=40, num_updates=8800, lr=4.81196e-05, gnorm=0.757, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40278
2022-10-13 20:59:28 - progress_bar.py[line:274] - INFO: epoch 001:   8822 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.8, ups=0.89, wpb=109.5, bsz=40, num_updates=8810, lr=4.81151e-05, gnorm=0.858, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40289
2022-10-13 20:59:39 - progress_bar.py[line:274] - INFO: epoch 001:   8832 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.8, ups=0.92, wpb=111.2, bsz=40, num_updates=8820, lr=4.81106e-05, gnorm=0.764, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=40300
2022-10-13 20:59:50 - progress_bar.py[line:274] - INFO: epoch 001:   8842 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.6, ups=0.88, wpb=110, bsz=40, num_updates=8830, lr=4.81061e-05, gnorm=0.757, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40311
2022-10-13 21:00:02 - progress_bar.py[line:274] - INFO: epoch 001:   8852 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.9, ups=0.88, wpb=109.1, bsz=40, num_updates=8840, lr=4.81016e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40323
2022-10-13 21:00:13 - progress_bar.py[line:274] - INFO: epoch 001:   8862 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.3, ups=0.9, wpb=110.2, bsz=40, num_updates=8850, lr=4.80971e-05, gnorm=0.862, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40334
2022-10-13 21:00:24 - progress_bar.py[line:274] - INFO: epoch 001:   8872 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=8860, lr=4.80926e-05, gnorm=0.802, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40345
2022-10-13 21:00:35 - progress_bar.py[line:274] - INFO: epoch 001:   8882 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.9, ups=0.88, wpb=109, bsz=40, num_updates=8870, lr=4.80881e-05, gnorm=0.848, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40356
2022-10-13 21:00:46 - progress_bar.py[line:274] - INFO: epoch 001:   8892 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.2, ups=0.9, wpb=111.4, bsz=40, num_updates=8880, lr=4.80836e-05, gnorm=0.753, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=40368
2022-10-13 21:00:57 - progress_bar.py[line:274] - INFO: epoch 001:   8902 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101, ups=0.9, wpb=112.1, bsz=40, num_updates=8890, lr=4.80791e-05, gnorm=0.729, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40379
2022-10-13 21:01:09 - progress_bar.py[line:274] - INFO: epoch 001:   8912 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=8900, lr=4.80746e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40390
2022-10-13 21:01:20 - progress_bar.py[line:274] - INFO: epoch 001:   8922 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.1, ups=0.91, wpb=109.5, bsz=40, num_updates=8910, lr=4.80701e-05, gnorm=0.9, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40401
2022-10-13 21:01:31 - progress_bar.py[line:274] - INFO: epoch 001:   8932 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99, ups=0.89, wpb=111.1, bsz=40, num_updates=8920, lr=4.80656e-05, gnorm=0.797, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40412
2022-10-13 21:01:42 - progress_bar.py[line:274] - INFO: epoch 001:   8942 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=102.7, ups=0.93, wpb=110.9, bsz=40, num_updates=8930, lr=4.80611e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40423
2022-10-13 21:01:53 - progress_bar.py[line:274] - INFO: epoch 001:   8952 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=8940, lr=4.80566e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40434
2022-10-13 21:02:04 - progress_bar.py[line:274] - INFO: epoch 001:   8962 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=8950, lr=4.80521e-05, gnorm=0.78, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40445
2022-10-13 21:02:15 - progress_bar.py[line:274] - INFO: epoch 001:   8972 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.6, ups=0.9, wpb=110.6, bsz=40, num_updates=8960, lr=4.80476e-05, gnorm=0.842, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40456
2022-10-13 21:02:26 - progress_bar.py[line:274] - INFO: epoch 001:   8982 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=101.5, ups=0.93, wpb=109.5, bsz=40, num_updates=8970, lr=4.80431e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40467
2022-10-13 21:02:37 - progress_bar.py[line:274] - INFO: epoch 001:   8992 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.4, ups=0.91, wpb=109.8, bsz=40, num_updates=8980, lr=4.80386e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40478
2022-10-13 21:02:48 - progress_bar.py[line:274] - INFO: epoch 001:   9002 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=101.2, ups=0.93, wpb=109.2, bsz=40, num_updates=8990, lr=4.8034e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40489
2022-10-13 21:02:59 - progress_bar.py[line:274] - INFO: epoch 001:   9012 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.2, ups=0.89, wpb=110.6, bsz=40, num_updates=9000, lr=4.80295e-05, gnorm=0.846, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40500
2022-10-13 21:02:59 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 21:03:00 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 21:03:00 - train.py[line:551] - INFO: load:1.18 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 21:05:33 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 21:05:33 - train.py[line:551] - INFO: load:1.20 valid_run:152.39 task_valid:148.66 collect_output:2.66
2022-10-13 21:08:02 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 21:08:02 - train.py[line:551] - INFO: load:1.23 valid_run:301.58 task_valid:292.57 collect_output:6.86
2022-10-13 21:10:36 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 21:10:36 - train.py[line:551] - INFO: load:1.25 valid_run:454.98 task_valid:436.76 collect_output:14.98
2022-10-13 21:13:06 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 21:13:06 - train.py[line:551] - INFO: load:1.28 valid_run:604.81 task_valid:582.73 collect_output:17.77
2022-10-13 21:15:38 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 21:15:38 - train.py[line:551] - INFO: load:1.31 valid_run:757.71 task_valid:731.07 collect_output:21.26
2022-10-13 21:18:11 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 21:18:11 - train.py[line:551] - INFO: load:1.33 valid_run:909.91 task_valid:877.51 collect_output:25.90
2022-10-13 21:20:46 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 21:20:46 - train.py[line:551] - INFO: load:1.36 valid_run:1064.63 task_valid:1026.47 collect_output:30.41
2022-10-13 21:23:19 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 21:23:19 - train.py[line:551] - INFO: load:1.39 valid_run:1217.60 task_valid:1170.83 collect_output:37.84
2022-10-13 21:25:50 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 21:25:50 - train.py[line:551] - INFO: load:1.41 valid_run:1369.31 task_valid:1318.65 collect_output:40.53
2022-10-13 21:28:20 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 21:28:20 - train.py[line:551] - INFO: load:1.44 valid_run:1518.88 task_valid:1463.12 collect_output:44.39
2022-10-13 21:30:51 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 21:30:51 - train.py[line:551] - INFO: load:1.46 valid_run:1669.96 task_valid:1609.71 collect_output:47.73
2022-10-13 21:33:22 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 21:33:22 - train.py[line:551] - INFO: load:1.49 valid_run:1821.22 task_valid:1756.51 collect_output:51.08
2022-10-13 21:35:54 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 21:35:54 - train.py[line:551] - INFO: load:1.52 valid_run:1972.24 task_valid:1900.18 collect_output:57.29
2022-10-13 21:38:26 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 21:38:26 - train.py[line:551] - INFO: load:1.54 valid_run:2124.43 task_valid:2047.69 collect_output:60.76
2022-10-13 21:40:57 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 21:40:57 - train.py[line:551] - INFO: load:1.57 valid_run:2276.07 task_valid:2195.73 collect_output:63.15
2022-10-13 21:43:29 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 21:43:29 - train.py[line:551] - INFO: load:1.59 valid_run:2427.44 task_valid:2341.59 collect_output:67.42
2022-10-13 21:46:01 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 21:46:01 - train.py[line:551] - INFO: load:1.62 valid_run:2579.92 task_valid:2488.90 collect_output:71.41
2022-10-13 21:48:34 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 21:48:34 - train.py[line:551] - INFO: load:1.65 valid_run:2731.95 task_valid:2637.73 collect_output:73.45
2022-10-13 21:51:02 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 21:51:02 - train.py[line:551] - INFO: load:1.67 valid_run:2880.80 task_valid:2780.61 collect_output:78.32
2022-10-13 21:53:33 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 21:53:33 - train.py[line:551] - INFO: load:1.70 valid_run:3031.71 task_valid:2926.99 collect_output:81.76
2022-10-13 21:56:06 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 21:56:06 - train.py[line:551] - INFO: load:1.73 valid_run:3183.84 task_valid:3072.95 collect_output:86.81
2022-10-13 21:58:36 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 21:58:36 - train.py[line:551] - INFO: load:1.75 valid_run:3334.10 task_valid:3218.83 collect_output:90.08
2022-10-13 22:01:08 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 22:01:08 - train.py[line:551] - INFO: load:1.78 valid_run:3485.87 task_valid:3366.36 collect_output:93.19
2022-10-13 22:03:40 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 22:03:40 - train.py[line:551] - INFO: load:1.81 valid_run:3638.17 task_valid:3514.28 collect_output:96.47
2022-10-14 16:24:31 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-14 16:24:31 - utils.py[line:261] - INFO: Start init
2022-10-14 16:24:31 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-14 16:24:31 - utils.py[line:261] - INFO: Start init
2022-10-14 16:24:32 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-14 16:24:32 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-14 16:24:32 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-14 16:24:32 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-14 16:24:38 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 4, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=4, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-14 16:24:38 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-14 16:24:38 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-10-14 16:24:42 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-14 16:24:42 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-14 16:24:42 - train.py[line:119] - INFO: model: OFAModel
2022-10-14 16:24:42 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-14 16:24:42 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-14 16:24:42 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-14 16:24:42 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-14 16:24:42 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-14 16:24:43 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-14 16:24:43 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-14 16:24:43 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-14 16:24:43 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-14 16:24:43 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-14 16:24:43 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-10-14 16:24:43 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt
2022-10-14 16:25:09 - trainer.py[line:605] - INFO: Loading EMA from checkpoint
2022-10-14 16:25:10 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-10-14 16:25:10 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-10-14 16:25:10 - trainer.py[line:612] - INFO: Loading EMA fp32 params from checkpoint
2022-10-14 16:25:10 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt (epoch 8 @ 0 updates)
2022-10-14 16:25:10 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 1 row count 578200 total row count 1156400
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 0 row count 578200 total row count 1156400
2022-10-14 16:25:11 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 115640, warmup steps 4625, warmup_factor 0.00021621621621621621
Total steps 115640, warmup steps 4625, warmup_factor 0.00021621621621621621
2022-10-14 16:25:12 - trainer.py[line:707] - INFO: begin training epoch 1
2022-10-14 16:25:12 - train.py[line:312] - INFO: Start iterating over samples
2022-10-14 16:25:29 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 28910 loss=0.828, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=91.6, ups=0.83, wpb=110.8, bsz=40, num_updates=10, lr=1.08108e-07, gnorm=2.424, clip=100, loss_scale=128, train_wall=16, gb_free=10.6, ema_decay=0.9999, wall=46
2022-10-14 16:25:41 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 28910 loss=0.886, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=95.7, ups=0.87, wpb=109.6, bsz=40, num_updates=20, lr=2.16216e-07, gnorm=2.496, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=58
2022-10-14 16:25:52 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 28910 loss=0.854, loss_v1=0, loss_v2=0, nll_loss=0.77, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.71, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=30, lr=3.24324e-07, gnorm=2.603, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=69
2022-10-14 16:26:03 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 28910 loss=0.812, loss_v1=0, loss_v2=0, nll_loss=0.718, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.64, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=40, lr=4.32432e-07, gnorm=2.346, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=80
2022-10-14 16:26:15 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 28910 loss=0.829, loss_v1=0, loss_v2=0, nll_loss=0.739, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=94.6, ups=0.86, wpb=109.4, bsz=40, num_updates=50, lr=5.40541e-07, gnorm=2.542, clip=100, loss_scale=128, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=92
2022-10-14 16:26:27 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 28910 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.674, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=94.7, ups=0.85, wpb=111.1, bsz=40, num_updates=60, lr=6.48649e-07, gnorm=2.232, clip=100, loss_scale=128, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=104
2022-10-14 16:26:38 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 28910 loss=0.766, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=95.1, ups=0.87, wpb=109.8, bsz=40, num_updates=70, lr=7.56757e-07, gnorm=2.215, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=115
2022-10-14 16:26:49 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 28910 loss=0.753, loss_v1=0, loss_v2=0, nll_loss=0.669, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=101.3, ups=0.92, wpb=110, bsz=40, num_updates=80, lr=8.64865e-07, gnorm=1.952, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=126
2022-10-14 16:27:01 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 28910 loss=0.739, loss_v1=0, loss_v2=0, nll_loss=0.654, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=96.4, ups=0.87, wpb=111, bsz=40, num_updates=90, lr=9.72973e-07, gnorm=1.82, clip=90, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=138
2022-10-14 16:27:12 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 28910 loss=0.738, loss_v1=0, loss_v2=0, nll_loss=0.662, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=95.9, ups=0.87, wpb=110.1, bsz=40, num_updates=100, lr=1.08108e-06, gnorm=2.01, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=149
2022-10-14 16:27:23 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 28910 loss=0.771, loss_v1=0, loss_v2=0, nll_loss=0.698, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.62, wps=100.7, ups=0.92, wpb=110, bsz=40, num_updates=110, lr=1.18919e-06, gnorm=1.673, clip=90, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=160
2022-10-14 16:27:34 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 28910 loss=0.687, loss_v1=0, loss_v2=0, nll_loss=0.614, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=98.6, ups=0.89, wpb=111.2, bsz=40, num_updates=120, lr=1.2973e-06, gnorm=1.339, clip=70, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=171
2022-10-14 16:27:45 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 28910 loss=0.742, loss_v1=0, loss_v2=0, nll_loss=0.676, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.6, wps=99.3, ups=0.9, wpb=110.8, bsz=40, num_updates=130, lr=1.40541e-06, gnorm=1.353, clip=90, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=182
2022-10-14 16:27:57 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 28910 loss=0.672, loss_v1=0, loss_v2=0, nll_loss=0.605, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=140, lr=1.51351e-06, gnorm=0.947, clip=60, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=194
2022-10-14 16:28:08 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 28910 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.589, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=150, lr=1.62162e-06, gnorm=0.832, clip=20, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=205
2022-10-14 16:28:19 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 28910 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.625, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.54, wps=100.9, ups=0.91, wpb=110.5, bsz=40, num_updates=160, lr=1.72973e-06, gnorm=0.778, clip=20, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=216
2022-10-14 16:28:30 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 28910 loss=0.711, loss_v1=0, loss_v2=0, nll_loss=0.653, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=170, lr=1.83784e-06, gnorm=0.728, clip=10, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=227
2022-10-14 16:28:41 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 28910 loss=0.619, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99.2, ups=0.89, wpb=111.4, bsz=40, num_updates=180, lr=1.94595e-06, gnorm=0.597, clip=0, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=238
2022-10-14 16:28:52 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 28910 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.6, ups=0.9, wpb=111.8, bsz=40, num_updates=190, lr=2.05405e-06, gnorm=0.533, clip=0, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=249
2022-10-14 16:29:04 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 28910 loss=0.704, loss_v1=0, loss_v2=0, nll_loss=0.649, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.57, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=200, lr=2.16216e-06, gnorm=0.653, clip=0, loss_scale=128, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=261
2022-10-14 16:29:15 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 28910 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.597, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=210, lr=2.27027e-06, gnorm=0.625, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=272
2022-10-14 16:29:26 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 28910 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.566, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=101.5, ups=0.92, wpb=109.8, bsz=40, num_updates=220, lr=2.37838e-06, gnorm=0.769, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=283
2022-10-14 16:29:37 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 28910 loss=0.653, loss_v1=0, loss_v2=0, nll_loss=0.59, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=230, lr=2.48649e-06, gnorm=0.634, clip=10, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=294
2022-10-14 16:29:48 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 28910 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.8, ups=0.91, wpb=111.4, bsz=40, num_updates=240, lr=2.59459e-06, gnorm=0.65, clip=10, loss_scale=128, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=305
2022-10-14 16:29:59 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 28910 loss=0.66, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=98.1, ups=0.9, wpb=109.5, bsz=40, num_updates=250, lr=2.7027e-06, gnorm=0.7, clip=10, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=316
2022-10-14 16:30:10 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 28910 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=103, ups=0.93, wpb=110.5, bsz=40, num_updates=260, lr=2.81081e-06, gnorm=0.74, clip=20, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=327
2022-10-14 16:30:21 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 28910 loss=0.724, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=98.6, ups=0.9, wpb=108.9, bsz=40, num_updates=270, lr=2.91892e-06, gnorm=0.949, clip=40, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=338
2022-10-14 16:30:32 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 28910 loss=0.662, loss_v1=0, loss_v2=0, nll_loss=0.599, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=280, lr=3.02703e-06, gnorm=0.683, clip=0, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=349
2022-10-14 16:30:43 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 28910 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.585, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=290, lr=3.13514e-06, gnorm=0.667, clip=0, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=360
2022-10-14 16:30:54 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 28910 loss=0.645, loss_v1=0, loss_v2=0, nll_loss=0.583, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=97.5, ups=0.89, wpb=109.8, bsz=40, num_updates=300, lr=3.24324e-06, gnorm=0.866, clip=20, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=371
2022-10-14 16:31:06 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 28910 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=310, lr=3.35135e-06, gnorm=0.83, clip=30, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=383
2022-10-14 16:31:17 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 28910 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=100.6, ups=0.9, wpb=111.3, bsz=40, num_updates=320, lr=3.45946e-06, gnorm=0.781, clip=10, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=394
2022-10-14 16:31:28 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 28910 loss=0.681, loss_v1=0, loss_v2=0, nll_loss=0.616, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.53, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=330, lr=3.56757e-06, gnorm=0.828, clip=20, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=405
2022-10-14 16:31:39 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 28910 loss=0.658, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=103.2, ups=0.93, wpb=111.2, bsz=40, num_updates=340, lr=3.67568e-06, gnorm=0.757, clip=20, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=416
2022-10-14 16:31:50 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 28910 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=102.4, ups=0.92, wpb=111.8, bsz=40, num_updates=350, lr=3.78378e-06, gnorm=0.762, clip=20, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=427
2022-10-14 16:32:01 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 28910 loss=0.648, loss_v1=0, loss_v2=0, nll_loss=0.581, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.5, wps=99.7, ups=0.9, wpb=110.2, bsz=40, num_updates=360, lr=3.89189e-06, gnorm=0.713, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=438
2022-10-14 16:32:12 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 28910 loss=0.657, loss_v1=0, loss_v2=0, nll_loss=0.591, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=101.1, ups=0.92, wpb=110.4, bsz=40, num_updates=370, lr=4e-06, gnorm=0.763, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=449
2022-10-14 16:32:23 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 28910 loss=0.666, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97.6, ups=0.89, wpb=109.9, bsz=40, num_updates=380, lr=4.10811e-06, gnorm=0.822, clip=10, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=460
2022-10-14 16:32:34 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=390, lr=4.21622e-06, gnorm=0.824, clip=10, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=471
2022-10-14 16:32:45 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 28910 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.561, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=400, lr=4.32432e-06, gnorm=0.757, clip=10, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=482
2022-10-14 16:32:56 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 28910 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.545, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.7, ups=0.89, wpb=109.5, bsz=40, num_updates=410, lr=4.43243e-06, gnorm=0.888, clip=20, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=493
2022-10-14 16:33:07 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 28910 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.569, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=101.3, ups=0.92, wpb=110.4, bsz=40, num_updates=420, lr=4.54054e-06, gnorm=0.984, clip=30, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=504
2022-10-14 16:33:18 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 28910 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=430, lr=4.64865e-06, gnorm=0.939, clip=30, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=515
2022-10-14 16:33:29 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 28910 loss=0.677, loss_v1=0, loss_v2=0, nll_loss=0.607, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=99, ups=0.9, wpb=109.6, bsz=40, num_updates=440, lr=4.75676e-06, gnorm=0.997, clip=50, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=526
2022-10-14 16:33:41 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 28910 loss=0.597, loss_v1=0, loss_v2=0, nll_loss=0.531, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.7, ups=0.88, wpb=110.8, bsz=40, num_updates=450, lr=4.86486e-06, gnorm=1.002, clip=40, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=538
2022-10-14 16:33:52 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 28910 loss=0.661, loss_v1=0, loss_v2=0, nll_loss=0.595, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=460, lr=4.97297e-06, gnorm=1.065, clip=60, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=549
2022-10-14 16:34:03 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 28910 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.9, ups=0.88, wpb=110.3, bsz=40, num_updates=470, lr=5.08108e-06, gnorm=1.092, clip=80, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=560
2022-10-14 16:34:15 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 28910 loss=0.631, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.9, ups=0.91, wpb=109.2, bsz=40, num_updates=480, lr=5.18919e-06, gnorm=1.11, clip=60, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=572
2022-10-14 16:34:26 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 28910 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.513, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.9, ups=0.89, wpb=110.4, bsz=40, num_updates=490, lr=5.2973e-06, gnorm=1.07, clip=60, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=583
2022-10-14 16:34:37 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 28910 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.538, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.9, ups=0.87, wpb=110, bsz=40, num_updates=500, lr=5.40541e-06, gnorm=1.024, clip=50, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=594
2022-10-14 16:34:48 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 28910 loss=0.599, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.3, ups=0.9, wpb=108.7, bsz=40, num_updates=510, lr=5.51351e-06, gnorm=1.279, clip=60, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=605
2022-10-14 16:35:00 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 28910 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.3, ups=0.89, wpb=111.5, bsz=40, num_updates=520, lr=5.62162e-06, gnorm=1.019, clip=60, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=617
2022-10-14 16:35:11 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 28910 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101.7, ups=0.92, wpb=111, bsz=40, num_updates=530, lr=5.72973e-06, gnorm=0.961, clip=20, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=628
2022-10-14 16:35:22 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 28910 loss=0.595, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=540, lr=5.83784e-06, gnorm=1.022, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=639
2022-10-14 16:35:33 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 28910 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=550, lr=5.94595e-06, gnorm=1.141, clip=60, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=650
2022-10-14 16:35:44 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 28910 loss=0.628, loss_v1=0, loss_v2=0, nll_loss=0.551, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=102.2, ups=0.93, wpb=110.1, bsz=40, num_updates=560, lr=6.05405e-06, gnorm=1.065, clip=70, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=661
2022-10-14 16:35:55 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 28910 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=570, lr=6.16216e-06, gnorm=0.973, clip=40, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=672
2022-10-14 16:36:06 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 28910 loss=0.603, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.4, ups=0.9, wpb=111.1, bsz=40, num_updates=580, lr=6.27027e-06, gnorm=0.99, clip=40, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=683
2022-10-14 16:36:17 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 28910 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.7, ups=0.9, wpb=112.1, bsz=40, num_updates=590, lr=6.37838e-06, gnorm=1.215, clip=80, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=694
2022-10-14 16:36:29 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 28910 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=95.9, ups=0.87, wpb=110.4, bsz=40, num_updates=600, lr=6.48649e-06, gnorm=1.153, clip=80, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=706
2022-10-14 16:36:40 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 28910 loss=0.614, loss_v1=0, loss_v2=0, nll_loss=0.537, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=96.5, ups=0.88, wpb=109.4, bsz=40, num_updates=610, lr=6.59459e-06, gnorm=1.052, clip=50, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=717
2022-10-14 16:36:51 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 28910 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.4, ups=0.92, wpb=109.6, bsz=40, num_updates=620, lr=6.7027e-06, gnorm=1.01, clip=50, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=728
2022-10-14 16:37:02 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.7, ups=0.9, wpb=111.7, bsz=40, num_updates=630, lr=6.81081e-06, gnorm=1.001, clip=40, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=739
2022-10-14 16:37:13 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 28910 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=95.6, ups=0.87, wpb=109.8, bsz=40, num_updates=640, lr=6.91892e-06, gnorm=1.153, clip=60, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=750
2022-10-14 16:37:25 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 28910 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.9, ups=0.88, wpb=110.1, bsz=40, num_updates=650, lr=7.02703e-06, gnorm=1.007, clip=50, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=762
2022-10-14 16:37:36 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=660, lr=7.13514e-06, gnorm=0.946, clip=30, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=773
2022-10-14 16:37:47 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 28910 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=670, lr=7.24324e-06, gnorm=0.93, clip=40, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=784
2022-10-14 16:37:59 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 28910 loss=0.654, loss_v1=0, loss_v2=0, nll_loss=0.574, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98, ups=0.89, wpb=109.6, bsz=40, num_updates=680, lr=7.35135e-06, gnorm=1.119, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=796
2022-10-14 16:38:09 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 28910 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.7, ups=0.92, wpb=109.9, bsz=40, num_updates=690, lr=7.45946e-06, gnorm=1, clip=60, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=807
2022-10-14 16:38:20 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 28910 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=105.7, ups=0.94, wpb=112.4, bsz=40, num_updates=700, lr=7.56757e-06, gnorm=1.008, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=817
2022-10-14 16:38:32 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 28910 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.8, ups=0.88, wpb=110, bsz=40, num_updates=710, lr=7.67568e-06, gnorm=1.098, clip=60, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=829
2022-10-14 16:38:43 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 28910 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=720, lr=7.78378e-06, gnorm=1.085, clip=60, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=840
2022-10-14 16:38:54 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.527, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=730, lr=7.89189e-06, gnorm=1.123, clip=60, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=851
2022-10-14 16:39:05 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 28910 loss=0.636, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=740, lr=8e-06, gnorm=1.065, clip=70, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=862
2022-10-14 16:39:16 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101, ups=0.91, wpb=111.6, bsz=40, num_updates=750, lr=8.10811e-06, gnorm=1.036, clip=60, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=873
2022-10-14 16:39:27 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 28910 loss=0.61, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100, ups=0.91, wpb=109.4, bsz=40, num_updates=760, lr=8.21622e-06, gnorm=1.132, clip=80, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=884
2022-10-14 16:39:39 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 28910 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.5, ups=0.88, wpb=111.8, bsz=40, num_updates=770, lr=8.32432e-06, gnorm=1.028, clip=40, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=896
2022-10-14 16:39:50 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 28910 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=780, lr=8.43243e-06, gnorm=1.04, clip=40, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=907
2022-10-14 16:40:01 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 28910 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=790, lr=8.54054e-06, gnorm=1.119, clip=60, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=918
2022-10-14 16:40:12 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.1, ups=0.9, wpb=108.7, bsz=40, num_updates=800, lr=8.64865e-06, gnorm=1.068, clip=50, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=929
2022-10-14 16:40:23 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.6, ups=0.91, wpb=110.1, bsz=40, num_updates=810, lr=8.75676e-06, gnorm=0.955, clip=30, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=940
2022-10-14 16:40:34 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 28910 loss=0.564, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=106.3, ups=0.96, wpb=110.3, bsz=40, num_updates=820, lr=8.86486e-06, gnorm=0.93, clip=20, loss_scale=256, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=951
2022-10-14 16:40:45 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 28910 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.4, ups=0.9, wpb=111.5, bsz=40, num_updates=830, lr=8.97297e-06, gnorm=1.084, clip=70, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=962
2022-10-14 16:40:56 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=840, lr=9.08108e-06, gnorm=1, clip=50, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=973
2022-10-14 16:41:08 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=93.5, ups=0.85, wpb=109.9, bsz=40, num_updates=850, lr=9.18919e-06, gnorm=1.032, clip=50, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=985
2022-10-14 16:41:19 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=860, lr=9.2973e-06, gnorm=1.035, clip=50, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=996
2022-10-14 16:41:30 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 28910 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=870, lr=9.40541e-06, gnorm=1.114, clip=60, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=1007
2022-10-14 16:41:41 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 28910 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.1, ups=0.89, wpb=109.8, bsz=40, num_updates=880, lr=9.51351e-06, gnorm=1.012, clip=60, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1018
2022-10-14 16:41:53 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 28910 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.5, ups=0.89, wpb=112.1, bsz=40, num_updates=890, lr=9.62162e-06, gnorm=0.935, clip=10, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1030
2022-10-14 16:42:04 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.5, ups=0.91, wpb=110.2, bsz=40, num_updates=900, lr=9.72973e-06, gnorm=0.971, clip=70, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1041
2022-10-14 16:42:15 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 28910 loss=0.596, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=910, lr=9.83784e-06, gnorm=1.013, clip=50, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1052
2022-10-14 16:42:27 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 28910 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.5, ups=0.87, wpb=111.7, bsz=40, num_updates=920, lr=9.94595e-06, gnorm=0.909, clip=0, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1064
2022-10-14 16:42:38 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=930, lr=1.00541e-05, gnorm=0.832, clip=20, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1075
2022-10-14 16:42:49 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=940, lr=1.01622e-05, gnorm=0.907, clip=30, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=1086
2022-10-14 16:43:00 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 28910 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=950, lr=1.02703e-05, gnorm=0.987, clip=40, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1097
2022-10-14 16:43:11 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.5, ups=0.88, wpb=109, bsz=40, num_updates=960, lr=1.03784e-05, gnorm=0.929, clip=20, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=1109
2022-10-14 16:43:23 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 28910 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96, ups=0.87, wpb=110.6, bsz=40, num_updates=970, lr=1.04865e-05, gnorm=1.011, clip=70, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1120
2022-10-14 16:43:35 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.5, ups=0.87, wpb=109.6, bsz=40, num_updates=980, lr=1.05946e-05, gnorm=0.968, clip=40, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1131
2022-10-14 16:43:45 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 28910 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.9, ups=0.92, wpb=111.3, bsz=40, num_updates=990, lr=1.07027e-05, gnorm=0.953, clip=40, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1142
2022-10-14 16:43:57 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 28910 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.4, ups=0.9, wpb=112.1, bsz=40, num_updates=1000, lr=1.08108e-05, gnorm=0.92, clip=20, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1154
2022-10-14 16:43:57 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-14 16:43:57 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-14 16:43:58 - train.py[line:549] - INFO: 0 / 4988
2022-10-14 16:43:58 - train.py[line:551] - INFO: load:1.17 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-14 16:46:34 - train.py[line:549] - INFO: 200 / 4988
2022-10-14 16:46:34 - train.py[line:551] - INFO: load:1.20 valid_run:155.84 task_valid:152.20 collect_output:2.50
2022-10-14 16:49:04 - train.py[line:549] - INFO: 400 / 4988
2022-10-14 16:49:04 - train.py[line:551] - INFO: load:1.22 valid_run:305.71 task_valid:296.57 collect_output:6.96
2022-10-14 16:51:38 - train.py[line:549] - INFO: 600 / 4988
2022-10-14 16:51:38 - train.py[line:551] - INFO: load:1.27 valid_run:459.77 task_valid:440.95 collect_output:15.54
2022-10-14 16:54:08 - train.py[line:549] - INFO: 800 / 4988
2022-10-14 16:54:08 - train.py[line:551] - INFO: load:1.29 valid_run:609.94 task_valid:587.23 collect_output:18.37
2022-10-14 16:56:42 - train.py[line:549] - INFO: 1000 / 4988
2022-10-14 16:56:42 - train.py[line:551] - INFO: load:1.32 valid_run:763.43 task_valid:736.01 collect_output:22.02
2022-10-14 16:59:15 - train.py[line:549] - INFO: 1200 / 4988
2022-10-14 16:59:15 - train.py[line:551] - INFO: load:1.35 valid_run:916.68 task_valid:883.31 collect_output:26.89
2022-10-14 17:01:50 - train.py[line:549] - INFO: 1400 / 4988
2022-10-14 17:01:50 - train.py[line:551] - INFO: load:1.39 valid_run:1070.95 task_valid:1030.51 collect_output:32.90
2022-10-14 17:04:22 - train.py[line:549] - INFO: 1600 / 4988
2022-10-14 17:04:22 - train.py[line:551] - INFO: load:1.42 valid_run:1223.50 task_valid:1173.47 collect_output:41.40
2022-10-14 17:06:54 - train.py[line:549] - INFO: 1800 / 4988
2022-10-14 17:06:54 - train.py[line:551] - INFO: load:1.45 valid_run:1374.93 task_valid:1320.39 collect_output:44.73
2022-10-14 17:09:24 - train.py[line:549] - INFO: 2000 / 4988
2022-10-14 17:09:24 - train.py[line:551] - INFO: load:1.48 valid_run:1525.14 task_valid:1465.58 collect_output:48.70
2022-10-14 17:11:55 - train.py[line:549] - INFO: 2200 / 4988
2022-10-14 17:11:55 - train.py[line:551] - INFO: load:1.52 valid_run:1675.77 task_valid:1611.65 collect_output:52.21
2022-10-14 17:14:25 - train.py[line:549] - INFO: 2400 / 4988
2022-10-14 17:14:25 - train.py[line:551] - INFO: load:1.54 valid_run:1826.21 task_valid:1757.14 collect_output:56.20
2022-10-14 17:16:56 - train.py[line:549] - INFO: 2600 / 4988
2022-10-14 17:16:56 - train.py[line:551] - INFO: load:1.57 valid_run:1976.82 task_valid:1899.59 collect_output:63.38
2022-10-14 17:19:27 - train.py[line:549] - INFO: 2800 / 4988
2022-10-14 17:19:27 - train.py[line:551] - INFO: load:1.59 valid_run:2128.02 task_valid:2045.87 collect_output:67.30
2022-10-14 17:21:58 - train.py[line:549] - INFO: 3000 / 4988
2022-10-14 17:21:58 - train.py[line:551] - INFO: load:1.62 valid_run:2278.86 task_valid:2193.16 collect_output:69.81
2022-10-14 17:24:29 - train.py[line:549] - INFO: 3200 / 4988
2022-10-14 17:24:29 - train.py[line:551] - INFO: load:1.65 valid_run:2429.90 task_valid:2338.34 collect_output:74.64
2022-10-14 17:27:01 - train.py[line:549] - INFO: 3400 / 4988
2022-10-14 17:27:01 - train.py[line:551] - INFO: load:1.67 valid_run:2582.09 task_valid:2484.27 collect_output:79.93
2022-10-14 17:29:32 - train.py[line:549] - INFO: 3600 / 4988
2022-10-14 17:29:32 - train.py[line:551] - INFO: load:1.70 valid_run:2733.09 task_valid:2631.68 collect_output:82.55
2022-10-14 17:32:01 - train.py[line:549] - INFO: 3800 / 4988
2022-10-14 17:32:01 - train.py[line:551] - INFO: load:1.72 valid_run:2881.91 task_valid:2773.52 collect_output:88.55
2022-10-14 17:34:32 - train.py[line:549] - INFO: 4000 / 4988
2022-10-14 17:34:32 - train.py[line:551] - INFO: load:1.75 valid_run:3032.98 task_valid:2919.31 collect_output:92.83
2022-10-14 17:37:05 - train.py[line:549] - INFO: 4200 / 4988
2022-10-14 17:37:05 - train.py[line:551] - INFO: load:1.77 valid_run:3185.44 task_valid:3064.20 collect_output:99.44
2022-10-14 17:39:35 - train.py[line:549] - INFO: 4400 / 4988
2022-10-14 17:39:35 - train.py[line:551] - INFO: load:1.80 valid_run:3335.51 task_valid:3209.29 collect_output:103.43
2022-10-14 17:42:07 - train.py[line:549] - INFO: 4600 / 4988
2022-10-14 17:42:07 - train.py[line:551] - INFO: load:1.82 valid_run:3487.45 task_valid:3356.09 collect_output:107.60
2022-10-14 17:44:39 - train.py[line:549] - INFO: 4800 / 4988
2022-10-14 17:44:39 - train.py[line:551] - INFO: load:1.85 valid_run:3639.34 task_valid:3503.10 collect_output:111.46

====================================================================================================
SGG eval:     R @ 50: 0.6420;     R @ 100: 0.6841;     R @ 500: 0.7151;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4348;    mR @ 100: 0.4882;    mR @ 500: 0.5325;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.4375) (covering:0.3714) (eating:0.7647) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5323) (lying on:0.5000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9624) (says:0.0000) (sitting on:0.6842) (standing on:0.5113) (using:0.4500) (walking in:0.0000) (walking on:0.6216) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6420;     R @ 100: 0.6841;     R @ 500: 0.7151;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4348;    mR @ 100: 0.4882;    mR @ 500: 0.5325;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.4375) (covering:0.3714) (eating:0.7647) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5323) (lying on:0.5000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9624) (says:0.0000) (sitting on:0.6842) (standing on:0.5113) (using:0.4500) (walking in:0.0000) (walking on:0.6216) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2022-10-14 17:47:11 - train.py[line:487] - INFO: 0.6841467787114845
2022-10-14 17:47:11 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-14 17:47:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.348 | loss_v1 0 | loss_v2 0 | nll_loss 0.221 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.684147 | ppl 1.17 | vqa_score 0.4876 | wps 118.3 | wpb 89.9 | bsz 30 | num_updates 1000
2022-10-14 17:47:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1000 updates
2022-10-14 17:47:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-14 17:47:18 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-14 17:47:23 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 0.6841467787114845) (writing took 11.349920865148306 seconds)
2022-10-14 17:47:33 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=0.3, ups=0, wpb=109.3, bsz=40, num_updates=1010, lr=1.09189e-05, gnorm=1.005, clip=40, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4970
2022-10-14 17:47:45 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 28910 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.517, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96, ups=0.87, wpb=110.6, bsz=40, num_updates=1020, lr=1.1027e-05, gnorm=0.999, clip=50, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=4982
2022-10-14 17:47:56 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.2, ups=0.89, wpb=111.2, bsz=40, num_updates=1030, lr=1.11351e-05, gnorm=0.962, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4993
2022-10-14 17:48:07 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 28910 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=1040, lr=1.12432e-05, gnorm=0.95, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5004
2022-10-14 17:48:19 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 28910 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.3, ups=0.88, wpb=111.2, bsz=40, num_updates=1050, lr=1.13514e-05, gnorm=0.956, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5016
2022-10-14 17:48:30 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 28910 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.2, ups=0.9, wpb=108.6, bsz=40, num_updates=1060, lr=1.14595e-05, gnorm=0.997, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5027
2022-10-14 17:48:41 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 28910 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.6, ups=0.88, wpb=111, bsz=40, num_updates=1070, lr=1.15676e-05, gnorm=1.079, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5038
2022-10-14 17:48:53 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.1, ups=0.87, wpb=110.8, bsz=40, num_updates=1080, lr=1.16757e-05, gnorm=0.979, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5050
2022-10-14 17:49:04 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=1090, lr=1.17838e-05, gnorm=1.02, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5061
2022-10-14 17:49:15 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.9, ups=0.9, wpb=110.4, bsz=40, num_updates=1100, lr=1.18919e-05, gnorm=0.964, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5072
2022-10-14 17:49:26 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 28910 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=1110, lr=1.2e-05, gnorm=1.073, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5083
2022-10-14 17:49:38 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.3, ups=0.88, wpb=110, bsz=40, num_updates=1120, lr=1.21081e-05, gnorm=0.963, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5095
2022-10-14 17:49:49 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.7, ups=0.92, wpb=110.7, bsz=40, num_updates=1130, lr=1.22162e-05, gnorm=0.993, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5106
2022-10-14 17:50:00 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 28910 loss=0.593, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=1140, lr=1.23243e-05, gnorm=0.901, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5117
2022-10-14 17:50:11 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.476, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.1, ups=0.87, wpb=110, bsz=40, num_updates=1150, lr=1.24324e-05, gnorm=1.031, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5128
2022-10-14 17:50:22 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 28910 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102.2, ups=0.93, wpb=110, bsz=40, num_updates=1160, lr=1.25405e-05, gnorm=0.966, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5139
2022-10-14 17:50:33 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 28910 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=1170, lr=1.26486e-05, gnorm=0.968, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5150
2022-10-14 17:50:44 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=1180, lr=1.27568e-05, gnorm=0.982, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5161
2022-10-14 17:50:56 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.8, ups=0.87, wpb=108.9, bsz=40, num_updates=1190, lr=1.28649e-05, gnorm=0.993, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5173
2022-10-14 17:51:07 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 28910 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.3, ups=0.89, wpb=109.8, bsz=40, num_updates=1200, lr=1.2973e-05, gnorm=1.083, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5184
2022-10-14 17:51:18 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.1, ups=0.9, wpb=109.1, bsz=40, num_updates=1210, lr=1.30811e-05, gnorm=1.012, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5195
2022-10-14 17:51:29 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=1220, lr=1.31892e-05, gnorm=0.954, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5206
2022-10-14 17:51:41 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=1230, lr=1.32973e-05, gnorm=0.99, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5218
2022-10-14 17:51:52 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98, ups=0.9, wpb=108.6, bsz=40, num_updates=1240, lr=1.34054e-05, gnorm=0.988, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5229
2022-10-14 17:52:03 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 28910 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=94.3, ups=0.87, wpb=108.5, bsz=40, num_updates=1250, lr=1.35135e-05, gnorm=0.96, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5240
2022-10-14 17:52:15 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 28910 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.493, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=94.5, ups=0.86, wpb=109.5, bsz=40, num_updates=1260, lr=1.36216e-05, gnorm=1.079, clip=60, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=5252
2022-10-14 17:52:26 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.7, ups=0.91, wpb=110.2, bsz=40, num_updates=1270, lr=1.37297e-05, gnorm=0.936, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5263
2022-10-14 17:52:37 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 28910 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=1280, lr=1.38378e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5274
2022-10-14 17:52:48 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 28910 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=1290, lr=1.39459e-05, gnorm=1.099, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5285
2022-10-14 17:53:00 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.2, ups=0.87, wpb=111.9, bsz=40, num_updates=1300, lr=1.40541e-05, gnorm=0.926, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5297
2022-10-14 17:53:11 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 28910 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=1310, lr=1.41622e-05, gnorm=0.864, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5308
2022-10-14 17:53:22 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.1, ups=0.9, wpb=109.6, bsz=40, num_updates=1320, lr=1.42703e-05, gnorm=1.066, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5319
2022-10-14 17:53:33 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=1330, lr=1.43784e-05, gnorm=0.979, clip=50, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5330
2022-10-14 17:53:45 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.2, ups=0.89, wpb=112.1, bsz=40, num_updates=1340, lr=1.44865e-05, gnorm=0.901, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5342
2022-10-14 17:53:56 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.88, wpb=110.5, bsz=40, num_updates=1350, lr=1.45946e-05, gnorm=0.98, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5353
2022-10-14 17:54:07 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=103.1, ups=0.93, wpb=111, bsz=40, num_updates=1360, lr=1.47027e-05, gnorm=1, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5364
2022-10-14 17:54:18 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 28910 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.4, ups=0.89, wpb=109.7, bsz=40, num_updates=1370, lr=1.48108e-05, gnorm=0.973, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5375
2022-10-14 17:54:29 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 28910 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=105.1, ups=0.95, wpb=110.2, bsz=40, num_updates=1380, lr=1.49189e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=5386
2022-10-14 17:54:40 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.3, ups=0.91, wpb=109.7, bsz=40, num_updates=1390, lr=1.5027e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5397
2022-10-14 17:54:51 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=1400, lr=1.51351e-05, gnorm=1.019, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5408
2022-10-14 17:55:02 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.7, ups=0.9, wpb=110.9, bsz=40, num_updates=1410, lr=1.52432e-05, gnorm=0.952, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5419
2022-10-14 17:55:13 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.4, ups=0.91, wpb=110.2, bsz=40, num_updates=1420, lr=1.53514e-05, gnorm=0.922, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5430
2022-10-14 17:55:24 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101, ups=0.92, wpb=109.8, bsz=40, num_updates=1430, lr=1.54595e-05, gnorm=1.071, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5441
2022-10-14 17:55:35 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.3, ups=0.91, wpb=108.6, bsz=40, num_updates=1440, lr=1.55676e-05, gnorm=1.054, clip=40, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=5452
2022-10-14 17:55:46 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=1450, lr=1.56757e-05, gnorm=0.993, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5463
2022-10-14 17:55:58 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.2, ups=0.89, wpb=109.1, bsz=40, num_updates=1460, lr=1.57838e-05, gnorm=0.995, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5475
2022-10-14 17:56:09 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=1470, lr=1.58919e-05, gnorm=0.951, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5486
2022-10-14 17:56:20 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=1480, lr=1.6e-05, gnorm=0.974, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5497
2022-10-14 17:56:31 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 28910 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=1490, lr=1.61081e-05, gnorm=0.957, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5508
2022-10-14 17:56:42 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.2, ups=0.88, wpb=111.8, bsz=40, num_updates=1500, lr=1.62162e-05, gnorm=0.829, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5519
2022-10-14 17:56:53 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.3, ups=0.88, wpb=110.6, bsz=40, num_updates=1510, lr=1.63243e-05, gnorm=1.03, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5530
2022-10-14 17:57:04 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.6, ups=0.93, wpb=110.1, bsz=40, num_updates=1520, lr=1.64324e-05, gnorm=1.001, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5541
2022-10-14 17:57:15 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.3, ups=0.92, wpb=111.6, bsz=40, num_updates=1530, lr=1.65405e-05, gnorm=1.001, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5552
2022-10-14 17:57:24 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-14 17:57:28 - progress_bar.py[line:274] - INFO: epoch 001:   1541 / 28910 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=88.4, ups=0.8, wpb=110.5, bsz=40, num_updates=1540, lr=1.66486e-05, gnorm=1.027, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5565
2022-10-14 17:57:39 - progress_bar.py[line:274] - INFO: epoch 001:   1551 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101, ups=0.91, wpb=110.9, bsz=40, num_updates=1550, lr=1.67568e-05, gnorm=1.025, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5576
2022-10-14 17:57:50 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99, ups=0.9, wpb=109.5, bsz=40, num_updates=1560, lr=1.68649e-05, gnorm=1.027, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5587
2022-10-14 17:58:01 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 28910 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.491, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=1570, lr=1.6973e-05, gnorm=0.944, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5598
2022-10-14 17:58:12 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.6, ups=0.9, wpb=111.3, bsz=40, num_updates=1580, lr=1.70811e-05, gnorm=1.01, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5609
2022-10-14 17:58:23 - progress_bar.py[line:274] - INFO: epoch 001:   1591 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=1590, lr=1.71892e-05, gnorm=0.866, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5620
2022-10-14 17:58:34 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.5, ups=0.87, wpb=111, bsz=40, num_updates=1600, lr=1.72973e-05, gnorm=0.923, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5631
2022-10-14 17:58:46 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.6, ups=0.87, wpb=109.4, bsz=40, num_updates=1610, lr=1.74054e-05, gnorm=1, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5643
2022-10-14 17:58:57 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 28910 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.7, ups=0.9, wpb=110, bsz=40, num_updates=1620, lr=1.75135e-05, gnorm=1.083, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5654
2022-10-14 17:59:08 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=1630, lr=1.76216e-05, gnorm=0.826, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5665
2022-10-14 17:59:19 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 28910 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=1640, lr=1.77297e-05, gnorm=0.979, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5676
2022-10-14 17:59:30 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100, ups=0.9, wpb=110.5, bsz=40, num_updates=1650, lr=1.78378e-05, gnorm=1.098, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5687
2022-10-14 17:59:42 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 28910 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=1660, lr=1.79459e-05, gnorm=0.928, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5699
2022-10-14 17:59:53 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.4, ups=0.92, wpb=110.6, bsz=40, num_updates=1670, lr=1.80541e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5710
2022-10-14 18:00:04 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=1680, lr=1.81622e-05, gnorm=1.052, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5721
2022-10-14 18:00:15 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 28910 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=1690, lr=1.82703e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5732
2022-10-14 18:00:26 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.3, ups=0.93, wpb=109.2, bsz=40, num_updates=1700, lr=1.83784e-05, gnorm=1.004, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5743
2022-10-14 18:00:37 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=1710, lr=1.84865e-05, gnorm=1.109, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5754
2022-10-14 18:00:48 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.8, ups=0.93, wpb=110.6, bsz=40, num_updates=1720, lr=1.85946e-05, gnorm=0.799, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5765
2022-10-14 18:00:59 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 28910 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.6, ups=0.87, wpb=110.6, bsz=40, num_updates=1730, lr=1.87027e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5776
2022-10-14 18:01:11 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 28910 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=1740, lr=1.88108e-05, gnorm=0.871, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5787
2022-10-14 18:01:22 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.7, ups=0.9, wpb=110.6, bsz=40, num_updates=1750, lr=1.89189e-05, gnorm=1.008, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5799
2022-10-14 18:01:33 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.6, ups=0.88, wpb=111.2, bsz=40, num_updates=1760, lr=1.9027e-05, gnorm=0.85, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5810
2022-10-14 18:01:44 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.8, ups=0.91, wpb=110.3, bsz=40, num_updates=1770, lr=1.91351e-05, gnorm=0.829, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5821
2022-10-14 18:01:56 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=94.8, ups=0.86, wpb=110.6, bsz=40, num_updates=1780, lr=1.92432e-05, gnorm=1.165, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=5833
2022-10-14 18:02:07 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 28910 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.451, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.2, ups=0.91, wpb=111.2, bsz=40, num_updates=1790, lr=1.93514e-05, gnorm=0.968, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5844
2022-10-14 18:02:18 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 28910 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=1800, lr=1.94595e-05, gnorm=0.885, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5855
2022-10-14 18:02:29 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.7, ups=0.89, wpb=108.4, bsz=40, num_updates=1810, lr=1.95676e-05, gnorm=0.983, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5866
2022-10-14 18:02:40 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=1820, lr=1.96757e-05, gnorm=0.941, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5877
2022-10-14 18:02:52 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 28910 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.5, ups=0.9, wpb=108.3, bsz=40, num_updates=1830, lr=1.97838e-05, gnorm=1.103, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5889
2022-10-14 18:03:03 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 28910 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=95.8, ups=0.87, wpb=110.4, bsz=40, num_updates=1840, lr=1.98919e-05, gnorm=0.997, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5900
2022-10-14 18:03:14 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.6, ups=0.92, wpb=111.9, bsz=40, num_updates=1850, lr=2e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5911
2022-10-14 18:03:25 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.6, ups=0.92, wpb=109, bsz=40, num_updates=1860, lr=2.01081e-05, gnorm=0.93, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5922
2022-10-14 18:03:36 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 28910 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.9, ups=0.89, wpb=111.8, bsz=40, num_updates=1870, lr=2.02162e-05, gnorm=1.023, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5933
2022-10-14 18:03:47 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 28910 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=1880, lr=2.03243e-05, gnorm=0.982, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5944
2022-10-14 18:03:58 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.8, ups=0.91, wpb=111.1, bsz=40, num_updates=1890, lr=2.04324e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5955
2022-10-14 18:04:09 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.6, ups=0.9, wpb=109.2, bsz=40, num_updates=1900, lr=2.05405e-05, gnorm=1, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5966
2022-10-14 18:04:20 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.2, ups=0.89, wpb=109.2, bsz=40, num_updates=1910, lr=2.06486e-05, gnorm=0.987, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5977
2022-10-14 18:04:31 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 28910 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.8, ups=0.91, wpb=110.9, bsz=40, num_updates=1920, lr=2.07568e-05, gnorm=0.949, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5988
2022-10-14 18:04:43 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.3, ups=0.88, wpb=110, bsz=40, num_updates=1930, lr=2.08649e-05, gnorm=1.036, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6000
2022-10-14 18:04:54 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.2, ups=0.9, wpb=110.4, bsz=40, num_updates=1940, lr=2.0973e-05, gnorm=0.919, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=6011
2022-10-14 18:05:05 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 28910 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.1, ups=0.9, wpb=110.2, bsz=40, num_updates=1950, lr=2.10811e-05, gnorm=0.916, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6022
2022-10-14 18:05:16 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101, ups=0.93, wpb=108.9, bsz=40, num_updates=1960, lr=2.11892e-05, gnorm=0.916, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=6033
2022-10-14 18:05:28 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=95.5, ups=0.87, wpb=110.3, bsz=40, num_updates=1970, lr=2.12973e-05, gnorm=0.878, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6045
2022-10-14 18:05:39 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 28910 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=1980, lr=2.14054e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6056
2022-10-14 18:05:50 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 28910 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.5, ups=0.91, wpb=111.2, bsz=40, num_updates=1990, lr=2.15135e-05, gnorm=0.952, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6067
2022-10-14 18:06:01 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.8, ups=0.9, wpb=109.5, bsz=40, num_updates=2000, lr=2.16216e-05, gnorm=0.973, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6078
2022-10-14 18:06:01 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-14 18:06:02 - train.py[line:549] - INFO: 0 / 4988
2022-10-14 18:06:02 - train.py[line:551] - INFO: load:1.01 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-14 18:06:03 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.87 GiB already allocated; 5.03 GiB free; 32.08 GiB reserved in total by PyTorch)
2022-10-14 18:06:03 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-14 18:06:03 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9082 MB |   10307 MB |     880 TB |     880 TB |
|       from large pool |    8937 MB |   10161 MB |     879 TB |     879 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9082 MB |   10307 MB |     880 TB |     880 TB |
|       from large pool |    8937 MB |   10161 MB |     879 TB |     879 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32850 MB |   36102 MB |  129536 MB |   96686 MB |
|       from large pool |   32704 MB |   35950 MB |  129280 MB |   96576 MB |
|       from small pool |     146 MB |     152 MB |     256 MB |     110 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23767 MB |   23767 MB |     956 TB |     956 TB |
|       from large pool |   23766 MB |   23766 MB |     956 TB |     956 TB |
|       from small pool |       1 MB |       2 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |   38495 K  |   38491 K  |
|       from large pool |     563    |     575    |   13267 K  |   13266 K  |
|       from small pool |    3095    |    3114    |   25227 K  |   25224 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |   38495 K  |   38491 K  |
|       from large pool |     563    |     575    |   13267 K  |   13266 K  |
|       from small pool |    3095    |    3114    |   25227 K  |   25224 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     199    |     214    |     453    |     254    |
|       from large pool |     126    |     138    |     325    |     199    |
|       from small pool |      73    |      76    |     128    |      55    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     135    |     140    |   26295 K  |   26295 K  |
|       from large pool |      93    |      94    |    5073 K  |    5073 K  |
|       from small pool |      42    |      49    |   21222 K  |   21222 K  |
|===========================================================================|

2022-10-14 18:06:03 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-14 18:08:36 - train.py[line:549] - INFO: 200 / 4988
2022-10-14 18:08:36 - train.py[line:551] - INFO: load:1.03 valid_run:154.07 task_valid:148.44 collect_output:4.57
2022-10-14 18:11:05 - train.py[line:549] - INFO: 400 / 4988
2022-10-14 18:11:05 - train.py[line:551] - INFO: load:1.06 valid_run:303.29 task_valid:291.73 collect_output:9.53
2022-10-14 18:13:39 - train.py[line:549] - INFO: 600 / 4988
2022-10-14 18:13:39 - train.py[line:551] - INFO: load:1.08 valid_run:456.45 task_valid:435.77 collect_output:17.64
2022-10-14 18:16:09 - train.py[line:549] - INFO: 800 / 4988
2022-10-14 18:16:09 - train.py[line:551] - INFO: load:1.11 valid_run:606.94 task_valid:582.45 collect_output:20.35
2022-10-14 18:18:42 - train.py[line:549] - INFO: 1000 / 4988
2022-10-14 18:18:42 - train.py[line:551] - INFO: load:1.13 valid_run:759.72 task_valid:730.56 collect_output:24.01
2022-10-14 18:21:15 - train.py[line:549] - INFO: 1200 / 4988
2022-10-14 18:21:15 - train.py[line:551] - INFO: load:1.16 valid_run:912.40 task_valid:877.15 collect_output:29.03
2022-10-14 18:23:49 - train.py[line:549] - INFO: 1400 / 4988
2022-10-14 18:23:49 - train.py[line:551] - INFO: load:1.19 valid_run:1066.74 task_valid:1025.25 collect_output:34.17
2022-10-14 18:26:22 - train.py[line:549] - INFO: 1600 / 4988
2022-10-14 18:26:22 - train.py[line:551] - INFO: load:1.21 valid_run:1219.42 task_valid:1168.76 collect_output:42.24
2022-10-14 18:28:53 - train.py[line:549] - INFO: 1800 / 4988
2022-10-14 18:28:53 - train.py[line:551] - INFO: load:1.24 valid_run:1370.23 task_valid:1314.96 collect_output:45.72
2022-10-14 18:31:22 - train.py[line:549] - INFO: 2000 / 4988
2022-10-14 18:31:22 - train.py[line:551] - INFO: load:1.26 valid_run:1519.77 task_valid:1459.39 collect_output:49.75
2022-10-14 18:33:53 - train.py[line:549] - INFO: 2200 / 4988
2022-10-14 18:33:53 - train.py[line:551] - INFO: load:1.29 valid_run:1670.65 task_valid:1605.76 collect_output:53.14
2022-10-14 18:36:24 - train.py[line:549] - INFO: 2400 / 4988
2022-10-14 18:36:24 - train.py[line:551] - INFO: load:1.32 valid_run:1821.41 task_valid:1751.73 collect_output:56.86
2022-10-14 18:38:55 - train.py[line:549] - INFO: 2600 / 4988
2022-10-14 18:38:55 - train.py[line:551] - INFO: load:1.35 valid_run:1972.26 task_valid:1894.57 collect_output:63.75
2022-10-14 18:41:27 - train.py[line:549] - INFO: 2800 / 4988
2022-10-14 18:41:27 - train.py[line:551] - INFO: load:1.37 valid_run:2123.73 task_valid:2040.84 collect_output:67.89
2022-10-14 18:43:57 - train.py[line:549] - INFO: 3000 / 4988
2022-10-14 18:43:57 - train.py[line:551] - INFO: load:1.40 valid_run:2274.57 task_valid:2188.22 collect_output:70.31
2022-10-14 18:46:28 - train.py[line:549] - INFO: 3200 / 4988
2022-10-14 18:46:28 - train.py[line:551] - INFO: load:1.42 valid_run:2425.25 task_valid:2332.96 collect_output:75.26
2022-10-14 18:49:00 - train.py[line:549] - INFO: 3400 / 4988
2022-10-14 18:49:00 - train.py[line:551] - INFO: load:1.45 valid_run:2577.35 task_valid:2478.83 collect_output:80.51
2022-10-14 18:51:31 - train.py[line:549] - INFO: 3600 / 4988
2022-10-14 18:51:31 - train.py[line:551] - INFO: load:1.47 valid_run:2728.47 task_valid:2626.32 collect_output:83.13
2022-10-14 18:54:00 - train.py[line:549] - INFO: 3800 / 4988
2022-10-14 18:54:00 - train.py[line:551] - INFO: load:1.50 valid_run:2877.16 task_valid:2768.28 collect_output:88.90
2022-10-14 18:56:31 - train.py[line:549] - INFO: 4000 / 4988
2022-10-14 18:56:31 - train.py[line:551] - INFO: load:1.52 valid_run:3028.32 task_valid:2914.05 collect_output:93.25
2022-10-14 18:59:04 - train.py[line:549] - INFO: 4200 / 4988
2022-10-14 18:59:04 - train.py[line:551] - INFO: load:1.55 valid_run:3180.76 task_valid:3059.37 collect_output:99.36
2022-10-14 19:01:34 - train.py[line:549] - INFO: 4400 / 4988
2022-10-14 19:01:34 - train.py[line:551] - INFO: load:1.57 valid_run:3330.74 task_valid:3204.54 collect_output:103.16
2022-10-14 19:04:06 - train.py[line:549] - INFO: 4600 / 4988
2022-10-14 19:04:06 - train.py[line:551] - INFO: load:1.60 valid_run:3482.82 task_valid:3351.61 collect_output:107.15
2022-10-14 19:06:38 - train.py[line:549] - INFO: 4800 / 4988
2022-10-14 19:06:38 - train.py[line:551] - INFO: load:1.63 valid_run:3634.77 task_valid:3498.83 collect_output:110.91

====================================================================================================
SGG eval:     R @ 50: 0.6673;     R @ 100: 0.7028;     R @ 500: 0.7282;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4573;    mR @ 100: 0.5103;    mR @ 500: 0.5441;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.3714) (eating:0.8235) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5000) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:1.0000) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7202) (standing on:0.4813) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6673;     R @ 100: 0.7028;     R @ 500: 0.7282;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4573;    mR @ 100: 0.5103;    mR @ 500: 0.5441;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.6875) (covering:0.3714) (eating:0.8235) (flying in:1.0000) (growing on:0.3750) (hanging from:0.5000) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:1.0000) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7202) (standing on:0.4813) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2022-10-14 19:09:10 - train.py[line:487] - INFO: 0.7028134453781513
2022-10-14 19:09:10 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-14 19:09:11 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.333 | loss_v1 0 | loss_v2 0 | nll_loss 0.182 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.702813 | ppl 1.13 | vqa_score 0.5158 | wps 118.5 | wpb 89.9 | bsz 30 | num_updates 2000 | best_R@100 0.702813
2022-10-14 19:09:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2022-10-14 19:09:11 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-14 19:09:18 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-14 19:09:26 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.7028134453781513) (writing took 14.96761072287336 seconds)
2022-10-14 19:09:37 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 28910 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=2010, lr=2.17297e-05, gnorm=0.924, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=9894
2022-10-14 19:09:48 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 28910 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.5, ups=0.89, wpb=109.3, bsz=40, num_updates=2020, lr=2.18378e-05, gnorm=0.959, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=9905
2022-10-14 19:10:00 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=94, ups=0.85, wpb=110.3, bsz=40, num_updates=2030, lr=2.19459e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=9917
2022-10-14 19:10:11 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 28910 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.5, ups=0.92, wpb=109.7, bsz=40, num_updates=2040, lr=2.20541e-05, gnorm=0.96, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9928
2022-10-14 19:10:22 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=2050, lr=2.21622e-05, gnorm=1.07, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9939
2022-10-14 19:10:30 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-14 19:10:34 - progress_bar.py[line:274] - INFO: epoch 001:   2062 / 28910 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.83, wpb=110.9, bsz=40, num_updates=2060, lr=2.22703e-05, gnorm=0.897, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=9951
2022-10-14 19:10:45 - progress_bar.py[line:274] - INFO: epoch 001:   2072 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.8, ups=0.88, wpb=108.7, bsz=40, num_updates=2070, lr=2.23784e-05, gnorm=0.956, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=9962
2022-10-14 19:10:57 - progress_bar.py[line:274] - INFO: epoch 001:   2082 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=2080, lr=2.24865e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=9974
2022-10-14 19:11:07 - progress_bar.py[line:274] - INFO: epoch 001:   2092 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101, ups=0.92, wpb=110.1, bsz=40, num_updates=2090, lr=2.25946e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9984
2022-10-14 19:11:19 - progress_bar.py[line:274] - INFO: epoch 001:   2102 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=2100, lr=2.27027e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=9996
2022-10-14 19:11:30 - progress_bar.py[line:274] - INFO: epoch 001:   2112 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.5, ups=0.89, wpb=109.4, bsz=40, num_updates=2110, lr=2.28108e-05, gnorm=1.005, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10007
2022-10-14 19:11:41 - progress_bar.py[line:274] - INFO: epoch 001:   2122 / 28910 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.4, ups=0.89, wpb=108.9, bsz=40, num_updates=2120, lr=2.29189e-05, gnorm=0.962, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10018
2022-10-14 19:11:52 - progress_bar.py[line:274] - INFO: epoch 001:   2132 / 28910 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.8, ups=0.88, wpb=108.7, bsz=40, num_updates=2130, lr=2.3027e-05, gnorm=0.995, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10029
2022-10-14 19:12:04 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=95.5, ups=0.88, wpb=108.3, bsz=40, num_updates=2140, lr=2.31351e-05, gnorm=1.059, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10041
2022-10-14 19:12:15 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=2150, lr=2.32432e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10052
2022-10-14 19:12:26 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=2160, lr=2.33514e-05, gnorm=1.044, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10063
2022-10-14 19:12:37 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 28910 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.4, ups=0.93, wpb=109.2, bsz=40, num_updates=2170, lr=2.34595e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10074
2022-10-14 19:12:48 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=2180, lr=2.35676e-05, gnorm=1.072, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10085
2022-10-14 19:12:59 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=2190, lr=2.36757e-05, gnorm=1.037, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10096
2022-10-14 19:13:10 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.9, wpb=109.4, bsz=40, num_updates=2200, lr=2.37838e-05, gnorm=1.017, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10107
2022-10-14 19:13:22 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98, ups=0.88, wpb=111.2, bsz=40, num_updates=2210, lr=2.38919e-05, gnorm=1.102, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10119
2022-10-14 19:13:33 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=2220, lr=2.4e-05, gnorm=0.896, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10130
2022-10-14 19:13:44 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=2230, lr=2.41081e-05, gnorm=0.956, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10141
2022-10-14 19:13:56 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=94.9, ups=0.87, wpb=109.2, bsz=40, num_updates=2240, lr=2.42162e-05, gnorm=1.078, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10153
2022-10-14 19:14:07 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=2250, lr=2.43243e-05, gnorm=0.999, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10164
2022-10-14 19:14:18 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 28910 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99, ups=0.88, wpb=112, bsz=40, num_updates=2260, lr=2.44324e-05, gnorm=1.022, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10175
2022-10-14 19:14:29 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.6, ups=0.9, wpb=111.1, bsz=40, num_updates=2270, lr=2.45405e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10186
2022-10-14 19:14:40 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=2280, lr=2.46486e-05, gnorm=0.885, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10197
2022-10-14 19:14:51 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 28910 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=2290, lr=2.47568e-05, gnorm=0.856, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10208
2022-10-14 19:15:03 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.3, ups=0.88, wpb=109.4, bsz=40, num_updates=2300, lr=2.48649e-05, gnorm=0.891, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10220
2022-10-14 19:15:14 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.7, ups=0.9, wpb=110.3, bsz=40, num_updates=2310, lr=2.4973e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10231
2022-10-14 19:15:25 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 28910 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.5, ups=0.9, wpb=108.9, bsz=40, num_updates=2320, lr=2.50811e-05, gnorm=0.998, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10242
2022-10-14 19:15:36 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 28910 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.4, ups=0.88, wpb=109.3, bsz=40, num_updates=2330, lr=2.51892e-05, gnorm=1.048, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10253
2022-10-14 19:15:47 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.9, ups=0.93, wpb=110.4, bsz=40, num_updates=2340, lr=2.52973e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10264
2022-10-14 19:15:58 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=95.9, ups=0.87, wpb=110.2, bsz=40, num_updates=2350, lr=2.54054e-05, gnorm=0.89, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10275
2022-10-14 19:16:10 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.5, ups=0.88, wpb=109.6, bsz=40, num_updates=2360, lr=2.55135e-05, gnorm=0.909, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10287
2022-10-14 19:16:21 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.5, ups=0.9, wpb=111.2, bsz=40, num_updates=2370, lr=2.56216e-05, gnorm=0.814, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10298
2022-10-14 19:16:32 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.1, ups=0.91, wpb=111.1, bsz=40, num_updates=2380, lr=2.57297e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10309
2022-10-14 19:16:43 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.3, ups=0.87, wpb=110.1, bsz=40, num_updates=2390, lr=2.58378e-05, gnorm=1.027, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10320
2022-10-14 19:16:55 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.9, ups=0.89, wpb=109.5, bsz=40, num_updates=2400, lr=2.59459e-05, gnorm=0.917, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10332
2022-10-14 19:17:06 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 28910 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.7, ups=0.9, wpb=110.2, bsz=40, num_updates=2410, lr=2.60541e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10343
2022-10-14 19:17:17 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.472, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101, ups=0.92, wpb=110.2, bsz=40, num_updates=2420, lr=2.61622e-05, gnorm=0.999, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10354
2022-10-14 19:17:28 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=2430, lr=2.62703e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10365
2022-10-14 19:17:39 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.5, ups=0.92, wpb=111.9, bsz=40, num_updates=2440, lr=2.63784e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10376
2022-10-14 19:17:50 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=2450, lr=2.64865e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10387
2022-10-14 19:18:00 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=103, ups=0.93, wpb=110.9, bsz=40, num_updates=2460, lr=2.65946e-05, gnorm=0.949, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10397
2022-10-14 19:18:12 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.5, ups=0.88, wpb=111.8, bsz=40, num_updates=2470, lr=2.67027e-05, gnorm=0.913, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10409
2022-10-14 19:18:23 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.4, ups=0.89, wpb=109.5, bsz=40, num_updates=2480, lr=2.68108e-05, gnorm=0.995, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10420
2022-10-14 19:18:34 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.1, ups=0.88, wpb=111.5, bsz=40, num_updates=2490, lr=2.69189e-05, gnorm=0.981, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10431
2022-10-14 19:18:46 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.9, ups=0.87, wpb=110.8, bsz=40, num_updates=2500, lr=2.7027e-05, gnorm=0.864, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10443
2022-10-14 19:18:57 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=2510, lr=2.71351e-05, gnorm=0.883, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10454
2022-10-14 19:19:08 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=2520, lr=2.72432e-05, gnorm=0.816, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10465
2022-10-14 19:19:20 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.9, ups=0.87, wpb=110.4, bsz=40, num_updates=2530, lr=2.73514e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10477
2022-10-14 19:19:31 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.9, ups=0.92, wpb=111, bsz=40, num_updates=2540, lr=2.74595e-05, gnorm=0.915, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10488
2022-10-14 19:19:42 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 28910 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.5, ups=0.91, wpb=108.7, bsz=40, num_updates=2550, lr=2.75676e-05, gnorm=0.98, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10499
2022-10-14 19:19:53 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.3, ups=0.88, wpb=111.7, bsz=40, num_updates=2560, lr=2.76757e-05, gnorm=0.932, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10510
2022-10-14 19:20:04 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-14 19:20:05 - progress_bar.py[line:274] - INFO: epoch 001:   2573 / 28910 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=91.8, ups=0.83, wpb=111, bsz=40, num_updates=2570, lr=2.77838e-05, gnorm=0.91, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=10522
2022-10-14 19:20:17 - progress_bar.py[line:274] - INFO: epoch 001:   2583 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=2580, lr=2.78919e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10534
2022-10-14 19:20:28 - progress_bar.py[line:274] - INFO: epoch 001:   2593 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=2590, lr=2.8e-05, gnorm=0.911, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10545
2022-10-14 19:20:39 - progress_bar.py[line:274] - INFO: epoch 001:   2603 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=2600, lr=2.81081e-05, gnorm=0.9, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10556
2022-10-14 19:20:51 - progress_bar.py[line:274] - INFO: epoch 001:   2613 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.8, ups=0.88, wpb=110.9, bsz=40, num_updates=2610, lr=2.82162e-05, gnorm=0.939, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10568
2022-10-14 19:21:02 - progress_bar.py[line:274] - INFO: epoch 001:   2623 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.8, ups=0.87, wpb=112.1, bsz=40, num_updates=2620, lr=2.83243e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10579
2022-10-14 19:21:13 - progress_bar.py[line:274] - INFO: epoch 001:   2633 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.7, ups=0.9, wpb=110.1, bsz=40, num_updates=2630, lr=2.84324e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10590
2022-10-14 19:21:25 - progress_bar.py[line:274] - INFO: epoch 001:   2643 / 28910 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.447, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98, ups=0.88, wpb=111.1, bsz=40, num_updates=2640, lr=2.85405e-05, gnorm=0.925, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10602
2022-10-14 19:21:36 - progress_bar.py[line:274] - INFO: epoch 001:   2653 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=2650, lr=2.86486e-05, gnorm=0.919, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10613
2022-10-14 19:21:47 - progress_bar.py[line:274] - INFO: epoch 001:   2663 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.3, ups=0.92, wpb=109.9, bsz=40, num_updates=2660, lr=2.87568e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10624
2022-10-14 19:21:58 - progress_bar.py[line:274] - INFO: epoch 001:   2673 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.5, ups=0.92, wpb=107.3, bsz=40, num_updates=2670, lr=2.88649e-05, gnorm=1.03, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10635
2022-10-14 19:22:09 - progress_bar.py[line:274] - INFO: epoch 001:   2683 / 28910 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.4, ups=0.87, wpb=110.6, bsz=40, num_updates=2680, lr=2.8973e-05, gnorm=0.883, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10646
2022-10-14 19:22:21 - progress_bar.py[line:274] - INFO: epoch 001:   2693 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=95.8, ups=0.87, wpb=109.9, bsz=40, num_updates=2690, lr=2.90811e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=10658
2022-10-14 19:22:31 - progress_bar.py[line:274] - INFO: epoch 001:   2703 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.1, ups=0.92, wpb=111.1, bsz=40, num_updates=2700, lr=2.91892e-05, gnorm=0.837, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10668
2022-10-14 19:22:43 - progress_bar.py[line:274] - INFO: epoch 001:   2713 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=2710, lr=2.92973e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10680
2022-10-14 19:22:54 - progress_bar.py[line:274] - INFO: epoch 001:   2723 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.2, ups=0.92, wpb=110.5, bsz=40, num_updates=2720, lr=2.94054e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10691
2022-10-14 19:23:05 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 28910 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.2, ups=0.87, wpb=108.2, bsz=40, num_updates=2730, lr=2.95135e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10702
2022-10-14 19:23:16 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=2740, lr=2.96216e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10713
2022-10-14 19:23:27 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 28910 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=2750, lr=2.97297e-05, gnorm=0.898, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10724
2022-10-14 19:23:38 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98, ups=0.89, wpb=109.6, bsz=40, num_updates=2760, lr=2.98378e-05, gnorm=0.915, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10735
2022-10-14 19:23:49 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.1, ups=0.91, wpb=110.2, bsz=40, num_updates=2770, lr=2.99459e-05, gnorm=0.869, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10746
2022-10-14 19:24:00 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.9, ups=0.91, wpb=110.4, bsz=40, num_updates=2780, lr=3.00541e-05, gnorm=0.937, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10757
2022-10-14 19:24:11 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=2790, lr=3.01622e-05, gnorm=0.869, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10768
2022-10-14 19:24:23 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.9, ups=0.9, wpb=111.5, bsz=40, num_updates=2800, lr=3.02703e-05, gnorm=0.946, clip=40, loss_scale=512, train_wall=11, gb_free=11.5, ema_decay=0.9999, wall=10780
2022-10-14 19:24:34 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.5, ups=0.88, wpb=111.7, bsz=40, num_updates=2810, lr=3.03784e-05, gnorm=0.948, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10791
2022-10-14 19:24:45 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.7, ups=0.92, wpb=111.1, bsz=40, num_updates=2820, lr=3.04865e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10802
2022-10-14 19:24:56 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.417, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=2830, lr=3.05946e-05, gnorm=0.846, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10813
2022-10-14 19:25:07 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.6, ups=0.92, wpb=111.7, bsz=40, num_updates=2840, lr=3.07027e-05, gnorm=0.894, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10824
2022-10-14 19:25:18 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.1, ups=0.92, wpb=110.4, bsz=40, num_updates=2850, lr=3.08108e-05, gnorm=0.965, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10835
2022-10-14 19:25:29 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.6, ups=0.89, wpb=109, bsz=40, num_updates=2860, lr=3.09189e-05, gnorm=0.991, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10846
2022-10-14 19:25:40 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 28910 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.4, ups=0.89, wpb=109.7, bsz=40, num_updates=2870, lr=3.1027e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10857
2022-10-14 19:25:52 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.4, ups=0.87, wpb=110.6, bsz=40, num_updates=2880, lr=3.11351e-05, gnorm=0.924, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10869
2022-10-14 19:26:03 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=2890, lr=3.12432e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10880
2022-10-14 19:26:14 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 28910 loss=0.481, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=2900, lr=3.13514e-05, gnorm=0.908, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10891
2022-10-14 19:26:26 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 28910 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.3, ups=0.87, wpb=110.9, bsz=40, num_updates=2910, lr=3.14595e-05, gnorm=0.846, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10903
2022-10-14 19:26:37 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.5, ups=0.92, wpb=110.6, bsz=40, num_updates=2920, lr=3.15676e-05, gnorm=0.849, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10914
2022-10-14 19:26:48 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.9, wpb=110.5, bsz=40, num_updates=2930, lr=3.16757e-05, gnorm=0.869, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10925
2022-10-14 19:26:59 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=2940, lr=3.17838e-05, gnorm=0.986, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10936
2022-10-14 19:27:10 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=2950, lr=3.18919e-05, gnorm=0.899, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10947
2022-10-14 19:27:21 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=2960, lr=3.2e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10958
2022-10-14 19:27:32 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.8, ups=0.89, wpb=109.3, bsz=40, num_updates=2970, lr=3.21081e-05, gnorm=0.804, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10969
2022-10-14 19:27:44 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=2980, lr=3.22162e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10981
2022-10-14 19:27:55 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=2990, lr=3.23243e-05, gnorm=0.82, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10992
2022-10-14 19:28:06 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=3000, lr=3.24324e-05, gnorm=0.912, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=11003
2022-10-14 19:28:06 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-14 19:28:07 - train.py[line:549] - INFO: 0 / 4988
2022-10-14 19:28:07 - train.py[line:551] - INFO: load:1.10 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-14 19:30:40 - train.py[line:549] - INFO: 200 / 4988
2022-10-14 19:30:40 - train.py[line:551] - INFO: load:1.13 valid_run:152.62 task_valid:148.97 collect_output:2.56
2022-10-14 19:33:10 - train.py[line:549] - INFO: 400 / 4988
2022-10-14 19:33:10 - train.py[line:551] - INFO: load:1.15 valid_run:302.68 task_valid:294.04 collect_output:6.42
2022-10-14 19:35:44 - train.py[line:549] - INFO: 600 / 4988
2022-10-14 19:35:44 - train.py[line:551] - INFO: load:1.18 valid_run:457.09 task_valid:439.62 collect_output:14.08
2022-10-14 19:38:15 - train.py[line:549] - INFO: 800 / 4988
2022-10-14 19:38:15 - train.py[line:551] - INFO: load:1.20 valid_run:607.40 task_valid:585.92 collect_output:16.99
2022-10-14 19:40:49 - train.py[line:549] - INFO: 1000 / 4988
2022-10-14 19:40:49 - train.py[line:551] - INFO: load:1.23 valid_run:761.42 task_valid:735.32 collect_output:20.46
2022-10-14 19:43:22 - train.py[line:549] - INFO: 1200 / 4988
2022-10-14 19:43:22 - train.py[line:551] - INFO: load:1.26 valid_run:914.59 task_valid:882.30 collect_output:25.56
2022-10-14 19:45:56 - train.py[line:549] - INFO: 1400 / 4988
2022-10-14 19:45:56 - train.py[line:551] - INFO: load:1.29 valid_run:1068.86 task_valid:1029.80 collect_output:31.26
2022-10-14 19:48:29 - train.py[line:549] - INFO: 1600 / 4988
2022-10-14 19:48:29 - train.py[line:551] - INFO: load:1.31 valid_run:1220.85 task_valid:1171.75 collect_output:40.18
2022-10-14 19:50:59 - train.py[line:549] - INFO: 1800 / 4988
2022-10-14 19:50:59 - train.py[line:551] - INFO: load:1.34 valid_run:1371.37 task_valid:1317.63 collect_output:43.72
2022-10-14 19:53:30 - train.py[line:549] - INFO: 2000 / 4988
2022-10-14 19:53:30 - train.py[line:551] - INFO: load:1.37 valid_run:1521.82 task_valid:1463.30 collect_output:47.36
2022-10-14 19:56:01 - train.py[line:549] - INFO: 2200 / 4988
2022-10-14 19:56:01 - train.py[line:551] - INFO: load:1.39 valid_run:1673.20 task_valid:1610.19 collect_output:50.72
2022-10-14 19:58:33 - train.py[line:549] - INFO: 2400 / 4988
2022-10-14 19:58:33 - train.py[line:551] - INFO: load:1.42 valid_run:1824.57 task_valid:1757.15 collect_output:54.04
2022-10-14 20:01:04 - train.py[line:549] - INFO: 2600 / 4988
2022-10-14 20:01:04 - train.py[line:551] - INFO: load:1.45 valid_run:1975.63 task_valid:1900.58 collect_output:60.60
2022-10-14 20:03:35 - train.py[line:549] - INFO: 2800 / 4988
2022-10-14 20:03:35 - train.py[line:551] - INFO: load:1.48 valid_run:2126.92 task_valid:2046.81 collect_output:64.66
2022-10-14 20:06:06 - train.py[line:549] - INFO: 3000 / 4988
2022-10-14 20:06:06 - train.py[line:551] - INFO: load:1.50 valid_run:2277.91 task_valid:2194.32 collect_output:67.13
2022-10-14 20:08:37 - train.py[line:549] - INFO: 3200 / 4988
2022-10-14 20:08:37 - train.py[line:551] - INFO: load:1.53 valid_run:2428.78 task_valid:2339.58 collect_output:71.72
2022-10-14 20:11:10 - train.py[line:549] - INFO: 3400 / 4988
2022-10-14 20:11:10 - train.py[line:551] - INFO: load:1.55 valid_run:2581.34 task_valid:2486.30 collect_output:76.56
2022-10-14 20:13:41 - train.py[line:549] - INFO: 3600 / 4988
2022-10-14 20:13:41 - train.py[line:551] - INFO: load:1.58 valid_run:2732.24 task_valid:2633.58 collect_output:79.18
2022-10-14 20:16:10 - train.py[line:549] - INFO: 3800 / 4988
2022-10-14 20:16:10 - train.py[line:551] - INFO: load:1.61 valid_run:2881.32 task_valid:2776.54 collect_output:84.25
2022-10-14 20:18:41 - train.py[line:549] - INFO: 4000 / 4988
2022-10-14 20:18:41 - train.py[line:551] - INFO: load:1.63 valid_run:3032.77 task_valid:2923.18 collect_output:87.99
2022-10-14 20:21:14 - train.py[line:549] - INFO: 4200 / 4988
2022-10-14 20:21:14 - train.py[line:551] - INFO: load:1.66 valid_run:3185.55 task_valid:3069.61 collect_output:93.28
2022-10-14 20:23:45 - train.py[line:549] - INFO: 4400 / 4988
2022-10-14 20:23:45 - train.py[line:551] - INFO: load:1.69 valid_run:3336.64 task_valid:3216.21 collect_output:96.69
2022-10-14 20:26:17 - train.py[line:549] - INFO: 4600 / 4988
2022-10-14 20:26:17 - train.py[line:551] - INFO: load:1.71 valid_run:3488.86 task_valid:3363.34 collect_output:100.78
2022-10-14 20:28:50 - train.py[line:549] - INFO: 4800 / 4988
2022-10-14 20:28:50 - train.py[line:551] - INFO: load:1.74 valid_run:3640.94 task_valid:3510.53 collect_output:104.69

====================================================================================================
SGG eval:     R @ 50: 0.6741;     R @ 100: 0.7018;     R @ 500: 0.7261;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4703;    mR @ 100: 0.5134;    mR @ 500: 0.5454;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.5143) (eating:0.8235) (flying in:0.9091) (growing on:0.5000) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7279) (standing on:0.4763) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6741;     R @ 100: 0.7018;     R @ 500: 0.7261;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4703;    mR @ 100: 0.5134;    mR @ 500: 0.5454;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7683) (covered in:0.6875) (covering:0.5143) (eating:0.8235) (flying in:0.9091) (growing on:0.5000) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7279) (standing on:0.4763) (using:0.5500) (walking in:0.0000) (walking on:0.6757) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-14 20:31:21 - train.py[line:487] - INFO: 0.7018164756811816
2022-10-14 20:31:21 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-14 20:31:21 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.356 | loss_v1 0 | loss_v2 0 | nll_loss 0.213 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.701816 | ppl 1.16 | vqa_score 0.5529 | wps 118.2 | wpb 89.9 | bsz 30 | num_updates 3000 | best_R@100 0.702813
2022-10-14 20:31:21 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3000 updates
2022-10-14 20:31:21 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-14 20:31:27 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-14 20:31:30 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 0.7018164756811816) (writing took 8.363199723884463 seconds)
2022-10-14 20:31:46 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=3010, lr=3.25405e-05, gnorm=0.937, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14818
2022-10-14 20:31:58 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.1, ups=0.88, wpb=110.4, bsz=40, num_updates=3020, lr=3.26486e-05, gnorm=0.841, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14835
2022-10-14 20:32:09 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.1, ups=0.91, wpb=111.5, bsz=40, num_updates=3030, lr=3.27568e-05, gnorm=0.931, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14846
2022-10-14 20:32:20 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.4, ups=0.89, wpb=109, bsz=40, num_updates=3040, lr=3.28649e-05, gnorm=0.903, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14857
2022-10-14 20:32:31 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.8, ups=0.93, wpb=110.5, bsz=40, num_updates=3050, lr=3.2973e-05, gnorm=0.866, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=14868
2022-10-14 20:32:42 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.8, ups=0.89, wpb=111.4, bsz=40, num_updates=3060, lr=3.30811e-05, gnorm=0.821, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14879
2022-10-14 20:32:53 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.5, ups=0.92, wpb=109.5, bsz=40, num_updates=3070, lr=3.31892e-05, gnorm=0.864, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14890
2022-10-14 20:33:04 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=3080, lr=3.32973e-05, gnorm=0.84, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14901
2022-10-14 20:33:15 - progress_bar.py[line:274] - INFO: epoch 001:   3093 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.7, ups=0.91, wpb=110.1, bsz=40, num_updates=3090, lr=3.34054e-05, gnorm=0.845, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14912
2022-10-14 20:33:17 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-14 20:33:27 - progress_bar.py[line:274] - INFO: epoch 001:   3104 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=89.1, ups=0.81, wpb=109.6, bsz=40, num_updates=3100, lr=3.35135e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=14924
2022-10-14 20:33:38 - progress_bar.py[line:274] - INFO: epoch 001:   3114 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.6, ups=0.89, wpb=109.1, bsz=40, num_updates=3110, lr=3.36216e-05, gnorm=0.787, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14935
2022-10-14 20:33:50 - progress_bar.py[line:274] - INFO: epoch 001:   3124 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=3120, lr=3.37297e-05, gnorm=0.853, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14947
2022-10-14 20:34:01 - progress_bar.py[line:274] - INFO: epoch 001:   3134 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.9, ups=0.91, wpb=111.4, bsz=40, num_updates=3130, lr=3.38378e-05, gnorm=0.781, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14958
2022-10-14 20:34:12 - progress_bar.py[line:274] - INFO: epoch 001:   3144 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.7, ups=0.87, wpb=109.7, bsz=40, num_updates=3140, lr=3.39459e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=14969
2022-10-14 20:34:23 - progress_bar.py[line:274] - INFO: epoch 001:   3154 / 28910 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.6, ups=0.91, wpb=109.8, bsz=40, num_updates=3150, lr=3.40541e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=14980
2022-10-14 20:34:35 - progress_bar.py[line:274] - INFO: epoch 001:   3164 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.1, ups=0.87, wpb=109.5, bsz=40, num_updates=3160, lr=3.41622e-05, gnorm=0.949, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14992
2022-10-14 20:34:46 - progress_bar.py[line:274] - INFO: epoch 001:   3174 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.5, ups=0.91, wpb=109.8, bsz=40, num_updates=3170, lr=3.42703e-05, gnorm=0.95, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15003
2022-10-14 20:34:57 - progress_bar.py[line:274] - INFO: epoch 001:   3184 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.4, ups=0.88, wpb=110.9, bsz=40, num_updates=3180, lr=3.43784e-05, gnorm=0.946, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15014
2022-10-14 20:35:08 - progress_bar.py[line:274] - INFO: epoch 001:   3194 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.2, ups=0.93, wpb=109.1, bsz=40, num_updates=3190, lr=3.44865e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15025
2022-10-14 20:35:19 - progress_bar.py[line:274] - INFO: epoch 001:   3204 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.9, ups=0.9, wpb=109.4, bsz=40, num_updates=3200, lr=3.45946e-05, gnorm=1.07, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15036
2022-10-14 20:35:30 - progress_bar.py[line:274] - INFO: epoch 001:   3214 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.3, ups=0.88, wpb=109.5, bsz=40, num_updates=3210, lr=3.47027e-05, gnorm=0.938, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15047
2022-10-14 20:35:42 - progress_bar.py[line:274] - INFO: epoch 001:   3224 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=96.6, ups=0.89, wpb=108.5, bsz=40, num_updates=3220, lr=3.48108e-05, gnorm=0.865, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15059
2022-10-14 20:35:52 - progress_bar.py[line:274] - INFO: epoch 001:   3234 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=102.6, ups=0.92, wpb=111.8, bsz=40, num_updates=3230, lr=3.49189e-05, gnorm=0.936, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15069
2022-10-14 20:36:04 - progress_bar.py[line:274] - INFO: epoch 001:   3244 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.2, ups=0.88, wpb=109.1, bsz=40, num_updates=3240, lr=3.5027e-05, gnorm=0.869, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15081
2022-10-14 20:36:15 - progress_bar.py[line:274] - INFO: epoch 001:   3254 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=3250, lr=3.51351e-05, gnorm=0.915, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15092
2022-10-14 20:36:26 - progress_bar.py[line:274] - INFO: epoch 001:   3264 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=3260, lr=3.52432e-05, gnorm=0.996, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15103
2022-10-14 20:36:37 - progress_bar.py[line:274] - INFO: epoch 001:   3274 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.5, ups=0.9, wpb=109.8, bsz=40, num_updates=3270, lr=3.53514e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15114
2022-10-14 20:36:49 - progress_bar.py[line:274] - INFO: epoch 001:   3284 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.9, ups=0.89, wpb=109.5, bsz=40, num_updates=3280, lr=3.54595e-05, gnorm=0.943, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15126
2022-10-14 20:36:59 - progress_bar.py[line:274] - INFO: epoch 001:   3294 / 28910 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.9, ups=0.93, wpb=109.2, bsz=40, num_updates=3290, lr=3.55676e-05, gnorm=0.851, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15136
2022-10-14 20:37:10 - progress_bar.py[line:274] - INFO: epoch 001:   3304 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.7, ups=0.91, wpb=111.3, bsz=40, num_updates=3300, lr=3.56757e-05, gnorm=0.925, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15147
2022-10-14 20:37:21 - progress_bar.py[line:274] - INFO: epoch 001:   3314 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.6, ups=0.89, wpb=110.2, bsz=40, num_updates=3310, lr=3.57838e-05, gnorm=0.888, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15158
2022-10-14 20:37:33 - progress_bar.py[line:274] - INFO: epoch 001:   3324 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=3320, lr=3.58919e-05, gnorm=1.071, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15170
2022-10-14 20:37:44 - progress_bar.py[line:274] - INFO: epoch 001:   3334 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=3330, lr=3.6e-05, gnorm=0.996, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15181
2022-10-14 20:37:55 - progress_bar.py[line:274] - INFO: epoch 001:   3344 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=95.3, ups=0.87, wpb=109.5, bsz=40, num_updates=3340, lr=3.61081e-05, gnorm=1.145, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15192
2022-10-14 20:38:06 - progress_bar.py[line:274] - INFO: epoch 001:   3354 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=3350, lr=3.62162e-05, gnorm=0.884, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15203
2022-10-14 20:38:18 - progress_bar.py[line:274] - INFO: epoch 001:   3364 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.4, ups=0.9, wpb=111.2, bsz=40, num_updates=3360, lr=3.63243e-05, gnorm=0.825, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15215
2022-10-14 20:38:29 - progress_bar.py[line:274] - INFO: epoch 001:   3374 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.9, ups=0.91, wpb=110, bsz=40, num_updates=3370, lr=3.64324e-05, gnorm=0.9, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15226
2022-10-14 20:38:40 - progress_bar.py[line:274] - INFO: epoch 001:   3384 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.4, ups=0.89, wpb=109, bsz=40, num_updates=3380, lr=3.65405e-05, gnorm=0.986, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15237
2022-10-14 20:38:51 - progress_bar.py[line:274] - INFO: epoch 001:   3394 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=3390, lr=3.66486e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15248
2022-10-14 20:39:02 - progress_bar.py[line:274] - INFO: epoch 001:   3404 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=3400, lr=3.67568e-05, gnorm=1.087, clip=70, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15259
2022-10-14 20:39:13 - progress_bar.py[line:274] - INFO: epoch 001:   3414 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.2, ups=0.89, wpb=111.7, bsz=40, num_updates=3410, lr=3.68649e-05, gnorm=1.141, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15270
2022-10-14 20:39:25 - progress_bar.py[line:274] - INFO: epoch 001:   3424 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.5, ups=0.89, wpb=109.7, bsz=40, num_updates=3420, lr=3.6973e-05, gnorm=0.992, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15282
2022-10-14 20:39:36 - progress_bar.py[line:274] - INFO: epoch 001:   3434 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=3430, lr=3.70811e-05, gnorm=0.863, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15293
2022-10-14 20:39:47 - progress_bar.py[line:274] - INFO: epoch 001:   3444 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=3440, lr=3.71892e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15304
2022-10-14 20:39:58 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 28910 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=3450, lr=3.72973e-05, gnorm=0.996, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15315
2022-10-14 20:40:09 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.7, ups=0.92, wpb=109.8, bsz=40, num_updates=3460, lr=3.74054e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=15326
2022-10-14 20:40:21 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=3470, lr=3.75135e-05, gnorm=1.106, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15338
2022-10-14 20:40:32 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.6, ups=0.9, wpb=111.9, bsz=40, num_updates=3480, lr=3.76216e-05, gnorm=0.894, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15349
2022-10-14 20:40:43 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.8, ups=0.87, wpb=111.2, bsz=40, num_updates=3490, lr=3.77297e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15360
2022-10-14 20:40:54 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.7, ups=0.91, wpb=109.2, bsz=40, num_updates=3500, lr=3.78378e-05, gnorm=0.955, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15371
2022-10-14 20:41:06 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.5, ups=0.87, wpb=109.4, bsz=40, num_updates=3510, lr=3.79459e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15383
2022-10-14 20:41:17 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.2, ups=0.89, wpb=108.7, bsz=40, num_updates=3520, lr=3.80541e-05, gnorm=0.929, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15394
2022-10-14 20:41:28 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.2, ups=0.91, wpb=110.1, bsz=40, num_updates=3530, lr=3.81622e-05, gnorm=1.001, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15405
2022-10-14 20:41:39 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.6, ups=0.88, wpb=109.3, bsz=40, num_updates=3540, lr=3.82703e-05, gnorm=1.226, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15416
2022-10-14 20:41:50 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=3550, lr=3.83784e-05, gnorm=1.051, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15427
2022-10-14 20:42:01 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=3560, lr=3.84865e-05, gnorm=0.943, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15438
2022-10-14 20:42:12 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=3570, lr=3.85946e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15450
2022-10-14 20:42:24 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=3580, lr=3.87027e-05, gnorm=0.878, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15461
2022-10-14 20:42:35 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=3590, lr=3.88108e-05, gnorm=0.976, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15472
2022-10-14 20:42:46 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.433, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.7, ups=0.89, wpb=109.9, bsz=40, num_updates=3600, lr=3.89189e-05, gnorm=1.03, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15483
2022-10-14 20:42:57 - progress_bar.py[line:274] - INFO: epoch 001:   3614 / 28910 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.6, ups=0.9, wpb=110.1, bsz=40, num_updates=3610, lr=3.9027e-05, gnorm=0.767, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15494
2022-10-14 20:43:09 - progress_bar.py[line:274] - INFO: epoch 001:   3624 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.355, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.1, ups=0.88, wpb=109, bsz=40, num_updates=3620, lr=3.91351e-05, gnorm=0.891, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15506
2022-10-14 20:43:20 - progress_bar.py[line:274] - INFO: epoch 001:   3634 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.3, ups=0.89, wpb=111, bsz=40, num_updates=3630, lr=3.92432e-05, gnorm=0.859, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15517
2022-10-14 20:43:31 - progress_bar.py[line:274] - INFO: epoch 001:   3644 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.6, ups=0.88, wpb=112.2, bsz=40, num_updates=3640, lr=3.93514e-05, gnorm=0.886, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15528
2022-10-14 20:43:43 - progress_bar.py[line:274] - INFO: epoch 001:   3654 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99, ups=0.89, wpb=111.7, bsz=40, num_updates=3650, lr=3.94595e-05, gnorm=0.88, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15540
2022-10-14 20:43:49 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-14 20:43:55 - progress_bar.py[line:274] - INFO: epoch 001:   3665 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=93, ups=0.84, wpb=111.2, bsz=40, num_updates=3660, lr=3.95676e-05, gnorm=0.984, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=15552
2022-10-14 20:44:06 - progress_bar.py[line:274] - INFO: epoch 001:   3675 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=3670, lr=3.96757e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15563
2022-10-14 20:44:17 - progress_bar.py[line:274] - INFO: epoch 001:   3685 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=3680, lr=3.97838e-05, gnorm=1.017, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15574
2022-10-14 20:44:28 - progress_bar.py[line:274] - INFO: epoch 001:   3695 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=3690, lr=3.98919e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=15585
2022-10-14 20:44:39 - progress_bar.py[line:274] - INFO: epoch 001:   3705 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=101.3, ups=0.92, wpb=110.4, bsz=40, num_updates=3700, lr=4e-05, gnorm=0.918, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15596
2022-10-14 20:44:51 - progress_bar.py[line:274] - INFO: epoch 001:   3715 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=3710, lr=4.01081e-05, gnorm=0.925, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15608
2022-10-14 20:45:02 - progress_bar.py[line:274] - INFO: epoch 001:   3725 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.5, ups=0.9, wpb=111.3, bsz=40, num_updates=3720, lr=4.02162e-05, gnorm=0.783, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15619
2022-10-14 20:45:13 - progress_bar.py[line:274] - INFO: epoch 001:   3735 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=3730, lr=4.03243e-05, gnorm=0.934, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15630
2022-10-14 20:45:24 - progress_bar.py[line:274] - INFO: epoch 001:   3745 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.382, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102.9, ups=0.93, wpb=110.9, bsz=40, num_updates=3740, lr=4.04324e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15641
2022-10-14 20:45:35 - progress_bar.py[line:274] - INFO: epoch 001:   3755 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.2, ups=0.87, wpb=110.8, bsz=40, num_updates=3750, lr=4.05405e-05, gnorm=0.849, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15652
2022-10-14 20:45:47 - progress_bar.py[line:274] - INFO: epoch 001:   3765 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=94.6, ups=0.86, wpb=109.5, bsz=40, num_updates=3760, lr=4.06486e-05, gnorm=0.983, clip=40, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=15664
2022-10-14 20:45:58 - progress_bar.py[line:274] - INFO: epoch 001:   3775 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.2, ups=0.89, wpb=111.4, bsz=40, num_updates=3770, lr=4.07568e-05, gnorm=0.978, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15675
2022-10-14 20:46:09 - progress_bar.py[line:274] - INFO: epoch 001:   3785 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.8, ups=0.88, wpb=110.5, bsz=40, num_updates=3780, lr=4.08649e-05, gnorm=0.852, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15686
2022-10-14 20:46:21 - progress_bar.py[line:274] - INFO: epoch 001:   3795 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=3790, lr=4.0973e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15698
2022-10-14 20:46:32 - progress_bar.py[line:274] - INFO: epoch 001:   3805 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.1, ups=0.9, wpb=111.2, bsz=40, num_updates=3800, lr=4.10811e-05, gnorm=0.809, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15709
2022-10-14 20:46:43 - progress_bar.py[line:274] - INFO: epoch 001:   3815 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.405, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.6, ups=0.88, wpb=108.9, bsz=40, num_updates=3810, lr=4.11892e-05, gnorm=1.197, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15720
2022-10-14 20:46:54 - progress_bar.py[line:274] - INFO: epoch 001:   3825 / 28910 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=102.9, ups=0.93, wpb=111, bsz=40, num_updates=3820, lr=4.12973e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15731
2022-10-14 20:47:05 - progress_bar.py[line:274] - INFO: epoch 001:   3835 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=3830, lr=4.14054e-05, gnorm=0.896, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15742
2022-10-14 20:47:17 - progress_bar.py[line:274] - INFO: epoch 001:   3845 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.3, ups=0.87, wpb=109.7, bsz=40, num_updates=3840, lr=4.15135e-05, gnorm=1.063, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15754
2022-10-14 20:47:28 - progress_bar.py[line:274] - INFO: epoch 001:   3855 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=3850, lr=4.16216e-05, gnorm=1.233, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=15765
2022-10-14 20:47:39 - progress_bar.py[line:274] - INFO: epoch 001:   3865 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.5, ups=0.9, wpb=109.4, bsz=40, num_updates=3860, lr=4.17297e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15776
2022-10-14 20:47:50 - progress_bar.py[line:274] - INFO: epoch 001:   3875 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.8, ups=0.89, wpb=110.1, bsz=40, num_updates=3870, lr=4.18378e-05, gnorm=0.891, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15787
2022-10-14 20:48:02 - progress_bar.py[line:274] - INFO: epoch 001:   3885 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.4, ups=0.89, wpb=110, bsz=40, num_updates=3880, lr=4.19459e-05, gnorm=0.784, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15799
2022-10-14 20:48:13 - progress_bar.py[line:274] - INFO: epoch 001:   3895 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.5, ups=0.89, wpb=112.8, bsz=40, num_updates=3890, lr=4.20541e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15810
2022-10-14 20:48:24 - progress_bar.py[line:274] - INFO: epoch 001:   3905 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96, ups=0.87, wpb=109.8, bsz=40, num_updates=3900, lr=4.21622e-05, gnorm=0.994, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15821
2022-10-14 20:48:35 - progress_bar.py[line:274] - INFO: epoch 001:   3915 / 28910 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.9, ups=0.9, wpb=109.7, bsz=40, num_updates=3910, lr=4.22703e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15832
2022-10-14 20:48:46 - progress_bar.py[line:274] - INFO: epoch 001:   3925 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=102.6, ups=0.93, wpb=110.8, bsz=40, num_updates=3920, lr=4.23784e-05, gnorm=0.797, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15843
2022-10-14 20:48:58 - progress_bar.py[line:274] - INFO: epoch 001:   3935 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=3930, lr=4.24865e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15855
2022-10-14 20:49:09 - progress_bar.py[line:274] - INFO: epoch 001:   3945 / 28910 loss=0.479, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.9, ups=0.9, wpb=111.8, bsz=40, num_updates=3940, lr=4.25946e-05, gnorm=0.941, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15866
2022-10-14 20:49:19 - progress_bar.py[line:274] - INFO: epoch 001:   3955 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=105.1, ups=0.95, wpb=111, bsz=40, num_updates=3950, lr=4.27027e-05, gnorm=1.095, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15876
2022-10-14 20:49:30 - progress_bar.py[line:274] - INFO: epoch 001:   3965 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.378, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102, ups=0.93, wpb=109.7, bsz=40, num_updates=3960, lr=4.28108e-05, gnorm=0.994, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15887
2022-10-14 20:49:41 - progress_bar.py[line:274] - INFO: epoch 001:   3975 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=3970, lr=4.29189e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15898
2022-10-14 20:49:53 - progress_bar.py[line:274] - INFO: epoch 001:   3985 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.1, ups=0.89, wpb=108.6, bsz=40, num_updates=3980, lr=4.3027e-05, gnorm=0.93, clip=20, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=15910
2022-10-14 20:50:04 - progress_bar.py[line:274] - INFO: epoch 001:   3995 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=3990, lr=4.31351e-05, gnorm=0.971, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15921
2022-10-14 20:50:15 - progress_bar.py[line:274] - INFO: epoch 001:   4005 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.7, ups=0.92, wpb=109.7, bsz=40, num_updates=4000, lr=4.32432e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=15932
2022-10-14 20:50:15 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-14 20:50:16 - train.py[line:549] - INFO: 0 / 4988
2022-10-14 20:50:16 - train.py[line:551] - INFO: load:0.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-14 20:52:49 - train.py[line:549] - INFO: 200 / 4988
2022-10-14 20:52:49 - train.py[line:551] - INFO: load:1.01 valid_run:152.97 task_valid:149.95 collect_output:1.92
2022-10-14 20:55:19 - train.py[line:549] - INFO: 400 / 4988
2022-10-14 20:55:19 - train.py[line:551] - INFO: load:1.04 valid_run:302.37 task_valid:294.39 collect_output:5.85
2022-10-14 20:55:20 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.35 GiB (GPU 1; 39.59 GiB total capacity; 8.97 GiB already allocated; 3.99 GiB free; 33.11 GiB reserved in total by PyTorch)
2022-10-14 20:55:20 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-14 20:55:20 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 17        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9185 MB |   15574 MB |    2342 TB |    2342 TB |
|       from large pool |    9041 MB |   15429 MB |    2342 TB |    2342 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9185 MB |   15574 MB |    2342 TB |    2342 TB |
|       from large pool |    9041 MB |   15429 MB |    2342 TB |    2342 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   33904 MB |   34762 MB |  187280 MB |  153376 MB |
|       from large pool |   33758 MB |   34610 MB |  186984 MB |  153226 MB |
|       from small pool |     146 MB |     152 MB |     296 MB |     150 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24718 MB |   29372 MB |    2399 TB |    2399 TB |
|       from large pool |   24717 MB |   29370 MB |    2398 TB |    2398 TB |
|       from small pool |       1 MB |       2 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |  107092 K  |  107089 K  |
|       from large pool |     563    |     575    |   35034 K  |   35033 K  |
|       from small pool |    3106    |    3116    |   72058 K  |   72055 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |  107092 K  |  107089 K  |
|       from large pool |     563    |     575    |   35034 K  |   35033 K  |
|       from small pool |    3106    |    3116    |   72058 K  |   72055 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     166    |     171    |     518    |     352    |
|       from large pool |      93    |      95    |     370    |     277    |
|       from small pool |      73    |      76    |     148    |      75    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     104    |     118    |   77569 K  |   77568 K  |
|       from large pool |      64    |      67    |   15516 K  |   15516 K  |
|       from small pool |      40    |      55    |   62052 K  |   62052 K  |
|===========================================================================|

2022-10-14 20:55:20 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-14 20:57:53 - train.py[line:549] - INFO: 600 / 4988
2022-10-14 20:57:53 - train.py[line:551] - INFO: load:1.07 valid_run:456.49 task_valid:438.97 collect_output:14.32
2022-10-14 21:00:23 - train.py[line:549] - INFO: 800 / 4988
2022-10-14 21:00:23 - train.py[line:551] - INFO: load:1.10 valid_run:606.39 task_valid:584.96 collect_output:17.19
2022-10-14 21:02:56 - train.py[line:549] - INFO: 1000 / 4988
2022-10-14 21:02:56 - train.py[line:551] - INFO: load:1.12 valid_run:759.41 task_valid:733.39 collect_output:20.73
2022-10-14 21:05:28 - train.py[line:549] - INFO: 1200 / 4988
2022-10-14 21:05:28 - train.py[line:551] - INFO: load:1.16 valid_run:911.68 task_valid:879.69 collect_output:25.65
2022-10-14 21:08:03 - train.py[line:549] - INFO: 1400 / 4988
2022-10-14 21:08:03 - train.py[line:551] - INFO: load:1.19 valid_run:1065.86 task_valid:1027.02 collect_output:31.44
2022-10-14 21:10:35 - train.py[line:549] - INFO: 1600 / 4988
2022-10-14 21:10:35 - train.py[line:551] - INFO: load:1.21 valid_run:1217.88 task_valid:1169.66 collect_output:39.75
2022-10-14 21:13:05 - train.py[line:549] - INFO: 1800 / 4988
2022-10-14 21:13:05 - train.py[line:551] - INFO: load:1.25 valid_run:1368.36 task_valid:1315.42 collect_output:43.41
2022-10-14 21:15:35 - train.py[line:549] - INFO: 2000 / 4988
2022-10-14 21:15:35 - train.py[line:551] - INFO: load:1.28 valid_run:1517.96 task_valid:1459.94 collect_output:47.46
2022-10-14 21:18:05 - train.py[line:549] - INFO: 2200 / 4988
2022-10-14 21:18:05 - train.py[line:551] - INFO: load:1.30 valid_run:1668.16 task_valid:1605.54 collect_output:51.05
2022-10-14 21:20:36 - train.py[line:549] - INFO: 2400 / 4988
2022-10-14 21:20:36 - train.py[line:551] - INFO: load:1.33 valid_run:1818.54 task_valid:1750.98 collect_output:55.00
2022-10-14 21:23:06 - train.py[line:549] - INFO: 2600 / 4988
2022-10-14 21:23:06 - train.py[line:551] - INFO: load:1.36 valid_run:1968.77 task_valid:1893.25 collect_output:61.95
2022-10-14 21:25:37 - train.py[line:549] - INFO: 2800 / 4988
2022-10-14 21:25:37 - train.py[line:551] - INFO: load:1.38 valid_run:2119.85 task_valid:2039.22 collect_output:66.04
2022-10-14 21:28:07 - train.py[line:549] - INFO: 3000 / 4988
2022-10-14 21:28:07 - train.py[line:551] - INFO: load:1.41 valid_run:2270.20 task_valid:2186.01 collect_output:68.60
2022-10-14 21:30:38 - train.py[line:549] - INFO: 3200 / 4988
2022-10-14 21:30:38 - train.py[line:551] - INFO: load:1.44 valid_run:2420.61 task_valid:2330.50 collect_output:73.51
2022-10-14 21:33:10 - train.py[line:549] - INFO: 3400 / 4988
2022-10-14 21:33:10 - train.py[line:551] - INFO: load:1.46 valid_run:2572.89 task_valid:2476.58 collect_output:78.72
2022-10-14 21:35:41 - train.py[line:549] - INFO: 3600 / 4988
2022-10-14 21:35:41 - train.py[line:551] - INFO: load:1.49 valid_run:2723.93 task_valid:2624.17 collect_output:81.16
2022-10-14 21:38:10 - train.py[line:549] - INFO: 3800 / 4988
2022-10-14 21:38:10 - train.py[line:551] - INFO: load:1.52 valid_run:2872.56 task_valid:2766.26 collect_output:86.67
2022-10-14 21:40:41 - train.py[line:549] - INFO: 4000 / 4988
2022-10-14 21:40:41 - train.py[line:551] - INFO: load:1.54 valid_run:3023.30 task_valid:2911.92 collect_output:90.75
2022-10-14 21:43:14 - train.py[line:549] - INFO: 4200 / 4988
2022-10-14 21:43:14 - train.py[line:551] - INFO: load:1.57 valid_run:3175.93 task_valid:3057.32 collect_output:96.95
2022-10-14 21:45:44 - train.py[line:549] - INFO: 4400 / 4988
2022-10-14 21:45:44 - train.py[line:551] - INFO: load:1.60 valid_run:3325.93 task_valid:3202.71 collect_output:100.54
2022-10-14 21:48:15 - train.py[line:549] - INFO: 4600 / 4988
2022-10-14 21:48:15 - train.py[line:551] - INFO: load:1.62 valid_run:3477.57 task_valid:3349.45 collect_output:104.44
2022-10-14 21:50:47 - train.py[line:549] - INFO: 4800 / 4988
2022-10-14 21:50:47 - train.py[line:551] - INFO: load:1.65 valid_run:3629.45 task_valid:3496.53 collect_output:108.26

====================================================================================================
SGG eval:     R @ 50: 0.6730;     R @ 100: 0.7076;     R @ 500: 0.7250;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4698;    mR @ 100: 0.5163;    mR @ 500: 0.5567;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.8125) (covering:0.4429) (eating:0.8235) (flying in:0.8182) (growing on:0.5000) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7687) (standing on:0.4343) (using:0.6000) (walking in:0.0000) (walking on:0.6622) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6730;     R @ 100: 0.7076;     R @ 500: 0.7250;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4698;    mR @ 100: 0.5163;    mR @ 500: 0.5567;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.8125) (covering:0.4429) (eating:0.8235) (flying in:0.8182) (growing on:0.5000) (hanging from:0.4677) (lying on:0.4000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7687) (standing on:0.4343) (using:0.6000) (walking in:0.0000) (walking on:0.6622) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-14 21:53:19 - train.py[line:487] - INFO: 0.7075528393175452
2022-10-14 21:53:19 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-14 21:53:19 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.365 | loss_v1 0 | loss_v2 0 | nll_loss 0.217 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.707553 | ppl 1.16 | vqa_score 0.5563 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.707553
2022-10-14 21:53:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2022-10-14 21:53:19 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-14 21:53:25 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-14 21:53:31 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.7075528393175452) (writing took 12.281347205862403 seconds)
2022-10-14 21:53:43 - progress_bar.py[line:274] - INFO: epoch 001:   4015 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=0.3, ups=0, wpb=109.2, bsz=40, num_updates=4010, lr=4.33514e-05, gnorm=0.986, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19740
2022-10-14 21:53:54 - progress_bar.py[line:274] - INFO: epoch 001:   4025 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.7, ups=0.89, wpb=111.1, bsz=40, num_updates=4020, lr=4.34595e-05, gnorm=0.828, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19751
2022-10-14 21:54:05 - progress_bar.py[line:274] - INFO: epoch 001:   4035 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.3, ups=0.91, wpb=111.2, bsz=40, num_updates=4030, lr=4.35676e-05, gnorm=1.126, clip=60, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=19762
2022-10-14 21:54:16 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.3, ups=0.88, wpb=111.1, bsz=40, num_updates=4040, lr=4.36757e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19773
2022-10-14 21:54:27 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101.5, ups=0.92, wpb=110.7, bsz=40, num_updates=4050, lr=4.37838e-05, gnorm=0.834, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19784
2022-10-14 21:54:38 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.4, ups=0.9, wpb=110.2, bsz=40, num_updates=4060, lr=4.38919e-05, gnorm=0.964, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19795
2022-10-14 21:54:49 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.3, ups=0.92, wpb=110.6, bsz=40, num_updates=4070, lr=4.4e-05, gnorm=1.148, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19806
2022-10-14 21:55:00 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101, ups=0.92, wpb=110.1, bsz=40, num_updates=4080, lr=4.41081e-05, gnorm=0.99, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19817
2022-10-14 21:55:12 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.2, ups=0.87, wpb=109.3, bsz=40, num_updates=4090, lr=4.42162e-05, gnorm=0.968, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19829
2022-10-14 21:55:23 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.4, ups=0.9, wpb=110.2, bsz=40, num_updates=4100, lr=4.43243e-05, gnorm=1.003, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19840
2022-10-14 21:55:34 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.36, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=4110, lr=4.44324e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19851
2022-10-14 21:55:45 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.7, ups=0.88, wpb=109.8, bsz=40, num_updates=4120, lr=4.45405e-05, gnorm=0.895, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19862
2022-10-14 21:55:56 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.91, wpb=110.5, bsz=40, num_updates=4130, lr=4.46486e-05, gnorm=0.916, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19873
2022-10-14 21:56:07 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=102.1, ups=0.93, wpb=110, bsz=40, num_updates=4140, lr=4.47568e-05, gnorm=0.858, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19884
2022-10-14 21:56:18 - progress_bar.py[line:274] - INFO: epoch 001:   4155 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101.6, ups=0.92, wpb=111, bsz=40, num_updates=4150, lr=4.48649e-05, gnorm=0.826, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19895
2022-10-14 21:56:29 - progress_bar.py[line:274] - INFO: epoch 001:   4165 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.5, ups=0.92, wpb=109.7, bsz=40, num_updates=4160, lr=4.4973e-05, gnorm=1.058, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19906
2022-10-14 21:56:40 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-14 21:56:41 - progress_bar.py[line:274] - INFO: epoch 001:   4176 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=87.7, ups=0.8, wpb=109, bsz=40, num_updates=4170, lr=4.50811e-05, gnorm=0.983, clip=40, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=19918
2022-10-14 21:56:53 - progress_bar.py[line:274] - INFO: epoch 001:   4186 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.5, ups=0.89, wpb=111.5, bsz=40, num_updates=4180, lr=4.51892e-05, gnorm=0.914, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19930
2022-10-14 21:57:04 - progress_bar.py[line:274] - INFO: epoch 001:   4196 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=4190, lr=4.52973e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19941
2022-10-14 21:57:15 - progress_bar.py[line:274] - INFO: epoch 001:   4206 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.9, ups=0.92, wpb=111.3, bsz=40, num_updates=4200, lr=4.54054e-05, gnorm=0.982, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19952
2022-10-14 21:57:26 - progress_bar.py[line:274] - INFO: epoch 001:   4216 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.363, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.9, ups=0.9, wpb=109.9, bsz=40, num_updates=4210, lr=4.55135e-05, gnorm=0.933, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19963
2022-10-14 21:57:37 - progress_bar.py[line:274] - INFO: epoch 001:   4226 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101.2, ups=0.91, wpb=110.8, bsz=40, num_updates=4220, lr=4.56216e-05, gnorm=0.991, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19974
2022-10-14 21:57:48 - progress_bar.py[line:274] - INFO: epoch 001:   4236 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=4230, lr=4.57297e-05, gnorm=0.982, clip=40, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=19985
2022-10-14 21:57:59 - progress_bar.py[line:274] - INFO: epoch 001:   4246 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.5, ups=0.92, wpb=110.7, bsz=40, num_updates=4240, lr=4.58378e-05, gnorm=0.82, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19996
2022-10-14 21:58:10 - progress_bar.py[line:274] - INFO: epoch 001:   4256 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=4250, lr=4.59459e-05, gnorm=0.898, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20007
2022-10-14 21:58:21 - progress_bar.py[line:274] - INFO: epoch 001:   4266 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.8, ups=0.89, wpb=111.8, bsz=40, num_updates=4260, lr=4.60541e-05, gnorm=1.114, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20018
2022-10-14 21:58:32 - progress_bar.py[line:274] - INFO: epoch 001:   4276 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.9, ups=0.9, wpb=109.4, bsz=40, num_updates=4270, lr=4.61622e-05, gnorm=1.037, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20029
2022-10-14 21:58:43 - progress_bar.py[line:274] - INFO: epoch 001:   4286 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.3, ups=0.91, wpb=108.4, bsz=40, num_updates=4280, lr=4.62703e-05, gnorm=1.103, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20040
2022-10-14 21:58:54 - progress_bar.py[line:274] - INFO: epoch 001:   4296 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=102.4, ups=0.92, wpb=111, bsz=40, num_updates=4290, lr=4.63784e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20051
2022-10-14 21:59:05 - progress_bar.py[line:274] - INFO: epoch 001:   4306 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=4300, lr=4.64865e-05, gnorm=0.979, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20063
2022-10-14 21:59:17 - progress_bar.py[line:274] - INFO: epoch 001:   4316 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.3, ups=0.89, wpb=111.4, bsz=40, num_updates=4310, lr=4.65946e-05, gnorm=0.933, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20074
2022-10-14 21:59:28 - progress_bar.py[line:274] - INFO: epoch 001:   4326 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=4320, lr=4.67027e-05, gnorm=0.922, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20085
2022-10-14 21:59:39 - progress_bar.py[line:274] - INFO: epoch 001:   4336 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.342, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=96.1, ups=0.88, wpb=108.7, bsz=40, num_updates=4330, lr=4.68108e-05, gnorm=1.005, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20096
2022-10-14 21:59:51 - progress_bar.py[line:274] - INFO: epoch 001:   4346 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.368, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.3, ups=0.89, wpb=110.8, bsz=40, num_updates=4340, lr=4.69189e-05, gnorm=1.116, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20108
2022-10-14 22:00:02 - progress_bar.py[line:274] - INFO: epoch 001:   4356 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.8, ups=0.9, wpb=111.6, bsz=40, num_updates=4350, lr=4.7027e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20119
2022-10-14 22:00:13 - progress_bar.py[line:274] - INFO: epoch 001:   4366 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=4360, lr=4.71351e-05, gnorm=1.022, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20130
2022-10-14 22:00:24 - progress_bar.py[line:274] - INFO: epoch 001:   4376 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.354, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=4370, lr=4.72432e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20141
2022-10-14 22:00:35 - progress_bar.py[line:274] - INFO: epoch 001:   4386 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.7, ups=0.88, wpb=110.9, bsz=40, num_updates=4380, lr=4.73514e-05, gnorm=0.946, clip=40, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=20152
2022-10-14 22:00:46 - progress_bar.py[line:274] - INFO: epoch 001:   4396 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=4390, lr=4.74595e-05, gnorm=0.847, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20163
2022-10-14 22:00:57 - progress_bar.py[line:274] - INFO: epoch 001:   4406 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=103.8, ups=0.94, wpb=110.8, bsz=40, num_updates=4400, lr=4.75676e-05, gnorm=0.847, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20174
2022-10-14 22:01:08 - progress_bar.py[line:274] - INFO: epoch 001:   4416 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=4410, lr=4.76757e-05, gnorm=0.983, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20185
2022-10-14 22:01:19 - progress_bar.py[line:274] - INFO: epoch 001:   4426 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.7, ups=0.89, wpb=111.8, bsz=40, num_updates=4420, lr=4.77838e-05, gnorm=0.883, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20196
2022-10-14 22:01:31 - progress_bar.py[line:274] - INFO: epoch 001:   4436 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=4430, lr=4.78919e-05, gnorm=0.864, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20208
2022-10-14 22:01:42 - progress_bar.py[line:274] - INFO: epoch 001:   4446 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.4, ups=0.91, wpb=109.8, bsz=40, num_updates=4440, lr=4.8e-05, gnorm=0.835, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20219
2022-10-14 22:01:53 - progress_bar.py[line:274] - INFO: epoch 001:   4456 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101.9, ups=0.92, wpb=111.3, bsz=40, num_updates=4450, lr=4.81081e-05, gnorm=0.824, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20230
2022-10-14 22:02:04 - progress_bar.py[line:274] - INFO: epoch 001:   4466 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=4460, lr=4.82162e-05, gnorm=0.914, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20241
2022-10-14 22:02:15 - progress_bar.py[line:274] - INFO: epoch 001:   4476 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.7, ups=0.92, wpb=109.8, bsz=40, num_updates=4470, lr=4.83243e-05, gnorm=1.083, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20252
2022-10-14 22:02:26 - progress_bar.py[line:274] - INFO: epoch 001:   4486 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=96.7, ups=0.88, wpb=109.5, bsz=40, num_updates=4480, lr=4.84324e-05, gnorm=0.94, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20263
2022-10-14 22:02:37 - progress_bar.py[line:274] - INFO: epoch 001:   4496 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99, ups=0.9, wpb=109.5, bsz=40, num_updates=4490, lr=4.85405e-05, gnorm=0.963, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20274
2022-10-14 22:02:48 - progress_bar.py[line:274] - INFO: epoch 001:   4506 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=4500, lr=4.86486e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20285
2022-10-14 22:03:00 - progress_bar.py[line:274] - INFO: epoch 001:   4516 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=4510, lr=4.87568e-05, gnorm=0.889, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20297
2022-10-14 22:03:11 - progress_bar.py[line:274] - INFO: epoch 001:   4526 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.8, ups=0.88, wpb=109.6, bsz=40, num_updates=4520, lr=4.88649e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20308
2022-10-14 22:03:22 - progress_bar.py[line:274] - INFO: epoch 001:   4536 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97, ups=0.89, wpb=108.6, bsz=40, num_updates=4530, lr=4.8973e-05, gnorm=0.933, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20319
2022-10-14 22:03:34 - progress_bar.py[line:274] - INFO: epoch 001:   4546 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=95.1, ups=0.87, wpb=109.4, bsz=40, num_updates=4540, lr=4.90811e-05, gnorm=1.001, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20331
2022-10-14 22:03:45 - progress_bar.py[line:274] - INFO: epoch 001:   4556 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.5, ups=0.89, wpb=110.8, bsz=40, num_updates=4550, lr=4.91892e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20342
2022-10-14 22:03:56 - progress_bar.py[line:274] - INFO: epoch 001:   4566 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.8, ups=0.87, wpb=109.9, bsz=40, num_updates=4560, lr=4.92973e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20353
2022-10-14 22:04:08 - progress_bar.py[line:274] - INFO: epoch 001:   4576 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=4570, lr=4.94054e-05, gnorm=0.86, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20365
2022-10-14 22:04:19 - progress_bar.py[line:274] - INFO: epoch 001:   4586 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100.2, ups=0.91, wpb=110.2, bsz=40, num_updates=4580, lr=4.95135e-05, gnorm=0.959, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20376
2022-10-14 22:04:30 - progress_bar.py[line:274] - INFO: epoch 001:   4596 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=4590, lr=4.96216e-05, gnorm=0.888, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20387
2022-10-14 22:04:41 - progress_bar.py[line:274] - INFO: epoch 001:   4606 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.5, ups=0.91, wpb=108.4, bsz=40, num_updates=4600, lr=4.97297e-05, gnorm=1.039, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20398
2022-10-14 22:04:52 - progress_bar.py[line:274] - INFO: epoch 001:   4616 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=4610, lr=4.98378e-05, gnorm=0.886, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20409
2022-10-14 22:05:04 - progress_bar.py[line:274] - INFO: epoch 001:   4626 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.6, ups=0.89, wpb=108.3, bsz=40, num_updates=4620, lr=4.99459e-05, gnorm=0.92, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20421
2022-10-14 22:05:15 - progress_bar.py[line:274] - INFO: epoch 001:   4636 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99, ups=0.91, wpb=109.3, bsz=40, num_updates=4630, lr=4.99977e-05, gnorm=0.894, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20432
2022-10-14 22:05:26 - progress_bar.py[line:274] - INFO: epoch 001:   4646 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.5, ups=0.9, wpb=109.5, bsz=40, num_updates=4640, lr=4.99932e-05, gnorm=0.916, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20443
2022-10-14 22:05:37 - progress_bar.py[line:274] - INFO: epoch 001:   4656 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=4650, lr=4.99887e-05, gnorm=0.821, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20454
2022-10-14 22:05:49 - progress_bar.py[line:274] - INFO: epoch 001:   4666 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.1, ups=0.87, wpb=112.5, bsz=40, num_updates=4660, lr=4.99842e-05, gnorm=0.825, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20466
2022-10-14 22:06:00 - progress_bar.py[line:274] - INFO: epoch 001:   4676 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.9, ups=0.9, wpb=110.8, bsz=40, num_updates=4670, lr=4.99797e-05, gnorm=0.881, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20477
2022-10-14 22:06:11 - progress_bar.py[line:274] - INFO: epoch 001:   4686 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=4680, lr=4.99752e-05, gnorm=0.969, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20488
2022-10-14 22:06:22 - progress_bar.py[line:274] - INFO: epoch 001:   4696 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.6, ups=0.88, wpb=109.7, bsz=40, num_updates=4690, lr=4.99707e-05, gnorm=0.88, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20499
2022-10-14 22:06:34 - progress_bar.py[line:274] - INFO: epoch 001:   4706 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=4700, lr=4.99662e-05, gnorm=0.813, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=20511
2022-10-14 22:06:45 - progress_bar.py[line:274] - INFO: epoch 001:   4716 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98, ups=0.88, wpb=111.3, bsz=40, num_updates=4710, lr=4.99617e-05, gnorm=0.894, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20522
2022-10-14 22:06:56 - progress_bar.py[line:274] - INFO: epoch 001:   4726 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=4720, lr=4.99572e-05, gnorm=0.974, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20533
2022-10-14 22:07:07 - progress_bar.py[line:274] - INFO: epoch 001:   4736 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=4730, lr=4.99527e-05, gnorm=0.966, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20544
2022-10-14 22:07:19 - progress_bar.py[line:274] - INFO: epoch 001:   4746 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=4740, lr=4.99482e-05, gnorm=0.95, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20556
2022-10-14 22:07:30 - progress_bar.py[line:274] - INFO: epoch 001:   4756 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=4750, lr=4.99437e-05, gnorm=0.86, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20567
2022-10-14 22:07:41 - progress_bar.py[line:274] - INFO: epoch 001:   4766 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.7, ups=0.91, wpb=110.7, bsz=40, num_updates=4760, lr=4.99392e-05, gnorm=0.9, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20578
2022-10-14 22:07:52 - progress_bar.py[line:274] - INFO: epoch 001:   4776 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=4770, lr=4.99347e-05, gnorm=0.994, clip=40, loss_scale=1024, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=20589
2022-10-14 22:08:03 - progress_bar.py[line:274] - INFO: epoch 001:   4786 / 28910 loss=0.478, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.1, ups=0.89, wpb=108.6, bsz=40, num_updates=4780, lr=4.99302e-05, gnorm=0.891, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20600
2022-10-14 22:08:14 - progress_bar.py[line:274] - INFO: epoch 001:   4796 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=101.6, ups=0.9, wpb=112.4, bsz=40, num_updates=4790, lr=4.99257e-05, gnorm=0.844, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20611
2022-10-14 22:08:25 - progress_bar.py[line:274] - INFO: epoch 001:   4806 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.9, ups=0.89, wpb=110.7, bsz=40, num_updates=4800, lr=4.99212e-05, gnorm=1.044, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20622
2022-10-14 22:08:36 - progress_bar.py[line:274] - INFO: epoch 001:   4816 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=101.3, ups=0.92, wpb=110.5, bsz=40, num_updates=4810, lr=4.99167e-05, gnorm=0.923, clip=40, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=20633
2022-10-14 22:08:47 - progress_bar.py[line:274] - INFO: epoch 001:   4826 / 28910 loss=0.474, loss_v1=0, loss_v2=0, nll_loss=0.358, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.3, ups=0.92, wpb=108.4, bsz=40, num_updates=4820, lr=4.99122e-05, gnorm=1.017, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20644
2022-10-14 22:08:59 - progress_bar.py[line:274] - INFO: epoch 001:   4836 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.6, ups=0.89, wpb=110.6, bsz=40, num_updates=4830, lr=4.99077e-05, gnorm=0.819, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20655
2022-10-14 22:09:09 - progress_bar.py[line:274] - INFO: epoch 001:   4846 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=103.2, ups=0.91, wpb=112.9, bsz=40, num_updates=4840, lr=4.99032e-05, gnorm=0.762, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20666
2022-10-14 22:09:20 - progress_bar.py[line:274] - INFO: epoch 001:   4856 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=102, ups=0.93, wpb=109.7, bsz=40, num_updates=4850, lr=4.98987e-05, gnorm=0.818, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20677
2022-10-14 22:09:31 - progress_bar.py[line:274] - INFO: epoch 001:   4866 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.4, ups=0.91, wpb=109.8, bsz=40, num_updates=4860, lr=4.98942e-05, gnorm=0.853, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20688
2022-10-14 22:09:42 - progress_bar.py[line:274] - INFO: epoch 001:   4876 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=4870, lr=4.98897e-05, gnorm=0.893, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20700
2022-10-14 22:09:54 - progress_bar.py[line:274] - INFO: epoch 001:   4886 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.6, ups=0.89, wpb=111, bsz=40, num_updates=4880, lr=4.98852e-05, gnorm=0.864, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20711
2022-10-14 22:10:05 - progress_bar.py[line:274] - INFO: epoch 001:   4896 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.4, ups=0.9, wpb=111, bsz=40, num_updates=4890, lr=4.98806e-05, gnorm=0.841, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20722
2022-10-14 22:10:16 - progress_bar.py[line:274] - INFO: epoch 001:   4906 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=102.4, ups=0.93, wpb=110.4, bsz=40, num_updates=4900, lr=4.98761e-05, gnorm=0.908, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20733
2022-10-14 22:10:27 - progress_bar.py[line:274] - INFO: epoch 001:   4916 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=4910, lr=4.98716e-05, gnorm=0.926, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20744
2022-10-14 22:10:38 - progress_bar.py[line:274] - INFO: epoch 001:   4926 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=102.4, ups=0.91, wpb=112.2, bsz=40, num_updates=4920, lr=4.98671e-05, gnorm=0.807, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20755
2022-10-14 22:10:49 - progress_bar.py[line:274] - INFO: epoch 001:   4936 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=4930, lr=4.98626e-05, gnorm=0.927, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20766
2022-10-14 22:11:00 - progress_bar.py[line:274] - INFO: epoch 001:   4946 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=4940, lr=4.98581e-05, gnorm=0.911, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20777
2022-10-14 22:11:11 - progress_bar.py[line:274] - INFO: epoch 001:   4956 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.3, ups=0.9, wpb=111.1, bsz=40, num_updates=4950, lr=4.98536e-05, gnorm=0.985, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20788
2022-10-14 22:11:23 - progress_bar.py[line:274] - INFO: epoch 001:   4966 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.3, ups=0.89, wpb=109.5, bsz=40, num_updates=4960, lr=4.98491e-05, gnorm=0.837, clip=10, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=20800
2022-10-14 22:11:34 - progress_bar.py[line:274] - INFO: epoch 001:   4976 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.8, ups=0.88, wpb=108.7, bsz=40, num_updates=4970, lr=4.98446e-05, gnorm=0.933, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20811
2022-10-14 22:11:45 - progress_bar.py[line:274] - INFO: epoch 001:   4986 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.2, ups=0.9, wpb=111.1, bsz=40, num_updates=4980, lr=4.98401e-05, gnorm=0.77, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20822
2022-10-14 22:11:56 - progress_bar.py[line:274] - INFO: epoch 001:   4996 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.6, ups=0.92, wpb=109.3, bsz=40, num_updates=4990, lr=4.98356e-05, gnorm=0.919, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20833
2022-10-14 22:12:07 - progress_bar.py[line:274] - INFO: epoch 001:   5006 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.8, ups=0.89, wpb=112.3, bsz=40, num_updates=5000, lr=4.98311e-05, gnorm=0.863, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20844
2022-10-14 22:12:07 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-14 22:12:09 - train.py[line:549] - INFO: 0 / 4988
2022-10-14 22:12:09 - train.py[line:551] - INFO: load:1.09 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-14 22:12:09 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.85 GiB already allocated; 6.07 GiB free; 31.03 GiB reserved in total by PyTorch)
2022-10-14 22:12:09 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-14 22:12:09 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 18        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9059 MB |   10284 MB |    3009 TB |    3009 TB |
|       from large pool |    8914 MB |   10139 MB |    3009 TB |    3009 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9059 MB |   10284 MB |    3009 TB |    3009 TB |
|       from large pool |    8914 MB |   10139 MB |    3009 TB |    3009 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31778 MB |   31780 MB |  193808 MB |  162030 MB |
|       from large pool |   31632 MB |   31632 MB |  193486 MB |  161854 MB |
|       from small pool |     146 MB |     148 MB |     322 MB |     176 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22718 MB |   27248 MB |    3810 TB |    3810 TB |
|       from large pool |   22717 MB |   27246 MB |    3809 TB |    3809 TB |
|       from small pool |       1 MB |       2 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  138029 K  |  138026 K  |
|       from large pool |     563    |     575    |   44968 K  |   44967 K  |
|       from small pool |    3095    |    3114    |   93061 K  |   93058 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  138029 K  |  138026 K  |
|       from large pool |     563    |     575    |   44968 K  |   44967 K  |
|       from small pool |    3095    |    3114    |   93061 K  |   93058 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     137    |     138    |     532    |     395    |
|       from large pool |      64    |      64    |     371    |     307    |
|       from small pool |      73    |      74    |     161    |      88    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      86    |      90    |  101858 K  |  101858 K  |
|       from large pool |      41    |      43    |   21387 K  |   21387 K  |
|       from small pool |      45    |      52    |   80471 K  |   80471 K  |
|===========================================================================|

2022-10-14 22:12:09 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-14 22:14:42 - train.py[line:549] - INFO: 200 / 4988
2022-10-14 22:14:42 - train.py[line:551] - INFO: load:1.12 valid_run:153.13 task_valid:149.29 collect_output:2.70
2022-10-14 22:17:11 - train.py[line:549] - INFO: 400 / 4988
2022-10-14 22:17:11 - train.py[line:551] - INFO: load:1.14 valid_run:302.23 task_valid:293.00 collect_output:7.03
2022-10-14 22:19:44 - train.py[line:549] - INFO: 600 / 4988
2022-10-14 22:19:44 - train.py[line:551] - INFO: load:1.17 valid_run:455.10 task_valid:436.62 collect_output:15.28
2022-10-14 22:22:14 - train.py[line:549] - INFO: 800 / 4988
2022-10-14 22:22:14 - train.py[line:551] - INFO: load:1.19 valid_run:604.86 task_valid:582.29 collect_output:18.34
2022-10-14 22:24:47 - train.py[line:549] - INFO: 1000 / 4988
2022-10-14 22:24:47 - train.py[line:551] - INFO: load:1.22 valid_run:758.09 task_valid:730.69 collect_output:22.12
2022-10-14 22:27:20 - train.py[line:549] - INFO: 1200 / 4988
2022-10-14 22:27:20 - train.py[line:551] - INFO: load:1.24 valid_run:910.43 task_valid:876.97 collect_output:27.16
2022-10-14 22:29:54 - train.py[line:549] - INFO: 1400 / 4988
2022-10-14 22:29:54 - train.py[line:551] - INFO: load:1.28 valid_run:1064.56 task_valid:1023.69 collect_output:33.54
2022-10-14 22:32:26 - train.py[line:549] - INFO: 1600 / 4988
2022-10-14 22:32:26 - train.py[line:551] - INFO: load:1.30 valid_run:1216.53 task_valid:1165.80 collect_output:42.37
2022-10-14 22:34:56 - train.py[line:549] - INFO: 1800 / 4988
2022-10-14 22:34:56 - train.py[line:551] - INFO: load:1.33 valid_run:1366.87 task_valid:1311.22 collect_output:46.31
2022-10-14 22:37:26 - train.py[line:549] - INFO: 2000 / 4988
2022-10-14 22:37:26 - train.py[line:551] - INFO: load:1.35 valid_run:1516.32 task_valid:1455.36 collect_output:50.56
2022-10-14 22:39:56 - train.py[line:549] - INFO: 2200 / 4988
2022-10-14 22:39:56 - train.py[line:551] - INFO: load:1.38 valid_run:1666.97 task_valid:1601.11 collect_output:54.45
2022-10-14 22:42:27 - train.py[line:549] - INFO: 2400 / 4988
2022-10-14 22:42:27 - train.py[line:551] - INFO: load:1.40 valid_run:1817.58 task_valid:1746.52 collect_output:58.62
2022-10-14 22:44:58 - train.py[line:549] - INFO: 2600 / 4988
2022-10-14 22:44:58 - train.py[line:551] - INFO: load:1.43 valid_run:1968.10 task_valid:1888.89 collect_output:65.73
2022-10-14 22:47:29 - train.py[line:549] - INFO: 2800 / 4988
2022-10-14 22:47:29 - train.py[line:551] - INFO: load:1.45 valid_run:2119.76 task_valid:2035.57 collect_output:69.64
2022-10-14 22:50:01 - train.py[line:549] - INFO: 3000 / 4988
2022-10-14 22:50:01 - train.py[line:551] - INFO: load:1.48 valid_run:2270.89 task_valid:2183.36 collect_output:71.92
2022-10-14 22:52:32 - train.py[line:549] - INFO: 3200 / 4988
2022-10-14 22:52:32 - train.py[line:551] - INFO: load:1.50 valid_run:2421.83 task_valid:2328.54 collect_output:76.65
2022-10-14 22:55:04 - train.py[line:549] - INFO: 3400 / 4988
2022-10-14 22:55:04 - train.py[line:551] - INFO: load:1.53 valid_run:2574.00 task_valid:2474.61 collect_output:81.78
2022-10-14 22:57:35 - train.py[line:549] - INFO: 3600 / 4988
2022-10-14 22:57:35 - train.py[line:551] - INFO: load:1.55 valid_run:2724.95 task_valid:2622.02 collect_output:84.34
2022-10-14 23:00:04 - train.py[line:549] - INFO: 3800 / 4988
2022-10-14 23:00:04 - train.py[line:551] - INFO: load:1.58 valid_run:2873.95 task_valid:2764.00 collect_output:90.36
2022-10-14 23:02:35 - train.py[line:549] - INFO: 4000 / 4988
2022-10-14 23:02:35 - train.py[line:551] - INFO: load:1.60 valid_run:3024.80 task_valid:2909.63 collect_output:94.59
2022-10-14 23:05:07 - train.py[line:549] - INFO: 4200 / 4988
2022-10-14 23:05:07 - train.py[line:551] - INFO: load:1.63 valid_run:3177.25 task_valid:3054.73 collect_output:100.96
2022-10-14 23:07:37 - train.py[line:549] - INFO: 4400 / 4988
2022-10-14 23:07:37 - train.py[line:551] - INFO: load:1.65 valid_run:3327.01 task_valid:3199.76 collect_output:104.72
2022-10-14 23:10:09 - train.py[line:549] - INFO: 4600 / 4988
2022-10-14 23:10:09 - train.py[line:551] - INFO: load:1.68 valid_run:3478.74 task_valid:3346.39 collect_output:108.84
2022-10-14 23:12:41 - train.py[line:549] - INFO: 4800 / 4988
2022-10-14 23:12:41 - train.py[line:551] - INFO: load:1.70 valid_run:3631.12 task_valid:3493.62 collect_output:113.01

====================================================================================================
SGG eval:     R @ 50: 0.6690;     R @ 100: 0.7096;     R @ 500: 0.7220;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4690;    mR @ 100: 0.5174;    mR @ 500: 0.5490;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.3714) (eating:0.8235) (flying in:0.7727) (growing on:0.5000) (hanging from:0.5323) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9467) (says:0.0000) (sitting on:0.7653) (standing on:0.4343) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6690;     R @ 100: 0.7096;     R @ 500: 0.7220;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4690;    mR @ 100: 0.5174;    mR @ 500: 0.5490;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:0.9375) (covering:0.3714) (eating:0.8235) (flying in:0.7727) (growing on:0.5000) (hanging from:0.5323) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9467) (says:0.0000) (sitting on:0.7653) (standing on:0.4343) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-14 23:15:13 - train.py[line:487] - INFO: 0.7096376878023937
2022-10-14 23:15:13 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-14 23:15:13 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.391 | loss_v1 0 | loss_v2 0 | nll_loss 0.248 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.709638 | ppl 1.19 | vqa_score 0.5597 | wps 118.5 | wpb 89.9 | bsz 30 | num_updates 5000 | best_R@100 0.709638
2022-10-14 23:15:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 5000 updates
2022-10-14 23:15:13 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-14 23:15:19 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-14 23:15:24 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 0.7096376878023937) (writing took 10.546978219877928 seconds)
2022-10-14 23:15:35 - progress_bar.py[line:274] - INFO: epoch 001:   5016 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=0.3, ups=0, wpb=109.8, bsz=40, num_updates=5010, lr=4.98266e-05, gnorm=0.915, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24652
2022-10-14 23:15:46 - progress_bar.py[line:274] - INFO: epoch 001:   5026 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=5020, lr=4.98221e-05, gnorm=0.934, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24663
2022-10-14 23:15:58 - progress_bar.py[line:274] - INFO: epoch 001:   5036 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.9, ups=0.88, wpb=112.1, bsz=40, num_updates=5030, lr=4.98176e-05, gnorm=0.682, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24675
2022-10-14 23:16:09 - progress_bar.py[line:274] - INFO: epoch 001:   5046 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=5040, lr=4.98131e-05, gnorm=0.81, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24686
2022-10-14 23:16:20 - progress_bar.py[line:274] - INFO: epoch 001:   5056 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=5050, lr=4.98086e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24697
2022-10-14 23:16:31 - progress_bar.py[line:274] - INFO: epoch 001:   5066 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101, ups=0.91, wpb=111.3, bsz=40, num_updates=5060, lr=4.98041e-05, gnorm=0.914, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24708
2022-10-14 23:16:42 - progress_bar.py[line:274] - INFO: epoch 001:   5076 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=5070, lr=4.97996e-05, gnorm=0.903, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24719
2022-10-14 23:16:53 - progress_bar.py[line:274] - INFO: epoch 001:   5086 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.9, ups=0.89, wpb=109.5, bsz=40, num_updates=5080, lr=4.97951e-05, gnorm=0.793, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24730
2022-10-14 23:17:04 - progress_bar.py[line:274] - INFO: epoch 001:   5096 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101.1, ups=0.92, wpb=110.2, bsz=40, num_updates=5090, lr=4.97906e-05, gnorm=0.916, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24741
2022-10-14 23:17:15 - progress_bar.py[line:274] - INFO: epoch 001:   5106 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101.8, ups=0.92, wpb=111, bsz=40, num_updates=5100, lr=4.97861e-05, gnorm=0.949, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24752
2022-10-14 23:17:26 - progress_bar.py[line:274] - INFO: epoch 001:   5116 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=5110, lr=4.97816e-05, gnorm=0.945, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24763
2022-10-14 23:17:37 - progress_bar.py[line:274] - INFO: epoch 001:   5126 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=5120, lr=4.97771e-05, gnorm=0.919, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24774
2022-10-14 23:17:48 - progress_bar.py[line:274] - INFO: epoch 001:   5136 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=5130, lr=4.97726e-05, gnorm=0.913, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24785
2022-10-14 23:17:59 - progress_bar.py[line:274] - INFO: epoch 001:   5146 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.7, ups=0.91, wpb=109.1, bsz=40, num_updates=5140, lr=4.9768e-05, gnorm=0.903, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24796
2022-10-14 23:18:11 - progress_bar.py[line:274] - INFO: epoch 001:   5156 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=5150, lr=4.97635e-05, gnorm=0.845, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24808
2022-10-14 23:18:22 - progress_bar.py[line:274] - INFO: epoch 001:   5166 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=5160, lr=4.9759e-05, gnorm=0.891, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24819
2022-10-14 23:18:33 - progress_bar.py[line:274] - INFO: epoch 001:   5176 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.5, ups=0.91, wpb=110.7, bsz=40, num_updates=5170, lr=4.97545e-05, gnorm=0.878, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24830
2022-10-14 23:18:44 - progress_bar.py[line:274] - INFO: epoch 001:   5186 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97, ups=0.88, wpb=110.8, bsz=40, num_updates=5180, lr=4.975e-05, gnorm=0.925, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24841
2022-10-14 23:18:55 - progress_bar.py[line:274] - INFO: epoch 001:   5196 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97, ups=0.88, wpb=109.7, bsz=40, num_updates=5190, lr=4.97455e-05, gnorm=0.856, clip=20, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=24852
2022-10-14 23:19:00 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-14 23:19:07 - progress_bar.py[line:274] - INFO: epoch 001:   5207 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.8, ups=0.84, wpb=110.5, bsz=40, num_updates=5200, lr=4.9741e-05, gnorm=0.852, clip=10, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=24864
2022-10-14 23:19:19 - progress_bar.py[line:274] - INFO: epoch 001:   5217 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.3, ups=0.89, wpb=112.1, bsz=40, num_updates=5210, lr=4.97365e-05, gnorm=0.811, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24876
2022-10-14 23:19:30 - progress_bar.py[line:274] - INFO: epoch 001:   5227 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=5220, lr=4.9732e-05, gnorm=0.901, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24887
2022-10-14 23:19:41 - progress_bar.py[line:274] - INFO: epoch 001:   5237 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.4, ups=0.9, wpb=109.9, bsz=40, num_updates=5230, lr=4.97275e-05, gnorm=0.941, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24898
2022-10-14 23:19:52 - progress_bar.py[line:274] - INFO: epoch 001:   5247 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97, ups=0.89, wpb=108.8, bsz=40, num_updates=5240, lr=4.9723e-05, gnorm=0.84, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24909
2022-10-14 23:20:03 - progress_bar.py[line:274] - INFO: epoch 001:   5257 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=101.7, ups=0.93, wpb=109.2, bsz=40, num_updates=5250, lr=4.97185e-05, gnorm=0.878, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24920
2022-10-14 23:20:14 - progress_bar.py[line:274] - INFO: epoch 001:   5267 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=5260, lr=4.9714e-05, gnorm=0.937, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24931
2022-10-14 23:20:25 - progress_bar.py[line:274] - INFO: epoch 001:   5277 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97, ups=0.88, wpb=109.9, bsz=40, num_updates=5270, lr=4.97095e-05, gnorm=0.891, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24942
2022-10-14 23:20:37 - progress_bar.py[line:274] - INFO: epoch 001:   5287 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.8, ups=0.88, wpb=108.5, bsz=40, num_updates=5280, lr=4.9705e-05, gnorm=0.875, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24954
2022-10-14 23:20:48 - progress_bar.py[line:274] - INFO: epoch 001:   5297 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=5290, lr=4.97005e-05, gnorm=0.797, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24965
2022-10-14 23:20:59 - progress_bar.py[line:274] - INFO: epoch 001:   5307 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.8, ups=0.91, wpb=109.9, bsz=40, num_updates=5300, lr=4.9696e-05, gnorm=0.905, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24976
2022-10-14 23:21:00 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-14 23:21:11 - progress_bar.py[line:274] - INFO: epoch 001:   5318 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=90.1, ups=0.83, wpb=108.8, bsz=40, num_updates=5310, lr=4.96915e-05, gnorm=0.987, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=24988
2022-10-14 23:21:22 - progress_bar.py[line:274] - INFO: epoch 001:   5328 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.341, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=5320, lr=4.9687e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24999
2022-10-14 23:21:33 - progress_bar.py[line:274] - INFO: epoch 001:   5338 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.2, ups=0.91, wpb=110.5, bsz=40, num_updates=5330, lr=4.96825e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25010
2022-10-14 23:21:44 - progress_bar.py[line:274] - INFO: epoch 001:   5348 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98, ups=0.9, wpb=109.4, bsz=40, num_updates=5340, lr=4.9678e-05, gnorm=0.78, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25021
2022-10-14 23:21:56 - progress_bar.py[line:274] - INFO: epoch 001:   5358 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.1, ups=0.89, wpb=112.3, bsz=40, num_updates=5350, lr=4.96735e-05, gnorm=0.884, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25033
2022-10-14 23:22:07 - progress_bar.py[line:274] - INFO: epoch 001:   5368 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.9, ups=0.91, wpb=111.1, bsz=40, num_updates=5360, lr=4.9669e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=25044
2022-10-14 23:22:18 - progress_bar.py[line:274] - INFO: epoch 001:   5378 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.3, ups=0.9, wpb=109.7, bsz=40, num_updates=5370, lr=4.96645e-05, gnorm=0.77, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25055
2022-10-14 23:22:29 - progress_bar.py[line:274] - INFO: epoch 001:   5388 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97, ups=0.87, wpb=111.3, bsz=40, num_updates=5380, lr=4.966e-05, gnorm=0.78, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25066
2022-10-14 23:22:41 - progress_bar.py[line:274] - INFO: epoch 001:   5398 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.7, ups=0.87, wpb=111, bsz=40, num_updates=5390, lr=4.96555e-05, gnorm=0.868, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25078
2022-10-14 23:22:52 - progress_bar.py[line:274] - INFO: epoch 001:   5408 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.6, ups=0.89, wpb=109.3, bsz=40, num_updates=5400, lr=4.96509e-05, gnorm=0.928, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=25089
2022-10-14 23:23:03 - progress_bar.py[line:274] - INFO: epoch 001:   5418 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.7, ups=0.9, wpb=109.9, bsz=40, num_updates=5410, lr=4.96464e-05, gnorm=0.9, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=25100
2022-10-14 23:23:14 - progress_bar.py[line:274] - INFO: epoch 001:   5428 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=5420, lr=4.96419e-05, gnorm=0.936, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25111
2022-10-14 23:23:25 - progress_bar.py[line:274] - INFO: epoch 001:   5438 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=5430, lr=4.96374e-05, gnorm=0.988, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25122
2022-10-14 23:23:37 - progress_bar.py[line:274] - INFO: epoch 001:   5448 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=5440, lr=4.96329e-05, gnorm=0.899, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25134
2022-10-14 23:23:48 - progress_bar.py[line:274] - INFO: epoch 001:   5458 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.2, ups=0.92, wpb=109.3, bsz=40, num_updates=5450, lr=4.96284e-05, gnorm=0.77, clip=0, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=25145
2022-10-14 23:23:59 - progress_bar.py[line:274] - INFO: epoch 001:   5468 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=5460, lr=4.96239e-05, gnorm=0.924, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25156
2022-10-14 23:24:10 - progress_bar.py[line:274] - INFO: epoch 001:   5478 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.5, ups=0.9, wpb=111.2, bsz=40, num_updates=5470, lr=4.96194e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25167
2022-10-14 23:24:21 - progress_bar.py[line:274] - INFO: epoch 001:   5488 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99, ups=0.91, wpb=109.3, bsz=40, num_updates=5480, lr=4.96149e-05, gnorm=0.915, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25178
2022-10-14 23:24:32 - progress_bar.py[line:274] - INFO: epoch 001:   5498 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=5490, lr=4.96104e-05, gnorm=0.805, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25189
2022-10-14 23:24:43 - progress_bar.py[line:274] - INFO: epoch 001:   5508 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=5500, lr=4.96059e-05, gnorm=0.75, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25200
2022-10-14 23:24:54 - progress_bar.py[line:274] - INFO: epoch 001:   5518 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.1, ups=0.91, wpb=109.4, bsz=40, num_updates=5510, lr=4.96014e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25211
2022-10-14 23:25:06 - progress_bar.py[line:274] - INFO: epoch 001:   5528 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.1, ups=0.88, wpb=111.1, bsz=40, num_updates=5520, lr=4.95969e-05, gnorm=0.83, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25223
2022-10-14 23:25:17 - progress_bar.py[line:274] - INFO: epoch 001:   5538 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.9, ups=0.86, wpb=110.9, bsz=40, num_updates=5530, lr=4.95924e-05, gnorm=0.789, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=25234
2022-10-14 23:25:29 - progress_bar.py[line:274] - INFO: epoch 001:   5548 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.4, ups=0.88, wpb=109.2, bsz=40, num_updates=5540, lr=4.95879e-05, gnorm=0.766, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25246
2022-10-14 23:25:40 - progress_bar.py[line:274] - INFO: epoch 001:   5558 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.9, ups=0.91, wpb=111, bsz=40, num_updates=5550, lr=4.95834e-05, gnorm=0.842, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25257
2022-10-14 23:25:51 - progress_bar.py[line:274] - INFO: epoch 001:   5568 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=5560, lr=4.95789e-05, gnorm=0.802, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25268
2022-10-14 23:26:02 - progress_bar.py[line:274] - INFO: epoch 001:   5578 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99, ups=0.89, wpb=110.8, bsz=40, num_updates=5570, lr=4.95744e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25279
2022-10-14 23:26:13 - progress_bar.py[line:274] - INFO: epoch 001:   5588 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=5580, lr=4.95699e-05, gnorm=0.919, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25290
2022-10-14 23:26:24 - progress_bar.py[line:274] - INFO: epoch 001:   5598 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=5590, lr=4.95654e-05, gnorm=0.842, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25301
2022-10-14 23:26:36 - progress_bar.py[line:274] - INFO: epoch 001:   5608 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=101.5, ups=0.91, wpb=111.9, bsz=40, num_updates=5600, lr=4.95609e-05, gnorm=0.733, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25313
2022-10-14 23:26:47 - progress_bar.py[line:274] - INFO: epoch 001:   5618 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.2, ups=0.9, wpb=110.7, bsz=40, num_updates=5610, lr=4.95564e-05, gnorm=0.838, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=25324
2022-10-14 23:26:58 - progress_bar.py[line:274] - INFO: epoch 001:   5628 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=5620, lr=4.95519e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25335
2022-10-14 23:27:09 - progress_bar.py[line:274] - INFO: epoch 001:   5638 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=102.4, ups=0.93, wpb=110.1, bsz=40, num_updates=5630, lr=4.95474e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25346
2022-10-14 23:27:20 - progress_bar.py[line:274] - INFO: epoch 001:   5648 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=5640, lr=4.95429e-05, gnorm=0.78, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25357
2022-10-14 23:27:31 - progress_bar.py[line:274] - INFO: epoch 001:   5658 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.8, ups=0.89, wpb=111.1, bsz=40, num_updates=5650, lr=4.95384e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25368
2022-10-14 23:27:42 - progress_bar.py[line:274] - INFO: epoch 001:   5668 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.4, ups=0.89, wpb=110, bsz=40, num_updates=5660, lr=4.95338e-05, gnorm=0.831, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25379
2022-10-14 23:27:53 - progress_bar.py[line:274] - INFO: epoch 001:   5678 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=5670, lr=4.95293e-05, gnorm=0.757, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25391
2022-10-14 23:28:05 - progress_bar.py[line:274] - INFO: epoch 001:   5688 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=5680, lr=4.95248e-05, gnorm=0.862, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25402
2022-10-14 23:28:16 - progress_bar.py[line:274] - INFO: epoch 001:   5698 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.2, ups=0.9, wpb=111.6, bsz=40, num_updates=5690, lr=4.95203e-05, gnorm=0.836, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25413
2022-10-14 23:28:27 - progress_bar.py[line:274] - INFO: epoch 001:   5708 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=5700, lr=4.95158e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25424
2022-10-14 23:28:38 - progress_bar.py[line:274] - INFO: epoch 001:   5718 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=101.6, ups=0.92, wpb=110.7, bsz=40, num_updates=5710, lr=4.95113e-05, gnorm=0.772, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25435
2022-10-14 23:28:49 - progress_bar.py[line:274] - INFO: epoch 001:   5728 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.4, ups=0.9, wpb=110.3, bsz=40, num_updates=5720, lr=4.95068e-05, gnorm=0.758, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25446
2022-10-14 23:29:00 - progress_bar.py[line:274] - INFO: epoch 001:   5738 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=5730, lr=4.95023e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25457
2022-10-14 23:29:12 - progress_bar.py[line:274] - INFO: epoch 001:   5748 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=5740, lr=4.94978e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25469
2022-10-14 23:29:23 - progress_bar.py[line:274] - INFO: epoch 001:   5758 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.8, ups=0.87, wpb=110, bsz=40, num_updates=5750, lr=4.94933e-05, gnorm=0.789, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25480
2022-10-14 23:29:34 - progress_bar.py[line:274] - INFO: epoch 001:   5768 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=5760, lr=4.94888e-05, gnorm=0.859, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25491
2022-10-14 23:29:46 - progress_bar.py[line:274] - INFO: epoch 001:   5778 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.9, ups=0.88, wpb=109.4, bsz=40, num_updates=5770, lr=4.94843e-05, gnorm=0.886, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25503
2022-10-14 23:29:57 - progress_bar.py[line:274] - INFO: epoch 001:   5788 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.9, ups=0.89, wpb=109.5, bsz=40, num_updates=5780, lr=4.94798e-05, gnorm=0.746, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25514
2022-10-14 23:30:08 - progress_bar.py[line:274] - INFO: epoch 001:   5798 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.9, ups=0.89, wpb=112.1, bsz=40, num_updates=5790, lr=4.94753e-05, gnorm=0.776, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25525
2022-10-14 23:30:19 - progress_bar.py[line:274] - INFO: epoch 001:   5808 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=107.7, nsentences=40, sample_size=107.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.1, ups=0.89, wpb=107.7, bsz=40, num_updates=5800, lr=4.94708e-05, gnorm=0.94, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25536
2022-10-14 23:30:30 - progress_bar.py[line:274] - INFO: epoch 001:   5818 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=102.2, ups=0.92, wpb=111.3, bsz=40, num_updates=5810, lr=4.94663e-05, gnorm=0.861, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25547
2022-10-14 23:30:41 - progress_bar.py[line:274] - INFO: epoch 001:   5828 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=5820, lr=4.94618e-05, gnorm=0.884, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25558
2022-10-14 23:30:53 - progress_bar.py[line:274] - INFO: epoch 001:   5838 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.9, ups=0.88, wpb=110.3, bsz=40, num_updates=5830, lr=4.94573e-05, gnorm=0.946, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25570
2022-10-14 23:31:04 - progress_bar.py[line:274] - INFO: epoch 001:   5848 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.3, ups=0.91, wpb=110.4, bsz=40, num_updates=5840, lr=4.94528e-05, gnorm=0.983, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25581
2022-10-14 23:31:15 - progress_bar.py[line:274] - INFO: epoch 001:   5858 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=5850, lr=4.94483e-05, gnorm=0.889, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25592
2022-10-14 23:31:26 - progress_bar.py[line:274] - INFO: epoch 001:   5868 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=5860, lr=4.94438e-05, gnorm=0.849, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25603
2022-10-14 23:31:37 - progress_bar.py[line:274] - INFO: epoch 001:   5878 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.7, ups=0.92, wpb=109.8, bsz=40, num_updates=5870, lr=4.94393e-05, gnorm=0.811, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25614
2022-10-14 23:31:48 - progress_bar.py[line:274] - INFO: epoch 001:   5888 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=5880, lr=4.94348e-05, gnorm=0.761, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25625
2022-10-14 23:31:59 - progress_bar.py[line:274] - INFO: epoch 001:   5898 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101, ups=0.91, wpb=111.2, bsz=40, num_updates=5890, lr=4.94303e-05, gnorm=0.806, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25636
2022-10-14 23:32:10 - progress_bar.py[line:274] - INFO: epoch 001:   5908 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=5900, lr=4.94258e-05, gnorm=0.821, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25647
2022-10-14 23:32:21 - progress_bar.py[line:274] - INFO: epoch 001:   5918 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=103.1, ups=0.92, wpb=112.5, bsz=40, num_updates=5910, lr=4.94212e-05, gnorm=0.774, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25658
2022-10-14 23:32:32 - progress_bar.py[line:274] - INFO: epoch 001:   5928 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.2, ups=0.91, wpb=109.5, bsz=40, num_updates=5920, lr=4.94167e-05, gnorm=0.905, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25669
2022-10-14 23:32:43 - progress_bar.py[line:274] - INFO: epoch 001:   5938 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=5930, lr=4.94122e-05, gnorm=0.842, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25680
2022-10-14 23:32:55 - progress_bar.py[line:274] - INFO: epoch 001:   5948 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.9, ups=0.88, wpb=109.2, bsz=40, num_updates=5940, lr=4.94077e-05, gnorm=0.808, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25692
2022-10-14 23:33:06 - progress_bar.py[line:274] - INFO: epoch 001:   5958 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.4, ups=0.87, wpb=109.7, bsz=40, num_updates=5950, lr=4.94032e-05, gnorm=0.876, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25703
2022-10-14 23:33:17 - progress_bar.py[line:274] - INFO: epoch 001:   5968 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.7, ups=0.9, wpb=109.1, bsz=40, num_updates=5960, lr=4.93987e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25714
2022-10-14 23:33:29 - progress_bar.py[line:274] - INFO: epoch 001:   5978 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=5970, lr=4.93942e-05, gnorm=0.923, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25726
2022-10-14 23:33:40 - progress_bar.py[line:274] - INFO: epoch 001:   5988 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=5980, lr=4.93897e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=25737
2022-10-14 23:33:51 - progress_bar.py[line:274] - INFO: epoch 001:   5998 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.1, ups=0.87, wpb=110.6, bsz=40, num_updates=5990, lr=4.93852e-05, gnorm=0.864, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25748
2022-10-14 23:34:02 - progress_bar.py[line:274] - INFO: epoch 001:   6008 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.4, ups=0.9, wpb=109.8, bsz=40, num_updates=6000, lr=4.93807e-05, gnorm=0.956, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25759
2022-10-14 23:34:02 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-14 23:34:04 - train.py[line:549] - INFO: 0 / 4988
2022-10-14 23:34:04 - train.py[line:551] - INFO: load:1.03 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-14 23:34:05 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.84 GiB already allocated; 3.52 GiB free; 33.58 GiB reserved in total by PyTorch)
2022-10-14 23:34:05 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-14 23:34:05 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 19        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9051 MB |   10275 MB |    3719 TB |    3719 TB |
|       from large pool |    8906 MB |   10130 MB |    3718 TB |    3718 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9051 MB |   10275 MB |    3719 TB |    3719 TB |
|       from large pool |    8906 MB |   10130 MB |    3718 TB |    3718 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34388 MB |   34388 MB |  203264 MB |  168876 MB |
|       from large pool |   34242 MB |   34242 MB |  202918 MB |  168676 MB |
|       from small pool |     146 MB |     146 MB |     346 MB |     200 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   25336 MB |   26723 MB |    5374 TB |    5374 TB |
|       from large pool |   25335 MB |   26721 MB |    5373 TB |    5373 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  171210 K  |  171206 K  |
|       from large pool |     563    |     575    |   55536 K  |   55535 K  |
|       from small pool |    3095    |    3114    |  115673 K  |  115670 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  171210 K  |  171206 K  |
|       from large pool |     563    |     575    |   55536 K  |   55535 K  |
|       from small pool |    3095    |    3114    |  115673 K  |  115670 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     134    |     134    |     546    |     412    |
|       from large pool |      61    |      61    |     373    |     312    |
|       from small pool |      73    |      73    |     173    |     100    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      88    |      95    |  127673 K  |  127673 K  |
|       from large pool |      41    |      44    |   27158 K  |   27158 K  |
|       from small pool |      47    |      55    |  100515 K  |  100515 K  |
|===========================================================================|

2022-10-14 23:34:05 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-14 23:36:37 - train.py[line:549] - INFO: 200 / 4988
2022-10-14 23:36:37 - train.py[line:551] - INFO: load:1.06 valid_run:152.73 task_valid:148.42 collect_output:3.29
2022-10-14 23:39:06 - train.py[line:549] - INFO: 400 / 4988
2022-10-14 23:39:06 - train.py[line:551] - INFO: load:1.08 valid_run:301.90 task_valid:292.42 collect_output:7.35
2022-10-14 23:41:39 - train.py[line:549] - INFO: 600 / 4988
2022-10-14 23:41:39 - train.py[line:551] - INFO: load:1.11 valid_run:454.75 task_valid:436.27 collect_output:15.29
2022-10-14 23:44:09 - train.py[line:549] - INFO: 800 / 4988
2022-10-14 23:44:09 - train.py[line:551] - INFO: load:1.13 valid_run:604.89 task_valid:582.34 collect_output:18.33
2022-10-14 23:46:42 - train.py[line:549] - INFO: 1000 / 4988
2022-10-14 23:46:42 - train.py[line:551] - INFO: load:1.16 valid_run:757.95 task_valid:730.64 collect_output:22.10
2022-10-14 23:49:15 - train.py[line:549] - INFO: 1200 / 4988
2022-10-14 23:49:15 - train.py[line:551] - INFO: load:1.19 valid_run:910.39 task_valid:877.09 collect_output:27.02
2022-10-14 23:51:49 - train.py[line:549] - INFO: 1400 / 4988
2022-10-14 23:51:49 - train.py[line:551] - INFO: load:1.21 valid_run:1064.65 task_valid:1024.10 collect_output:33.24
2022-10-14 23:54:21 - train.py[line:549] - INFO: 1600 / 4988
2022-10-14 23:54:21 - train.py[line:551] - INFO: load:1.24 valid_run:1216.38 task_valid:1165.78 collect_output:42.28
2022-10-14 23:56:51 - train.py[line:549] - INFO: 1800 / 4988
2022-10-14 23:56:51 - train.py[line:551] - INFO: load:1.26 valid_run:1366.65 task_valid:1311.19 collect_output:46.07
2022-10-14 23:59:20 - train.py[line:549] - INFO: 2000 / 4988
2022-10-14 23:59:20 - train.py[line:551] - INFO: load:1.29 valid_run:1516.04 task_valid:1455.11 collect_output:50.51
2022-10-15 00:01:51 - train.py[line:549] - INFO: 2200 / 4988
2022-10-15 00:01:51 - train.py[line:551] - INFO: load:1.31 valid_run:1666.66 task_valid:1601.02 collect_output:54.20
2022-10-15 00:04:22 - train.py[line:549] - INFO: 2400 / 4988
2022-10-15 00:04:22 - train.py[line:551] - INFO: load:1.34 valid_run:1817.68 task_valid:1747.07 collect_output:58.16
2022-10-15 00:06:53 - train.py[line:549] - INFO: 2600 / 4988
2022-10-15 00:06:53 - train.py[line:551] - INFO: load:1.36 valid_run:1968.19 task_valid:1889.77 collect_output:64.93
2022-10-15 00:09:24 - train.py[line:549] - INFO: 2800 / 4988
2022-10-15 00:09:24 - train.py[line:551] - INFO: load:1.39 valid_run:2119.25 task_valid:2035.63 collect_output:69.15
2022-10-15 00:11:54 - train.py[line:549] - INFO: 3000 / 4988
2022-10-15 00:11:54 - train.py[line:551] - INFO: load:1.41 valid_run:2269.79 task_valid:2182.62 collect_output:71.70
2022-10-15 00:14:25 - train.py[line:549] - INFO: 3200 / 4988
2022-10-15 00:14:25 - train.py[line:551] - INFO: load:1.44 valid_run:2420.23 task_valid:2327.31 collect_output:76.49
2022-10-15 00:16:57 - train.py[line:549] - INFO: 3400 / 4988
2022-10-15 00:16:57 - train.py[line:551] - INFO: load:1.46 valid_run:2572.26 task_valid:2473.04 collect_output:81.81
2022-10-15 00:19:28 - train.py[line:549] - INFO: 3600 / 4988
2022-10-15 00:19:28 - train.py[line:551] - INFO: load:1.48 valid_run:2723.36 task_valid:2620.48 collect_output:84.50
2022-10-15 00:21:57 - train.py[line:549] - INFO: 3800 / 4988
2022-10-15 00:21:57 - train.py[line:551] - INFO: load:1.51 valid_run:2872.11 task_valid:2762.38 collect_output:90.39
2022-10-15 00:24:28 - train.py[line:549] - INFO: 4000 / 4988
2022-10-15 00:24:28 - train.py[line:551] - INFO: load:1.53 valid_run:3022.68 task_valid:2907.87 collect_output:94.50
2022-10-15 00:27:00 - train.py[line:549] - INFO: 4200 / 4988
2022-10-15 00:27:00 - train.py[line:551] - INFO: load:1.56 valid_run:3175.22 task_valid:3052.93 collect_output:100.98
2022-10-15 00:29:30 - train.py[line:549] - INFO: 4400 / 4988
2022-10-15 00:29:30 - train.py[line:551] - INFO: load:1.58 valid_run:3324.94 task_valid:3197.97 collect_output:104.67
2022-10-15 00:32:02 - train.py[line:549] - INFO: 4600 / 4988
2022-10-15 00:32:02 - train.py[line:551] - INFO: load:1.61 valid_run:3476.53 task_valid:3344.57 collect_output:108.69
2022-10-15 00:34:34 - train.py[line:549] - INFO: 4800 / 4988
2022-10-15 00:34:34 - train.py[line:551] - INFO: load:1.63 valid_run:3628.42 task_valid:3491.72 collect_output:112.46

====================================================================================================
SGG eval:     R @ 50: 0.6724;     R @ 100: 0.7094;     R @ 500: 0.7212;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4763;    mR @ 100: 0.5195;    mR @ 500: 0.5480;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8659) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.8636) (growing on:0.5000) (hanging from:0.5645) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7585) (standing on:0.4243) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6724;     R @ 100: 0.7094;     R @ 500: 0.7212;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4763;    mR @ 100: 0.5195;    mR @ 500: 0.5480;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8659) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.8636) (growing on:0.5000) (hanging from:0.5645) (lying on:0.3000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9583) (playing:0.0000) (riding:0.9565) (says:0.0000) (sitting on:0.7585) (standing on:0.4243) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-15 00:37:05 - train.py[line:487] - INFO: 0.7093503437738732
2022-10-15 00:37:05 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-15 00:37:05 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.354 | loss_v1 0 | loss_v2 0 | nll_loss 0.198 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.70935 | ppl 1.15 | vqa_score 0.5811 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 6000 | best_R@100 0.709638
2022-10-15 00:37:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2022-10-15 00:37:05 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-15 00:37:11 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-15 00:37:13 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.7093503437738732) (writing took 8.020212931092829 seconds)
2022-10-15 00:37:26 - progress_bar.py[line:274] - INFO: epoch 001:   6018 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=0.3, ups=0, wpb=110.7, bsz=40, num_updates=6010, lr=4.93762e-05, gnorm=0.894, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29562
2022-10-15 00:37:37 - progress_bar.py[line:274] - INFO: epoch 001:   6028 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.5, ups=0.92, wpb=109.4, bsz=40, num_updates=6020, lr=4.93717e-05, gnorm=0.892, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29574
2022-10-15 00:37:48 - progress_bar.py[line:274] - INFO: epoch 001:   6038 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=6030, lr=4.93672e-05, gnorm=0.92, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29585
2022-10-15 00:37:56 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 00:38:00 - progress_bar.py[line:274] - INFO: epoch 001:   6049 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=93.1, ups=0.84, wpb=111.2, bsz=40, num_updates=6040, lr=4.93627e-05, gnorm=0.89, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=29597
2022-10-15 00:38:11 - progress_bar.py[line:274] - INFO: epoch 001:   6059 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.6, ups=0.91, wpb=109.9, bsz=40, num_updates=6050, lr=4.93582e-05, gnorm=0.875, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29608
2022-10-15 00:38:22 - progress_bar.py[line:274] - INFO: epoch 001:   6069 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=6060, lr=4.93537e-05, gnorm=0.825, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29619
2022-10-15 00:38:34 - progress_bar.py[line:274] - INFO: epoch 001:   6079 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.7, ups=0.87, wpb=108.9, bsz=40, num_updates=6070, lr=4.93492e-05, gnorm=0.868, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29631
2022-10-15 00:38:45 - progress_bar.py[line:274] - INFO: epoch 001:   6089 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=104.6, ups=0.94, wpb=111.8, bsz=40, num_updates=6080, lr=4.93447e-05, gnorm=0.821, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29642
2022-10-15 00:38:56 - progress_bar.py[line:274] - INFO: epoch 001:   6099 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=6090, lr=4.93402e-05, gnorm=0.887, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=29653
2022-10-15 00:39:07 - progress_bar.py[line:274] - INFO: epoch 001:   6109 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=6100, lr=4.93357e-05, gnorm=0.782, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29664
2022-10-15 00:39:18 - progress_bar.py[line:274] - INFO: epoch 001:   6119 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.5, ups=0.92, wpb=109.3, bsz=40, num_updates=6110, lr=4.93312e-05, gnorm=0.817, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29675
2022-10-15 00:39:29 - progress_bar.py[line:274] - INFO: epoch 001:   6129 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101.6, ups=0.92, wpb=110.9, bsz=40, num_updates=6120, lr=4.93267e-05, gnorm=0.92, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29686
2022-10-15 00:39:40 - progress_bar.py[line:274] - INFO: epoch 001:   6139 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=6130, lr=4.93222e-05, gnorm=0.723, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29697
2022-10-15 00:39:51 - progress_bar.py[line:274] - INFO: epoch 001:   6149 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98, ups=0.89, wpb=110.6, bsz=40, num_updates=6140, lr=4.93177e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=29708
2022-10-15 00:40:02 - progress_bar.py[line:274] - INFO: epoch 001:   6159 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=6150, lr=4.93132e-05, gnorm=0.725, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29719
2022-10-15 00:40:13 - progress_bar.py[line:274] - INFO: epoch 001:   6169 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=103.5, ups=0.93, wpb=111.2, bsz=40, num_updates=6160, lr=4.93087e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29730
2022-10-15 00:40:24 - progress_bar.py[line:274] - INFO: epoch 001:   6179 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.5, ups=0.88, wpb=110.8, bsz=40, num_updates=6170, lr=4.93041e-05, gnorm=0.851, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=29741
2022-10-15 00:40:36 - progress_bar.py[line:274] - INFO: epoch 001:   6189 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.1, ups=0.89, wpb=109.8, bsz=40, num_updates=6180, lr=4.92996e-05, gnorm=0.779, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29753
2022-10-15 00:40:47 - progress_bar.py[line:274] - INFO: epoch 001:   6199 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.8, ups=0.88, wpb=109.2, bsz=40, num_updates=6190, lr=4.92951e-05, gnorm=0.861, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29764
2022-10-15 00:40:58 - progress_bar.py[line:274] - INFO: epoch 001:   6209 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=6200, lr=4.92906e-05, gnorm=0.777, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29775
2022-10-15 00:41:09 - progress_bar.py[line:274] - INFO: epoch 001:   6219 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=6210, lr=4.92861e-05, gnorm=0.812, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=29786
2022-10-15 00:41:21 - progress_bar.py[line:274] - INFO: epoch 001:   6229 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=6220, lr=4.92816e-05, gnorm=0.748, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=29798
2022-10-15 00:41:32 - progress_bar.py[line:274] - INFO: epoch 001:   6239 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.2, ups=0.9, wpb=109.6, bsz=40, num_updates=6230, lr=4.92771e-05, gnorm=0.864, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29809
2022-10-15 00:41:43 - progress_bar.py[line:274] - INFO: epoch 001:   6249 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.4, ups=0.87, wpb=109.3, bsz=40, num_updates=6240, lr=4.92726e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29820
2022-10-15 00:41:54 - progress_bar.py[line:274] - INFO: epoch 001:   6259 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.1, ups=0.89, wpb=109.7, bsz=40, num_updates=6250, lr=4.92681e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29831
2022-10-15 00:42:06 - progress_bar.py[line:274] - INFO: epoch 001:   6269 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.2, ups=0.86, wpb=109.2, bsz=40, num_updates=6260, lr=4.92636e-05, gnorm=0.893, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=29843
2022-10-15 00:42:17 - progress_bar.py[line:274] - INFO: epoch 001:   6279 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.3, ups=0.9, wpb=111.5, bsz=40, num_updates=6270, lr=4.92591e-05, gnorm=0.834, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29854
2022-10-15 00:42:28 - progress_bar.py[line:274] - INFO: epoch 001:   6289 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.7, ups=0.88, wpb=110.7, bsz=40, num_updates=6280, lr=4.92546e-05, gnorm=0.737, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29865
2022-10-15 00:42:40 - progress_bar.py[line:274] - INFO: epoch 001:   6299 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=95.3, ups=0.87, wpb=109.3, bsz=40, num_updates=6290, lr=4.92501e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=29877
2022-10-15 00:42:51 - progress_bar.py[line:274] - INFO: epoch 001:   6309 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=6300, lr=4.92456e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29888
2022-10-15 00:43:02 - progress_bar.py[line:274] - INFO: epoch 001:   6319 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.6, ups=0.91, wpb=109.4, bsz=40, num_updates=6310, lr=4.92411e-05, gnorm=0.937, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29899
2022-10-15 00:43:13 - progress_bar.py[line:274] - INFO: epoch 001:   6329 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.4, ups=0.91, wpb=110.7, bsz=40, num_updates=6320, lr=4.92366e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29910
2022-10-15 00:43:25 - progress_bar.py[line:274] - INFO: epoch 001:   6339 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96, ups=0.87, wpb=110.1, bsz=40, num_updates=6330, lr=4.92321e-05, gnorm=0.797, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=29922
2022-10-15 00:43:36 - progress_bar.py[line:274] - INFO: epoch 001:   6349 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=6340, lr=4.92276e-05, gnorm=0.797, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29933
2022-10-15 00:43:47 - progress_bar.py[line:274] - INFO: epoch 001:   6359 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.9, ups=0.91, wpb=109.1, bsz=40, num_updates=6350, lr=4.92231e-05, gnorm=0.9, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29944
2022-10-15 00:43:58 - progress_bar.py[line:274] - INFO: epoch 001:   6369 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.2, ups=0.9, wpb=109.7, bsz=40, num_updates=6360, lr=4.92186e-05, gnorm=0.85, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29955
2022-10-15 00:44:09 - progress_bar.py[line:274] - INFO: epoch 001:   6379 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.8, ups=0.88, wpb=110.5, bsz=40, num_updates=6370, lr=4.92141e-05, gnorm=0.764, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29966
2022-10-15 00:44:21 - progress_bar.py[line:274] - INFO: epoch 001:   6389 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.5, ups=0.88, wpb=109.3, bsz=40, num_updates=6380, lr=4.92096e-05, gnorm=0.832, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29978
2022-10-15 00:44:31 - progress_bar.py[line:274] - INFO: epoch 001:   6399 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=104.7, ups=0.94, wpb=110.9, bsz=40, num_updates=6390, lr=4.92051e-05, gnorm=0.698, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29988
2022-10-15 00:44:43 - progress_bar.py[line:274] - INFO: epoch 001:   6409 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=6400, lr=4.92006e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30000
2022-10-15 00:44:54 - progress_bar.py[line:274] - INFO: epoch 001:   6419 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.7, ups=0.91, wpb=110, bsz=40, num_updates=6410, lr=4.91961e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30011
2022-10-15 00:45:05 - progress_bar.py[line:274] - INFO: epoch 001:   6429 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=6420, lr=4.91916e-05, gnorm=0.822, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30022
2022-10-15 00:45:16 - progress_bar.py[line:274] - INFO: epoch 001:   6439 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.1, ups=0.9, wpb=109.8, bsz=40, num_updates=6430, lr=4.9187e-05, gnorm=0.83, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30033
2022-10-15 00:45:27 - progress_bar.py[line:274] - INFO: epoch 001:   6449 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=101.4, ups=0.92, wpb=110.6, bsz=40, num_updates=6440, lr=4.91825e-05, gnorm=0.838, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30044
2022-10-15 00:45:38 - progress_bar.py[line:274] - INFO: epoch 001:   6459 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.314, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.6, ups=0.87, wpb=108.7, bsz=40, num_updates=6450, lr=4.9178e-05, gnorm=0.76, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30055
2022-10-15 00:45:49 - progress_bar.py[line:274] - INFO: epoch 001:   6469 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=102.8, ups=0.92, wpb=111.9, bsz=40, num_updates=6460, lr=4.91735e-05, gnorm=0.746, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30066
2022-10-15 00:46:01 - progress_bar.py[line:274] - INFO: epoch 001:   6479 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.6, ups=0.88, wpb=109.9, bsz=40, num_updates=6470, lr=4.9169e-05, gnorm=0.824, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30078
2022-10-15 00:46:12 - progress_bar.py[line:274] - INFO: epoch 001:   6489 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.8, ups=0.89, wpb=111.9, bsz=40, num_updates=6480, lr=4.91645e-05, gnorm=0.835, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30089
2022-10-15 00:46:23 - progress_bar.py[line:274] - INFO: epoch 001:   6499 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.5, ups=0.91, wpb=109.6, bsz=40, num_updates=6490, lr=4.916e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30100
2022-10-15 00:46:34 - progress_bar.py[line:274] - INFO: epoch 001:   6509 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.9, ups=0.92, wpb=110, bsz=40, num_updates=6500, lr=4.91555e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30111
2022-10-15 00:46:45 - progress_bar.py[line:274] - INFO: epoch 001:   6519 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=6510, lr=4.9151e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30122
2022-10-15 00:46:56 - progress_bar.py[line:274] - INFO: epoch 001:   6529 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=6520, lr=4.91465e-05, gnorm=0.914, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30133
2022-10-15 00:47:07 - progress_bar.py[line:274] - INFO: epoch 001:   6539 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=6530, lr=4.9142e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30144
2022-10-15 00:47:18 - progress_bar.py[line:274] - INFO: epoch 001:   6549 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.6, ups=0.89, wpb=109.4, bsz=40, num_updates=6540, lr=4.91375e-05, gnorm=0.812, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30155
2022-10-15 00:47:30 - progress_bar.py[line:274] - INFO: epoch 001:   6559 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=6550, lr=4.9133e-05, gnorm=0.714, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30167
2022-10-15 00:47:41 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 00:47:42 - progress_bar.py[line:274] - INFO: epoch 001:   6570 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=90.5, ups=0.83, wpb=109.3, bsz=40, num_updates=6560, lr=4.91285e-05, gnorm=0.79, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=30179
2022-10-15 00:47:53 - progress_bar.py[line:274] - INFO: epoch 001:   6580 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=6570, lr=4.9124e-05, gnorm=0.778, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30190
2022-10-15 00:48:04 - progress_bar.py[line:274] - INFO: epoch 001:   6590 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.7, ups=0.9, wpb=109.3, bsz=40, num_updates=6580, lr=4.91195e-05, gnorm=0.8, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30201
2022-10-15 00:48:15 - progress_bar.py[line:274] - INFO: epoch 001:   6600 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.8, ups=0.89, wpb=109.5, bsz=40, num_updates=6590, lr=4.9115e-05, gnorm=1.005, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=30212
2022-10-15 00:48:26 - progress_bar.py[line:274] - INFO: epoch 001:   6610 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=101.7, ups=0.92, wpb=111, bsz=40, num_updates=6600, lr=4.91105e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30223
2022-10-15 00:48:38 - progress_bar.py[line:274] - INFO: epoch 001:   6620 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=6610, lr=4.9106e-05, gnorm=0.78, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30235
2022-10-15 00:48:49 - progress_bar.py[line:274] - INFO: epoch 001:   6630 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=101, ups=0.92, wpb=110.1, bsz=40, num_updates=6620, lr=4.91015e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=30246
2022-10-15 00:49:00 - progress_bar.py[line:274] - INFO: epoch 001:   6640 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.1, ups=0.88, wpb=109.1, bsz=40, num_updates=6630, lr=4.9097e-05, gnorm=0.902, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30257
2022-10-15 00:49:12 - progress_bar.py[line:274] - INFO: epoch 001:   6650 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.5, ups=0.87, wpb=110.9, bsz=40, num_updates=6640, lr=4.90925e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30269
2022-10-15 00:49:23 - progress_bar.py[line:274] - INFO: epoch 001:   6660 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.9, ups=0.89, wpb=109.4, bsz=40, num_updates=6650, lr=4.9088e-05, gnorm=0.745, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30280
2022-10-15 00:49:33 - progress_bar.py[line:274] - INFO: epoch 001:   6670 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.3, ups=0.93, wpb=110, bsz=40, num_updates=6660, lr=4.90835e-05, gnorm=0.681, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30290
2022-10-15 00:49:45 - progress_bar.py[line:274] - INFO: epoch 001:   6680 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.6, ups=0.89, wpb=110.2, bsz=40, num_updates=6670, lr=4.9079e-05, gnorm=0.887, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30302
2022-10-15 00:49:56 - progress_bar.py[line:274] - INFO: epoch 001:   6690 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=102.1, ups=0.92, wpb=111, bsz=40, num_updates=6680, lr=4.90744e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30313
2022-10-15 00:50:07 - progress_bar.py[line:274] - INFO: epoch 001:   6700 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.9, ups=0.89, wpb=108.8, bsz=40, num_updates=6690, lr=4.90699e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30324
2022-10-15 00:50:18 - progress_bar.py[line:274] - INFO: epoch 001:   6710 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.5, ups=0.87, wpb=111, bsz=40, num_updates=6700, lr=4.90654e-05, gnorm=0.826, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=30335
2022-10-15 00:50:29 - progress_bar.py[line:274] - INFO: epoch 001:   6720 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.4, ups=0.9, wpb=110.1, bsz=40, num_updates=6710, lr=4.90609e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30346
2022-10-15 00:50:40 - progress_bar.py[line:274] - INFO: epoch 001:   6730 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=6720, lr=4.90564e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30358
2022-10-15 00:50:52 - progress_bar.py[line:274] - INFO: epoch 001:   6740 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.7, ups=0.87, wpb=109.8, bsz=40, num_updates=6730, lr=4.90519e-05, gnorm=0.803, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30369
2022-10-15 00:51:03 - progress_bar.py[line:274] - INFO: epoch 001:   6750 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=6740, lr=4.90474e-05, gnorm=0.822, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30380
2022-10-15 00:51:14 - progress_bar.py[line:274] - INFO: epoch 001:   6760 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=101.4, ups=0.92, wpb=110.3, bsz=40, num_updates=6750, lr=4.90429e-05, gnorm=0.859, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30391
2022-10-15 00:51:25 - progress_bar.py[line:274] - INFO: epoch 001:   6770 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=6760, lr=4.90384e-05, gnorm=0.732, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30402
2022-10-15 00:51:36 - progress_bar.py[line:274] - INFO: epoch 001:   6780 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.1, ups=0.88, wpb=109.5, bsz=40, num_updates=6770, lr=4.90339e-05, gnorm=0.793, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30413
2022-10-15 00:51:48 - progress_bar.py[line:274] - INFO: epoch 001:   6790 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.4, ups=0.88, wpb=108.2, bsz=40, num_updates=6780, lr=4.90294e-05, gnorm=0.89, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30425
2022-10-15 00:51:59 - progress_bar.py[line:274] - INFO: epoch 001:   6800 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=6790, lr=4.90249e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30436
2022-10-15 00:52:10 - progress_bar.py[line:274] - INFO: epoch 001:   6810 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.4, ups=0.87, wpb=110.2, bsz=40, num_updates=6800, lr=4.90204e-05, gnorm=0.769, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=30447
2022-10-15 00:52:21 - progress_bar.py[line:274] - INFO: epoch 001:   6820 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=6810, lr=4.90159e-05, gnorm=0.741, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30458
2022-10-15 00:52:33 - progress_bar.py[line:274] - INFO: epoch 001:   6830 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.3, ups=0.89, wpb=109.2, bsz=40, num_updates=6820, lr=4.90114e-05, gnorm=0.766, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30470
2022-10-15 00:52:44 - progress_bar.py[line:274] - INFO: epoch 001:   6840 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=6830, lr=4.90069e-05, gnorm=0.784, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30481
2022-10-15 00:52:55 - progress_bar.py[line:274] - INFO: epoch 001:   6850 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=6840, lr=4.90024e-05, gnorm=0.753, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30492
2022-10-15 00:53:06 - progress_bar.py[line:274] - INFO: epoch 001:   6860 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=6850, lr=4.89979e-05, gnorm=0.803, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30503
2022-10-15 00:53:17 - progress_bar.py[line:274] - INFO: epoch 001:   6870 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=6860, lr=4.89934e-05, gnorm=0.768, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30514
2022-10-15 00:53:28 - progress_bar.py[line:274] - INFO: epoch 001:   6880 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.4, ups=0.91, wpb=110.4, bsz=40, num_updates=6870, lr=4.89889e-05, gnorm=0.904, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30525
2022-10-15 00:53:39 - progress_bar.py[line:274] - INFO: epoch 001:   6890 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.8, ups=0.89, wpb=111.7, bsz=40, num_updates=6880, lr=4.89844e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30536
2022-10-15 00:53:51 - progress_bar.py[line:274] - INFO: epoch 001:   6900 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.7, ups=0.87, wpb=110.4, bsz=40, num_updates=6890, lr=4.89799e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30548
2022-10-15 00:54:02 - progress_bar.py[line:274] - INFO: epoch 001:   6910 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=6900, lr=4.89754e-05, gnorm=0.692, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30559
2022-10-15 00:54:13 - progress_bar.py[line:274] - INFO: epoch 001:   6920 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=6910, lr=4.89709e-05, gnorm=0.769, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30570
2022-10-15 00:54:24 - progress_bar.py[line:274] - INFO: epoch 001:   6930 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=6920, lr=4.89664e-05, gnorm=0.856, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30581
2022-10-15 00:54:35 - progress_bar.py[line:274] - INFO: epoch 001:   6940 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100, ups=0.9, wpb=110.9, bsz=40, num_updates=6930, lr=4.89619e-05, gnorm=0.864, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30592
2022-10-15 00:54:46 - progress_bar.py[line:274] - INFO: epoch 001:   6950 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=6940, lr=4.89573e-05, gnorm=0.876, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30603
2022-10-15 00:54:58 - progress_bar.py[line:274] - INFO: epoch 001:   6960 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.2, ups=0.87, wpb=110.9, bsz=40, num_updates=6950, lr=4.89528e-05, gnorm=0.74, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30615
2022-10-15 00:55:09 - progress_bar.py[line:274] - INFO: epoch 001:   6970 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100, ups=0.89, wpb=112.2, bsz=40, num_updates=6960, lr=4.89483e-05, gnorm=0.773, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30626
2022-10-15 00:55:20 - progress_bar.py[line:274] - INFO: epoch 001:   6980 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.9, ups=0.91, wpb=110.8, bsz=40, num_updates=6970, lr=4.89438e-05, gnorm=0.775, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30637
2022-10-15 00:55:31 - progress_bar.py[line:274] - INFO: epoch 001:   6990 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=6980, lr=4.89393e-05, gnorm=0.868, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30648
2022-10-15 00:55:42 - progress_bar.py[line:274] - INFO: epoch 001:   7000 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.6, ups=0.92, wpb=109.9, bsz=40, num_updates=6990, lr=4.89348e-05, gnorm=0.751, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30659
2022-10-15 00:55:53 - progress_bar.py[line:274] - INFO: epoch 001:   7010 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.9, ups=0.9, wpb=111.1, bsz=40, num_updates=7000, lr=4.89303e-05, gnorm=0.811, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30670
2022-10-15 00:55:53 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-15 00:55:54 - train.py[line:549] - INFO: 0 / 4988
2022-10-15 00:55:54 - train.py[line:551] - INFO: load:0.91 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-15 00:55:55 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 39.59 GiB total capacity; 8.42 GiB already allocated; 1.88 GiB free; 35.23 GiB reserved in total by PyTorch)
2022-10-15 00:55:55 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 8         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8624 MB |    9757 MB |    4420 TB |    4420 TB |
|       from large pool |    8480 MB |    9612 MB |    4418 TB |    4418 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8624 MB |    9757 MB |    4420 TB |    4420 TB |
|       from large pool |    8480 MB |    9612 MB |    4418 TB |    4418 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36076 MB |   36988 MB |  123268 MB |   87192 MB |
|       from large pool |   35930 MB |   36836 MB |  123006 MB |   87076 MB |
|       from small pool |     146 MB |     152 MB |     262 MB |     116 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   27451 MB |   27451 MB |    4342 TB |    4342 TB |
|       from large pool |   27449 MB |   27449 MB |    4341 TB |    4341 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  204387 K  |  204383 K  |
|       from large pool |     563    |     575    |   66100 K  |   66100 K  |
|       from small pool |    3095    |    3114    |  138286 K  |  138283 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  204387 K  |  204383 K  |
|       from large pool |     563    |     575    |   66100 K  |   66100 K  |
|       from small pool |    3095    |    3114    |  138286 K  |  138283 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     194    |     198    |     461    |     267    |
|       from large pool |     121    |     122    |     330    |     209    |
|       from small pool |      73    |      76    |     131    |      58    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     134    |     140    |  145230 K  |  145230 K  |
|       from large pool |      90    |      93    |   24050 K  |   24050 K  |
|       from small pool |      44    |      51    |  121179 K  |  121179 K  |
|===========================================================================|

2022-10-15 00:55:55 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-15 00:55:55 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-15 00:55:55 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.84 GiB already allocated; 4.02 GiB free; 33.09 GiB reserved in total by PyTorch)
2022-10-15 00:55:55 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-15 00:55:55 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 5            |        cudaMalloc retries: 20        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9047 MB |   10272 MB |    4429 TB |    4429 TB |
|       from large pool |    8902 MB |   10127 MB |    4428 TB |    4428 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9047 MB |   10272 MB |    4429 TB |    4429 TB |
|       from large pool |    8902 MB |   10127 MB |    4428 TB |    4428 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   33880 MB |   33880 MB |  209576 MB |  175696 MB |
|       from large pool |   33734 MB |   33734 MB |  209206 MB |  175472 MB |
|       from small pool |     146 MB |     146 MB |     370 MB |     224 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24832 MB |   29362 MB |    6288 TB |    6288 TB |
|       from large pool |   24831 MB |   29360 MB |    6287 TB |    6287 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  204390 K  |  204387 K  |
|       from large pool |     563    |     575    |   66104 K  |   66104 K  |
|       from small pool |    3095    |    3114    |  138286 K  |  138283 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  204390 K  |  204387 K  |
|       from large pool |     563    |     575    |   66104 K  |   66104 K  |
|       from small pool |    3095    |    3114    |  138286 K  |  138283 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     132    |     132    |     559    |     427    |
|       from large pool |      59    |      59    |     374    |     315    |
|       from small pool |      73    |      73    |     185    |     112    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      76    |      80    |  152946 K  |  152946 K  |
|       from large pool |      35    |      36    |   32713 K  |   32713 K  |
|       from small pool |      41    |      49    |  120232 K  |  120232 K  |
|===========================================================================|

2022-10-15 00:55:55 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-15 00:58:28 - train.py[line:549] - INFO: 200 / 4988
2022-10-15 00:58:28 - train.py[line:551] - INFO: load:0.93 valid_run:153.42 task_valid:148.72 collect_output:2.60
2022-10-15 01:00:57 - train.py[line:549] - INFO: 400 / 4988
2022-10-15 01:00:57 - train.py[line:551] - INFO: load:0.96 valid_run:302.23 task_valid:292.40 collect_output:6.70
2022-10-15 01:03:30 - train.py[line:549] - INFO: 600 / 4988
2022-10-15 01:03:30 - train.py[line:551] - INFO: load:0.98 valid_run:455.19 task_valid:436.46 collect_output:14.56
2022-10-15 01:06:00 - train.py[line:549] - INFO: 800 / 4988
2022-10-15 01:06:00 - train.py[line:551] - INFO: load:1.01 valid_run:605.15 task_valid:582.28 collect_output:17.68
2022-10-15 01:08:33 - train.py[line:549] - INFO: 1000 / 4988
2022-10-15 01:08:33 - train.py[line:551] - INFO: load:1.03 valid_run:758.06 task_valid:730.62 collect_output:21.23
2022-10-15 01:11:05 - train.py[line:549] - INFO: 1200 / 4988
2022-10-15 01:11:05 - train.py[line:551] - INFO: load:1.06 valid_run:910.70 task_valid:877.06 collect_output:26.43
2022-10-15 01:13:39 - train.py[line:549] - INFO: 1400 / 4988
2022-10-15 01:13:39 - train.py[line:551] - INFO: load:1.09 valid_run:1064.68 task_valid:1024.35 collect_output:32.07
2022-10-15 01:16:11 - train.py[line:549] - INFO: 1600 / 4988
2022-10-15 01:16:11 - train.py[line:551] - INFO: load:1.11 valid_run:1216.36 task_valid:1166.31 collect_output:40.79
2022-10-15 01:18:41 - train.py[line:549] - INFO: 1800 / 4988
2022-10-15 01:18:41 - train.py[line:551] - INFO: load:1.14 valid_run:1366.56 task_valid:1311.79 collect_output:44.49
2022-10-15 01:21:11 - train.py[line:549] - INFO: 2000 / 4988
2022-10-15 01:21:11 - train.py[line:551] - INFO: load:1.16 valid_run:1516.22 task_valid:1456.25 collect_output:48.65
2022-10-15 01:23:41 - train.py[line:549] - INFO: 2200 / 4988
2022-10-15 01:23:41 - train.py[line:551] - INFO: load:1.19 valid_run:1666.26 task_valid:1601.30 collect_output:52.67
2022-10-15 01:26:12 - train.py[line:549] - INFO: 2400 / 4988
2022-10-15 01:26:12 - train.py[line:551] - INFO: load:1.21 valid_run:1816.57 task_valid:1746.51 collect_output:56.80
2022-10-15 01:28:42 - train.py[line:549] - INFO: 2600 / 4988
2022-10-15 01:28:42 - train.py[line:551] - INFO: load:1.24 valid_run:1966.81 task_valid:1888.67 collect_output:63.89
2022-10-15 01:31:13 - train.py[line:549] - INFO: 2800 / 4988
2022-10-15 01:31:13 - train.py[line:551] - INFO: load:1.26 valid_run:2117.73 task_valid:2034.34 collect_output:68.16
2022-10-15 01:33:43 - train.py[line:549] - INFO: 3000 / 4988
2022-10-15 01:33:43 - train.py[line:551] - INFO: load:1.29 valid_run:2267.94 task_valid:2180.99 collect_output:70.73
2022-10-15 01:36:14 - train.py[line:549] - INFO: 3200 / 4988
2022-10-15 01:36:14 - train.py[line:551] - INFO: load:1.31 valid_run:2418.29 task_valid:2325.39 collect_output:75.71
2022-10-15 01:38:46 - train.py[line:549] - INFO: 3400 / 4988
2022-10-15 01:38:46 - train.py[line:551] - INFO: load:1.34 valid_run:2570.23 task_valid:2471.19 collect_output:80.84
2022-10-15 01:41:16 - train.py[line:549] - INFO: 3600 / 4988
2022-10-15 01:41:16 - train.py[line:551] - INFO: load:1.36 valid_run:2721.07 task_valid:2618.25 collect_output:83.65
2022-10-15 01:43:45 - train.py[line:549] - INFO: 3800 / 4988
2022-10-15 01:43:45 - train.py[line:551] - INFO: load:1.39 valid_run:2869.77 task_valid:2760.17 collect_output:89.46
2022-10-15 01:46:16 - train.py[line:549] - INFO: 4000 / 4988
2022-10-15 01:46:16 - train.py[line:551] - INFO: load:1.41 valid_run:3020.45 task_valid:2905.79 collect_output:93.51
2022-10-15 01:48:48 - train.py[line:549] - INFO: 4200 / 4988
2022-10-15 01:48:48 - train.py[line:551] - INFO: load:1.44 valid_run:3172.74 task_valid:3050.55 collect_output:100.03
2022-10-15 01:51:18 - train.py[line:549] - INFO: 4400 / 4988
2022-10-15 01:51:18 - train.py[line:551] - INFO: load:1.46 valid_run:3322.39 task_valid:3195.32 collect_output:103.92
2022-10-15 01:53:50 - train.py[line:549] - INFO: 4600 / 4988
2022-10-15 01:53:50 - train.py[line:551] - INFO: load:1.49 valid_run:3474.06 task_valid:3341.86 collect_output:108.08
2022-10-15 01:56:22 - train.py[line:549] - INFO: 4800 / 4988
2022-10-15 01:56:22 - train.py[line:551] - INFO: load:1.51 valid_run:3625.87 task_valid:3488.79 collect_output:111.98

====================================================================================================
SGG eval:     R @ 50: 0.6621;     R @ 100: 0.6971;     R @ 500: 0.7075;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4390;    mR @ 100: 0.4705;    mR @ 500: 0.5083;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:1.0000) (covering:0.3000) (eating:0.8235) (flying in:0.0909) (growing on:0.3750) (hanging from:0.5645) (lying on:0.3000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9575) (says:0.0000) (sitting on:0.7551) (standing on:0.4043) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6621;     R @ 100: 0.6971;     R @ 500: 0.7075;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4390;    mR @ 100: 0.4705;    mR @ 500: 0.5083;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:1.0000) (covering:0.3000) (eating:0.8235) (flying in:0.0909) (growing on:0.3750) (hanging from:0.5645) (lying on:0.3000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9575) (says:0.0000) (sitting on:0.7551) (standing on:0.4043) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-15 01:58:53 - train.py[line:487] - INFO: 0.6970784823020117
2022-10-15 01:58:53 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-15 01:58:53 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.345 | loss_v1 0 | loss_v2 0 | nll_loss 0.185 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.697078 | ppl 1.14 | vqa_score 0.5901 | wps 118.7 | wpb 89.9 | bsz 30 | num_updates 7000 | best_R@100 0.709638
2022-10-15 01:58:53 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 7000 updates
2022-10-15 01:58:53 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-15 01:58:59 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-15 01:59:01 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 0.6970784823020117) (writing took 8.114771895110607 seconds)
2022-10-15 01:59:12 - progress_bar.py[line:274] - INFO: epoch 001:   7020 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=0.3, ups=0, wpb=111.8, bsz=40, num_updates=7010, lr=4.89258e-05, gnorm=0.895, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34469
2022-10-15 01:59:24 - progress_bar.py[line:274] - INFO: epoch 001:   7030 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=7020, lr=4.89213e-05, gnorm=0.868, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34481
2022-10-15 01:59:35 - progress_bar.py[line:274] - INFO: epoch 001:   7040 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.8, ups=0.88, wpb=108.3, bsz=40, num_updates=7030, lr=4.89168e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34492
2022-10-15 01:59:46 - progress_bar.py[line:274] - INFO: epoch 001:   7050 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=7040, lr=4.89123e-05, gnorm=0.822, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34503
2022-10-15 01:59:57 - progress_bar.py[line:274] - INFO: epoch 001:   7060 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.8, ups=0.91, wpb=111.4, bsz=40, num_updates=7050, lr=4.89078e-05, gnorm=0.775, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34514
2022-10-15 02:00:09 - progress_bar.py[line:274] - INFO: epoch 001:   7070 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=7060, lr=4.89033e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34526
2022-10-15 02:00:20 - progress_bar.py[line:274] - INFO: epoch 001:   7080 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.6, ups=0.91, wpb=112.2, bsz=40, num_updates=7070, lr=4.88988e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34537
2022-10-15 02:00:31 - progress_bar.py[line:274] - INFO: epoch 001:   7090 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=7080, lr=4.88943e-05, gnorm=0.759, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34548
2022-10-15 02:00:42 - progress_bar.py[line:274] - INFO: epoch 001:   7100 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=7090, lr=4.88898e-05, gnorm=0.872, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34559
2022-10-15 02:00:53 - progress_bar.py[line:274] - INFO: epoch 001:   7110 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.5, ups=0.89, wpb=109.4, bsz=40, num_updates=7100, lr=4.88853e-05, gnorm=0.85, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34570
2022-10-15 02:01:04 - progress_bar.py[line:274] - INFO: epoch 001:   7120 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=7110, lr=4.88808e-05, gnorm=0.865, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34581
2022-10-15 02:01:16 - progress_bar.py[line:274] - INFO: epoch 001:   7130 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.3, ups=0.87, wpb=110.2, bsz=40, num_updates=7120, lr=4.88763e-05, gnorm=0.778, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34593
2022-10-15 02:01:27 - progress_bar.py[line:274] - INFO: epoch 001:   7140 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=7130, lr=4.88718e-05, gnorm=0.803, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34604
2022-10-15 02:01:38 - progress_bar.py[line:274] - INFO: epoch 001:   7150 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.6, ups=0.91, wpb=108.9, bsz=40, num_updates=7140, lr=4.88673e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34615
2022-10-15 02:01:49 - progress_bar.py[line:274] - INFO: epoch 001:   7160 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.4, ups=0.92, wpb=111.4, bsz=40, num_updates=7150, lr=4.88628e-05, gnorm=0.825, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34626
2022-10-15 02:02:00 - progress_bar.py[line:274] - INFO: epoch 001:   7170 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=7160, lr=4.88583e-05, gnorm=0.758, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34637
2022-10-15 02:02:11 - progress_bar.py[line:274] - INFO: epoch 001:   7180 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=7170, lr=4.88538e-05, gnorm=0.76, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34648
2022-10-15 02:02:22 - progress_bar.py[line:274] - INFO: epoch 001:   7190 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=7180, lr=4.88493e-05, gnorm=0.84, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34659
2022-10-15 02:02:34 - progress_bar.py[line:274] - INFO: epoch 001:   7200 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.8, ups=0.87, wpb=111.2, bsz=40, num_updates=7190, lr=4.88448e-05, gnorm=0.815, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34671
2022-10-15 02:02:45 - progress_bar.py[line:274] - INFO: epoch 001:   7210 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100, ups=0.91, wpb=109.7, bsz=40, num_updates=7200, lr=4.88402e-05, gnorm=0.892, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34682
2022-10-15 02:02:56 - progress_bar.py[line:274] - INFO: epoch 001:   7220 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=103.4, ups=0.93, wpb=111.1, bsz=40, num_updates=7210, lr=4.88357e-05, gnorm=0.872, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34693
2022-10-15 02:03:07 - progress_bar.py[line:274] - INFO: epoch 001:   7230 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=7220, lr=4.88312e-05, gnorm=0.821, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34704
2022-10-15 02:03:18 - progress_bar.py[line:274] - INFO: epoch 001:   7240 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.9, ups=0.9, wpb=109.2, bsz=40, num_updates=7230, lr=4.88267e-05, gnorm=0.793, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34715
2022-10-15 02:03:29 - progress_bar.py[line:274] - INFO: epoch 001:   7250 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=102.6, ups=0.92, wpb=111.7, bsz=40, num_updates=7240, lr=4.88222e-05, gnorm=0.781, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34726
2022-10-15 02:03:40 - progress_bar.py[line:274] - INFO: epoch 001:   7260 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=7250, lr=4.88177e-05, gnorm=0.676, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34737
2022-10-15 02:03:51 - progress_bar.py[line:274] - INFO: epoch 001:   7270 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.1, ups=0.92, wpb=110.2, bsz=40, num_updates=7260, lr=4.88132e-05, gnorm=0.765, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34748
2022-10-15 02:04:02 - progress_bar.py[line:274] - INFO: epoch 001:   7280 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.1, ups=0.89, wpb=109.6, bsz=40, num_updates=7270, lr=4.88087e-05, gnorm=0.749, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34759
2022-10-15 02:04:13 - progress_bar.py[line:274] - INFO: epoch 001:   7290 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99, ups=0.91, wpb=109.2, bsz=40, num_updates=7280, lr=4.88042e-05, gnorm=0.787, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34770
2022-10-15 02:04:24 - progress_bar.py[line:274] - INFO: epoch 001:   7300 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=7290, lr=4.87997e-05, gnorm=0.843, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34781
2022-10-15 02:04:36 - progress_bar.py[line:274] - INFO: epoch 001:   7310 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=7300, lr=4.87952e-05, gnorm=0.794, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34793
2022-10-15 02:04:47 - progress_bar.py[line:274] - INFO: epoch 001:   7320 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.7, ups=0.91, wpb=110.6, bsz=40, num_updates=7310, lr=4.87907e-05, gnorm=0.927, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34804
2022-10-15 02:04:58 - progress_bar.py[line:274] - INFO: epoch 001:   7330 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=7320, lr=4.87862e-05, gnorm=0.698, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34815
2022-10-15 02:05:09 - progress_bar.py[line:274] - INFO: epoch 001:   7340 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101, ups=0.9, wpb=111.7, bsz=40, num_updates=7330, lr=4.87817e-05, gnorm=0.761, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34826
2022-10-15 02:05:20 - progress_bar.py[line:274] - INFO: epoch 001:   7350 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=7340, lr=4.87772e-05, gnorm=0.805, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34837
2022-10-15 02:05:31 - progress_bar.py[line:274] - INFO: epoch 001:   7360 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.5, ups=0.9, wpb=111.2, bsz=40, num_updates=7350, lr=4.87727e-05, gnorm=0.777, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34848
2022-10-15 02:05:43 - progress_bar.py[line:274] - INFO: epoch 001:   7370 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.3, ups=0.89, wpb=112.3, bsz=40, num_updates=7360, lr=4.87682e-05, gnorm=0.78, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34860
2022-10-15 02:05:54 - progress_bar.py[line:274] - INFO: epoch 001:   7380 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101, ups=0.9, wpb=111.7, bsz=40, num_updates=7370, lr=4.87637e-05, gnorm=0.76, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34871
2022-10-15 02:06:05 - progress_bar.py[line:274] - INFO: epoch 001:   7390 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.1, ups=0.88, wpb=109.9, bsz=40, num_updates=7380, lr=4.87592e-05, gnorm=0.753, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=34882
2022-10-15 02:06:17 - progress_bar.py[line:274] - INFO: epoch 001:   7400 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=95.3, ups=0.86, wpb=110.8, bsz=40, num_updates=7390, lr=4.87547e-05, gnorm=0.832, clip=10, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=34894
2022-10-15 02:06:28 - progress_bar.py[line:274] - INFO: epoch 001:   7410 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=7400, lr=4.87502e-05, gnorm=0.866, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34905
2022-10-15 02:06:39 - progress_bar.py[line:274] - INFO: epoch 001:   7420 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=7410, lr=4.87457e-05, gnorm=0.719, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34916
2022-10-15 02:06:50 - progress_bar.py[line:274] - INFO: epoch 001:   7430 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=7420, lr=4.87412e-05, gnorm=0.77, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34927
2022-10-15 02:07:02 - progress_bar.py[line:274] - INFO: epoch 001:   7440 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.3, ups=0.88, wpb=110.6, bsz=40, num_updates=7430, lr=4.87367e-05, gnorm=0.809, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34939
2022-10-15 02:07:13 - progress_bar.py[line:274] - INFO: epoch 001:   7450 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.5, ups=0.9, wpb=109.3, bsz=40, num_updates=7440, lr=4.87322e-05, gnorm=0.739, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34950
2022-10-15 02:07:23 - progress_bar.py[line:274] - INFO: epoch 001:   7460 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=102.2, ups=0.93, wpb=110.3, bsz=40, num_updates=7450, lr=4.87276e-05, gnorm=0.771, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34960
2022-10-15 02:07:35 - progress_bar.py[line:274] - INFO: epoch 001:   7470 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=7460, lr=4.87231e-05, gnorm=0.823, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34972
2022-10-15 02:07:46 - progress_bar.py[line:274] - INFO: epoch 001:   7480 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=7470, lr=4.87186e-05, gnorm=0.7, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=34983
2022-10-15 02:07:57 - progress_bar.py[line:274] - INFO: epoch 001:   7490 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100, ups=0.9, wpb=110.9, bsz=40, num_updates=7480, lr=4.87141e-05, gnorm=0.725, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34994
2022-10-15 02:08:08 - progress_bar.py[line:274] - INFO: epoch 001:   7500 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=102.8, ups=0.93, wpb=110.9, bsz=40, num_updates=7490, lr=4.87096e-05, gnorm=0.741, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=35005
2022-10-15 02:08:19 - progress_bar.py[line:274] - INFO: epoch 001:   7510 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.8, ups=0.88, wpb=110, bsz=40, num_updates=7500, lr=4.87051e-05, gnorm=0.752, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35016
2022-10-15 02:08:31 - progress_bar.py[line:274] - INFO: epoch 001:   7520 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=7510, lr=4.87006e-05, gnorm=0.794, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35028
2022-10-15 02:08:42 - progress_bar.py[line:274] - INFO: epoch 001:   7530 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.1, ups=0.91, wpb=109.5, bsz=40, num_updates=7520, lr=4.86961e-05, gnorm=0.789, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35039
2022-10-15 02:08:53 - progress_bar.py[line:274] - INFO: epoch 001:   7540 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.4, ups=0.88, wpb=111.9, bsz=40, num_updates=7530, lr=4.86916e-05, gnorm=0.697, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35050
2022-10-15 02:09:04 - progress_bar.py[line:274] - INFO: epoch 001:   7550 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.7, ups=0.93, wpb=109.5, bsz=40, num_updates=7540, lr=4.86871e-05, gnorm=0.815, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35061
2022-10-15 02:09:15 - progress_bar.py[line:274] - INFO: epoch 001:   7560 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.3, ups=0.89, wpb=108.7, bsz=40, num_updates=7550, lr=4.86826e-05, gnorm=0.889, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35072
2022-10-15 02:09:26 - progress_bar.py[line:274] - INFO: epoch 001:   7570 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101.1, ups=0.91, wpb=110.8, bsz=40, num_updates=7560, lr=4.86781e-05, gnorm=0.819, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35083
2022-10-15 02:09:37 - progress_bar.py[line:274] - INFO: epoch 001:   7580 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.8, ups=0.89, wpb=109.7, bsz=40, num_updates=7570, lr=4.86736e-05, gnorm=0.73, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35094
2022-10-15 02:09:48 - progress_bar.py[line:274] - INFO: epoch 001:   7590 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.1, ups=0.91, wpb=109.7, bsz=40, num_updates=7580, lr=4.86691e-05, gnorm=0.724, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35105
2022-10-15 02:09:56 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-15 02:10:01 - progress_bar.py[line:274] - INFO: epoch 001:   7601 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=86.8, ups=0.79, wpb=109.8, bsz=40, num_updates=7590, lr=4.86646e-05, gnorm=0.749, clip=0, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=35118
2022-10-15 02:10:12 - progress_bar.py[line:274] - INFO: epoch 001:   7611 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=7600, lr=4.86601e-05, gnorm=0.742, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35129
2022-10-15 02:10:23 - progress_bar.py[line:274] - INFO: epoch 001:   7621 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=7610, lr=4.86556e-05, gnorm=0.806, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35140
2022-10-15 02:10:34 - progress_bar.py[line:274] - INFO: epoch 001:   7631 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.8, ups=0.91, wpb=109.8, bsz=40, num_updates=7620, lr=4.86511e-05, gnorm=0.719, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35151
2022-10-15 02:10:46 - progress_bar.py[line:274] - INFO: epoch 001:   7641 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.7, ups=0.89, wpb=111.5, bsz=40, num_updates=7630, lr=4.86466e-05, gnorm=0.805, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35163
2022-10-15 02:10:57 - progress_bar.py[line:274] - INFO: epoch 001:   7651 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.1, ups=0.91, wpb=111.5, bsz=40, num_updates=7640, lr=4.86421e-05, gnorm=0.712, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35174
2022-10-15 02:11:08 - progress_bar.py[line:274] - INFO: epoch 001:   7661 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96, ups=0.88, wpb=109.2, bsz=40, num_updates=7650, lr=4.86376e-05, gnorm=0.771, clip=0, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=35185
2022-10-15 02:11:19 - progress_bar.py[line:274] - INFO: epoch 001:   7671 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101, ups=0.9, wpb=111.9, bsz=40, num_updates=7660, lr=4.86331e-05, gnorm=0.783, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35196
2022-10-15 02:11:30 - progress_bar.py[line:274] - INFO: epoch 001:   7681 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.2, ups=0.89, wpb=110.7, bsz=40, num_updates=7670, lr=4.86286e-05, gnorm=0.678, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35207
2022-10-15 02:11:42 - progress_bar.py[line:274] - INFO: epoch 001:   7691 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.2, ups=0.9, wpb=109.7, bsz=40, num_updates=7680, lr=4.86241e-05, gnorm=0.811, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35219
2022-10-15 02:11:53 - progress_bar.py[line:274] - INFO: epoch 001:   7701 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=7690, lr=4.86196e-05, gnorm=0.861, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=35230
2022-10-15 02:12:04 - progress_bar.py[line:274] - INFO: epoch 001:   7711 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.1, ups=0.88, wpb=109.5, bsz=40, num_updates=7700, lr=4.86151e-05, gnorm=0.798, clip=20, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=35241
2022-10-15 02:12:15 - progress_bar.py[line:274] - INFO: epoch 001:   7721 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.3, ups=0.88, wpb=109.3, bsz=40, num_updates=7710, lr=4.86105e-05, gnorm=0.836, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35252
2022-10-15 02:12:27 - progress_bar.py[line:274] - INFO: epoch 001:   7731 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.6, ups=0.87, wpb=111.3, bsz=40, num_updates=7720, lr=4.8606e-05, gnorm=0.789, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35264
2022-10-15 02:12:38 - progress_bar.py[line:274] - INFO: epoch 001:   7741 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=7730, lr=4.86015e-05, gnorm=0.651, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35275
2022-10-15 02:12:49 - progress_bar.py[line:274] - INFO: epoch 001:   7751 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.3, ups=0.9, wpb=110, bsz=40, num_updates=7740, lr=4.8597e-05, gnorm=0.655, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35286
2022-10-15 02:13:00 - progress_bar.py[line:274] - INFO: epoch 001:   7761 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=103.2, ups=0.92, wpb=111.9, bsz=40, num_updates=7750, lr=4.85925e-05, gnorm=0.777, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35297
2022-10-15 02:13:11 - progress_bar.py[line:274] - INFO: epoch 001:   7771 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.1, ups=0.9, wpb=111.8, bsz=40, num_updates=7760, lr=4.8588e-05, gnorm=0.735, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35308
2022-10-15 02:13:23 - progress_bar.py[line:274] - INFO: epoch 001:   7781 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.5, ups=0.88, wpb=108.4, bsz=40, num_updates=7770, lr=4.85835e-05, gnorm=0.844, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35320
2022-10-15 02:13:34 - progress_bar.py[line:274] - INFO: epoch 001:   7791 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=7780, lr=4.8579e-05, gnorm=0.789, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35331
2022-10-15 02:13:45 - progress_bar.py[line:274] - INFO: epoch 001:   7801 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.8, ups=0.89, wpb=111, bsz=40, num_updates=7790, lr=4.85745e-05, gnorm=0.73, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35342
2022-10-15 02:13:56 - progress_bar.py[line:274] - INFO: epoch 001:   7811 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=7800, lr=4.857e-05, gnorm=0.749, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35353
2022-10-15 02:14:07 - progress_bar.py[line:274] - INFO: epoch 001:   7821 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.3, ups=0.9, wpb=111, bsz=40, num_updates=7810, lr=4.85655e-05, gnorm=0.79, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35364
2022-10-15 02:14:08 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 02:14:20 - progress_bar.py[line:274] - INFO: epoch 001:   7832 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=89.6, ups=0.8, wpb=112.4, bsz=40, num_updates=7820, lr=4.8561e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=35377
2022-10-15 02:14:31 - progress_bar.py[line:274] - INFO: epoch 001:   7842 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=7830, lr=4.85565e-05, gnorm=0.929, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=35388
2022-10-15 02:14:42 - progress_bar.py[line:274] - INFO: epoch 001:   7852 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95, ups=0.87, wpb=109.6, bsz=40, num_updates=7840, lr=4.8552e-05, gnorm=0.835, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35399
2022-10-15 02:14:54 - progress_bar.py[line:274] - INFO: epoch 001:   7862 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.1, ups=0.9, wpb=110, bsz=40, num_updates=7850, lr=4.85475e-05, gnorm=0.862, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35411
2022-10-15 02:15:05 - progress_bar.py[line:274] - INFO: epoch 001:   7872 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.2, ups=0.88, wpb=108.9, bsz=40, num_updates=7860, lr=4.8543e-05, gnorm=0.836, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35422
2022-10-15 02:15:16 - progress_bar.py[line:274] - INFO: epoch 001:   7882 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.4, ups=0.9, wpb=109.6, bsz=40, num_updates=7870, lr=4.85385e-05, gnorm=0.777, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35433
2022-10-15 02:15:27 - progress_bar.py[line:274] - INFO: epoch 001:   7892 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.9, ups=0.93, wpb=109.8, bsz=40, num_updates=7880, lr=4.8534e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35444
2022-10-15 02:15:38 - progress_bar.py[line:274] - INFO: epoch 001:   7902 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=7890, lr=4.85295e-05, gnorm=0.723, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35455
2022-10-15 02:15:49 - progress_bar.py[line:274] - INFO: epoch 001:   7912 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=7900, lr=4.8525e-05, gnorm=0.885, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35466
2022-10-15 02:16:00 - progress_bar.py[line:274] - INFO: epoch 001:   7922 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=102.7, ups=0.93, wpb=110.7, bsz=40, num_updates=7910, lr=4.85205e-05, gnorm=0.768, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35477
2022-10-15 02:16:11 - progress_bar.py[line:274] - INFO: epoch 001:   7932 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=7920, lr=4.8516e-05, gnorm=0.691, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35488
2022-10-15 02:16:22 - progress_bar.py[line:274] - INFO: epoch 001:   7942 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.5, ups=0.9, wpb=110.4, bsz=40, num_updates=7930, lr=4.85115e-05, gnorm=0.908, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35499
2022-10-15 02:16:34 - progress_bar.py[line:274] - INFO: epoch 001:   7952 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.3, ups=0.87, wpb=109.8, bsz=40, num_updates=7940, lr=4.8507e-05, gnorm=0.812, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35511
2022-10-15 02:16:45 - progress_bar.py[line:274] - INFO: epoch 001:   7962 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.6, ups=0.91, wpb=109.6, bsz=40, num_updates=7950, lr=4.85025e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=35522
2022-10-15 02:16:56 - progress_bar.py[line:274] - INFO: epoch 001:   7972 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=7960, lr=4.8498e-05, gnorm=0.725, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35533
2022-10-15 02:17:07 - progress_bar.py[line:274] - INFO: epoch 001:   7982 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.2, ups=0.92, wpb=111.7, bsz=40, num_updates=7970, lr=4.84934e-05, gnorm=0.741, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35544
2022-10-15 02:17:18 - progress_bar.py[line:274] - INFO: epoch 001:   7992 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=7980, lr=4.84889e-05, gnorm=0.804, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=35555
2022-10-15 02:17:29 - progress_bar.py[line:274] - INFO: epoch 001:   8002 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.7, ups=0.91, wpb=110.9, bsz=40, num_updates=7990, lr=4.84844e-05, gnorm=0.805, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=35566
2022-10-15 02:17:40 - progress_bar.py[line:274] - INFO: epoch 001:   8012 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.8, ups=0.89, wpb=109.9, bsz=40, num_updates=8000, lr=4.84799e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=35577
2022-10-15 02:17:40 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-15 02:17:41 - train.py[line:549] - INFO: 0 / 4988
2022-10-15 02:17:41 - train.py[line:551] - INFO: load:1.02 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-15 02:20:15 - train.py[line:549] - INFO: 200 / 4988
2022-10-15 02:20:15 - train.py[line:551] - INFO: load:1.04 valid_run:153.40 task_valid:149.75 collect_output:2.63
2022-10-15 02:22:44 - train.py[line:549] - INFO: 400 / 4988
2022-10-15 02:22:44 - train.py[line:551] - INFO: load:1.07 valid_run:303.01 task_valid:293.68 collect_output:7.24
2022-10-15 02:25:18 - train.py[line:549] - INFO: 600 / 4988
2022-10-15 02:25:18 - train.py[line:551] - INFO: load:1.10 valid_run:456.93 task_valid:437.80 collect_output:15.99
2022-10-15 02:27:48 - train.py[line:549] - INFO: 800 / 4988
2022-10-15 02:27:48 - train.py[line:551] - INFO: load:1.12 valid_run:606.87 task_valid:583.79 collect_output:18.93
2022-10-15 02:30:22 - train.py[line:549] - INFO: 1000 / 4988
2022-10-15 02:30:22 - train.py[line:551] - INFO: load:1.15 valid_run:760.23 task_valid:732.23 collect_output:22.75
2022-10-15 02:32:54 - train.py[line:549] - INFO: 1200 / 4988
2022-10-15 02:32:54 - train.py[line:551] - INFO: load:1.19 valid_run:912.63 task_valid:878.55 collect_output:27.80
2022-10-15 02:35:28 - train.py[line:549] - INFO: 1400 / 4988
2022-10-15 02:35:28 - train.py[line:551] - INFO: load:1.22 valid_run:1066.51 task_valid:1025.37 collect_output:33.77
2022-10-15 02:38:00 - train.py[line:549] - INFO: 1600 / 4988
2022-10-15 02:38:00 - train.py[line:551] - INFO: load:1.24 valid_run:1218.07 task_valid:1166.71 collect_output:43.02
2022-10-15 02:40:30 - train.py[line:549] - INFO: 1800 / 4988
2022-10-15 02:40:30 - train.py[line:551] - INFO: load:1.27 valid_run:1368.15 task_valid:1311.69 collect_output:47.17
2022-10-15 02:42:59 - train.py[line:549] - INFO: 2000 / 4988
2022-10-15 02:42:59 - train.py[line:551] - INFO: load:1.29 valid_run:1517.25 task_valid:1455.17 collect_output:51.83
2022-10-15 02:45:29 - train.py[line:549] - INFO: 2200 / 4988
2022-10-15 02:45:29 - train.py[line:551] - INFO: load:1.32 valid_run:1667.36 task_valid:1600.36 collect_output:55.80
2022-10-15 02:48:00 - train.py[line:549] - INFO: 2400 / 4988
2022-10-15 02:48:00 - train.py[line:551] - INFO: load:1.34 valid_run:1817.84 task_valid:1745.64 collect_output:60.05
2022-10-15 02:50:30 - train.py[line:549] - INFO: 2600 / 4988
2022-10-15 02:50:30 - train.py[line:551] - INFO: load:1.37 valid_run:1968.26 task_valid:1887.92 collect_output:67.22
2022-10-15 02:53:01 - train.py[line:549] - INFO: 2800 / 4988
2022-10-15 02:53:01 - train.py[line:551] - INFO: load:1.39 valid_run:2119.30 task_valid:2033.80 collect_output:71.40
2022-10-15 02:55:32 - train.py[line:549] - INFO: 3000 / 4988
2022-10-15 02:55:32 - train.py[line:551] - INFO: load:1.42 valid_run:2269.81 task_valid:2180.53 collect_output:74.21
2022-10-15 02:58:02 - train.py[line:549] - INFO: 3200 / 4988
2022-10-15 02:58:02 - train.py[line:551] - INFO: load:1.44 valid_run:2420.13 task_valid:2325.02 collect_output:79.07
2022-10-15 03:00:35 - train.py[line:549] - INFO: 3400 / 4988
2022-10-15 03:00:35 - train.py[line:551] - INFO: load:1.47 valid_run:2572.35 task_valid:2471.11 collect_output:84.22
2022-10-15 03:03:06 - train.py[line:549] - INFO: 3600 / 4988
2022-10-15 03:03:06 - train.py[line:551] - INFO: load:1.49 valid_run:2723.29 task_valid:2618.53 collect_output:86.77
2022-10-15 03:05:35 - train.py[line:549] - INFO: 3800 / 4988
2022-10-15 03:05:35 - train.py[line:551] - INFO: load:1.52 valid_run:2872.16 task_valid:2760.43 collect_output:92.75
2022-10-15 03:08:05 - train.py[line:549] - INFO: 4000 / 4988
2022-10-15 03:08:05 - train.py[line:551] - INFO: load:1.55 valid_run:3022.78 task_valid:2905.99 collect_output:96.81
2022-10-15 03:10:38 - train.py[line:549] - INFO: 4200 / 4988
2022-10-15 03:10:38 - train.py[line:551] - INFO: load:1.57 valid_run:3175.13 task_valid:3050.95 collect_output:103.20
2022-10-15 03:13:08 - train.py[line:549] - INFO: 4400 / 4988
2022-10-15 03:13:08 - train.py[line:551] - INFO: load:1.60 valid_run:3325.04 task_valid:3195.98 collect_output:107.09
2022-10-15 03:15:39 - train.py[line:549] - INFO: 4600 / 4988
2022-10-15 03:15:39 - train.py[line:551] - INFO: load:1.62 valid_run:3476.59 task_valid:3342.58 collect_output:111.07
2022-10-15 03:18:11 - train.py[line:549] - INFO: 4800 / 4988
2022-10-15 03:18:11 - train.py[line:551] - INFO: load:1.65 valid_run:3628.40 task_valid:3489.64 collect_output:114.80

====================================================================================================
SGG eval:     R @ 50: 0.6554;     R @ 100: 0.6897;     R @ 500: 0.7048;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4340;    mR @ 100: 0.4576;    mR @ 500: 0.5023;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:1.0000) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.2500) (hanging from:0.5323) (lying on:0.3000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9477) (says:0.0000) (sitting on:0.7506) (standing on:0.4093) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6554;     R @ 100: 0.6897;     R @ 500: 0.7048;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4340;    mR @ 100: 0.4576;    mR @ 500: 0.5023;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:1.0000) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.2500) (hanging from:0.5323) (lying on:0.3000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.9583) (playing:0.0000) (riding:0.9477) (says:0.0000) (sitting on:0.7506) (standing on:0.4093) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.5972) 
--------------------------------------------------------
====================================================================================================

2022-10-15 03:20:43 - train.py[line:487] - INFO: 0.6897148459383752
2022-10-15 03:20:43 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-15 03:20:43 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.338 | loss_v1 0 | loss_v2 0 | nll_loss 0.188 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.689715 | ppl 1.14 | vqa_score 0.5991 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 8000 | best_R@100 0.709638
2022-10-15 03:20:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2022-10-15 03:20:43 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-15 03:20:49 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-15 03:20:52 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.6897148459383752) (writing took 8.118252609856427 seconds)
2022-10-15 03:21:03 - progress_bar.py[line:274] - INFO: epoch 001:   8022 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=0.3, ups=0, wpb=111.3, bsz=40, num_updates=8010, lr=4.84754e-05, gnorm=0.868, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39380
2022-10-15 03:21:14 - progress_bar.py[line:274] - INFO: epoch 001:   8032 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=95.8, ups=0.88, wpb=108.4, bsz=40, num_updates=8020, lr=4.84709e-05, gnorm=0.831, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=39391
2022-10-15 03:21:25 - progress_bar.py[line:274] - INFO: epoch 001:   8042 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.9, ups=0.9, wpb=110.8, bsz=40, num_updates=8030, lr=4.84664e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=39402
2022-10-15 03:21:37 - progress_bar.py[line:274] - INFO: epoch 001:   8052 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.7, ups=0.88, wpb=112, bsz=40, num_updates=8040, lr=4.84619e-05, gnorm=0.721, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39414
2022-10-15 03:21:48 - progress_bar.py[line:274] - INFO: epoch 001:   8062 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.8, ups=0.87, wpb=110.3, bsz=40, num_updates=8050, lr=4.84574e-05, gnorm=0.82, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39425
2022-10-15 03:21:59 - progress_bar.py[line:274] - INFO: epoch 001:   8072 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.6, ups=0.88, wpb=109.8, bsz=40, num_updates=8060, lr=4.84529e-05, gnorm=0.869, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39437
2022-10-15 03:22:10 - progress_bar.py[line:274] - INFO: epoch 001:   8082 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.1, ups=0.91, wpb=110.5, bsz=40, num_updates=8070, lr=4.84484e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39447
2022-10-15 03:22:21 - progress_bar.py[line:274] - INFO: epoch 001:   8092 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.4, ups=0.9, wpb=110, bsz=40, num_updates=8080, lr=4.84439e-05, gnorm=0.838, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39459
2022-10-15 03:22:33 - progress_bar.py[line:274] - INFO: epoch 001:   8102 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=8090, lr=4.84394e-05, gnorm=0.859, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39470
2022-10-15 03:22:44 - progress_bar.py[line:274] - INFO: epoch 001:   8112 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=103.2, ups=0.93, wpb=111.4, bsz=40, num_updates=8100, lr=4.84349e-05, gnorm=0.894, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39481
2022-10-15 03:22:54 - progress_bar.py[line:274] - INFO: epoch 001:   8122 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.2, ups=0.94, wpb=108.7, bsz=40, num_updates=8110, lr=4.84304e-05, gnorm=0.809, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39491
2022-10-15 03:23:05 - progress_bar.py[line:274] - INFO: epoch 001:   8132 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=8120, lr=4.84259e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39502
2022-10-15 03:23:17 - progress_bar.py[line:274] - INFO: epoch 001:   8142 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=8130, lr=4.84214e-05, gnorm=0.871, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39514
2022-10-15 03:23:28 - progress_bar.py[line:274] - INFO: epoch 001:   8152 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.5, ups=0.87, wpb=109.6, bsz=40, num_updates=8140, lr=4.84169e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39525
2022-10-15 03:23:39 - progress_bar.py[line:274] - INFO: epoch 001:   8162 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.2, ups=0.91, wpb=109.5, bsz=40, num_updates=8150, lr=4.84124e-05, gnorm=0.788, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39536
2022-10-15 03:23:50 - progress_bar.py[line:274] - INFO: epoch 001:   8172 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.9, ups=0.89, wpb=108.7, bsz=40, num_updates=8160, lr=4.84079e-05, gnorm=0.83, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39547
2022-10-15 03:24:01 - progress_bar.py[line:274] - INFO: epoch 001:   8182 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=8170, lr=4.84034e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=39558
2022-10-15 03:24:12 - progress_bar.py[line:274] - INFO: epoch 001:   8192 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101, ups=0.92, wpb=110.2, bsz=40, num_updates=8180, lr=4.83989e-05, gnorm=0.782, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39569
2022-10-15 03:24:23 - progress_bar.py[line:274] - INFO: epoch 001:   8202 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=8190, lr=4.83944e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39580
2022-10-15 03:24:35 - progress_bar.py[line:274] - INFO: epoch 001:   8212 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=8200, lr=4.83899e-05, gnorm=0.781, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39592
2022-10-15 03:24:46 - progress_bar.py[line:274] - INFO: epoch 001:   8222 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.4, ups=0.9, wpb=112.3, bsz=40, num_updates=8210, lr=4.83854e-05, gnorm=0.798, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39603
2022-10-15 03:24:57 - progress_bar.py[line:274] - INFO: epoch 001:   8232 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.5, ups=0.87, wpb=111.1, bsz=40, num_updates=8220, lr=4.83808e-05, gnorm=0.816, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39614
2022-10-15 03:25:08 - progress_bar.py[line:274] - INFO: epoch 001:   8242 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=8230, lr=4.83763e-05, gnorm=0.762, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39625
2022-10-15 03:25:20 - progress_bar.py[line:274] - INFO: epoch 001:   8252 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=8240, lr=4.83718e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39637
2022-10-15 03:25:31 - progress_bar.py[line:274] - INFO: epoch 001:   8262 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.9, ups=0.89, wpb=110.4, bsz=40, num_updates=8250, lr=4.83673e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39648
2022-10-15 03:25:42 - progress_bar.py[line:274] - INFO: epoch 001:   8272 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=8260, lr=4.83628e-05, gnorm=0.917, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39659
2022-10-15 03:25:53 - progress_bar.py[line:274] - INFO: epoch 001:   8282 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99, ups=0.9, wpb=109.5, bsz=40, num_updates=8270, lr=4.83583e-05, gnorm=0.885, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39670
2022-10-15 03:26:04 - progress_bar.py[line:274] - INFO: epoch 001:   8292 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.5, ups=0.89, wpb=109, bsz=40, num_updates=8280, lr=4.83538e-05, gnorm=0.815, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39681
2022-10-15 03:26:16 - progress_bar.py[line:274] - INFO: epoch 001:   8302 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=8290, lr=4.83493e-05, gnorm=0.753, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39693
2022-10-15 03:26:27 - progress_bar.py[line:274] - INFO: epoch 001:   8312 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.7, ups=0.91, wpb=111.3, bsz=40, num_updates=8300, lr=4.83448e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39704
2022-10-15 03:26:38 - progress_bar.py[line:274] - INFO: epoch 001:   8322 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.1, ups=0.89, wpb=109.1, bsz=40, num_updates=8310, lr=4.83403e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39715
2022-10-15 03:26:49 - progress_bar.py[line:274] - INFO: epoch 001:   8332 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.5, ups=0.87, wpb=111, bsz=40, num_updates=8320, lr=4.83358e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=39726
2022-10-15 03:27:01 - progress_bar.py[line:274] - INFO: epoch 001:   8342 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98, ups=0.89, wpb=110.5, bsz=40, num_updates=8330, lr=4.83313e-05, gnorm=0.648, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39738
2022-10-15 03:27:12 - progress_bar.py[line:274] - INFO: epoch 001:   8352 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=103.1, ups=0.93, wpb=111.2, bsz=40, num_updates=8340, lr=4.83268e-05, gnorm=0.819, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39749
2022-10-15 03:27:23 - progress_bar.py[line:274] - INFO: epoch 001:   8362 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.4, ups=0.88, wpb=111.7, bsz=40, num_updates=8350, lr=4.83223e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39760
2022-10-15 03:27:34 - progress_bar.py[line:274] - INFO: epoch 001:   8372 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.7, ups=0.91, wpb=109, bsz=40, num_updates=8360, lr=4.83178e-05, gnorm=0.81, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39771
2022-10-15 03:27:45 - progress_bar.py[line:274] - INFO: epoch 001:   8382 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.2, ups=0.88, wpb=109.9, bsz=40, num_updates=8370, lr=4.83133e-05, gnorm=0.875, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39782
2022-10-15 03:27:56 - progress_bar.py[line:274] - INFO: epoch 001:   8392 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=8380, lr=4.83088e-05, gnorm=0.84, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39794
2022-10-15 03:28:07 - progress_bar.py[line:274] - INFO: epoch 001:   8402 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.6, ups=0.91, wpb=107.8, bsz=40, num_updates=8390, lr=4.83043e-05, gnorm=0.866, clip=30, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=39804
2022-10-15 03:28:18 - progress_bar.py[line:274] - INFO: epoch 001:   8412 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.5, ups=0.92, wpb=109.8, bsz=40, num_updates=8400, lr=4.82998e-05, gnorm=0.774, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39815
2022-10-15 03:28:30 - progress_bar.py[line:274] - INFO: epoch 001:   8422 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.9, ups=0.87, wpb=110.5, bsz=40, num_updates=8410, lr=4.82953e-05, gnorm=0.705, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39827
2022-10-15 03:28:41 - progress_bar.py[line:274] - INFO: epoch 001:   8432 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.4, ups=0.91, wpb=109.9, bsz=40, num_updates=8420, lr=4.82908e-05, gnorm=0.891, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39838
2022-10-15 03:28:52 - progress_bar.py[line:274] - INFO: epoch 001:   8442 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99, ups=0.9, wpb=109.4, bsz=40, num_updates=8430, lr=4.82863e-05, gnorm=0.78, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39849
2022-10-15 03:29:03 - progress_bar.py[line:274] - INFO: epoch 001:   8452 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=102.6, ups=0.92, wpb=112, bsz=40, num_updates=8440, lr=4.82818e-05, gnorm=0.821, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39860
2022-10-15 03:29:14 - progress_bar.py[line:274] - INFO: epoch 001:   8462 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=108.1, nsentences=40, sample_size=108.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.6, ups=0.89, wpb=108.1, bsz=40, num_updates=8450, lr=4.82773e-05, gnorm=0.888, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39871
2022-10-15 03:29:25 - progress_bar.py[line:274] - INFO: epoch 001:   8472 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96, ups=0.87, wpb=110.4, bsz=40, num_updates=8460, lr=4.82728e-05, gnorm=0.821, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39882
2022-10-15 03:29:26 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 03:29:37 - progress_bar.py[line:274] - INFO: epoch 001:   8483 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=92.4, ups=0.83, wpb=111.6, bsz=40, num_updates=8470, lr=4.82683e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=39894
2022-10-15 03:29:49 - progress_bar.py[line:274] - INFO: epoch 001:   8493 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.2, ups=0.88, wpb=109.8, bsz=40, num_updates=8480, lr=4.82637e-05, gnorm=0.78, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39906
2022-10-15 03:30:00 - progress_bar.py[line:274] - INFO: epoch 001:   8503 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.6, ups=0.87, wpb=112.9, bsz=40, num_updates=8490, lr=4.82592e-05, gnorm=0.818, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39917
2022-10-15 03:30:12 - progress_bar.py[line:274] - INFO: epoch 001:   8513 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.3, ups=0.88, wpb=110.6, bsz=40, num_updates=8500, lr=4.82547e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39929
2022-10-15 03:30:22 - progress_bar.py[line:274] - INFO: epoch 001:   8523 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.7, ups=0.93, wpb=110.7, bsz=40, num_updates=8510, lr=4.82502e-05, gnorm=0.852, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39940
2022-10-15 03:30:33 - progress_bar.py[line:274] - INFO: epoch 001:   8533 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.8, ups=0.92, wpb=110.1, bsz=40, num_updates=8520, lr=4.82457e-05, gnorm=0.949, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39950
2022-10-15 03:30:45 - progress_bar.py[line:274] - INFO: epoch 001:   8543 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=8530, lr=4.82412e-05, gnorm=0.688, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39962
2022-10-15 03:30:56 - progress_bar.py[line:274] - INFO: epoch 001:   8553 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100, ups=0.89, wpb=111.8, bsz=40, num_updates=8540, lr=4.82367e-05, gnorm=0.757, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39973
2022-10-15 03:31:07 - progress_bar.py[line:274] - INFO: epoch 001:   8563 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.2, ups=0.89, wpb=111.2, bsz=40, num_updates=8550, lr=4.82322e-05, gnorm=0.766, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39984
2022-10-15 03:31:18 - progress_bar.py[line:274] - INFO: epoch 001:   8573 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.5, ups=0.88, wpb=109.3, bsz=40, num_updates=8560, lr=4.82277e-05, gnorm=0.844, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39995
2022-10-15 03:31:29 - progress_bar.py[line:274] - INFO: epoch 001:   8583 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=8570, lr=4.82232e-05, gnorm=0.804, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40006
2022-10-15 03:31:41 - progress_bar.py[line:274] - INFO: epoch 001:   8593 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.9, ups=0.9, wpb=110.8, bsz=40, num_updates=8580, lr=4.82187e-05, gnorm=0.764, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40018
2022-10-15 03:31:52 - progress_bar.py[line:274] - INFO: epoch 001:   8603 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=8590, lr=4.82142e-05, gnorm=0.798, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40029
2022-10-15 03:32:03 - progress_bar.py[line:274] - INFO: epoch 001:   8613 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.6, ups=0.91, wpb=109.6, bsz=40, num_updates=8600, lr=4.82097e-05, gnorm=0.751, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40040
2022-10-15 03:32:14 - progress_bar.py[line:274] - INFO: epoch 001:   8623 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=8610, lr=4.82052e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40051
2022-10-15 03:32:25 - progress_bar.py[line:274] - INFO: epoch 001:   8633 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.4, ups=0.91, wpb=111.1, bsz=40, num_updates=8620, lr=4.82007e-05, gnorm=0.802, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40062
2022-10-15 03:32:36 - progress_bar.py[line:274] - INFO: epoch 001:   8643 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.2, ups=0.89, wpb=109.8, bsz=40, num_updates=8630, lr=4.81962e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40074
2022-10-15 03:32:48 - progress_bar.py[line:274] - INFO: epoch 001:   8653 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.7, ups=0.89, wpb=111.7, bsz=40, num_updates=8640, lr=4.81917e-05, gnorm=0.742, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40085
2022-10-15 03:32:59 - progress_bar.py[line:274] - INFO: epoch 001:   8663 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.6, ups=0.91, wpb=110.1, bsz=40, num_updates=8650, lr=4.81872e-05, gnorm=0.776, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40096
2022-10-15 03:33:10 - progress_bar.py[line:274] - INFO: epoch 001:   8673 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=8660, lr=4.81827e-05, gnorm=0.74, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40107
2022-10-15 03:33:21 - progress_bar.py[line:274] - INFO: epoch 001:   8683 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=8670, lr=4.81782e-05, gnorm=0.771, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40118
2022-10-15 03:33:32 - progress_bar.py[line:274] - INFO: epoch 001:   8693 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.4, ups=0.92, wpb=110.8, bsz=40, num_updates=8680, lr=4.81737e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40129
2022-10-15 03:33:43 - progress_bar.py[line:274] - INFO: epoch 001:   8703 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.7, ups=0.9, wpb=110, bsz=40, num_updates=8690, lr=4.81692e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40140
2022-10-15 03:33:55 - progress_bar.py[line:274] - INFO: epoch 001:   8713 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=94.7, ups=0.87, wpb=108.5, bsz=40, num_updates=8700, lr=4.81647e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40152
2022-10-15 03:34:06 - progress_bar.py[line:274] - INFO: epoch 001:   8723 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.9, ups=0.89, wpb=110.7, bsz=40, num_updates=8710, lr=4.81602e-05, gnorm=0.727, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40163
2022-10-15 03:34:16 - progress_bar.py[line:274] - INFO: epoch 001:   8733 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=103, ups=0.94, wpb=109.6, bsz=40, num_updates=8720, lr=4.81557e-05, gnorm=0.744, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=40173
2022-10-15 03:34:28 - progress_bar.py[line:274] - INFO: epoch 001:   8743 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.8, ups=0.89, wpb=111.8, bsz=40, num_updates=8730, lr=4.81512e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40185
2022-10-15 03:34:39 - progress_bar.py[line:274] - INFO: epoch 001:   8753 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.1, ups=0.89, wpb=109.2, bsz=40, num_updates=8740, lr=4.81466e-05, gnorm=0.78, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40196
2022-10-15 03:34:50 - progress_bar.py[line:274] - INFO: epoch 001:   8763 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.1, ups=0.88, wpb=111.3, bsz=40, num_updates=8750, lr=4.81421e-05, gnorm=0.725, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40207
2022-10-15 03:35:02 - progress_bar.py[line:274] - INFO: epoch 001:   8773 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.9, ups=0.88, wpb=109.7, bsz=40, num_updates=8760, lr=4.81376e-05, gnorm=0.783, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40219
2022-10-15 03:35:13 - progress_bar.py[line:274] - INFO: epoch 001:   8783 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.2, ups=0.89, wpb=109.3, bsz=40, num_updates=8770, lr=4.81331e-05, gnorm=0.835, clip=20, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=40230
2022-10-15 03:35:24 - progress_bar.py[line:274] - INFO: epoch 001:   8793 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=8780, lr=4.81286e-05, gnorm=0.811, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=40241
2022-10-15 03:35:35 - progress_bar.py[line:274] - INFO: epoch 001:   8803 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.5, ups=0.89, wpb=109.2, bsz=40, num_updates=8790, lr=4.81241e-05, gnorm=0.774, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40252
2022-10-15 03:35:47 - progress_bar.py[line:274] - INFO: epoch 001:   8813 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=8800, lr=4.81196e-05, gnorm=0.79, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=40264
2022-10-15 03:35:57 - progress_bar.py[line:274] - INFO: epoch 001:   8823 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101, ups=0.92, wpb=110.3, bsz=40, num_updates=8810, lr=4.81151e-05, gnorm=0.799, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40274
2022-10-15 03:36:08 - progress_bar.py[line:274] - INFO: epoch 001:   8833 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.3, ups=0.91, wpb=110.7, bsz=40, num_updates=8820, lr=4.81106e-05, gnorm=0.79, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40285
2022-10-15 03:36:20 - progress_bar.py[line:274] - INFO: epoch 001:   8843 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=8830, lr=4.81061e-05, gnorm=0.781, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40297
2022-10-15 03:36:31 - progress_bar.py[line:274] - INFO: epoch 001:   8853 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.7, ups=0.88, wpb=109.5, bsz=40, num_updates=8840, lr=4.81016e-05, gnorm=0.827, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40308
2022-10-15 03:36:42 - progress_bar.py[line:274] - INFO: epoch 001:   8863 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=8850, lr=4.80971e-05, gnorm=0.757, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40319
2022-10-15 03:36:53 - progress_bar.py[line:274] - INFO: epoch 001:   8873 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=8860, lr=4.80926e-05, gnorm=0.689, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40330
2022-10-15 03:37:05 - progress_bar.py[line:274] - INFO: epoch 001:   8883 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.3, ups=0.88, wpb=109, bsz=40, num_updates=8870, lr=4.80881e-05, gnorm=0.893, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40342
2022-10-15 03:37:16 - progress_bar.py[line:274] - INFO: epoch 001:   8893 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.7, ups=0.9, wpb=111.3, bsz=40, num_updates=8880, lr=4.80836e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40353
2022-10-15 03:37:27 - progress_bar.py[line:274] - INFO: epoch 001:   8903 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.9, ups=0.9, wpb=112.1, bsz=40, num_updates=8890, lr=4.80791e-05, gnorm=0.836, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40364
2022-10-15 03:37:38 - progress_bar.py[line:274] - INFO: epoch 001:   8913 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.2, ups=0.88, wpb=109.4, bsz=40, num_updates=8900, lr=4.80746e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40375
2022-10-15 03:37:49 - progress_bar.py[line:274] - INFO: epoch 001:   8923 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.4, ups=0.91, wpb=109.8, bsz=40, num_updates=8910, lr=4.80701e-05, gnorm=0.78, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40386
2022-10-15 03:38:00 - progress_bar.py[line:274] - INFO: epoch 001:   8933 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.6, ups=0.9, wpb=111.5, bsz=40, num_updates=8920, lr=4.80656e-05, gnorm=0.808, clip=10, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=40397
2022-10-15 03:38:11 - progress_bar.py[line:274] - INFO: epoch 001:   8943 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.8, ups=0.92, wpb=111, bsz=40, num_updates=8930, lr=4.80611e-05, gnorm=0.756, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40408
2022-10-15 03:38:22 - progress_bar.py[line:274] - INFO: epoch 001:   8953 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=8940, lr=4.80566e-05, gnorm=0.868, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40419
2022-10-15 03:38:33 - progress_bar.py[line:274] - INFO: epoch 001:   8963 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.2, ups=0.9, wpb=110.9, bsz=40, num_updates=8950, lr=4.80521e-05, gnorm=0.802, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40430
2022-10-15 03:38:45 - progress_bar.py[line:274] - INFO: epoch 001:   8973 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.8, ups=0.9, wpb=110.3, bsz=40, num_updates=8960, lr=4.80476e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40442
2022-10-15 03:38:55 - progress_bar.py[line:274] - INFO: epoch 001:   8983 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.9, ups=0.93, wpb=110.5, bsz=40, num_updates=8970, lr=4.80431e-05, gnorm=0.767, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40452
2022-10-15 03:39:06 - progress_bar.py[line:274] - INFO: epoch 001:   8993 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.6, ups=0.91, wpb=109.2, bsz=40, num_updates=8980, lr=4.80386e-05, gnorm=0.805, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40463
2022-10-15 03:39:17 - progress_bar.py[line:274] - INFO: epoch 001:   9003 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.2, ups=0.92, wpb=109.5, bsz=40, num_updates=8990, lr=4.8034e-05, gnorm=0.891, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40474
2022-10-15 03:39:29 - progress_bar.py[line:274] - INFO: epoch 001:   9013 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.1, ups=0.89, wpb=110.7, bsz=40, num_updates=9000, lr=4.80295e-05, gnorm=0.807, clip=20, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=40486
2022-10-15 03:39:29 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-15 03:39:30 - train.py[line:549] - INFO: 0 / 4988
2022-10-15 03:39:30 - train.py[line:551] - INFO: load:1.03 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-15 03:39:31 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.84 GiB already allocated; 202.19 MiB free; 36.91 GiB reserved in total by PyTorch)
2022-10-15 03:39:31 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-15 03:39:31 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 6            |        cudaMalloc retries: 26        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9048 MB |   10273 MB |    5849 TB |    5849 TB |
|       from large pool |    8903 MB |   10127 MB |    5847 TB |    5847 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9048 MB |   10273 MB |    5849 TB |    5849 TB |
|       from large pool |    8903 MB |   10127 MB |    5847 TB |    5847 TB |
|       from small pool |     144 MB |     145 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   37792 MB |   37798 MB |  255162 MB |  217370 MB |
|       from large pool |   37646 MB |   37646 MB |  254760 MB |  217114 MB |
|       from small pool |     146 MB |     152 MB |     402 MB |     256 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   28743 MB |   28743 MB |    7783 TB |    7783 TB |
|       from large pool |   28742 MB |   28742 MB |    7782 TB |    7782 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  270743 K  |  270740 K  |
|       from large pool |     563    |     575    |   87237 K  |   87236 K  |
|       from small pool |    3095    |    3114    |  183506 K  |  183503 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  270743 K  |  270740 K  |
|       from large pool |     563    |     575    |   87237 K  |   87236 K  |
|       from small pool |    3095    |    3114    |  183506 K  |  183503 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     132    |     135    |     583    |     451    |
|       from large pool |      59    |      59    |     382    |     323    |
|       from small pool |      73    |      76    |     201    |     128    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      87    |      89    |  200645 K  |  200645 K  |
|       from large pool |      44    |      46    |   40890 K  |   40890 K  |
|       from small pool |      43    |      50    |  159754 K  |  159754 K  |
|===========================================================================|

2022-10-15 03:39:31 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-15 03:42:03 - train.py[line:549] - INFO: 200 / 4988
2022-10-15 03:42:03 - train.py[line:551] - INFO: load:1.06 valid_run:153.07 task_valid:148.69 collect_output:3.27
2022-10-15 03:44:32 - train.py[line:549] - INFO: 400 / 4988
2022-10-15 03:44:32 - train.py[line:551] - INFO: load:1.08 valid_run:302.19 task_valid:292.49 collect_output:7.49
2022-10-15 03:47:05 - train.py[line:549] - INFO: 600 / 4988
2022-10-15 03:47:05 - train.py[line:551] - INFO: load:1.11 valid_run:455.12 task_valid:436.85 collect_output:15.01
2022-10-15 03:49:35 - train.py[line:549] - INFO: 800 / 4988
2022-10-15 03:49:35 - train.py[line:551] - INFO: load:1.13 valid_run:604.88 task_valid:582.67 collect_output:17.91
2022-10-15 03:52:08 - train.py[line:549] - INFO: 1000 / 4988
2022-10-15 03:52:08 - train.py[line:551] - INFO: load:1.16 valid_run:757.55 task_valid:730.47 collect_output:21.80
2022-10-15 03:54:40 - train.py[line:549] - INFO: 1200 / 4988
2022-10-15 03:54:40 - train.py[line:551] - INFO: load:1.18 valid_run:909.75 task_valid:876.40 collect_output:27.08
2022-10-15 03:57:14 - train.py[line:549] - INFO: 1400 / 4988
2022-10-15 03:57:14 - train.py[line:551] - INFO: load:1.21 valid_run:1063.50 task_valid:1022.84 collect_output:33.40
2022-10-15 03:59:45 - train.py[line:549] - INFO: 1600 / 4988
2022-10-15 03:59:45 - train.py[line:551] - INFO: load:1.23 valid_run:1215.07 task_valid:1164.20 collect_output:42.65
2022-10-15 04:02:16 - train.py[line:549] - INFO: 1800 / 4988
2022-10-15 04:02:16 - train.py[line:551] - INFO: load:1.26 valid_run:1365.22 task_valid:1309.40 collect_output:46.59
2022-10-15 04:04:45 - train.py[line:549] - INFO: 2000 / 4988
2022-10-15 04:04:45 - train.py[line:551] - INFO: load:1.28 valid_run:1514.17 task_valid:1453.00 collect_output:50.97
2022-10-15 04:07:15 - train.py[line:549] - INFO: 2200 / 4988
2022-10-15 04:07:15 - train.py[line:551] - INFO: load:1.31 valid_run:1664.09 task_valid:1598.16 collect_output:54.76
2022-10-15 04:09:45 - train.py[line:549] - INFO: 2400 / 4988
2022-10-15 04:09:45 - train.py[line:551] - INFO: load:1.33 valid_run:1814.36 task_valid:1743.42 collect_output:58.81
2022-10-15 04:12:15 - train.py[line:549] - INFO: 2600 / 4988
2022-10-15 04:12:15 - train.py[line:551] - INFO: load:1.36 valid_run:1964.62 task_valid:1885.85 collect_output:65.62
2022-10-15 04:14:46 - train.py[line:549] - INFO: 2800 / 4988
2022-10-15 04:14:46 - train.py[line:551] - INFO: load:1.39 valid_run:2115.33 task_valid:2031.58 collect_output:69.63
2022-10-15 04:17:16 - train.py[line:549] - INFO: 3000 / 4988
2022-10-15 04:17:16 - train.py[line:551] - INFO: load:1.41 valid_run:2265.70 task_valid:2178.37 collect_output:72.23
2022-10-15 04:19:47 - train.py[line:549] - INFO: 3200 / 4988
2022-10-15 04:19:47 - train.py[line:551] - INFO: load:1.44 valid_run:2416.19 task_valid:2322.88 collect_output:77.23
2022-10-15 04:22:19 - train.py[line:549] - INFO: 3400 / 4988
2022-10-15 04:22:19 - train.py[line:551] - INFO: load:1.46 valid_run:2568.01 task_valid:2468.72 collect_output:82.25
2022-10-15 04:24:50 - train.py[line:549] - INFO: 3600 / 4988
2022-10-15 04:24:50 - train.py[line:551] - INFO: load:1.49 valid_run:2718.83 task_valid:2616.04 collect_output:84.79
2022-10-15 04:27:19 - train.py[line:549] - INFO: 3800 / 4988
2022-10-15 04:27:19 - train.py[line:551] - INFO: load:1.51 valid_run:2867.60 task_valid:2757.95 collect_output:90.68
2022-10-15 04:29:49 - train.py[line:549] - INFO: 4000 / 4988
2022-10-15 04:29:49 - train.py[line:551] - INFO: load:1.54 valid_run:3018.19 task_valid:2903.52 collect_output:94.74
2022-10-15 04:32:21 - train.py[line:549] - INFO: 4200 / 4988
2022-10-15 04:32:21 - train.py[line:551] - INFO: load:1.56 valid_run:3170.39 task_valid:3048.55 collect_output:100.93
2022-10-15 04:34:51 - train.py[line:549] - INFO: 4400 / 4988
2022-10-15 04:34:51 - train.py[line:551] - INFO: load:1.59 valid_run:3320.23 task_valid:3193.56 collect_output:104.78
2022-10-15 04:37:23 - train.py[line:549] - INFO: 4600 / 4988
2022-10-15 04:37:23 - train.py[line:551] - INFO: load:1.61 valid_run:3472.18 task_valid:3340.70 collect_output:108.51
2022-10-15 04:39:56 - train.py[line:549] - INFO: 4800 / 4988
2022-10-15 04:39:56 - train.py[line:551] - INFO: load:1.64 valid_run:3624.55 task_valid:3488.47 collect_output:112.06

====================================================================================================
SGG eval:     R @ 50: 0.6347;     R @ 100: 0.6704;     R @ 500: 0.6835;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4209;    mR @ 100: 0.4460;    mR @ 500: 0.4667;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:1.0000) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.2500) (hanging from:0.5323) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9510) (says:0.0000) (sitting on:0.7358) (standing on:0.3610) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.5069) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6347;     R @ 100: 0.6704;     R @ 500: 0.6835;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4209;    mR @ 100: 0.4460;    mR @ 500: 0.4667;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8415) (covered in:1.0000) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.2500) (hanging from:0.5323) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9510) (says:0.0000) (sitting on:0.7358) (standing on:0.3610) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.5069) 
--------------------------------------------------------
====================================================================================================

2022-10-15 04:42:28 - train.py[line:487] - INFO: 0.670381512605042
2022-10-15 04:42:28 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-15 04:42:28 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.348 | loss_v1 0 | loss_v2 0 | nll_loss 0.187 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.670382 | ppl 1.14 | vqa_score 0.598 | wps 118.7 | wpb 89.9 | bsz 30 | num_updates 9000 | best_R@100 0.709638
2022-10-15 04:42:28 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 9000 updates
2022-10-15 04:42:28 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_9000.pt
2022-10-15 04:42:34 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_9000.pt
2022-10-15 04:42:37 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_9000.pt (epoch 1 @ 9000 updates, score 0.670381512605042) (writing took 8.643792781047523 seconds)
2022-10-15 04:42:48 - progress_bar.py[line:274] - INFO: epoch 001:   9023 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=0.3, ups=0, wpb=110.2, bsz=40, num_updates=9010, lr=4.8025e-05, gnorm=0.783, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44285
2022-10-15 04:42:59 - progress_bar.py[line:274] - INFO: epoch 001:   9033 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=9020, lr=4.80205e-05, gnorm=0.937, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44296
2022-10-15 04:43:10 - progress_bar.py[line:274] - INFO: epoch 001:   9043 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.2, ups=0.9, wpb=111.1, bsz=40, num_updates=9030, lr=4.8016e-05, gnorm=0.922, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44307
2022-10-15 04:43:22 - progress_bar.py[line:274] - INFO: epoch 001:   9053 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.8, ups=0.87, wpb=110.1, bsz=40, num_updates=9040, lr=4.80115e-05, gnorm=0.75, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44319
2022-10-15 04:43:33 - progress_bar.py[line:274] - INFO: epoch 001:   9063 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=9050, lr=4.8007e-05, gnorm=0.789, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44330
2022-10-15 04:43:44 - progress_bar.py[line:274] - INFO: epoch 001:   9073 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.1, ups=0.88, wpb=109, bsz=40, num_updates=9060, lr=4.80025e-05, gnorm=0.718, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44341
2022-10-15 04:43:49 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 04:43:56 - progress_bar.py[line:274] - INFO: epoch 001:   9084 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=90.2, ups=0.83, wpb=109.1, bsz=40, num_updates=9070, lr=4.7998e-05, gnorm=0.795, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=44354
2022-10-15 04:44:08 - progress_bar.py[line:274] - INFO: epoch 001:   9094 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.9, ups=0.9, wpb=110.6, bsz=40, num_updates=9080, lr=4.79935e-05, gnorm=0.832, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44365
2022-10-15 04:44:19 - progress_bar.py[line:274] - INFO: epoch 001:   9104 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96, ups=0.88, wpb=108.9, bsz=40, num_updates=9090, lr=4.7989e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44376
2022-10-15 04:44:30 - progress_bar.py[line:274] - INFO: epoch 001:   9114 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.1, ups=0.87, wpb=109.1, bsz=40, num_updates=9100, lr=4.79845e-05, gnorm=0.805, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44387
2022-10-15 04:44:42 - progress_bar.py[line:274] - INFO: epoch 001:   9124 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=95.4, ups=0.87, wpb=109.7, bsz=40, num_updates=9110, lr=4.798e-05, gnorm=0.78, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44399
2022-10-15 04:44:53 - progress_bar.py[line:274] - INFO: epoch 001:   9134 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=104.8, ups=0.94, wpb=111.5, bsz=40, num_updates=9120, lr=4.79755e-05, gnorm=0.738, clip=0, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=44410
2022-10-15 04:45:04 - progress_bar.py[line:274] - INFO: epoch 001:   9144 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.1, ups=0.89, wpb=112.4, bsz=40, num_updates=9130, lr=4.7971e-05, gnorm=0.775, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=44421
2022-10-15 04:45:15 - progress_bar.py[line:274] - INFO: epoch 001:   9154 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101, ups=0.92, wpb=110, bsz=40, num_updates=9140, lr=4.79665e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44432
2022-10-15 04:45:26 - progress_bar.py[line:274] - INFO: epoch 001:   9164 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.5, ups=0.91, wpb=110.9, bsz=40, num_updates=9150, lr=4.7962e-05, gnorm=0.809, clip=0, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=44443
2022-10-15 04:45:37 - progress_bar.py[line:274] - INFO: epoch 001:   9174 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=9160, lr=4.79575e-05, gnorm=0.779, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44454
2022-10-15 04:45:48 - progress_bar.py[line:274] - INFO: epoch 001:   9184 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.1, ups=0.87, wpb=109.5, bsz=40, num_updates=9170, lr=4.7953e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44465
2022-10-15 04:46:00 - progress_bar.py[line:274] - INFO: epoch 001:   9194 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.3, ups=0.91, wpb=110.8, bsz=40, num_updates=9180, lr=4.79485e-05, gnorm=0.824, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44477
2022-10-15 04:46:11 - progress_bar.py[line:274] - INFO: epoch 001:   9204 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=9190, lr=4.7944e-05, gnorm=0.806, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44488
2022-10-15 04:46:22 - progress_bar.py[line:274] - INFO: epoch 001:   9214 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.6, ups=0.89, wpb=109.9, bsz=40, num_updates=9200, lr=4.79395e-05, gnorm=0.748, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44499
2022-10-15 04:46:33 - progress_bar.py[line:274] - INFO: epoch 001:   9224 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=9210, lr=4.7935e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44510
2022-10-15 04:46:44 - progress_bar.py[line:274] - INFO: epoch 001:   9234 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.9, ups=0.93, wpb=109.9, bsz=40, num_updates=9220, lr=4.79305e-05, gnorm=0.763, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44521
2022-10-15 04:46:55 - progress_bar.py[line:274] - INFO: epoch 001:   9244 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.2, ups=0.92, wpb=111.5, bsz=40, num_updates=9230, lr=4.7926e-05, gnorm=0.759, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44532
2022-10-15 04:47:07 - progress_bar.py[line:274] - INFO: epoch 001:   9254 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.4, ups=0.87, wpb=110.9, bsz=40, num_updates=9240, lr=4.79215e-05, gnorm=0.858, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44544
2022-10-15 04:47:18 - progress_bar.py[line:274] - INFO: epoch 001:   9264 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=9250, lr=4.79169e-05, gnorm=0.747, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44555
2022-10-15 04:47:29 - progress_bar.py[line:274] - INFO: epoch 001:   9274 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.3, ups=0.91, wpb=109.7, bsz=40, num_updates=9260, lr=4.79124e-05, gnorm=0.824, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44566
2022-10-15 04:47:40 - progress_bar.py[line:274] - INFO: epoch 001:   9284 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99, ups=0.9, wpb=109.7, bsz=40, num_updates=9270, lr=4.79079e-05, gnorm=0.725, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=44577
2022-10-15 04:47:51 - progress_bar.py[line:274] - INFO: epoch 001:   9294 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=104, ups=0.94, wpb=110.1, bsz=40, num_updates=9280, lr=4.79034e-05, gnorm=0.858, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44588
2022-10-15 04:48:02 - progress_bar.py[line:274] - INFO: epoch 001:   9304 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.7, ups=0.87, wpb=109.6, bsz=40, num_updates=9290, lr=4.78989e-05, gnorm=0.767, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44599
2022-10-15 04:48:13 - progress_bar.py[line:274] - INFO: epoch 001:   9314 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=9300, lr=4.78944e-05, gnorm=0.736, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44610
2022-10-15 04:48:25 - progress_bar.py[line:274] - INFO: epoch 001:   9324 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=9310, lr=4.78899e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44622
2022-10-15 04:48:36 - progress_bar.py[line:274] - INFO: epoch 001:   9334 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.4, ups=0.88, wpb=111.7, bsz=40, num_updates=9320, lr=4.78854e-05, gnorm=0.779, clip=10, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=44633
2022-10-15 04:48:47 - progress_bar.py[line:274] - INFO: epoch 001:   9344 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=9330, lr=4.78809e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44644
2022-10-15 04:48:59 - progress_bar.py[line:274] - INFO: epoch 001:   9354 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=9340, lr=4.78764e-05, gnorm=0.833, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44656
2022-10-15 04:49:10 - progress_bar.py[line:274] - INFO: epoch 001:   9364 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=9350, lr=4.78719e-05, gnorm=0.839, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44667
2022-10-15 04:49:21 - progress_bar.py[line:274] - INFO: epoch 001:   9374 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=9360, lr=4.78674e-05, gnorm=0.781, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44678
2022-10-15 04:49:32 - progress_bar.py[line:274] - INFO: epoch 001:   9384 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.9, ups=0.89, wpb=110.5, bsz=40, num_updates=9370, lr=4.78629e-05, gnorm=0.695, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44689
2022-10-15 04:49:43 - progress_bar.py[line:274] - INFO: epoch 001:   9394 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=9380, lr=4.78584e-05, gnorm=0.793, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44700
2022-10-15 04:49:55 - progress_bar.py[line:274] - INFO: epoch 001:   9404 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=9390, lr=4.78539e-05, gnorm=0.879, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44712
2022-10-15 04:50:06 - progress_bar.py[line:274] - INFO: epoch 001:   9414 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=9400, lr=4.78494e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44723
2022-10-15 04:50:17 - progress_bar.py[line:274] - INFO: epoch 001:   9424 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=102.2, ups=0.93, wpb=110.3, bsz=40, num_updates=9410, lr=4.78449e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44734
2022-10-15 04:50:28 - progress_bar.py[line:274] - INFO: epoch 001:   9434 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.7, ups=0.88, wpb=109.4, bsz=40, num_updates=9420, lr=4.78404e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44745
2022-10-15 04:50:39 - progress_bar.py[line:274] - INFO: epoch 001:   9444 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.2, ups=0.9, wpb=112, bsz=40, num_updates=9430, lr=4.78359e-05, gnorm=0.789, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44756
2022-10-15 04:50:50 - progress_bar.py[line:274] - INFO: epoch 001:   9454 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.6, ups=0.89, wpb=109.5, bsz=40, num_updates=9440, lr=4.78314e-05, gnorm=0.822, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=44767
2022-10-15 04:51:02 - progress_bar.py[line:274] - INFO: epoch 001:   9464 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=9450, lr=4.78269e-05, gnorm=0.812, clip=0, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=44779
2022-10-15 04:51:13 - progress_bar.py[line:274] - INFO: epoch 001:   9474 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99, ups=0.89, wpb=111.2, bsz=40, num_updates=9460, lr=4.78224e-05, gnorm=0.787, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44790
2022-10-15 04:51:24 - progress_bar.py[line:274] - INFO: epoch 001:   9484 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.4, ups=0.91, wpb=110, bsz=40, num_updates=9470, lr=4.78179e-05, gnorm=0.838, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44801
2022-10-15 04:51:35 - progress_bar.py[line:274] - INFO: epoch 001:   9494 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.5, ups=0.88, wpb=109.7, bsz=40, num_updates=9480, lr=4.78134e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=44812
2022-10-15 04:51:47 - progress_bar.py[line:274] - INFO: epoch 001:   9504 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.5, ups=0.87, wpb=111, bsz=40, num_updates=9490, lr=4.78089e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44824
2022-10-15 04:51:58 - progress_bar.py[line:274] - INFO: epoch 001:   9514 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=101.8, ups=0.92, wpb=111.2, bsz=40, num_updates=9500, lr=4.78044e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44835
2022-10-15 04:52:09 - progress_bar.py[line:274] - INFO: epoch 001:   9524 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.7, ups=0.91, wpb=109, bsz=40, num_updates=9510, lr=4.77998e-05, gnorm=0.875, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44846
2022-10-15 04:52:20 - progress_bar.py[line:274] - INFO: epoch 001:   9534 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.4, ups=0.86, wpb=110.6, bsz=40, num_updates=9520, lr=4.77953e-05, gnorm=0.8, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=44857
2022-10-15 04:52:31 - progress_bar.py[line:274] - INFO: epoch 001:   9544 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=9530, lr=4.77908e-05, gnorm=0.775, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44868
2022-10-15 04:52:43 - progress_bar.py[line:274] - INFO: epoch 001:   9554 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=9540, lr=4.77863e-05, gnorm=0.904, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44880
2022-10-15 04:52:53 - progress_bar.py[line:274] - INFO: epoch 001:   9564 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=104.9, ups=0.95, wpb=110.4, bsz=40, num_updates=9550, lr=4.77818e-05, gnorm=0.829, clip=10, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=44890
2022-10-15 04:53:04 - progress_bar.py[line:274] - INFO: epoch 001:   9574 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=9560, lr=4.77773e-05, gnorm=0.773, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44901
2022-10-15 04:53:16 - progress_bar.py[line:274] - INFO: epoch 001:   9584 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=9570, lr=4.77728e-05, gnorm=0.837, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44913
2022-10-15 04:53:27 - progress_bar.py[line:274] - INFO: epoch 001:   9594 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=94.7, ups=0.87, wpb=109.2, bsz=40, num_updates=9580, lr=4.77683e-05, gnorm=0.797, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44924
2022-10-15 04:53:39 - progress_bar.py[line:274] - INFO: epoch 001:   9604 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.8, ups=0.88, wpb=110.5, bsz=40, num_updates=9590, lr=4.77638e-05, gnorm=0.842, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44936
2022-10-15 04:53:50 - progress_bar.py[line:274] - INFO: epoch 001:   9614 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99, ups=0.9, wpb=109.6, bsz=40, num_updates=9600, lr=4.77593e-05, gnorm=0.889, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44947
2022-10-15 04:54:01 - progress_bar.py[line:274] - INFO: epoch 001:   9624 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.9, ups=0.89, wpb=111.2, bsz=40, num_updates=9610, lr=4.77548e-05, gnorm=0.848, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=44958
2022-10-15 04:54:11 - progress_bar.py[line:274] - INFO: epoch 001:   9634 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=104.9, ups=0.95, wpb=110, bsz=40, num_updates=9620, lr=4.77503e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=44968
2022-10-15 04:54:23 - progress_bar.py[line:274] - INFO: epoch 001:   9644 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=9630, lr=4.77458e-05, gnorm=0.808, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=44980
2022-10-15 04:54:34 - progress_bar.py[line:274] - INFO: epoch 001:   9654 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=9640, lr=4.77413e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=44991
2022-10-15 04:54:45 - progress_bar.py[line:274] - INFO: epoch 001:   9664 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.6, ups=0.89, wpb=108.6, bsz=40, num_updates=9650, lr=4.77368e-05, gnorm=0.807, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=45002
2022-10-15 04:54:56 - progress_bar.py[line:274] - INFO: epoch 001:   9674 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.5, ups=0.89, wpb=110.7, bsz=40, num_updates=9660, lr=4.77323e-05, gnorm=0.75, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45013
2022-10-15 04:55:08 - progress_bar.py[line:274] - INFO: epoch 001:   9684 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.9, ups=0.87, wpb=110.6, bsz=40, num_updates=9670, lr=4.77278e-05, gnorm=0.738, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45025
2022-10-15 04:55:19 - progress_bar.py[line:274] - INFO: epoch 001:   9694 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.2, ups=0.92, wpb=108.2, bsz=40, num_updates=9680, lr=4.77233e-05, gnorm=0.844, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45036
2022-10-15 04:55:30 - progress_bar.py[line:274] - INFO: epoch 001:   9704 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101.1, ups=0.92, wpb=110.4, bsz=40, num_updates=9690, lr=4.77188e-05, gnorm=0.799, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45047
2022-10-15 04:55:41 - progress_bar.py[line:274] - INFO: epoch 001:   9714 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.204, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.7, ups=0.91, wpb=110.4, bsz=40, num_updates=9700, lr=4.77143e-05, gnorm=0.751, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45058
2022-10-15 04:55:52 - progress_bar.py[line:274] - INFO: epoch 001:   9724 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.2, ups=0.89, wpb=111.2, bsz=40, num_updates=9710, lr=4.77098e-05, gnorm=0.893, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45069
2022-10-15 04:56:03 - progress_bar.py[line:274] - INFO: epoch 001:   9734 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.6, ups=0.92, wpb=108.7, bsz=40, num_updates=9720, lr=4.77053e-05, gnorm=0.862, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45080
2022-10-15 04:56:14 - progress_bar.py[line:274] - INFO: epoch 001:   9744 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.3, ups=0.88, wpb=108.4, bsz=40, num_updates=9730, lr=4.77008e-05, gnorm=0.914, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=45091
2022-10-15 04:56:25 - progress_bar.py[line:274] - INFO: epoch 001:   9754 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=9740, lr=4.76963e-05, gnorm=0.824, clip=10, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=45102
2022-10-15 04:56:37 - progress_bar.py[line:274] - INFO: epoch 001:   9764 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.4, ups=0.88, wpb=109.6, bsz=40, num_updates=9750, lr=4.76918e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45114
2022-10-15 04:56:48 - progress_bar.py[line:274] - INFO: epoch 001:   9774 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=9760, lr=4.76872e-05, gnorm=0.658, clip=10, loss_scale=1024, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=45125
2022-10-15 04:56:59 - progress_bar.py[line:274] - INFO: epoch 001:   9784 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.7, ups=0.88, wpb=109.5, bsz=40, num_updates=9770, lr=4.76827e-05, gnorm=0.739, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45136
2022-10-15 04:57:11 - progress_bar.py[line:274] - INFO: epoch 001:   9794 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=9780, lr=4.76782e-05, gnorm=0.823, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45148
2022-10-15 04:57:22 - progress_bar.py[line:274] - INFO: epoch 001:   9804 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=101.5, ups=0.91, wpb=111.9, bsz=40, num_updates=9790, lr=4.76737e-05, gnorm=0.753, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45159
2022-10-15 04:57:33 - progress_bar.py[line:274] - INFO: epoch 001:   9814 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=9800, lr=4.76692e-05, gnorm=0.78, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45170
2022-10-15 04:57:44 - progress_bar.py[line:274] - INFO: epoch 001:   9824 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.9, ups=0.89, wpb=111, bsz=40, num_updates=9810, lr=4.76647e-05, gnorm=0.708, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45181
2022-10-15 04:57:55 - progress_bar.py[line:274] - INFO: epoch 001:   9834 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=9820, lr=4.76602e-05, gnorm=0.799, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45192
2022-10-15 04:58:06 - progress_bar.py[line:274] - INFO: epoch 001:   9844 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.5, ups=0.92, wpb=109.7, bsz=40, num_updates=9830, lr=4.76557e-05, gnorm=0.761, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45203
2022-10-15 04:58:17 - progress_bar.py[line:274] - INFO: epoch 001:   9854 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.2, ups=0.89, wpb=108.7, bsz=40, num_updates=9840, lr=4.76512e-05, gnorm=0.871, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=45214
2022-10-15 04:58:28 - progress_bar.py[line:274] - INFO: epoch 001:   9864 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.3, ups=0.92, wpb=111.8, bsz=40, num_updates=9850, lr=4.76467e-05, gnorm=0.816, clip=10, loss_scale=1024, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=45225
2022-10-15 04:58:39 - progress_bar.py[line:274] - INFO: epoch 001:   9874 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.5, ups=0.9, wpb=111.5, bsz=40, num_updates=9860, lr=4.76422e-05, gnorm=0.836, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45236
2022-10-15 04:58:50 - progress_bar.py[line:274] - INFO: epoch 001:   9884 / 28910 loss=0.418, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.8, ups=0.89, wpb=108.7, bsz=40, num_updates=9870, lr=4.76377e-05, gnorm=0.909, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45247
2022-10-15 04:59:02 - progress_bar.py[line:274] - INFO: epoch 001:   9894 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.5, ups=0.91, wpb=111.9, bsz=40, num_updates=9880, lr=4.76332e-05, gnorm=0.801, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45259
2022-10-15 04:59:13 - progress_bar.py[line:274] - INFO: epoch 001:   9904 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.6, ups=0.89, wpb=110.6, bsz=40, num_updates=9890, lr=4.76287e-05, gnorm=0.858, clip=30, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=45270
2022-10-15 04:59:24 - progress_bar.py[line:274] - INFO: epoch 001:   9914 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=9900, lr=4.76242e-05, gnorm=0.918, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=45281
2022-10-15 04:59:35 - progress_bar.py[line:274] - INFO: epoch 001:   9924 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.6, ups=0.91, wpb=109, bsz=40, num_updates=9910, lr=4.76197e-05, gnorm=0.832, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45292
2022-10-15 04:59:46 - progress_bar.py[line:274] - INFO: epoch 001:   9934 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=9920, lr=4.76152e-05, gnorm=0.812, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45303
2022-10-15 04:59:57 - progress_bar.py[line:274] - INFO: epoch 001:   9944 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.3, ups=0.9, wpb=111.2, bsz=40, num_updates=9930, lr=4.76107e-05, gnorm=0.822, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=45314
2022-10-15 05:00:09 - progress_bar.py[line:274] - INFO: epoch 001:   9954 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.2, ups=0.87, wpb=109.5, bsz=40, num_updates=9940, lr=4.76062e-05, gnorm=0.92, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45326
2022-10-15 05:00:20 - progress_bar.py[line:274] - INFO: epoch 001:   9964 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.6, ups=0.87, wpb=110.5, bsz=40, num_updates=9950, lr=4.76017e-05, gnorm=0.775, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=45337
2022-10-15 05:00:31 - progress_bar.py[line:274] - INFO: epoch 001:   9974 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=9960, lr=4.75972e-05, gnorm=0.79, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45348
2022-10-15 05:00:42 - progress_bar.py[line:274] - INFO: epoch 001:   9984 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=101.2, ups=0.92, wpb=110.1, bsz=40, num_updates=9970, lr=4.75927e-05, gnorm=0.704, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45359
2022-10-15 05:00:54 - progress_bar.py[line:274] - INFO: epoch 001:   9994 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=9980, lr=4.75882e-05, gnorm=0.921, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=45371
2022-10-15 05:01:05 - progress_bar.py[line:274] - INFO: epoch 001:  10004 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97, ups=0.88, wpb=109.7, bsz=40, num_updates=9990, lr=4.75837e-05, gnorm=0.754, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=45382
2022-10-15 05:01:16 - progress_bar.py[line:274] - INFO: epoch 001:  10014 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=10000, lr=4.75792e-05, gnorm=0.926, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=45393
2022-10-15 05:01:16 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-15 05:01:17 - train.py[line:549] - INFO: 0 / 4988
2022-10-15 05:01:17 - train.py[line:551] - INFO: load:1.09 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-15 05:03:50 - train.py[line:549] - INFO: 200 / 4988
2022-10-15 05:03:50 - train.py[line:551] - INFO: load:1.12 valid_run:152.42 task_valid:148.80 collect_output:2.43
2022-10-15 05:06:19 - train.py[line:549] - INFO: 400 / 4988
2022-10-15 05:06:19 - train.py[line:551] - INFO: load:1.15 valid_run:301.47 task_valid:292.60 collect_output:6.63
2022-10-15 05:08:52 - train.py[line:549] - INFO: 600 / 4988
2022-10-15 05:08:52 - train.py[line:551] - INFO: load:1.17 valid_run:454.29 task_valid:435.89 collect_output:15.17
2022-10-15 05:11:21 - train.py[line:549] - INFO: 800 / 4988
2022-10-15 05:11:21 - train.py[line:551] - INFO: load:1.20 valid_run:603.62 task_valid:581.08 collect_output:18.34
2022-10-15 05:13:54 - train.py[line:549] - INFO: 1000 / 4988
2022-10-15 05:13:54 - train.py[line:551] - INFO: load:1.23 valid_run:756.30 task_valid:728.81 collect_output:22.31
2022-10-15 05:16:26 - train.py[line:549] - INFO: 1200 / 4988
2022-10-15 05:16:26 - train.py[line:551] - INFO: load:1.25 valid_run:908.30 task_valid:874.57 collect_output:27.57
2022-10-15 05:19:00 - train.py[line:549] - INFO: 1400 / 4988
2022-10-15 05:19:00 - train.py[line:551] - INFO: load:1.28 valid_run:1062.13 task_valid:1020.93 collect_output:34.07
2022-10-15 05:21:32 - train.py[line:549] - INFO: 1600 / 4988
2022-10-15 05:21:32 - train.py[line:551] - INFO: load:1.30 valid_run:1213.67 task_valid:1162.12 collect_output:43.44
2022-10-15 05:24:02 - train.py[line:549] - INFO: 1800 / 4988
2022-10-15 05:24:02 - train.py[line:551] - INFO: load:1.33 valid_run:1363.66 task_valid:1307.20 collect_output:47.37
2022-10-15 05:26:31 - train.py[line:549] - INFO: 2000 / 4988
2022-10-15 05:26:31 - train.py[line:551] - INFO: load:1.35 valid_run:1512.64 task_valid:1450.54 collect_output:52.04
2022-10-15 05:29:01 - train.py[line:549] - INFO: 2200 / 4988
2022-10-15 05:29:01 - train.py[line:551] - INFO: load:1.38 valid_run:1662.57 task_valid:1595.61 collect_output:55.93
2022-10-15 05:31:31 - train.py[line:549] - INFO: 2400 / 4988
2022-10-15 05:31:31 - train.py[line:551] - INFO: load:1.40 valid_run:1812.89 task_valid:1740.72 collect_output:60.17
2022-10-15 05:34:01 - train.py[line:549] - INFO: 2600 / 4988
2022-10-15 05:34:01 - train.py[line:551] - INFO: load:1.43 valid_run:1963.17 task_valid:1882.71 collect_output:67.48
2022-10-15 05:36:32 - train.py[line:549] - INFO: 2800 / 4988
2022-10-15 05:36:32 - train.py[line:551] - INFO: load:1.45 valid_run:2113.89 task_valid:2028.40 collect_output:71.53
2022-10-15 05:39:03 - train.py[line:549] - INFO: 3000 / 4988
2022-10-15 05:39:03 - train.py[line:551] - INFO: load:1.48 valid_run:2264.27 task_valid:2175.17 collect_output:74.18
2022-10-15 05:41:33 - train.py[line:549] - INFO: 3200 / 4988
2022-10-15 05:41:33 - train.py[line:551] - INFO: load:1.51 valid_run:2414.92 task_valid:2319.90 collect_output:79.11
2022-10-15 05:44:06 - train.py[line:549] - INFO: 3400 / 4988
2022-10-15 05:44:06 - train.py[line:551] - INFO: load:1.53 valid_run:2567.20 task_valid:2465.93 collect_output:84.35
2022-10-15 05:46:37 - train.py[line:549] - INFO: 3600 / 4988
2022-10-15 05:46:37 - train.py[line:551] - INFO: load:1.56 valid_run:2718.21 task_valid:2613.31 collect_output:87.00
2022-10-15 05:49:06 - train.py[line:549] - INFO: 3800 / 4988
2022-10-15 05:49:06 - train.py[line:551] - INFO: load:1.58 valid_run:2867.27 task_valid:2755.63 collect_output:92.71
2022-10-15 05:51:37 - train.py[line:549] - INFO: 4000 / 4988
2022-10-15 05:51:37 - train.py[line:551] - INFO: load:1.62 valid_run:3018.25 task_valid:2901.64 collect_output:96.64
2022-10-15 05:54:10 - train.py[line:549] - INFO: 4200 / 4988
2022-10-15 05:54:10 - train.py[line:551] - INFO: load:1.65 valid_run:3170.92 task_valid:3047.18 collect_output:102.68
2022-10-15 05:56:40 - train.py[line:549] - INFO: 4400 / 4988
2022-10-15 05:56:40 - train.py[line:551] - INFO: load:1.67 valid_run:3321.62 task_valid:3193.18 collect_output:106.26
2022-10-15 05:59:13 - train.py[line:549] - INFO: 4600 / 4988
2022-10-15 05:59:13 - train.py[line:551] - INFO: load:1.70 valid_run:3473.72 task_valid:3340.30 collect_output:110.18
2022-10-15 06:01:45 - train.py[line:549] - INFO: 4800 / 4988
2022-10-15 06:01:45 - train.py[line:551] - INFO: load:1.73 valid_run:3625.87 task_valid:3487.69 collect_output:113.90

====================================================================================================
SGG eval:     R @ 50: 0.6243;     R @ 100: 0.6656;     R @ 500: 0.6777;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4084;    mR @ 100: 0.4380;    mR @ 500: 0.4582;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:1.0000) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.1250) (hanging from:0.5323) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9412) (says:0.0000) (sitting on:0.7392) (standing on:0.3510) (using:0.6000) (walking in:0.0000) (walking on:0.7027) (watching:0.4861) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6243;     R @ 100: 0.6656;     R @ 500: 0.6777;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4084;    mR @ 100: 0.4380;    mR @ 500: 0.4582;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:1.0000) (covering:0.3000) (eating:0.8235) (flying in:0.0000) (growing on:0.1250) (hanging from:0.5323) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.9583) (playing:0.0000) (riding:0.9412) (says:0.0000) (sitting on:0.7392) (standing on:0.3510) (using:0.6000) (walking in:0.0000) (walking on:0.7027) (watching:0.4861) 
--------------------------------------------------------
====================================================================================================

2022-10-15 06:04:17 - train.py[line:487] - INFO: 0.6655815126050421
2022-10-15 06:04:17 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-15 06:04:17 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.304 | loss_v1 0 | loss_v2 0 | nll_loss 0.142 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.665582 | ppl 1.1 | vqa_score 0.6025 | wps 118.7 | wpb 89.9 | bsz 30 | num_updates 10000 | best_R@100 0.709638
2022-10-15 06:04:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 10000 updates
2022-10-15 06:04:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_10000.pt
2022-10-15 06:04:22 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_10000.pt
2022-10-15 06:04:25 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_10000.pt (epoch 1 @ 10000 updates, score 0.6655815126050421) (writing took 8.104846123140305 seconds)
2022-10-15 06:04:36 - progress_bar.py[line:274] - INFO: epoch 001:  10024 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=0.3, ups=0, wpb=109.5, bsz=40, num_updates=10010, lr=4.75747e-05, gnorm=0.768, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49193
2022-10-15 06:04:47 - progress_bar.py[line:274] - INFO: epoch 001:  10034 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=10020, lr=4.75701e-05, gnorm=0.716, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49204
2022-10-15 06:04:58 - progress_bar.py[line:274] - INFO: epoch 001:  10044 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.5, ups=0.92, wpb=111, bsz=40, num_updates=10030, lr=4.75656e-05, gnorm=0.917, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49215
2022-10-15 06:05:09 - progress_bar.py[line:274] - INFO: epoch 001:  10054 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=10040, lr=4.75611e-05, gnorm=0.882, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49226
2022-10-15 06:05:21 - progress_bar.py[line:274] - INFO: epoch 001:  10064 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.7, ups=0.87, wpb=111.1, bsz=40, num_updates=10050, lr=4.75566e-05, gnorm=0.753, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49238
2022-10-15 06:05:32 - progress_bar.py[line:274] - INFO: epoch 001:  10074 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.9, ups=0.91, wpb=109, bsz=40, num_updates=10060, lr=4.75521e-05, gnorm=0.901, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=49249
2022-10-15 06:05:43 - progress_bar.py[line:274] - INFO: epoch 001:  10084 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.4, ups=0.92, wpb=110.9, bsz=40, num_updates=10070, lr=4.75476e-05, gnorm=0.862, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49260
2022-10-15 06:05:54 - progress_bar.py[line:274] - INFO: epoch 001:  10094 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=10080, lr=4.75431e-05, gnorm=0.829, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49271
2022-10-15 06:06:05 - progress_bar.py[line:274] - INFO: epoch 001:  10104 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.4, ups=0.94, wpb=109.2, bsz=40, num_updates=10090, lr=4.75386e-05, gnorm=0.815, clip=10, loss_scale=2048, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=49282
2022-10-15 06:06:09 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-15 06:06:17 - progress_bar.py[line:274] - INFO: epoch 001:  10115 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=92.3, ups=0.84, wpb=110.1, bsz=40, num_updates=10100, lr=4.75341e-05, gnorm=0.859, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=49294
2022-10-15 06:06:28 - progress_bar.py[line:274] - INFO: epoch 001:  10125 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.1, ups=0.9, wpb=109.6, bsz=40, num_updates=10110, lr=4.75296e-05, gnorm=0.765, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49305
2022-10-15 06:06:39 - progress_bar.py[line:274] - INFO: epoch 001:  10135 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=10120, lr=4.75251e-05, gnorm=0.758, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49316
2022-10-15 06:06:43 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 06:06:51 - progress_bar.py[line:274] - INFO: epoch 001:  10146 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=92.6, ups=0.83, wpb=111.1, bsz=40, num_updates=10130, lr=4.75206e-05, gnorm=0.75, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=49328
2022-10-15 06:07:02 - progress_bar.py[line:274] - INFO: epoch 001:  10156 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=10140, lr=4.75161e-05, gnorm=0.849, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49339
2022-10-15 06:07:13 - progress_bar.py[line:274] - INFO: epoch 001:  10166 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.1, ups=0.92, wpb=111.6, bsz=40, num_updates=10150, lr=4.75116e-05, gnorm=0.847, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49350
2022-10-15 06:07:24 - progress_bar.py[line:274] - INFO: epoch 001:  10176 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.9, ups=0.89, wpb=110.4, bsz=40, num_updates=10160, lr=4.75071e-05, gnorm=0.821, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49361
2022-10-15 06:07:35 - progress_bar.py[line:274] - INFO: epoch 001:  10186 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.4, ups=0.9, wpb=109.9, bsz=40, num_updates=10170, lr=4.75026e-05, gnorm=0.778, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49372
2022-10-15 06:07:47 - progress_bar.py[line:274] - INFO: epoch 001:  10196 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.2, ups=0.88, wpb=111.5, bsz=40, num_updates=10180, lr=4.74981e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49384
2022-10-15 06:07:58 - progress_bar.py[line:274] - INFO: epoch 001:  10206 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.2, ups=0.89, wpb=111.4, bsz=40, num_updates=10190, lr=4.74936e-05, gnorm=0.83, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49395
2022-10-15 06:08:09 - progress_bar.py[line:274] - INFO: epoch 001:  10216 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=10200, lr=4.74891e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49406
2022-10-15 06:08:20 - progress_bar.py[line:274] - INFO: epoch 001:  10226 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.5, ups=0.87, wpb=109.6, bsz=40, num_updates=10210, lr=4.74846e-05, gnorm=0.734, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49417
2022-10-15 06:08:31 - progress_bar.py[line:274] - INFO: epoch 001:  10236 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=10220, lr=4.74801e-05, gnorm=0.808, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49428
2022-10-15 06:08:43 - progress_bar.py[line:274] - INFO: epoch 001:  10246 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.5, ups=0.88, wpb=111, bsz=40, num_updates=10230, lr=4.74756e-05, gnorm=0.801, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49440
2022-10-15 06:08:54 - progress_bar.py[line:274] - INFO: epoch 001:  10256 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.2, ups=0.88, wpb=110.5, bsz=40, num_updates=10240, lr=4.74711e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49451
2022-10-15 06:09:05 - progress_bar.py[line:274] - INFO: epoch 001:  10266 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.1, ups=0.92, wpb=110.3, bsz=40, num_updates=10250, lr=4.74666e-05, gnorm=0.754, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49462
2022-10-15 06:09:16 - progress_bar.py[line:274] - INFO: epoch 001:  10276 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101, ups=0.93, wpb=108.9, bsz=40, num_updates=10260, lr=4.74621e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49473
2022-10-15 06:09:27 - progress_bar.py[line:274] - INFO: epoch 001:  10286 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=10270, lr=4.74576e-05, gnorm=0.8, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49484
2022-10-15 06:09:38 - progress_bar.py[line:274] - INFO: epoch 001:  10296 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=102.4, ups=0.92, wpb=110.9, bsz=40, num_updates=10280, lr=4.7453e-05, gnorm=0.71, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49495
2022-10-15 06:09:49 - progress_bar.py[line:274] - INFO: epoch 001:  10306 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.4, ups=0.89, wpb=110.6, bsz=40, num_updates=10290, lr=4.74485e-05, gnorm=0.685, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49506
2022-10-15 06:10:00 - progress_bar.py[line:274] - INFO: epoch 001:  10316 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.4, ups=0.9, wpb=110.7, bsz=40, num_updates=10300, lr=4.7444e-05, gnorm=0.848, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49517
2022-10-15 06:10:11 - progress_bar.py[line:274] - INFO: epoch 001:  10326 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=10310, lr=4.74395e-05, gnorm=0.842, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49528
2022-10-15 06:10:23 - progress_bar.py[line:274] - INFO: epoch 001:  10336 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100, ups=0.89, wpb=111.7, bsz=40, num_updates=10320, lr=4.7435e-05, gnorm=0.738, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=49540
2022-10-15 06:10:33 - progress_bar.py[line:274] - INFO: epoch 001:  10346 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.6, ups=0.92, wpb=110.8, bsz=40, num_updates=10330, lr=4.74305e-05, gnorm=0.731, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49550
2022-10-15 06:10:45 - progress_bar.py[line:274] - INFO: epoch 001:  10356 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=10340, lr=4.7426e-05, gnorm=0.71, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49562
2022-10-15 06:10:55 - progress_bar.py[line:274] - INFO: epoch 001:  10366 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101.7, ups=0.93, wpb=109.3, bsz=40, num_updates=10350, lr=4.74215e-05, gnorm=0.875, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49572
2022-10-15 06:11:06 - progress_bar.py[line:274] - INFO: epoch 001:  10376 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.3, ups=0.92, wpb=108.2, bsz=40, num_updates=10360, lr=4.7417e-05, gnorm=0.705, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49583
2022-10-15 06:11:18 - progress_bar.py[line:274] - INFO: epoch 001:  10386 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.5, ups=0.88, wpb=111.7, bsz=40, num_updates=10370, lr=4.74125e-05, gnorm=0.748, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49595
2022-10-15 06:11:28 - progress_bar.py[line:274] - INFO: epoch 001:  10396 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=103, ups=0.93, wpb=110.5, bsz=40, num_updates=10380, lr=4.7408e-05, gnorm=0.739, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49605
2022-10-15 06:11:39 - progress_bar.py[line:274] - INFO: epoch 001:  10406 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.9, ups=0.9, wpb=108.8, bsz=40, num_updates=10390, lr=4.74035e-05, gnorm=0.792, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49616
2022-10-15 06:11:51 - progress_bar.py[line:274] - INFO: epoch 001:  10416 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.7, ups=0.89, wpb=111.5, bsz=40, num_updates=10400, lr=4.7399e-05, gnorm=0.672, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49628
2022-10-15 06:12:02 - progress_bar.py[line:274] - INFO: epoch 001:  10426 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=10410, lr=4.73945e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49639
2022-10-15 06:12:13 - progress_bar.py[line:274] - INFO: epoch 001:  10436 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.1, ups=0.9, wpb=110.5, bsz=40, num_updates=10420, lr=4.739e-05, gnorm=0.766, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49650
2022-10-15 06:12:24 - progress_bar.py[line:274] - INFO: epoch 001:  10446 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=103, ups=0.93, wpb=110.9, bsz=40, num_updates=10430, lr=4.73855e-05, gnorm=0.714, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=49661
2022-10-15 06:12:35 - progress_bar.py[line:274] - INFO: epoch 001:  10456 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=10440, lr=4.7381e-05, gnorm=0.843, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49672
2022-10-15 06:12:46 - progress_bar.py[line:274] - INFO: epoch 001:  10466 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=10450, lr=4.73765e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49683
2022-10-15 06:12:57 - progress_bar.py[line:274] - INFO: epoch 001:  10476 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.2, ups=0.89, wpb=110.4, bsz=40, num_updates=10460, lr=4.7372e-05, gnorm=0.779, clip=10, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=49694
2022-10-15 06:13:08 - progress_bar.py[line:274] - INFO: epoch 001:  10486 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.7, ups=0.91, wpb=110, bsz=40, num_updates=10470, lr=4.73675e-05, gnorm=0.767, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49705
2022-10-15 06:13:19 - progress_bar.py[line:274] - INFO: epoch 001:  10496 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=102.2, ups=0.92, wpb=110.7, bsz=40, num_updates=10480, lr=4.7363e-05, gnorm=0.858, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49716
2022-10-15 06:13:31 - progress_bar.py[line:274] - INFO: epoch 001:  10506 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.8, ups=0.88, wpb=110.7, bsz=40, num_updates=10490, lr=4.73585e-05, gnorm=0.764, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49728
2022-10-15 06:13:41 - progress_bar.py[line:274] - INFO: epoch 001:  10516 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=102.9, ups=0.94, wpb=109.3, bsz=40, num_updates=10500, lr=4.7354e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=49738
2022-10-15 06:13:52 - progress_bar.py[line:274] - INFO: epoch 001:  10526 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.1, ups=0.89, wpb=110.8, bsz=40, num_updates=10510, lr=4.73495e-05, gnorm=0.707, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=49749
2022-10-15 06:14:04 - progress_bar.py[line:274] - INFO: epoch 001:  10536 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=10520, lr=4.7345e-05, gnorm=0.741, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49761
2022-10-15 06:14:15 - progress_bar.py[line:274] - INFO: epoch 001:  10546 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.3, ups=0.92, wpb=108.4, bsz=40, num_updates=10530, lr=4.73404e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49772
2022-10-15 06:14:26 - progress_bar.py[line:274] - INFO: epoch 001:  10556 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.7, ups=0.91, wpb=110, bsz=40, num_updates=10540, lr=4.73359e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49783
2022-10-15 06:14:37 - progress_bar.py[line:274] - INFO: epoch 001:  10566 / 28910 loss=0.338, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.3, ups=0.89, wpb=111.3, bsz=40, num_updates=10550, lr=4.73314e-05, gnorm=0.763, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49794
2022-10-15 06:14:48 - progress_bar.py[line:274] - INFO: epoch 001:  10576 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100, ups=0.9, wpb=110.9, bsz=40, num_updates=10560, lr=4.73269e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49805
2022-10-15 06:14:59 - progress_bar.py[line:274] - INFO: epoch 001:  10586 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.9, ups=0.9, wpb=109.7, bsz=40, num_updates=10570, lr=4.73224e-05, gnorm=0.788, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49816
2022-10-15 06:15:10 - progress_bar.py[line:274] - INFO: epoch 001:  10596 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=10580, lr=4.73179e-05, gnorm=0.758, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49827
2022-10-15 06:15:21 - progress_bar.py[line:274] - INFO: epoch 001:  10606 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.1, ups=0.91, wpb=110.7, bsz=40, num_updates=10590, lr=4.73134e-05, gnorm=0.786, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49838
2022-10-15 06:15:32 - progress_bar.py[line:274] - INFO: epoch 001:  10616 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=105.5, ups=0.95, wpb=110.6, bsz=40, num_updates=10600, lr=4.73089e-05, gnorm=0.769, clip=0, loss_scale=512, train_wall=10, gb_free=10.7, ema_decay=0.9999, wall=49849
2022-10-15 06:15:43 - progress_bar.py[line:274] - INFO: epoch 001:  10626 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99, ups=0.9, wpb=109.6, bsz=40, num_updates=10610, lr=4.73044e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=49860
2022-10-15 06:15:54 - progress_bar.py[line:274] - INFO: epoch 001:  10636 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.7, ups=0.88, wpb=109.5, bsz=40, num_updates=10620, lr=4.72999e-05, gnorm=0.834, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49871
2022-10-15 06:16:06 - progress_bar.py[line:274] - INFO: epoch 001:  10646 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.2, ups=0.88, wpb=110.6, bsz=40, num_updates=10630, lr=4.72954e-05, gnorm=0.692, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49883
2022-10-15 06:16:16 - progress_bar.py[line:274] - INFO: epoch 001:  10656 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=103, ups=0.92, wpb=112.3, bsz=40, num_updates=10640, lr=4.72909e-05, gnorm=0.705, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49893
2022-10-15 06:16:28 - progress_bar.py[line:274] - INFO: epoch 001:  10666 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99, ups=0.9, wpb=110.4, bsz=40, num_updates=10650, lr=4.72864e-05, gnorm=0.822, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49905
2022-10-15 06:16:39 - progress_bar.py[line:274] - INFO: epoch 001:  10676 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.5, ups=0.89, wpb=110.1, bsz=40, num_updates=10660, lr=4.72819e-05, gnorm=0.808, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49916
2022-10-15 06:16:50 - progress_bar.py[line:274] - INFO: epoch 001:  10686 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.6, ups=0.89, wpb=110.2, bsz=40, num_updates=10670, lr=4.72774e-05, gnorm=0.771, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=49927
2022-10-15 06:17:01 - progress_bar.py[line:274] - INFO: epoch 001:  10696 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.9, ups=0.89, wpb=110.6, bsz=40, num_updates=10680, lr=4.72729e-05, gnorm=0.859, clip=30, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=49938
2022-10-15 06:17:13 - progress_bar.py[line:274] - INFO: epoch 001:  10706 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=10690, lr=4.72684e-05, gnorm=0.759, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=49950
2022-10-15 06:17:24 - progress_bar.py[line:274] - INFO: epoch 001:  10716 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.7, ups=0.88, wpb=111.8, bsz=40, num_updates=10700, lr=4.72639e-05, gnorm=0.746, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=49961
2022-10-15 06:17:35 - progress_bar.py[line:274] - INFO: epoch 001:  10726 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.7, ups=0.88, wpb=109.5, bsz=40, num_updates=10710, lr=4.72594e-05, gnorm=0.809, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=49972
2022-10-15 06:17:47 - progress_bar.py[line:274] - INFO: epoch 001:  10736 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=10720, lr=4.72549e-05, gnorm=0.813, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=49984
2022-10-15 06:17:58 - progress_bar.py[line:274] - INFO: epoch 001:  10746 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.7, ups=0.88, wpb=110.8, bsz=40, num_updates=10730, lr=4.72504e-05, gnorm=0.869, clip=20, loss_scale=1024, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=49995
2022-10-15 06:18:09 - progress_bar.py[line:274] - INFO: epoch 001:  10756 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.1, ups=0.88, wpb=112.2, bsz=40, num_updates=10740, lr=4.72459e-05, gnorm=0.719, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50006
2022-10-15 06:18:20 - progress_bar.py[line:274] - INFO: epoch 001:  10766 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.3, ups=0.9, wpb=109.8, bsz=40, num_updates=10750, lr=4.72414e-05, gnorm=0.879, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50017
2022-10-15 06:18:32 - progress_bar.py[line:274] - INFO: epoch 001:  10776 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=10760, lr=4.72369e-05, gnorm=0.975, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50029
2022-10-15 06:18:43 - progress_bar.py[line:274] - INFO: epoch 001:  10786 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.4, ups=0.89, wpb=109.9, bsz=40, num_updates=10770, lr=4.72324e-05, gnorm=0.875, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50040
2022-10-15 06:18:54 - progress_bar.py[line:274] - INFO: epoch 001:  10796 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.3, ups=0.9, wpb=109.5, bsz=40, num_updates=10780, lr=4.72279e-05, gnorm=0.698, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50051
2022-10-15 06:19:05 - progress_bar.py[line:274] - INFO: epoch 001:  10806 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=10790, lr=4.72233e-05, gnorm=0.884, clip=20, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=50062
2022-10-15 06:19:16 - progress_bar.py[line:274] - INFO: epoch 001:  10816 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.2, ups=0.91, wpb=109.6, bsz=40, num_updates=10800, lr=4.72188e-05, gnorm=0.832, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50073
2022-10-15 06:19:27 - progress_bar.py[line:274] - INFO: epoch 001:  10826 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.7, ups=0.9, wpb=110.3, bsz=40, num_updates=10810, lr=4.72143e-05, gnorm=0.776, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50084
2022-10-15 06:19:38 - progress_bar.py[line:274] - INFO: epoch 001:  10836 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=10820, lr=4.72098e-05, gnorm=0.798, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=50095
2022-10-15 06:19:49 - progress_bar.py[line:274] - INFO: epoch 001:  10846 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=10830, lr=4.72053e-05, gnorm=0.746, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=50106
2022-10-15 06:20:00 - progress_bar.py[line:274] - INFO: epoch 001:  10856 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.8, ups=0.9, wpb=111.7, bsz=40, num_updates=10840, lr=4.72008e-05, gnorm=0.781, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50117
2022-10-15 06:20:12 - progress_bar.py[line:274] - INFO: epoch 001:  10866 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.5, ups=0.89, wpb=111.5, bsz=40, num_updates=10850, lr=4.71963e-05, gnorm=0.799, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=50129
2022-10-15 06:20:23 - progress_bar.py[line:274] - INFO: epoch 001:  10876 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=10860, lr=4.71918e-05, gnorm=0.889, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50140
2022-10-15 06:20:34 - progress_bar.py[line:274] - INFO: epoch 001:  10886 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.6, ups=0.9, wpb=111.2, bsz=40, num_updates=10870, lr=4.71873e-05, gnorm=0.781, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50151
2022-10-15 06:20:45 - progress_bar.py[line:274] - INFO: epoch 001:  10896 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.6, ups=0.89, wpb=109.2, bsz=40, num_updates=10880, lr=4.71828e-05, gnorm=0.905, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50162
2022-10-15 06:20:57 - progress_bar.py[line:274] - INFO: epoch 001:  10906 / 28910 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=95.4, ups=0.86, wpb=110.5, bsz=40, num_updates=10890, lr=4.71783e-05, gnorm=0.747, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=50174
2022-10-15 06:21:08 - progress_bar.py[line:274] - INFO: epoch 001:  10916 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.9, ups=0.88, wpb=109.9, bsz=40, num_updates=10900, lr=4.71738e-05, gnorm=0.776, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=50185
2022-10-15 06:21:19 - progress_bar.py[line:274] - INFO: epoch 001:  10926 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.7, ups=0.88, wpb=111.1, bsz=40, num_updates=10910, lr=4.71693e-05, gnorm=0.751, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50196
2022-10-15 06:21:31 - progress_bar.py[line:274] - INFO: epoch 001:  10936 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=10920, lr=4.71648e-05, gnorm=0.806, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=50208
2022-10-15 06:21:42 - progress_bar.py[line:274] - INFO: epoch 001:  10946 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.9, ups=0.89, wpb=112, bsz=40, num_updates=10930, lr=4.71603e-05, gnorm=0.716, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50219
2022-10-15 06:21:53 - progress_bar.py[line:274] - INFO: epoch 001:  10956 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=10940, lr=4.71558e-05, gnorm=0.899, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50230
2022-10-15 06:22:04 - progress_bar.py[line:274] - INFO: epoch 001:  10966 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.7, ups=0.88, wpb=110.4, bsz=40, num_updates=10950, lr=4.71513e-05, gnorm=0.781, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50241
2022-10-15 06:22:16 - progress_bar.py[line:274] - INFO: epoch 001:  10976 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.3, ups=0.9, wpb=112, bsz=40, num_updates=10960, lr=4.71468e-05, gnorm=0.778, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50253
2022-10-15 06:22:27 - progress_bar.py[line:274] - INFO: epoch 001:  10986 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=10970, lr=4.71423e-05, gnorm=0.796, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=50264
2022-10-15 06:22:38 - progress_bar.py[line:274] - INFO: epoch 001:  10996 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.7, ups=0.92, wpb=110.7, bsz=40, num_updates=10980, lr=4.71378e-05, gnorm=0.78, clip=10, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=50275
2022-10-15 06:22:49 - progress_bar.py[line:274] - INFO: epoch 001:  11006 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.6, ups=0.92, wpb=108.4, bsz=40, num_updates=10990, lr=4.71333e-05, gnorm=0.796, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=50286
2022-10-15 06:23:00 - progress_bar.py[line:274] - INFO: epoch 001:  11016 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101.7, ups=0.92, wpb=110.8, bsz=40, num_updates=11000, lr=4.71288e-05, gnorm=0.785, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=50297
2022-10-15 06:23:00 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-15 06:23:01 - train.py[line:549] - INFO: 0 / 4988
2022-10-15 06:23:01 - train.py[line:551] - INFO: load:1.06 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-15 06:25:33 - train.py[line:549] - INFO: 200 / 4988
2022-10-15 06:25:33 - train.py[line:551] - INFO: load:1.09 valid_run:151.72 task_valid:148.31 collect_output:2.41
2022-10-15 06:28:02 - train.py[line:549] - INFO: 400 / 4988
2022-10-15 06:28:02 - train.py[line:551] - INFO: load:1.11 valid_run:300.59 task_valid:291.92 collect_output:6.71
2022-10-15 06:30:34 - train.py[line:549] - INFO: 600 / 4988
2022-10-15 06:30:34 - train.py[line:551] - INFO: load:1.13 valid_run:453.03 task_valid:435.26 collect_output:14.84
2022-10-15 06:33:03 - train.py[line:549] - INFO: 800 / 4988
2022-10-15 06:33:03 - train.py[line:551] - INFO: load:1.16 valid_run:602.31 task_valid:580.48 collect_output:17.91
2022-10-15 06:35:36 - train.py[line:549] - INFO: 1000 / 4988
2022-10-15 06:35:36 - train.py[line:551] - INFO: load:1.18 valid_run:755.05 task_valid:728.24 collect_output:21.93
2022-10-15 06:38:08 - train.py[line:549] - INFO: 1200 / 4988
2022-10-15 06:38:08 - train.py[line:551] - INFO: load:1.21 valid_run:907.07 task_valid:874.12 collect_output:27.10
2022-10-15 06:40:42 - train.py[line:549] - INFO: 1400 / 4988
2022-10-15 06:40:42 - train.py[line:551] - INFO: load:1.23 valid_run:1060.61 task_valid:1020.35 collect_output:33.45
2022-10-15 06:43:14 - train.py[line:549] - INFO: 1600 / 4988
2022-10-15 06:43:14 - train.py[line:551] - INFO: load:1.25 valid_run:1212.14 task_valid:1161.64 collect_output:42.74
2022-10-15 06:45:44 - train.py[line:549] - INFO: 1800 / 4988
2022-10-15 06:45:44 - train.py[line:551] - INFO: load:1.28 valid_run:1362.08 task_valid:1306.77 collect_output:46.59
2022-10-15 06:48:12 - train.py[line:549] - INFO: 2000 / 4988
2022-10-15 06:48:12 - train.py[line:551] - INFO: load:1.30 valid_run:1510.91 task_valid:1450.25 collect_output:50.97
2022-10-15 06:50:43 - train.py[line:549] - INFO: 2200 / 4988
2022-10-15 06:50:43 - train.py[line:551] - INFO: load:1.33 valid_run:1660.95 task_valid:1595.31 collect_output:54.98
2022-10-15 06:53:13 - train.py[line:549] - INFO: 2400 / 4988
2022-10-15 06:53:13 - train.py[line:551] - INFO: load:1.35 valid_run:1811.18 task_valid:1740.65 collect_output:58.91
2022-10-15 06:55:43 - train.py[line:549] - INFO: 2600 / 4988
2022-10-15 06:55:43 - train.py[line:551] - INFO: load:1.38 valid_run:1961.41 task_valid:1882.83 collect_output:65.98
2022-10-15 06:58:14 - train.py[line:549] - INFO: 2800 / 4988
2022-10-15 06:58:14 - train.py[line:551] - INFO: load:1.40 valid_run:2112.37 task_valid:2028.79 collect_output:70.01
2022-10-15 07:00:45 - train.py[line:549] - INFO: 3000 / 4988
2022-10-15 07:00:45 - train.py[line:551] - INFO: load:1.43 valid_run:2262.87 task_valid:2175.86 collect_output:72.46
2022-10-15 07:03:15 - train.py[line:549] - INFO: 3200 / 4988
2022-10-15 07:03:15 - train.py[line:551] - INFO: load:1.45 valid_run:2413.33 task_valid:2320.59 collect_output:77.23
2022-10-15 07:05:47 - train.py[line:549] - INFO: 3400 / 4988
2022-10-15 07:05:47 - train.py[line:551] - INFO: load:1.48 valid_run:2565.56 task_valid:2467.07 collect_output:81.98
2022-10-15 07:08:19 - train.py[line:549] - INFO: 3600 / 4988
2022-10-15 07:08:19 - train.py[line:551] - INFO: load:1.50 valid_run:2717.22 task_valid:2615.15 collect_output:84.50
2022-10-15 07:10:48 - train.py[line:549] - INFO: 3800 / 4988
2022-10-15 07:10:48 - train.py[line:551] - INFO: load:1.53 valid_run:2866.34 task_valid:2757.75 collect_output:89.97
2022-10-15 07:13:19 - train.py[line:549] - INFO: 4000 / 4988
2022-10-15 07:13:19 - train.py[line:551] - INFO: load:1.55 valid_run:3017.26 task_valid:2903.84 collect_output:93.79
2022-10-15 07:15:52 - train.py[line:549] - INFO: 4200 / 4988
2022-10-15 07:15:52 - train.py[line:551] - INFO: load:1.58 valid_run:3170.10 task_valid:3049.66 collect_output:99.80
2022-10-15 07:18:23 - train.py[line:549] - INFO: 4400 / 4988
2022-10-15 07:18:23 - train.py[line:551] - INFO: load:1.60 valid_run:3320.51 task_valid:3195.70 collect_output:103.11
2022-10-15 07:20:55 - train.py[line:549] - INFO: 4600 / 4988
2022-10-15 07:20:55 - train.py[line:551] - INFO: load:1.64 valid_run:3472.67 task_valid:3342.98 collect_output:106.92
2022-10-15 07:23:28 - train.py[line:549] - INFO: 4800 / 4988
2022-10-15 07:23:28 - train.py[line:551] - INFO: load:1.66 valid_run:3625.37 task_valid:3491.06 collect_output:110.47

====================================================================================================
SGG eval:     R @ 50: 0.6202;     R @ 100: 0.6560;     R @ 500: 0.6685;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4014;    mR @ 100: 0.4327;    mR @ 500: 0.4505;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:1.0000) (covering:0.3714) (eating:0.8235) (flying in:0.0000) (growing on:0.1250) (hanging from:0.5129) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9461) (says:0.0000) (sitting on:0.7392) (standing on:0.3260) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.4861) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6202;     R @ 100: 0.6560;     R @ 500: 0.6685;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4014;    mR @ 100: 0.4327;    mR @ 500: 0.4505;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:1.0000) (covering:0.3714) (eating:0.8235) (flying in:0.0000) (growing on:0.1250) (hanging from:0.5129) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9461) (says:0.0000) (sitting on:0.7392) (standing on:0.3260) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.4861) 
--------------------------------------------------------
====================================================================================================

2022-10-15 07:26:00 - train.py[line:487] - INFO: 0.6560481792717087
2022-10-15 07:26:00 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-15 07:26:00 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.333 | loss_v1 0 | loss_v2 0 | nll_loss 0.175 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.656048 | ppl 1.13 | vqa_score 0.6014 | wps 118.7 | wpb 89.9 | bsz 30 | num_updates 11000 | best_R@100 0.709638
2022-10-15 07:26:00 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 11000 updates
2022-10-15 07:26:00 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_11000.pt
2022-10-15 07:26:07 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_11000.pt
2022-10-15 07:26:09 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_11000.pt (epoch 1 @ 11000 updates, score 0.6560481792717087) (writing took 8.926282234024256 seconds)
2022-10-15 07:26:20 - progress_bar.py[line:274] - INFO: epoch 001:  11026 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=0.3, ups=0, wpb=109.4, bsz=40, num_updates=11010, lr=4.71243e-05, gnorm=0.857, clip=30, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=54097
2022-10-15 07:26:32 - progress_bar.py[line:274] - INFO: epoch 001:  11036 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.5, ups=0.9, wpb=110.5, bsz=40, num_updates=11020, lr=4.71198e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54109
2022-10-15 07:26:43 - progress_bar.py[line:274] - INFO: epoch 001:  11046 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.5, ups=0.9, wpb=109.3, bsz=40, num_updates=11030, lr=4.71153e-05, gnorm=0.872, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54120
2022-10-15 07:26:54 - progress_bar.py[line:274] - INFO: epoch 001:  11056 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.1, ups=0.9, wpb=109.9, bsz=40, num_updates=11040, lr=4.71108e-05, gnorm=0.779, clip=10, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=54131
2022-10-15 07:27:05 - progress_bar.py[line:274] - INFO: epoch 001:  11066 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=11050, lr=4.71062e-05, gnorm=0.769, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54142
2022-10-15 07:27:16 - progress_bar.py[line:274] - INFO: epoch 001:  11076 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=11060, lr=4.71017e-05, gnorm=0.839, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54153
2022-10-15 07:27:27 - progress_bar.py[line:274] - INFO: epoch 001:  11086 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.2, ups=0.9, wpb=110.7, bsz=40, num_updates=11070, lr=4.70972e-05, gnorm=0.795, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54164
2022-10-15 07:27:39 - progress_bar.py[line:274] - INFO: epoch 001:  11096 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.2, ups=0.91, wpb=110.7, bsz=40, num_updates=11080, lr=4.70927e-05, gnorm=0.786, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54176
2022-10-15 07:27:50 - progress_bar.py[line:274] - INFO: epoch 001:  11106 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.5, ups=0.89, wpb=108.6, bsz=40, num_updates=11090, lr=4.70882e-05, gnorm=0.688, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54187
2022-10-15 07:28:01 - progress_bar.py[line:274] - INFO: epoch 001:  11116 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.4, ups=0.92, wpb=110.7, bsz=40, num_updates=11100, lr=4.70837e-05, gnorm=0.685, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54198
2022-10-15 07:28:12 - progress_bar.py[line:274] - INFO: epoch 001:  11126 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=11110, lr=4.70792e-05, gnorm=0.724, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54209
2022-10-15 07:28:23 - progress_bar.py[line:274] - INFO: epoch 001:  11136 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.5, ups=0.88, wpb=109.7, bsz=40, num_updates=11120, lr=4.70747e-05, gnorm=0.845, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=54220
2022-10-15 07:28:35 - progress_bar.py[line:274] - INFO: epoch 001:  11146 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=11130, lr=4.70702e-05, gnorm=0.791, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54232
2022-10-15 07:28:45 - progress_bar.py[line:274] - INFO: epoch 001:  11156 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=103.6, ups=0.94, wpb=110.1, bsz=40, num_updates=11140, lr=4.70657e-05, gnorm=0.818, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54242
2022-10-15 07:28:56 - progress_bar.py[line:274] - INFO: epoch 001:  11166 / 28910 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.188, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=101.1, ups=0.92, wpb=110, bsz=40, num_updates=11150, lr=4.70612e-05, gnorm=0.786, clip=10, loss_scale=2048, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54253
2022-10-15 07:29:01 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1024.0
2022-10-15 07:29:08 - progress_bar.py[line:274] - INFO: epoch 001:  11177 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=91, ups=0.83, wpb=109.9, bsz=40, num_updates=11160, lr=4.70567e-05, gnorm=0.938, clip=30, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=54265
2022-10-15 07:29:20 - progress_bar.py[line:274] - INFO: epoch 001:  11187 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.3, ups=0.89, wpb=108.7, bsz=40, num_updates=11170, lr=4.70522e-05, gnorm=0.915, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54276
2022-10-15 07:29:31 - progress_bar.py[line:274] - INFO: epoch 001:  11197 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=96.1, ups=0.88, wpb=109.3, bsz=40, num_updates=11180, lr=4.70477e-05, gnorm=0.894, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54288
2022-10-15 07:29:42 - progress_bar.py[line:274] - INFO: epoch 001:  11207 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.226, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=11190, lr=4.70432e-05, gnorm=0.971, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54299
2022-10-15 07:29:53 - progress_bar.py[line:274] - INFO: epoch 001:  11217 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=11200, lr=4.70387e-05, gnorm=0.828, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54310
2022-10-15 07:30:04 - progress_bar.py[line:274] - INFO: epoch 001:  11227 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=11210, lr=4.70342e-05, gnorm=0.704, clip=10, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=54321
2022-10-15 07:30:16 - progress_bar.py[line:274] - INFO: epoch 001:  11237 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=11220, lr=4.70297e-05, gnorm=0.859, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54333
2022-10-15 07:30:27 - progress_bar.py[line:274] - INFO: epoch 001:  11247 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=95.8, ups=0.88, wpb=109.2, bsz=40, num_updates=11230, lr=4.70252e-05, gnorm=0.832, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54344
2022-10-15 07:30:38 - progress_bar.py[line:274] - INFO: epoch 001:  11257 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.7, ups=0.9, wpb=110.5, bsz=40, num_updates=11240, lr=4.70207e-05, gnorm=0.804, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54355
2022-10-15 07:30:49 - progress_bar.py[line:274] - INFO: epoch 001:  11267 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.5, ups=0.91, wpb=110.3, bsz=40, num_updates=11250, lr=4.70162e-05, gnorm=0.843, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54366
2022-10-15 07:31:01 - progress_bar.py[line:274] - INFO: epoch 001:  11277 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=95.2, ups=0.86, wpb=110.8, bsz=40, num_updates=11260, lr=4.70117e-05, gnorm=0.707, clip=0, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=54378
2022-10-15 07:31:12 - progress_bar.py[line:274] - INFO: epoch 001:  11287 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.5, ups=0.89, wpb=110.6, bsz=40, num_updates=11270, lr=4.70072e-05, gnorm=0.815, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54389
2022-10-15 07:31:23 - progress_bar.py[line:274] - INFO: epoch 001:  11297 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.1, ups=0.89, wpb=110.4, bsz=40, num_updates=11280, lr=4.70027e-05, gnorm=0.766, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54400
2022-10-15 07:31:34 - progress_bar.py[line:274] - INFO: epoch 001:  11307 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.205, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.9, ups=0.9, wpb=111.5, bsz=40, num_updates=11290, lr=4.69982e-05, gnorm=0.79, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54411
2022-10-15 07:31:45 - progress_bar.py[line:274] - INFO: epoch 001:  11317 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.7, ups=0.89, wpb=109.2, bsz=40, num_updates=11300, lr=4.69936e-05, gnorm=0.781, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54423
2022-10-15 07:31:57 - progress_bar.py[line:274] - INFO: epoch 001:  11327 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.6, ups=0.9, wpb=109.4, bsz=40, num_updates=11310, lr=4.69891e-05, gnorm=0.841, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54434
2022-10-15 07:32:08 - progress_bar.py[line:274] - INFO: epoch 001:  11337 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.5, ups=0.9, wpb=109.1, bsz=40, num_updates=11320, lr=4.69846e-05, gnorm=0.823, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54445
2022-10-15 07:32:19 - progress_bar.py[line:274] - INFO: epoch 001:  11347 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=11330, lr=4.69801e-05, gnorm=0.74, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54456
2022-10-15 07:32:30 - progress_bar.py[line:274] - INFO: epoch 001:  11357 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.7, ups=0.9, wpb=110.3, bsz=40, num_updates=11340, lr=4.69756e-05, gnorm=1.004, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54467
2022-10-15 07:32:41 - progress_bar.py[line:274] - INFO: epoch 001:  11367 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.3, ups=0.88, wpb=110.6, bsz=40, num_updates=11350, lr=4.69711e-05, gnorm=0.825, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54478
2022-10-15 07:32:52 - progress_bar.py[line:274] - INFO: epoch 001:  11377 / 28910 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.2, ups=0.91, wpb=109.5, bsz=40, num_updates=11360, lr=4.69666e-05, gnorm=0.842, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54489
2022-10-15 07:33:04 - progress_bar.py[line:274] - INFO: epoch 001:  11387 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.5, ups=0.88, wpb=110.1, bsz=40, num_updates=11370, lr=4.69621e-05, gnorm=0.82, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54501
2022-10-15 07:33:15 - progress_bar.py[line:274] - INFO: epoch 001:  11397 / 28910 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.1, ups=0.91, wpb=111.2, bsz=40, num_updates=11380, lr=4.69576e-05, gnorm=0.732, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54512
2022-10-15 07:33:20 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 07:33:27 - progress_bar.py[line:274] - INFO: epoch 001:  11408 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=90.9, ups=0.83, wpb=109.3, bsz=40, num_updates=11390, lr=4.69531e-05, gnorm=0.773, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=54524
2022-10-15 07:33:38 - progress_bar.py[line:274] - INFO: epoch 001:  11418 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.8, ups=0.89, wpb=108.6, bsz=40, num_updates=11400, lr=4.69486e-05, gnorm=0.724, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54535
2022-10-15 07:33:49 - progress_bar.py[line:274] - INFO: epoch 001:  11428 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.9, ups=0.93, wpb=108.8, bsz=40, num_updates=11410, lr=4.69441e-05, gnorm=0.846, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=54546
2022-10-15 07:34:00 - progress_bar.py[line:274] - INFO: epoch 001:  11438 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.8, ups=0.87, wpb=109.7, bsz=40, num_updates=11420, lr=4.69396e-05, gnorm=0.832, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54557
2022-10-15 07:34:11 - progress_bar.py[line:274] - INFO: epoch 001:  11448 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=11430, lr=4.69351e-05, gnorm=0.78, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54568
2022-10-15 07:34:22 - progress_bar.py[line:274] - INFO: epoch 001:  11458 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.5, ups=0.91, wpb=110.1, bsz=40, num_updates=11440, lr=4.69306e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54579
2022-10-15 07:34:33 - progress_bar.py[line:274] - INFO: epoch 001:  11468 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=103.5, ups=0.93, wpb=111.3, bsz=40, num_updates=11450, lr=4.69261e-05, gnorm=0.766, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54590
2022-10-15 07:34:44 - progress_bar.py[line:274] - INFO: epoch 001:  11478 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.6, ups=0.9, wpb=110.5, bsz=40, num_updates=11460, lr=4.69216e-05, gnorm=0.782, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54601
2022-10-15 07:34:56 - progress_bar.py[line:274] - INFO: epoch 001:  11488 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=11470, lr=4.69171e-05, gnorm=0.729, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54613
2022-10-15 07:35:07 - progress_bar.py[line:274] - INFO: epoch 001:  11498 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=11480, lr=4.69126e-05, gnorm=0.777, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54624
2022-10-15 07:35:18 - progress_bar.py[line:274] - INFO: epoch 001:  11508 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.2, ups=0.88, wpb=111.6, bsz=40, num_updates=11490, lr=4.69081e-05, gnorm=0.717, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54635
2022-10-15 07:35:30 - progress_bar.py[line:274] - INFO: epoch 001:  11518 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.2, ups=0.87, wpb=110.1, bsz=40, num_updates=11500, lr=4.69036e-05, gnorm=0.828, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54647
2022-10-15 07:35:41 - progress_bar.py[line:274] - INFO: epoch 001:  11528 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=11510, lr=4.68991e-05, gnorm=0.787, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54658
2022-10-15 07:35:52 - progress_bar.py[line:274] - INFO: epoch 001:  11538 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.4, ups=0.89, wpb=111.4, bsz=40, num_updates=11520, lr=4.68946e-05, gnorm=0.699, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54669
2022-10-15 07:36:03 - progress_bar.py[line:274] - INFO: epoch 001:  11548 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101, ups=0.9, wpb=111.6, bsz=40, num_updates=11530, lr=4.68901e-05, gnorm=0.815, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54680
2022-10-15 07:36:14 - progress_bar.py[line:274] - INFO: epoch 001:  11558 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=103.5, ups=0.93, wpb=110.8, bsz=40, num_updates=11540, lr=4.68856e-05, gnorm=0.801, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54691
2022-10-15 07:36:25 - progress_bar.py[line:274] - INFO: epoch 001:  11568 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.2, ups=0.92, wpb=109.4, bsz=40, num_updates=11550, lr=4.68811e-05, gnorm=0.733, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=54702
2022-10-15 07:36:36 - progress_bar.py[line:274] - INFO: epoch 001:  11578 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=11560, lr=4.68765e-05, gnorm=0.808, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=54713
2022-10-15 07:36:47 - progress_bar.py[line:274] - INFO: epoch 001:  11588 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=11570, lr=4.6872e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54724
2022-10-15 07:36:58 - progress_bar.py[line:274] - INFO: epoch 001:  11598 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.7, ups=0.9, wpb=110.1, bsz=40, num_updates=11580, lr=4.68675e-05, gnorm=0.767, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=54735
2022-10-15 07:37:09 - progress_bar.py[line:274] - INFO: epoch 001:  11608 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=11590, lr=4.6863e-05, gnorm=0.856, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54746
2022-10-15 07:37:20 - progress_bar.py[line:274] - INFO: epoch 001:  11618 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96, ups=0.87, wpb=110, bsz=40, num_updates=11600, lr=4.68585e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54757
2022-10-15 07:37:31 - progress_bar.py[line:274] - INFO: epoch 001:  11628 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.2, ups=0.93, wpb=110.2, bsz=40, num_updates=11610, lr=4.6854e-05, gnorm=0.784, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54768
2022-10-15 07:37:43 - progress_bar.py[line:274] - INFO: epoch 001:  11638 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.2, ups=0.88, wpb=111, bsz=40, num_updates=11620, lr=4.68495e-05, gnorm=0.723, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=54780
2022-10-15 07:37:54 - progress_bar.py[line:274] - INFO: epoch 001:  11648 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.5, ups=0.89, wpb=110.1, bsz=40, num_updates=11630, lr=4.6845e-05, gnorm=0.756, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54791
2022-10-15 07:38:05 - progress_bar.py[line:274] - INFO: epoch 001:  11658 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.4, ups=0.92, wpb=110.7, bsz=40, num_updates=11640, lr=4.68405e-05, gnorm=0.683, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54802
2022-10-15 07:38:16 - progress_bar.py[line:274] - INFO: epoch 001:  11668 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97, ups=0.89, wpb=109, bsz=40, num_updates=11650, lr=4.6836e-05, gnorm=0.9, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54813
2022-10-15 07:38:28 - progress_bar.py[line:274] - INFO: epoch 001:  11678 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=94.7, ups=0.86, wpb=109.9, bsz=40, num_updates=11660, lr=4.68315e-05, gnorm=0.743, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=54825
2022-10-15 07:38:39 - progress_bar.py[line:274] - INFO: epoch 001:  11688 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=11670, lr=4.6827e-05, gnorm=0.751, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54836
2022-10-15 07:38:50 - progress_bar.py[line:274] - INFO: epoch 001:  11698 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=11680, lr=4.68225e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54847
2022-10-15 07:39:01 - progress_bar.py[line:274] - INFO: epoch 001:  11708 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=101.3, ups=0.93, wpb=109, bsz=40, num_updates=11690, lr=4.6818e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54858
2022-10-15 07:39:12 - progress_bar.py[line:274] - INFO: epoch 001:  11718 / 28910 loss=0.331, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.7, ups=0.89, wpb=111.4, bsz=40, num_updates=11700, lr=4.68135e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=54869
2022-10-15 07:39:23 - progress_bar.py[line:274] - INFO: epoch 001:  11728 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97, ups=0.88, wpb=110.1, bsz=40, num_updates=11710, lr=4.6809e-05, gnorm=0.935, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=54880
2022-10-15 07:39:34 - progress_bar.py[line:274] - INFO: epoch 001:  11738 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=11720, lr=4.68045e-05, gnorm=0.748, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54891
2022-10-15 07:39:45 - progress_bar.py[line:274] - INFO: epoch 001:  11748 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.6, ups=0.9, wpb=111.1, bsz=40, num_updates=11730, lr=4.68e-05, gnorm=0.828, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54902
2022-10-15 07:39:57 - progress_bar.py[line:274] - INFO: epoch 001:  11758 / 28910 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.1, ups=0.87, wpb=110.2, bsz=40, num_updates=11740, lr=4.67955e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54914
2022-10-15 07:40:08 - progress_bar.py[line:274] - INFO: epoch 001:  11768 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.6, ups=0.89, wpb=110.6, bsz=40, num_updates=11750, lr=4.6791e-05, gnorm=0.799, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54925
2022-10-15 07:40:19 - progress_bar.py[line:274] - INFO: epoch 001:  11778 / 28910 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=11760, lr=4.67865e-05, gnorm=0.83, clip=10, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=54936
2022-10-15 07:40:31 - progress_bar.py[line:274] - INFO: epoch 001:  11788 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.6, ups=0.88, wpb=109.5, bsz=40, num_updates=11770, lr=4.6782e-05, gnorm=0.796, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=54948
2022-10-15 07:40:42 - progress_bar.py[line:274] - INFO: epoch 001:  11798 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.8, ups=0.91, wpb=109.1, bsz=40, num_updates=11780, lr=4.67775e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54959
2022-10-15 07:40:53 - progress_bar.py[line:274] - INFO: epoch 001:  11808 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=11790, lr=4.6773e-05, gnorm=0.842, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=54970
2022-10-15 07:41:04 - progress_bar.py[line:274] - INFO: epoch 001:  11818 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101.1, ups=0.92, wpb=110.3, bsz=40, num_updates=11800, lr=4.67685e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=54981
2022-10-15 07:41:15 - progress_bar.py[line:274] - INFO: epoch 001:  11828 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.7, ups=0.89, wpb=109.6, bsz=40, num_updates=11810, lr=4.6764e-05, gnorm=0.75, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=54992
2022-10-15 07:41:26 - progress_bar.py[line:274] - INFO: epoch 001:  11838 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=11820, lr=4.67594e-05, gnorm=0.795, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=55003
2022-10-15 07:41:37 - progress_bar.py[line:274] - INFO: epoch 001:  11848 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=95.5, ups=0.87, wpb=109.7, bsz=40, num_updates=11830, lr=4.67549e-05, gnorm=0.87, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55015
2022-10-15 07:41:48 - progress_bar.py[line:274] - INFO: epoch 001:  11858 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=11840, lr=4.67504e-05, gnorm=0.847, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55025
2022-10-15 07:41:59 - progress_bar.py[line:274] - INFO: epoch 001:  11868 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.1, ups=0.9, wpb=110.6, bsz=40, num_updates=11850, lr=4.67459e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55036
2022-10-15 07:42:11 - progress_bar.py[line:274] - INFO: epoch 001:  11878 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=11860, lr=4.67414e-05, gnorm=0.817, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=55048
2022-10-15 07:42:22 - progress_bar.py[line:274] - INFO: epoch 001:  11888 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.2, ups=0.88, wpb=109.2, bsz=40, num_updates=11870, lr=4.67369e-05, gnorm=0.79, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=55059
2022-10-15 07:42:33 - progress_bar.py[line:274] - INFO: epoch 001:  11898 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.3, ups=0.9, wpb=109.7, bsz=40, num_updates=11880, lr=4.67324e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55070
2022-10-15 07:42:45 - progress_bar.py[line:274] - INFO: epoch 001:  11908 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97, ups=0.87, wpb=111.3, bsz=40, num_updates=11890, lr=4.67279e-05, gnorm=0.799, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=55082
2022-10-15 07:42:56 - progress_bar.py[line:274] - INFO: epoch 001:  11918 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.6, ups=0.9, wpb=109.1, bsz=40, num_updates=11900, lr=4.67234e-05, gnorm=0.766, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=55093
2022-10-15 07:43:07 - progress_bar.py[line:274] - INFO: epoch 001:  11928 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.2, ups=0.93, wpb=110.2, bsz=40, num_updates=11910, lr=4.67189e-05, gnorm=0.799, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55104
2022-10-15 07:43:18 - progress_bar.py[line:274] - INFO: epoch 001:  11938 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.7, ups=0.87, wpb=110.9, bsz=40, num_updates=11920, lr=4.67144e-05, gnorm=0.754, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55115
2022-10-15 07:43:28 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 07:43:30 - progress_bar.py[line:274] - INFO: epoch 001:  11949 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=91.5, ups=0.83, wpb=110.8, bsz=40, num_updates=11930, lr=4.67099e-05, gnorm=0.858, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=55127
2022-10-15 07:43:41 - progress_bar.py[line:274] - INFO: epoch 001:  11959 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.7, ups=0.93, wpb=110.6, bsz=40, num_updates=11940, lr=4.67054e-05, gnorm=0.811, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55138
2022-10-15 07:43:52 - progress_bar.py[line:274] - INFO: epoch 001:  11969 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=11950, lr=4.67009e-05, gnorm=0.857, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=55149
2022-10-15 07:44:03 - progress_bar.py[line:274] - INFO: epoch 001:  11979 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=11960, lr=4.66964e-05, gnorm=0.755, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55160
2022-10-15 07:44:14 - progress_bar.py[line:274] - INFO: epoch 001:  11989 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.8, ups=0.9, wpb=109.4, bsz=40, num_updates=11970, lr=4.66919e-05, gnorm=0.895, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55171
2022-10-15 07:44:25 - progress_bar.py[line:274] - INFO: epoch 001:  11999 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=11980, lr=4.66874e-05, gnorm=0.814, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=55182
2022-10-15 07:44:36 - progress_bar.py[line:274] - INFO: epoch 001:  12009 / 28910 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.8, ups=0.9, wpb=109.2, bsz=40, num_updates=11990, lr=4.66829e-05, gnorm=0.718, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=55193
2022-10-15 07:44:48 - progress_bar.py[line:274] - INFO: epoch 001:  12019 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.1, ups=0.87, wpb=111.7, bsz=40, num_updates=12000, lr=4.66784e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=55205
2022-10-15 07:44:48 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-15 07:44:49 - train.py[line:549] - INFO: 0 / 4988
2022-10-15 07:44:49 - train.py[line:551] - INFO: load:1.03 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-15 07:47:21 - train.py[line:549] - INFO: 200 / 4988
2022-10-15 07:47:21 - train.py[line:551] - INFO: load:1.05 valid_run:151.94 task_valid:148.07 collect_output:2.86
2022-10-15 07:49:50 - train.py[line:549] - INFO: 400 / 4988
2022-10-15 07:49:50 - train.py[line:551] - INFO: load:1.07 valid_run:300.57 task_valid:291.34 collect_output:7.26
2022-10-15 07:52:22 - train.py[line:549] - INFO: 600 / 4988
2022-10-15 07:52:22 - train.py[line:551] - INFO: load:1.10 valid_run:453.07 task_valid:434.62 collect_output:15.53
2022-10-15 07:54:53 - train.py[line:549] - INFO: 800 / 4988
2022-10-15 07:54:53 - train.py[line:551] - INFO: load:1.12 valid_run:603.22 task_valid:580.65 collect_output:18.66
2022-10-15 07:57:26 - train.py[line:549] - INFO: 1000 / 4988
2022-10-15 07:57:26 - train.py[line:551] - INFO: load:1.15 valid_run:756.93 task_valid:728.64 collect_output:23.32
2022-10-15 07:59:59 - train.py[line:549] - INFO: 1200 / 4988
2022-10-15 07:59:59 - train.py[line:551] - INFO: load:1.17 valid_run:909.25 task_valid:874.31 collect_output:28.99
2022-10-15 08:02:33 - train.py[line:549] - INFO: 1400 / 4988
2022-10-15 08:02:33 - train.py[line:551] - INFO: load:1.19 valid_run:1063.34 task_valid:1020.56 collect_output:35.86
2022-10-15 08:05:05 - train.py[line:549] - INFO: 1600 / 4988
2022-10-15 08:05:05 - train.py[line:551] - INFO: load:1.22 valid_run:1215.18 task_valid:1161.79 collect_output:45.53
2022-10-15 08:07:35 - train.py[line:549] - INFO: 1800 / 4988
2022-10-15 08:07:35 - train.py[line:551] - INFO: load:1.24 valid_run:1365.38 task_valid:1306.81 collect_output:49.75
2022-10-15 08:10:04 - train.py[line:549] - INFO: 2000 / 4988
2022-10-15 08:10:04 - train.py[line:551] - INFO: load:1.27 valid_run:1514.70 task_valid:1450.45 collect_output:54.42
2022-10-15 08:12:35 - train.py[line:549] - INFO: 2200 / 4988
2022-10-15 08:12:35 - train.py[line:551] - INFO: load:1.29 valid_run:1665.17 task_valid:1595.52 collect_output:58.86
2022-10-15 08:15:05 - train.py[line:549] - INFO: 2400 / 4988
2022-10-15 08:15:05 - train.py[line:551] - INFO: load:1.31 valid_run:1815.56 task_valid:1740.57 collect_output:63.24
2022-10-15 08:17:36 - train.py[line:549] - INFO: 2600 / 4988
2022-10-15 08:17:36 - train.py[line:551] - INFO: load:1.34 valid_run:1966.04 task_valid:1882.64 collect_output:70.69
2022-10-15 08:20:07 - train.py[line:549] - INFO: 2800 / 4988
2022-10-15 08:20:07 - train.py[line:551] - INFO: load:1.36 valid_run:2117.51 task_valid:2028.85 collect_output:74.92
2022-10-15 08:22:38 - train.py[line:549] - INFO: 3000 / 4988
2022-10-15 08:22:38 - train.py[line:551] - INFO: load:1.39 valid_run:2268.45 task_valid:2176.26 collect_output:77.39
2022-10-15 08:25:09 - train.py[line:549] - INFO: 3200 / 4988
2022-10-15 08:25:09 - train.py[line:551] - INFO: load:1.41 valid_run:2419.41 task_valid:2321.50 collect_output:81.99
2022-10-15 08:27:42 - train.py[line:549] - INFO: 3400 / 4988
2022-10-15 08:27:42 - train.py[line:551] - INFO: load:1.44 valid_run:2572.17 task_valid:2467.72 collect_output:87.47
2022-10-15 08:30:14 - train.py[line:549] - INFO: 3600 / 4988
2022-10-15 08:30:14 - train.py[line:551] - INFO: load:1.47 valid_run:2723.93 task_valid:2615.92 collect_output:89.93
2022-10-15 08:32:44 - train.py[line:549] - INFO: 3800 / 4988
2022-10-15 08:32:44 - train.py[line:551] - INFO: load:1.49 valid_run:2873.55 task_valid:2758.18 collect_output:96.25
2022-10-15 08:35:15 - train.py[line:549] - INFO: 4000 / 4988
2022-10-15 08:35:15 - train.py[line:551] - INFO: load:1.54 valid_run:3025.00 task_valid:2904.44 collect_output:100.36
2022-10-15 08:37:48 - train.py[line:549] - INFO: 4200 / 4988
2022-10-15 08:37:48 - train.py[line:551] - INFO: load:1.56 valid_run:3177.98 task_valid:3049.95 collect_output:106.77
2022-10-15 08:40:19 - train.py[line:549] - INFO: 4400 / 4988
2022-10-15 08:40:19 - train.py[line:551] - INFO: load:1.59 valid_run:3328.45 task_valid:3195.71 collect_output:110.40
2022-10-15 08:42:51 - train.py[line:549] - INFO: 4600 / 4988
2022-10-15 08:42:51 - train.py[line:551] - INFO: load:1.61 valid_run:3480.84 task_valid:3342.90 collect_output:114.51
2022-10-15 08:45:24 - train.py[line:549] - INFO: 4800 / 4988
2022-10-15 08:45:24 - train.py[line:551] - INFO: load:1.64 valid_run:3633.34 task_valid:3490.73 collect_output:118.11

====================================================================================================
SGG eval:     R @ 50: 0.6110;     R @ 100: 0.6472;     R @ 500: 0.6615;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3982;    mR @ 100: 0.4235;    mR @ 500: 0.4480;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.8750) (covering:0.3714) (eating:0.8235) (flying in:0.0000) (growing on:0.1250) (hanging from:0.5129) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9461) (says:0.0000) (sitting on:0.7086) (standing on:0.3360) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.4444) 
--------------------------------------------------------
====================================================================================================

2022-10-15 08:47:56 - train.py[line:487] - INFO: 0.6471815126050419
2022-10-15 08:47:57 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.6110;     R @ 100: 0.6472;     R @ 500: 0.6615;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3982;    mR @ 100: 0.4235;    mR @ 500: 0.4480;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.8750) (covering:0.3714) (eating:0.8235) (flying in:0.0000) (growing on:0.1250) (hanging from:0.5129) (lying on:0.3000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9461) (says:0.0000) (sitting on:0.7086) (standing on:0.3360) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.4444) 
--------------------------------------------------------
====================================================================================================

2022-10-15 08:47:57 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.339 | loss_v1 0 | loss_v2 0 | nll_loss 0.181 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.647182 | ppl 1.13 | vqa_score 0.5935 | wps 118.4 | wpb 89.9 | bsz 30 | num_updates 12000 | best_R@100 0.709638
2022-10-15 08:47:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 12000 updates
2022-10-15 08:47:57 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_12000.pt
2022-10-15 08:48:02 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_12000.pt
2022-10-15 08:48:05 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_12000.pt (epoch 1 @ 12000 updates, score 0.6471815126050419) (writing took 8.522880132775754 seconds)
2022-10-15 08:48:16 - progress_bar.py[line:274] - INFO: epoch 001:  12029 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=0.3, ups=0, wpb=110.8, bsz=40, num_updates=12010, lr=4.66739e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59013
2022-10-15 08:48:28 - progress_bar.py[line:274] - INFO: epoch 001:  12039 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=95.3, ups=0.87, wpb=109.9, bsz=40, num_updates=12020, lr=4.66694e-05, gnorm=0.808, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59025
2022-10-15 08:48:39 - progress_bar.py[line:274] - INFO: epoch 001:  12049 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.6, ups=0.9, wpb=108.8, bsz=40, num_updates=12030, lr=4.66649e-05, gnorm=0.822, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59036
2022-10-15 08:48:50 - progress_bar.py[line:274] - INFO: epoch 001:  12059 / 28910 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.3, ups=0.88, wpb=110.9, bsz=40, num_updates=12040, lr=4.66604e-05, gnorm=0.763, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59047
2022-10-15 08:49:01 - progress_bar.py[line:274] - INFO: epoch 001:  12069 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.4, ups=0.91, wpb=110, bsz=40, num_updates=12050, lr=4.66559e-05, gnorm=0.922, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59058
2022-10-15 08:49:13 - progress_bar.py[line:274] - INFO: epoch 001:  12079 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.4, ups=0.88, wpb=110.7, bsz=40, num_updates=12060, lr=4.66514e-05, gnorm=0.733, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=59070
2022-10-15 08:49:24 - progress_bar.py[line:274] - INFO: epoch 001:  12089 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.2, ups=0.87, wpb=109.4, bsz=40, num_updates=12070, lr=4.66468e-05, gnorm=0.804, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59081
2022-10-15 08:49:35 - progress_bar.py[line:274] - INFO: epoch 001:  12099 / 28910 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=98.4, ups=0.89, wpb=110.3, bsz=40, num_updates=12080, lr=4.66423e-05, gnorm=0.7, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59092
2022-10-15 08:49:46 - progress_bar.py[line:274] - INFO: epoch 001:  12109 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101, ups=0.93, wpb=108.9, bsz=40, num_updates=12090, lr=4.66378e-05, gnorm=0.905, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=59103
2022-10-15 08:49:57 - progress_bar.py[line:274] - INFO: epoch 001:  12119 / 28910 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.182, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=102.9, ups=0.93, wpb=110.5, bsz=40, num_updates=12100, lr=4.66333e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59114
2022-10-15 08:50:08 - progress_bar.py[line:274] - INFO: epoch 001:  12129 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97, ups=0.89, wpb=109.1, bsz=40, num_updates=12110, lr=4.66288e-05, gnorm=0.838, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59125
2022-10-15 08:50:20 - progress_bar.py[line:274] - INFO: epoch 001:  12139 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97, ups=0.87, wpb=110.9, bsz=40, num_updates=12120, lr=4.66243e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=59137
2022-10-15 08:50:31 - progress_bar.py[line:274] - INFO: epoch 001:  12149 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.4, ups=0.89, wpb=110.7, bsz=40, num_updates=12130, lr=4.66198e-05, gnorm=0.686, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=59148
2022-10-15 08:50:42 - progress_bar.py[line:274] - INFO: epoch 001:  12159 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98, ups=0.89, wpb=110.2, bsz=40, num_updates=12140, lr=4.66153e-05, gnorm=0.706, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59159
2022-10-15 08:50:53 - progress_bar.py[line:274] - INFO: epoch 001:  12169 / 28910 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.2, ups=0.9, wpb=110.2, bsz=40, num_updates=12150, lr=4.66108e-05, gnorm=0.726, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59170
2022-10-15 08:51:04 - progress_bar.py[line:274] - INFO: epoch 001:  12179 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=103.7, ups=0.94, wpb=110, bsz=40, num_updates=12160, lr=4.66063e-05, gnorm=0.818, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59181
2022-10-15 08:51:15 - progress_bar.py[line:274] - INFO: epoch 001:  12189 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.4, ups=0.9, wpb=109.3, bsz=40, num_updates=12170, lr=4.66018e-05, gnorm=0.86, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59192
2022-10-15 08:51:26 - progress_bar.py[line:274] - INFO: epoch 001:  12199 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=12180, lr=4.65973e-05, gnorm=0.776, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59203
2022-10-15 08:51:38 - progress_bar.py[line:274] - INFO: epoch 001:  12209 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=12190, lr=4.65928e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59215
2022-10-15 08:51:49 - progress_bar.py[line:274] - INFO: epoch 001:  12219 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.5, ups=0.9, wpb=111.1, bsz=40, num_updates=12200, lr=4.65883e-05, gnorm=0.742, clip=0, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=59226
2022-10-15 08:52:00 - progress_bar.py[line:274] - INFO: epoch 001:  12229 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.7, ups=0.88, wpb=110.8, bsz=40, num_updates=12210, lr=4.65838e-05, gnorm=0.778, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59237
2022-10-15 08:52:11 - progress_bar.py[line:274] - INFO: epoch 001:  12239 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=12220, lr=4.65793e-05, gnorm=0.846, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59248
2022-10-15 08:52:22 - progress_bar.py[line:274] - INFO: epoch 001:  12249 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=12230, lr=4.65748e-05, gnorm=0.763, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59259
2022-10-15 08:52:33 - progress_bar.py[line:274] - INFO: epoch 001:  12259 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.2, ups=0.91, wpb=110.3, bsz=40, num_updates=12240, lr=4.65703e-05, gnorm=0.81, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59270
2022-10-15 08:52:44 - progress_bar.py[line:274] - INFO: epoch 001:  12269 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.8, ups=0.9, wpb=109.1, bsz=40, num_updates=12250, lr=4.65658e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59281
2022-10-15 08:52:56 - progress_bar.py[line:274] - INFO: epoch 001:  12279 / 28910 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=12260, lr=4.65613e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59293
2022-10-15 08:53:07 - progress_bar.py[line:274] - INFO: epoch 001:  12289 / 28910 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.4, ups=0.88, wpb=110.5, bsz=40, num_updates=12270, lr=4.65568e-05, gnorm=0.8, clip=10, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=59304
2022-10-15 08:53:18 - progress_bar.py[line:274] - INFO: epoch 001:  12299 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.9, ups=0.9, wpb=109.7, bsz=40, num_updates=12280, lr=4.65523e-05, gnorm=0.838, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59315
2022-10-15 08:53:29 - progress_bar.py[line:274] - INFO: epoch 001:  12309 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.2, ups=0.9, wpb=110.1, bsz=40, num_updates=12290, lr=4.65478e-05, gnorm=0.82, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59326
2022-10-15 08:53:40 - progress_bar.py[line:274] - INFO: epoch 001:  12319 / 28910 loss=0.34, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.8, ups=0.9, wpb=111.5, bsz=40, num_updates=12300, lr=4.65433e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59337
2022-10-15 08:53:52 - progress_bar.py[line:274] - INFO: epoch 001:  12329 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.6, ups=0.88, wpb=110.9, bsz=40, num_updates=12310, lr=4.65388e-05, gnorm=0.833, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59349
2022-10-15 08:54:03 - progress_bar.py[line:274] - INFO: epoch 001:  12339 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=97.3, ups=0.89, wpb=109, bsz=40, num_updates=12320, lr=4.65343e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59360
2022-10-15 08:54:14 - progress_bar.py[line:274] - INFO: epoch 001:  12349 / 28910 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=95.9, ups=0.88, wpb=108.8, bsz=40, num_updates=12330, lr=4.65297e-05, gnorm=0.772, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=59371
2022-10-15 08:54:25 - progress_bar.py[line:274] - INFO: epoch 001:  12359 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=103.4, ups=0.93, wpb=111.1, bsz=40, num_updates=12340, lr=4.65252e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59382
2022-10-15 08:54:36 - progress_bar.py[line:274] - INFO: epoch 001:  12369 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.3, ups=0.88, wpb=110.1, bsz=40, num_updates=12350, lr=4.65207e-05, gnorm=0.845, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59393
2022-10-15 08:54:47 - progress_bar.py[line:274] - INFO: epoch 001:  12379 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=107.8, nsentences=40, sample_size=107.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.7, ups=0.91, wpb=107.8, bsz=40, num_updates=12360, lr=4.65162e-05, gnorm=0.9, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59405
2022-10-15 08:54:59 - progress_bar.py[line:274] - INFO: epoch 001:  12389 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.6, ups=0.9, wpb=109.9, bsz=40, num_updates=12370, lr=4.65117e-05, gnorm=0.746, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59416
2022-10-15 08:55:10 - progress_bar.py[line:274] - INFO: epoch 001:  12399 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.1, ups=0.9, wpb=111.9, bsz=40, num_updates=12380, lr=4.65072e-05, gnorm=0.818, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59427
2022-10-15 08:55:21 - progress_bar.py[line:274] - INFO: epoch 001:  12409 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.4, ups=0.89, wpb=110.4, bsz=40, num_updates=12390, lr=4.65027e-05, gnorm=0.731, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59438
2022-10-15 08:55:32 - progress_bar.py[line:274] - INFO: epoch 001:  12419 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=12400, lr=4.64982e-05, gnorm=0.748, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59449
2022-10-15 08:55:44 - progress_bar.py[line:274] - INFO: epoch 001:  12429 / 28910 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.1, ups=0.88, wpb=111.6, bsz=40, num_updates=12410, lr=4.64937e-05, gnorm=0.772, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59461
2022-10-15 08:55:55 - progress_bar.py[line:274] - INFO: epoch 001:  12439 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.22, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.9, ups=0.91, wpb=111.4, bsz=40, num_updates=12420, lr=4.64892e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59472
2022-10-15 08:56:05 - progress_bar.py[line:274] - INFO: epoch 001:  12449 / 28910 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.207, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.7, ups=0.92, wpb=110.9, bsz=40, num_updates=12430, lr=4.64847e-05, gnorm=0.72, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=59482
2022-10-15 08:56:16 - progress_bar.py[line:274] - INFO: epoch 001:  12459 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.5, ups=0.92, wpb=110.8, bsz=40, num_updates=12440, lr=4.64802e-05, gnorm=0.745, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59493
2022-10-15 08:56:27 - progress_bar.py[line:274] - INFO: epoch 001:  12469 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.9, ups=0.9, wpb=110.4, bsz=40, num_updates=12450, lr=4.64757e-05, gnorm=0.803, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59504
2022-10-15 08:56:39 - progress_bar.py[line:274] - INFO: epoch 001:  12479 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=94.4, ups=0.87, wpb=108.3, bsz=40, num_updates=12460, lr=4.64712e-05, gnorm=0.81, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59516
2022-10-15 08:56:50 - progress_bar.py[line:274] - INFO: epoch 001:  12489 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.203, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=99, ups=0.9, wpb=110.4, bsz=40, num_updates=12470, lr=4.64667e-05, gnorm=0.873, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59527
2022-10-15 08:57:01 - progress_bar.py[line:274] - INFO: epoch 001:  12499 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.3, ups=0.93, wpb=110.3, bsz=40, num_updates=12480, lr=4.64622e-05, gnorm=0.857, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59538
2022-10-15 08:57:12 - progress_bar.py[line:274] - INFO: epoch 001:  12509 / 28910 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=101.5, ups=0.91, wpb=111.8, bsz=40, num_updates=12490, lr=4.64577e-05, gnorm=0.903, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59549
2022-10-15 08:57:23 - progress_bar.py[line:274] - INFO: epoch 001:  12519 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=12500, lr=4.64532e-05, gnorm=0.871, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59560
2022-10-15 08:57:34 - progress_bar.py[line:274] - INFO: epoch 001:  12529 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.7, ups=0.9, wpb=109.2, bsz=40, num_updates=12510, lr=4.64487e-05, gnorm=0.862, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=59571
2022-10-15 08:57:46 - progress_bar.py[line:274] - INFO: epoch 001:  12539 / 28910 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=95.7, ups=0.87, wpb=109.7, bsz=40, num_updates=12520, lr=4.64442e-05, gnorm=0.842, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59583
2022-10-15 08:57:57 - progress_bar.py[line:274] - INFO: epoch 001:  12549 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=12530, lr=4.64397e-05, gnorm=0.881, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59594
2022-10-15 08:58:08 - progress_bar.py[line:274] - INFO: epoch 001:  12559 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=12540, lr=4.64352e-05, gnorm=0.825, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59605
2022-10-15 08:58:19 - progress_bar.py[line:274] - INFO: epoch 001:  12569 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.4, ups=0.92, wpb=110.6, bsz=40, num_updates=12550, lr=4.64307e-05, gnorm=0.765, clip=0, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=59616
2022-10-15 08:58:30 - progress_bar.py[line:274] - INFO: epoch 001:  12579 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=12560, lr=4.64262e-05, gnorm=0.837, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59627
2022-10-15 08:58:41 - progress_bar.py[line:274] - INFO: epoch 001:  12589 / 28910 loss=0.336, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=100.2, ups=0.9, wpb=110.8, bsz=40, num_updates=12570, lr=4.64217e-05, gnorm=0.781, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59638
2022-10-15 08:58:53 - progress_bar.py[line:274] - INFO: epoch 001:  12599 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.3, ups=0.88, wpb=111.3, bsz=40, num_updates=12580, lr=4.64172e-05, gnorm=0.775, clip=10, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59650
2022-10-15 08:59:04 - progress_bar.py[line:274] - INFO: epoch 001:  12609 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=12590, lr=4.64126e-05, gnorm=0.79, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59661
2022-10-15 08:59:15 - progress_bar.py[line:274] - INFO: epoch 001:  12619 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.2, ups=0.89, wpb=108.9, bsz=40, num_updates=12600, lr=4.64081e-05, gnorm=0.827, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59672
2022-10-15 08:59:26 - progress_bar.py[line:274] - INFO: epoch 001:  12629 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.202, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100, ups=0.9, wpb=111.4, bsz=40, num_updates=12610, lr=4.64036e-05, gnorm=0.751, clip=20, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=59683
2022-10-15 08:59:37 - progress_bar.py[line:274] - INFO: epoch 001:  12639 / 28910 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.196, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.5, ups=0.92, wpb=110.3, bsz=40, num_updates=12620, lr=4.63991e-05, gnorm=0.834, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59694
2022-10-15 08:59:48 - progress_bar.py[line:274] - INFO: epoch 001:  12649 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=12630, lr=4.63946e-05, gnorm=0.814, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59705
2022-10-15 09:00:00 - progress_bar.py[line:274] - INFO: epoch 001:  12659 / 28910 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.5, ups=0.87, wpb=110.9, bsz=40, num_updates=12640, lr=4.63901e-05, gnorm=0.831, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59717
2022-10-15 09:00:10 - progress_bar.py[line:274] - INFO: epoch 001:  12669 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.5, ups=0.94, wpb=108.9, bsz=40, num_updates=12650, lr=4.63856e-05, gnorm=0.984, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59728
2022-10-15 09:00:22 - progress_bar.py[line:274] - INFO: epoch 001:  12679 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=12660, lr=4.63811e-05, gnorm=0.931, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59739
2022-10-15 09:00:33 - progress_bar.py[line:274] - INFO: epoch 001:  12689 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=12670, lr=4.63766e-05, gnorm=0.907, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59750
2022-10-15 09:00:44 - progress_bar.py[line:274] - INFO: epoch 001:  12699 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=12680, lr=4.63721e-05, gnorm=0.808, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59761
2022-10-15 09:00:55 - progress_bar.py[line:274] - INFO: epoch 001:  12709 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.219, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.6, ups=0.92, wpb=110.8, bsz=40, num_updates=12690, lr=4.63676e-05, gnorm=0.791, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=59772
2022-10-15 09:01:06 - progress_bar.py[line:274] - INFO: epoch 001:  12719 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.2, ups=0.89, wpb=110, bsz=40, num_updates=12700, lr=4.63631e-05, gnorm=0.792, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59783
2022-10-15 09:01:17 - progress_bar.py[line:274] - INFO: epoch 001:  12729 / 28910 loss=0.358, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.1, ups=0.9, wpb=108, bsz=40, num_updates=12710, lr=4.63586e-05, gnorm=0.867, clip=30, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=59794
2022-10-15 09:01:29 - progress_bar.py[line:274] - INFO: epoch 001:  12739 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=97.7, ups=0.89, wpb=110.3, bsz=40, num_updates=12720, lr=4.63541e-05, gnorm=0.829, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59806
2022-10-15 09:01:40 - progress_bar.py[line:274] - INFO: epoch 001:  12749 / 28910 loss=0.33, loss_v1=0, loss_v2=0, nll_loss=0.184, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=99.9, ups=0.9, wpb=111.2, bsz=40, num_updates=12730, lr=4.63496e-05, gnorm=0.732, clip=0, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=59817
2022-10-15 09:01:48 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-15 09:01:52 - progress_bar.py[line:274] - INFO: epoch 001:  12760 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=92.1, ups=0.84, wpb=110, bsz=40, num_updates=12740, lr=4.63451e-05, gnorm=0.997, clip=40, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=59829
2022-10-15 09:02:03 - progress_bar.py[line:274] - INFO: epoch 001:  12770 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=12750, lr=4.63406e-05, gnorm=0.9, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59840
2022-10-15 09:02:13 - progress_bar.py[line:274] - INFO: epoch 001:  12780 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=103, ups=0.93, wpb=110.9, bsz=40, num_updates=12760, lr=4.63361e-05, gnorm=0.914, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=59850
2022-10-15 09:02:25 - progress_bar.py[line:274] - INFO: epoch 001:  12790 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.8, ups=0.89, wpb=108.9, bsz=40, num_updates=12770, lr=4.63316e-05, gnorm=0.968, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=59862
2022-10-15 09:02:36 - progress_bar.py[line:274] - INFO: epoch 001:  12800 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.1, ups=0.9, wpb=108.8, bsz=40, num_updates=12780, lr=4.63271e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=59873
2022-10-15 09:02:47 - progress_bar.py[line:274] - INFO: epoch 001:  12810 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=12790, lr=4.63226e-05, gnorm=0.711, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59884
2022-10-15 09:02:58 - progress_bar.py[line:274] - INFO: epoch 001:  12820 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.197, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.2, ups=0.89, wpb=110.3, bsz=40, num_updates=12800, lr=4.63181e-05, gnorm=0.791, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59895
2022-10-15 09:03:09 - progress_bar.py[line:274] - INFO: epoch 001:  12830 / 28910 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.2, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=100.3, ups=0.9, wpb=111.3, bsz=40, num_updates=12810, lr=4.63136e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59906
2022-10-15 09:03:21 - progress_bar.py[line:274] - INFO: epoch 001:  12840 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.2, ups=0.89, wpb=110.8, bsz=40, num_updates=12820, lr=4.63091e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=59918
2022-10-15 09:03:32 - progress_bar.py[line:274] - INFO: epoch 001:  12850 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.216, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.1, ups=0.87, wpb=109.8, bsz=40, num_updates=12830, lr=4.63046e-05, gnorm=0.828, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=59929
2022-10-15 09:03:44 - progress_bar.py[line:274] - INFO: epoch 001:  12860 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=96.9, ups=0.87, wpb=110.9, bsz=40, num_updates=12840, lr=4.63e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59941
2022-10-15 09:03:55 - progress_bar.py[line:274] - INFO: epoch 001:  12870 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.1, ups=0.9, wpb=109.2, bsz=40, num_updates=12850, lr=4.62955e-05, gnorm=0.843, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59952
2022-10-15 09:04:05 - progress_bar.py[line:274] - INFO: epoch 001:  12880 / 28910 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=102.3, ups=0.93, wpb=110.1, bsz=40, num_updates=12860, lr=4.6291e-05, gnorm=0.731, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=59962
2022-10-15 09:04:16 - progress_bar.py[line:274] - INFO: epoch 001:  12890 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.6, ups=0.91, wpb=109.8, bsz=40, num_updates=12870, lr=4.62865e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59973
2022-10-15 09:04:28 - progress_bar.py[line:274] - INFO: epoch 001:  12900 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.213, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=12880, lr=4.6282e-05, gnorm=0.775, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59985
2022-10-15 09:04:39 - progress_bar.py[line:274] - INFO: epoch 001:  12910 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.225, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=96.3, ups=0.88, wpb=109.3, bsz=40, num_updates=12890, lr=4.62775e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=59996
2022-10-15 09:04:50 - progress_bar.py[line:274] - INFO: epoch 001:  12920 / 28910 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=102.1, ups=0.92, wpb=111.2, bsz=40, num_updates=12900, lr=4.6273e-05, gnorm=0.84, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60007
2022-10-15 09:05:01 - progress_bar.py[line:274] - INFO: epoch 001:  12930 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.218, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=12910, lr=4.62685e-05, gnorm=0.891, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60018
2022-10-15 09:05:12 - progress_bar.py[line:274] - INFO: epoch 001:  12940 / 28910 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=103, ups=0.92, wpb=112.5, bsz=40, num_updates=12920, lr=4.6264e-05, gnorm=0.768, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60029
2022-10-15 09:05:23 - progress_bar.py[line:274] - INFO: epoch 001:  12950 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=12930, lr=4.62595e-05, gnorm=0.827, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60040
2022-10-15 09:05:34 - progress_bar.py[line:274] - INFO: epoch 001:  12960 / 28910 loss=0.357, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.8, ups=0.89, wpb=111.4, bsz=40, num_updates=12940, lr=4.6255e-05, gnorm=0.823, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60051
2022-10-15 09:05:45 - progress_bar.py[line:274] - INFO: epoch 001:  12970 / 28910 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=101.7, ups=0.91, wpb=112.1, bsz=40, num_updates=12950, lr=4.62505e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=60062
2022-10-15 09:05:57 - progress_bar.py[line:274] - INFO: epoch 001:  12980 / 28910 loss=0.342, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.7, ups=0.89, wpb=111.5, bsz=40, num_updates=12960, lr=4.6246e-05, gnorm=0.824, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=60074
2022-10-15 09:06:08 - progress_bar.py[line:274] - INFO: epoch 001:  12990 / 28910 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.195, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=102.1, ups=0.92, wpb=110.6, bsz=40, num_updates=12970, lr=4.62415e-05, gnorm=0.78, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=60085
2022-10-15 09:06:19 - progress_bar.py[line:274] - INFO: epoch 001:  13000 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.2, ups=0.9, wpb=109.6, bsz=40, num_updates=12980, lr=4.6237e-05, gnorm=0.879, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=60096
2022-10-15 09:06:30 - progress_bar.py[line:274] - INFO: epoch 001:  13010 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.7, ups=0.91, wpb=110.1, bsz=40, num_updates=12990, lr=4.62325e-05, gnorm=0.945, clip=40, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=60107
2022-10-15 09:06:41 - progress_bar.py[line:274] - INFO: epoch 001:  13020 / 28910 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=102.1, ups=0.92, wpb=111.4, bsz=40, num_updates=13000, lr=4.6228e-05, gnorm=0.74, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=60118
2022-10-15 09:06:41 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-15 09:06:42 - train.py[line:549] - INFO: 0 / 4988
2022-10-15 09:06:42 - train.py[line:551] - INFO: load:1.04 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-15 09:06:43 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.84 GiB already allocated; 248.19 MiB free; 36.86 GiB reserved in total by PyTorch)
2022-10-15 09:06:43 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-15 09:06:43 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 7            |        cudaMalloc retries: 27        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9047 MB |   10272 MB |    8688 TB |    8688 TB |
|       from large pool |    8902 MB |   10127 MB |    8686 TB |    8686 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9047 MB |   10272 MB |    8688 TB |    8688 TB |
|       from large pool |    8902 MB |   10127 MB |    8686 TB |    8686 TB |
|       from small pool |     144 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   37746 MB |   37752 MB |  261482 MB |  223736 MB |
|       from large pool |   37600 MB |   37600 MB |  261048 MB |  223448 MB |
|       from small pool |     146 MB |     152 MB |     434 MB |     288 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   28698 MB |   28698 MB |   10764 TB |   10764 TB |
|       from large pool |   28697 MB |   28697 MB |   10761 TB |   10761 TB |
|       from small pool |       1 MB |       1 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  403451 K  |  403447 K  |
|       from large pool |     563    |     575    |  129502 K  |  129502 K  |
|       from small pool |    3095    |    3114    |  273948 K  |  273945 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  403451 K  |  403447 K  |
|       from large pool |     563    |     575    |  129502 K  |  129502 K  |
|       from small pool |    3095    |    3114    |  273948 K  |  273945 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     131    |     134    |     600    |     469    |
|       from large pool |      58    |      58    |     383    |     325    |
|       from small pool |      73    |      76    |     217    |     144    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      96    |      98    |  293760 K  |  293760 K  |
|       from large pool |      56    |      56    |   54932 K  |   54931 K  |
|       from small pool |      40    |      48    |  238828 K  |  238828 K  |
|===========================================================================|

2022-10-15 09:06:43 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-15 09:06:44 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 12.88 GiB already allocated; 318.19 MiB free; 36.79 GiB reserved in total by PyTorch)
2022-10-15 09:06:44 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-15 09:06:44 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 8            |        cudaMalloc retries: 28        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   13186 MB |   14411 MB |    8688 TB |    8688 TB |
|       from large pool |   13069 MB |   14294 MB |    8686 TB |    8686 TB |
|       from small pool |     117 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Active memory         |   13186 MB |   14411 MB |    8688 TB |    8688 TB |
|       from large pool |   13069 MB |   14294 MB |    8686 TB |    8686 TB |
|       from small pool |     117 MB |     145 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   37676 MB |   37752 MB |  261482 MB |  223806 MB |
|       from large pool |   37554 MB |   37600 MB |  261048 MB |  223494 MB |
|       from small pool |     122 MB |     152 MB |     434 MB |     312 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24489 MB |   28924 MB |   10764 TB |   10764 TB |
|       from large pool |   24484 MB |   28918 MB |   10761 TB |   10761 TB |
|       from small pool |       4 MB |       5 MB |       2 TB |       2 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3014    |    3672    |  403454 K  |  403451 K  |
|       from large pool |     447    |     575    |  129504 K  |  129503 K  |
|       from small pool |    2567    |    3114    |  273950 K  |  273947 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3014    |    3672    |  403454 K  |  403451 K  |
|       from large pool |     447    |     575    |  129504 K  |  129503 K  |
|       from small pool |    2567    |    3114    |  273950 K  |  273947 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     118    |     134    |     600    |     482    |
|       from large pool |      57    |      58    |     383    |     326    |
|       from small pool |      61    |      76    |     217    |     156    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     119    |     152    |  293763 K  |  293763 K  |
|       from large pool |      56    |      58    |   54932 K  |   54932 K  |
|       from small pool |      63    |     109    |  238830 K  |  238830 K  |
|===========================================================================|

Traceback (most recent call last):
  File "/data/private/yutianyu/OFA/trainer.py", line 1075, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 286, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.84 GiB already allocated; 248.19 MiB free; 36.86 GiB reserved in total by PyTorch)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../../train.py", line 632, in <module>
    cli_main()
  File "../../train.py", line 625, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "../../train.py", line 332, in train
    cfg, trainer, task, epoch_itr, valid_subsets, end_of_epoch
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1090, in valid_step
    return self.valid_step(sample, raise_oom=True)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/data/private/yutianyu/OFA/trainer.py", line 1091, in valid_step
    raise e
  File "/data/private/yutianyu/OFA/trainer.py", line 1075, in valid_step
    sample, self.model, self.criterion, **extra_kwargs
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 286, in valid_step
    lprobs = eval_model.get_normalized_probs(decoder_out, log_probs=True)
  File "/data/private/yutianyu/OFA/models/ofa/unify_transformer.py", line 481, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_model.py", line 83, in get_normalized_probs_scriptable
    return self.decoder.get_normalized_probs(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 67, in get_normalized_probs
    return self.get_normalized_probs_scriptable(net_output, log_probs, sample)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/models/fairseq_decoder.py", line 92, in get_normalized_probs_scriptable
    return utils.log_softmax(logits, dim=-1, onnx_trace=self.onnx_trace)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/utils.py", line 521, in log_softmax
    return F.log_softmax(x, dim=dim, dtype=torch.float32)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/nn/functional.py", line 1674, in log_softmax
    ret = input.log_softmax(dim, dtype=dtype)
RuntimeError: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 12.88 GiB already allocated; 318.19 MiB free; 36.79 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_caption_opt_new/1_B3_A1_E50_0.04_5e-5_480/checkpoint_best.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0-maskName1.0/1_B20_A1_E4_0.04_5e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=15', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=5e-5', '--max-epoch=4', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=1000', '--validate-interval-updates=1000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=5']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 842779
Killing subprocess 842781
