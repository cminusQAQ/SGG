*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 2395
Killing subprocess 2396
Main process received SIGINT, exiting
2022-10-10 16:54:52 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-10 16:54:52 - utils.py[line:261] - INFO: Start init
2022-10-10 16:54:53 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-10 16:54:53 - utils.py[line:261] - INFO: Start init
2022-10-10 16:54:53 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-10 16:54:53 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-10 16:54:53 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-10 16:54:53 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-10 16:55:02 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 50, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=50, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480/checkpoint_best.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-10 16:55:02 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-10 16:55:02 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-10 16:55:08 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-10 16:55:08 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-10 16:55:08 - train.py[line:119] - INFO: model: OFAModel
2022-10-10 16:55:08 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-10 16:55:08 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-10 16:55:08 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-10 16:55:09 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-10 16:55:09 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-10 16:55:09 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-10 16:55:09 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-10 16:55:09 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-10 16:55:09 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-10 16:55:09 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-10 16:55:09 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-10-10 16:55:09 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480/checkpoint_best.pt
2022-10-10 16:55:36 - trainer.py[line:605] - INFO: Loading EMA from checkpoint
2022-10-10 16:55:37 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-10-10 16:55:37 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 16:55:38 - trainer.py[line:612] - INFO: Loading EMA fp32 params from checkpoint
2022-10-10 16:55:38 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480/checkpoint_best.pt (epoch 1 @ 0 updates)
2022-10-10 16:55:38 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 16:55:38 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 20600, warmup steps 824, warmup_factor 0.0012135922330097086
Total steps 20600, warmup steps 824, warmup_factor 0.0012135922330097086
2022-10-10 16:55:39 - trainer.py[line:707] - INFO: begin training epoch 1
2022-10-10 16:55:39 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 16:56:02 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 412 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=68.9, ups=0.63, wpb=109.8, bsz=40, num_updates=10, lr=6.06796e-07, gnorm=1.571, clip=100, loss_scale=128, train_wall=20, gb_free=10.8, ema_decay=0.9999, wall=52
2022-10-10 16:56:15 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 412 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=82.1, ups=0.73, wpb=111.9, bsz=40, num_updates=20, lr=1.21359e-06, gnorm=1.365, clip=90, loss_scale=128, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=66
2022-10-10 16:56:29 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 412 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=81, ups=0.73, wpb=111.5, bsz=40, num_updates=30, lr=1.82039e-06, gnorm=1.512, clip=90, loss_scale=128, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=80
2022-10-10 16:56:43 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 412 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=78.7, ups=0.71, wpb=110.8, bsz=40, num_updates=40, lr=2.42718e-06, gnorm=1.428, clip=80, loss_scale=128, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=94
2022-10-10 16:56:57 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 412 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=81.1, ups=0.73, wpb=111.4, bsz=40, num_updates=50, lr=3.03398e-06, gnorm=1.567, clip=90, loss_scale=128, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=108
2022-10-10 16:57:11 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 412 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=77.4, ups=0.7, wpb=110.7, bsz=40, num_updates=60, lr=3.64078e-06, gnorm=1.329, clip=80, loss_scale=128, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=122
2022-10-10 16:57:25 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 412 loss=0.351, loss_v1=0, loss_v2=0, nll_loss=0.19, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=80.7, ups=0.73, wpb=111.3, bsz=40, num_updates=70, lr=4.24757e-06, gnorm=1.083, clip=60, loss_scale=128, train_wall=14, gb_free=11.2, ema_decay=0.9999, wall=136
2022-10-10 16:57:38 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 412 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.206, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=87, ups=0.79, wpb=110.4, bsz=40, num_updates=80, lr=4.85437e-06, gnorm=1.343, clip=80, loss_scale=128, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=149
2022-10-10 16:57:52 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 412 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=79.4, ups=0.71, wpb=111.5, bsz=40, num_updates=90, lr=5.46117e-06, gnorm=1.054, clip=50, loss_scale=128, train_wall=14, gb_free=10.8, ema_decay=0.9999, wall=163
2022-10-10 16:58:05 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 412 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=87.4, ups=0.79, wpb=111.2, bsz=40, num_updates=100, lr=6.06796e-06, gnorm=1.321, clip=70, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=175
2022-10-10 16:58:19 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 412 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=77.7, ups=0.71, wpb=110.1, bsz=40, num_updates=110, lr=6.67476e-06, gnorm=1.242, clip=80, loss_scale=128, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=190
2022-10-10 16:58:32 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 412 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.135, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=85.4, ups=0.78, wpb=110, bsz=40, num_updates=120, lr=7.28155e-06, gnorm=0.935, clip=30, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=202
2022-10-10 16:58:45 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 412 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.112, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=86.2, ups=0.77, wpb=111.5, bsz=40, num_updates=130, lr=7.88835e-06, gnorm=0.93, clip=40, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=215
2022-10-10 16:58:59 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 412 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.105, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=79.3, ups=0.71, wpb=112.2, bsz=40, num_updates=140, lr=8.49515e-06, gnorm=0.854, clip=20, loss_scale=128, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=229
2022-10-10 16:59:12 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 412 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.095, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=84.6, ups=0.76, wpb=111.2, bsz=40, num_updates=150, lr=9.10194e-06, gnorm=0.783, clip=0, loss_scale=128, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=243
2022-10-10 16:59:26 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 412 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.098, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=80.5, ups=0.72, wpb=112.2, bsz=40, num_updates=160, lr=9.70874e-06, gnorm=0.783, clip=10, loss_scale=128, train_wall=14, gb_free=10.9, ema_decay=0.9999, wall=257
2022-10-10 16:59:40 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 412 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=81.1, ups=0.73, wpb=111.3, bsz=40, num_updates=170, lr=1.03155e-05, gnorm=0.623, clip=10, loss_scale=128, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=270
2022-10-10 16:59:53 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=82, ups=0.74, wpb=111.1, bsz=40, num_updates=180, lr=1.09223e-05, gnorm=0.541, clip=10, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=284
2022-10-10 17:00:07 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 412 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=83.3, ups=0.74, wpb=112.8, bsz=40, num_updates=190, lr=1.15291e-05, gnorm=0.655, clip=20, loss_scale=128, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=297
2022-10-10 17:00:20 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 412 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.085, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=83.2, ups=0.75, wpb=111.5, bsz=40, num_updates=200, lr=1.21359e-05, gnorm=0.965, clip=40, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=311
2022-10-10 17:00:34 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=78.6, ups=0.71, wpb=111.3, bsz=40, num_updates=210, lr=1.27427e-05, gnorm=0.65, clip=20, loss_scale=128, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=325
2022-10-10 17:00:47 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.5, ups=0.76, wpb=111.5, bsz=40, num_updates=220, lr=1.33495e-05, gnorm=0.501, clip=10, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=338
2022-10-10 17:01:00 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 412 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.1, ups=0.77, wpb=110.8, bsz=40, num_updates=230, lr=1.39563e-05, gnorm=0.714, clip=20, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=351
2022-10-10 17:01:13 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.4, ups=0.77, wpb=111.8, bsz=40, num_updates=240, lr=1.45631e-05, gnorm=0.496, clip=0, loss_scale=128, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=364
2022-10-10 17:01:27 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=80.4, ups=0.73, wpb=110.4, bsz=40, num_updates=250, lr=1.51699e-05, gnorm=0.424, clip=0, loss_scale=128, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=378
2022-10-10 17:01:41 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=81.6, ups=0.73, wpb=111.4, bsz=40, num_updates=260, lr=1.57767e-05, gnorm=0.6, clip=0, loss_scale=128, train_wall=14, gb_free=11.3, ema_decay=0.9999, wall=392
2022-10-10 17:01:54 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83, ups=0.75, wpb=111.1, bsz=40, num_updates=270, lr=1.63835e-05, gnorm=0.688, clip=30, loss_scale=128, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=405
2022-10-10 17:02:07 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83.8, ups=0.76, wpb=110.6, bsz=40, num_updates=280, lr=1.69903e-05, gnorm=0.658, clip=20, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=418
2022-10-10 17:02:20 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 412 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.8, ups=0.78, wpb=109.8, bsz=40, num_updates=290, lr=1.75971e-05, gnorm=0.759, clip=30, loss_scale=128, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=431
2022-10-10 17:02:34 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=79.9, ups=0.72, wpb=110.8, bsz=40, num_updates=300, lr=1.82039e-05, gnorm=0.781, clip=30, loss_scale=128, train_wall=14, gb_free=10.4, ema_decay=0.9999, wall=445
2022-10-10 17:02:48 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=79.7, ups=0.72, wpb=111.1, bsz=40, num_updates=310, lr=1.88107e-05, gnorm=0.471, clip=0, loss_scale=128, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=459
2022-10-10 17:03:02 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=82.8, ups=0.74, wpb=111.7, bsz=40, num_updates=320, lr=1.94175e-05, gnorm=0.689, clip=30, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=472
2022-10-10 17:03:15 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=82.2, ups=0.73, wpb=112.8, bsz=40, num_updates=330, lr=2.00243e-05, gnorm=0.535, clip=20, loss_scale=128, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=486
2022-10-10 17:03:29 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=81.9, ups=0.74, wpb=110.1, bsz=40, num_updates=340, lr=2.06311e-05, gnorm=0.543, clip=0, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=499
2022-10-10 17:03:43 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=80.8, ups=0.72, wpb=111.7, bsz=40, num_updates=350, lr=2.12379e-05, gnorm=0.816, clip=40, loss_scale=128, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=513
2022-10-10 17:03:57 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=74.9, ups=0.68, wpb=110.3, bsz=40, num_updates=360, lr=2.18447e-05, gnorm=0.826, clip=30, loss_scale=128, train_wall=15, gb_free=11, ema_decay=0.9999, wall=528
2022-10-10 17:04:11 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=83.3, ups=0.75, wpb=110.7, bsz=40, num_updates=370, lr=2.24515e-05, gnorm=0.646, clip=20, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=541
2022-10-10 17:04:25 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=77, ups=0.7, wpb=109.7, bsz=40, num_updates=380, lr=2.30583e-05, gnorm=0.704, clip=20, loss_scale=128, train_wall=14, gb_free=10.5, ema_decay=0.9999, wall=556
2022-10-10 17:04:38 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=81.6, ups=0.73, wpb=111.4, bsz=40, num_updates=390, lr=2.3665e-05, gnorm=0.562, clip=10, loss_scale=128, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=569
2022-10-10 17:04:51 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.8, ups=0.78, wpb=111.4, bsz=40, num_updates=400, lr=2.42718e-05, gnorm=0.916, clip=40, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=582
2022-10-10 17:05:03 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.2, ups=0.83, wpb=111.6, bsz=40, num_updates=410, lr=2.48786e-05, gnorm=0.504, clip=20, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=594
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 17:05:06 - train.py[line:339] - INFO: end of epoch 1 (average epoch stats below)
2022-10-10 17:05:06 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.292 | loss_v1 0 | loss_v2 0 | nll_loss 0.115 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.08 | wps 81.8 | ups 0.74 | wpb 111.1 | bsz 40 | num_updates 412 | lr 2.5e-05 | gnorm 0.862 | clip 35 | loss_scale 128 | train_wall 560 | gb_free 10.7 | ema_decay 0.9999 | wall 596
2022-10-10 17:05:06 - trainer.py[line:643] - INFO: loading train data for epoch 2
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 17:05:06 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 17:05:06 - trainer.py[line:707] - INFO: begin training epoch 2
2022-10-10 17:05:06 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 17:05:19 - progress_bar.py[line:274] - INFO: epoch 002:      8 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=71.9, ups=0.65, wpb=110, bsz=40, num_updates=420, lr=2.54854e-05, gnorm=0.612, clip=10, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=610
2022-10-10 17:05:31 - progress_bar.py[line:274] - INFO: epoch 002:     18 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.8, ups=0.82, wpb=111.2, bsz=40, num_updates=430, lr=2.60922e-05, gnorm=0.465, clip=10, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=622
2022-10-10 17:05:43 - progress_bar.py[line:274] - INFO: epoch 002:     28 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.5, ups=0.82, wpb=110.3, bsz=40, num_updates=440, lr=2.6699e-05, gnorm=0.559, clip=20, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=634
2022-10-10 17:05:56 - progress_bar.py[line:274] - INFO: epoch 002:     38 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.3, ups=0.8, wpb=111.7, bsz=40, num_updates=450, lr=2.73058e-05, gnorm=0.633, clip=30, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=647
2022-10-10 17:06:08 - progress_bar.py[line:274] - INFO: epoch 002:     48 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.8, ups=0.83, wpb=109.4, bsz=40, num_updates=460, lr=2.79126e-05, gnorm=0.407, clip=10, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=659
2022-10-10 17:06:21 - progress_bar.py[line:274] - INFO: epoch 002:     58 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.3, ups=0.78, wpb=111.1, bsz=40, num_updates=470, lr=2.85194e-05, gnorm=0.51, clip=10, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=671
2022-10-10 17:06:33 - progress_bar.py[line:274] - INFO: epoch 002:     68 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88, ups=0.79, wpb=111.3, bsz=40, num_updates=480, lr=2.91262e-05, gnorm=0.574, clip=10, loss_scale=128, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=684
2022-10-10 17:06:46 - progress_bar.py[line:274] - INFO: epoch 002:     78 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89, ups=0.8, wpb=111.1, bsz=40, num_updates=490, lr=2.9733e-05, gnorm=0.854, clip=40, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=697
2022-10-10 17:06:58 - progress_bar.py[line:274] - INFO: epoch 002:     88 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.4, ups=0.8, wpb=111.1, bsz=40, num_updates=500, lr=3.03398e-05, gnorm=0.43, clip=0, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=709
2022-10-10 17:07:11 - progress_bar.py[line:274] - INFO: epoch 002:     98 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.4, ups=0.8, wpb=109.8, bsz=40, num_updates=510, lr=3.09466e-05, gnorm=0.683, clip=30, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=722
2022-10-10 17:07:23 - progress_bar.py[line:274] - INFO: epoch 002:    108 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.8, ups=0.82, wpb=111.4, bsz=40, num_updates=520, lr=3.15534e-05, gnorm=0.697, clip=20, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=734
2022-10-10 17:07:35 - progress_bar.py[line:274] - INFO: epoch 002:    118 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=95.4, ups=0.86, wpb=111, bsz=40, num_updates=530, lr=3.21602e-05, gnorm=0.657, clip=20, loss_scale=256, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=745
2022-10-10 17:07:47 - progress_bar.py[line:274] - INFO: epoch 002:    128 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.1, ups=0.8, wpb=111.5, bsz=40, num_updates=540, lr=3.2767e-05, gnorm=0.87, clip=30, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=758
2022-10-10 17:08:00 - progress_bar.py[line:274] - INFO: epoch 002:    138 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.4, ups=0.81, wpb=111.3, bsz=40, num_updates=550, lr=3.33738e-05, gnorm=0.58, clip=10, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=770
2022-10-10 17:08:12 - progress_bar.py[line:274] - INFO: epoch 002:    148 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.2, ups=0.78, wpb=112.4, bsz=40, num_updates=560, lr=3.39806e-05, gnorm=0.942, clip=40, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=783
2022-10-10 17:08:24 - progress_bar.py[line:274] - INFO: epoch 002:    158 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92, ups=0.83, wpb=111.4, bsz=40, num_updates=570, lr=3.45874e-05, gnorm=1.117, clip=40, loss_scale=256, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=795
2022-10-10 17:08:37 - progress_bar.py[line:274] - INFO: epoch 002:    168 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87, ups=0.77, wpb=112.5, bsz=40, num_updates=580, lr=3.51942e-05, gnorm=0.463, clip=0, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=808
2022-10-10 17:08:50 - progress_bar.py[line:274] - INFO: epoch 002:    178 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.4, ups=0.78, wpb=111.1, bsz=40, num_updates=590, lr=3.5801e-05, gnorm=0.591, clip=30, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=821
2022-10-10 17:09:03 - progress_bar.py[line:274] - INFO: epoch 002:    188 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.2, ups=0.79, wpb=110, bsz=40, num_updates=600, lr=3.64078e-05, gnorm=0.66, clip=10, loss_scale=256, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=834
2022-10-10 17:09:15 - progress_bar.py[line:274] - INFO: epoch 002:    198 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=92.6, ups=0.83, wpb=112.2, bsz=40, num_updates=610, lr=3.70146e-05, gnorm=0.836, clip=30, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=846
2022-10-10 17:09:27 - progress_bar.py[line:274] - INFO: epoch 002:    208 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91, ups=0.82, wpb=111.5, bsz=40, num_updates=620, lr=3.76214e-05, gnorm=0.596, clip=20, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=858
2022-10-10 17:09:40 - progress_bar.py[line:274] - INFO: epoch 002:    218 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.1, ups=0.79, wpb=110.8, bsz=40, num_updates=630, lr=3.82282e-05, gnorm=0.494, clip=10, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=871
2022-10-10 17:09:52 - progress_bar.py[line:274] - INFO: epoch 002:    228 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.3, ups=0.81, wpb=110.1, bsz=40, num_updates=640, lr=3.8835e-05, gnorm=0.772, clip=30, loss_scale=256, train_wall=12, gb_free=11, ema_decay=0.9999, wall=883
2022-10-10 17:10:05 - progress_bar.py[line:274] - INFO: epoch 002:    238 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.7, ups=0.79, wpb=111.8, bsz=40, num_updates=650, lr=3.94417e-05, gnorm=0.514, clip=10, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=896
2022-10-10 17:10:18 - progress_bar.py[line:274] - INFO: epoch 002:    248 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.8, ups=0.78, wpb=111.1, bsz=40, num_updates=660, lr=4.00485e-05, gnorm=0.723, clip=30, loss_scale=256, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=909
2022-10-10 17:10:30 - progress_bar.py[line:274] - INFO: epoch 002:    258 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.8, ups=0.82, wpb=111.1, bsz=40, num_updates=670, lr=4.06553e-05, gnorm=0.526, clip=20, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=921
2022-10-10 17:10:42 - progress_bar.py[line:274] - INFO: epoch 002:    268 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.1, ups=0.81, wpb=110.6, bsz=40, num_updates=680, lr=4.12621e-05, gnorm=0.674, clip=30, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=933
2022-10-10 17:10:55 - progress_bar.py[line:274] - INFO: epoch 002:    278 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.7, ups=0.81, wpb=111.4, bsz=40, num_updates=690, lr=4.18689e-05, gnorm=0.449, clip=10, loss_scale=256, train_wall=12, gb_free=11.2, ema_decay=0.9999, wall=945
2022-10-10 17:11:07 - progress_bar.py[line:274] - INFO: epoch 002:    288 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.9, ups=0.78, wpb=112, bsz=40, num_updates=700, lr=4.24757e-05, gnorm=0.668, clip=30, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=958
2022-10-10 17:11:20 - progress_bar.py[line:274] - INFO: epoch 002:    298 / 412 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=88.3, ups=0.8, wpb=110.1, bsz=40, num_updates=710, lr=4.30825e-05, gnorm=0.835, clip=30, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=971
2022-10-10 17:11:33 - progress_bar.py[line:274] - INFO: epoch 002:    308 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.4, ups=0.77, wpb=111.7, bsz=40, num_updates=720, lr=4.36893e-05, gnorm=0.606, clip=10, loss_scale=256, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=984
2022-10-10 17:11:45 - progress_bar.py[line:274] - INFO: epoch 002:    318 / 412 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.6, ups=0.8, wpb=111.3, bsz=40, num_updates=730, lr=4.42961e-05, gnorm=0.647, clip=20, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=996
2022-10-10 17:11:58 - progress_bar.py[line:274] - INFO: epoch 002:    328 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.2, ups=0.78, wpb=110.5, bsz=40, num_updates=740, lr=4.49029e-05, gnorm=0.464, clip=0, loss_scale=256, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=1009
2022-10-10 17:12:10 - progress_bar.py[line:274] - INFO: epoch 002:    338 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.8, ups=0.82, wpb=111.4, bsz=40, num_updates=750, lr=4.55097e-05, gnorm=0.841, clip=30, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1021
2022-10-10 17:12:23 - progress_bar.py[line:274] - INFO: epoch 002:    348 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.8, ups=0.8, wpb=111.8, bsz=40, num_updates=760, lr=4.61165e-05, gnorm=0.606, clip=10, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1034
2022-10-10 17:12:35 - progress_bar.py[line:274] - INFO: epoch 002:    358 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.8, ups=0.81, wpb=110.6, bsz=40, num_updates=770, lr=4.67233e-05, gnorm=0.665, clip=30, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1046
2022-10-10 17:12:48 - progress_bar.py[line:274] - INFO: epoch 002:    368 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86, ups=0.77, wpb=111.1, bsz=40, num_updates=780, lr=4.73301e-05, gnorm=0.545, clip=10, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1059
2022-10-10 17:13:01 - progress_bar.py[line:274] - INFO: epoch 002:    378 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.2, ups=0.78, wpb=111.3, bsz=40, num_updates=790, lr=4.79369e-05, gnorm=0.892, clip=30, loss_scale=256, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=1072
2022-10-10 17:13:13 - progress_bar.py[line:274] - INFO: epoch 002:    388 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.1, ups=0.8, wpb=110.3, bsz=40, num_updates=800, lr=4.85437e-05, gnorm=0.572, clip=20, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1084
2022-10-10 17:13:26 - progress_bar.py[line:274] - INFO: epoch 002:    398 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.8, ups=0.81, wpb=112.4, bsz=40, num_updates=810, lr=4.91505e-05, gnorm=0.678, clip=10, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1097
2022-10-10 17:13:38 - progress_bar.py[line:274] - INFO: epoch 002:    408 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.7, ups=0.81, wpb=111.4, bsz=40, num_updates=820, lr=4.97573e-05, gnorm=0.769, clip=40, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=1109
2022-10-10 17:13:43 - train.py[line:339] - INFO: end of epoch 2 (average epoch stats below)
2022-10-10 17:13:43 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.248 | loss_v1 0 | loss_v2 0 | nll_loss 0.063 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 88.5 | ups 0.8 | wpb 111.1 | bsz 40 | num_updates 824 | lr 5e-05 | gnorm 0.652 | clip 20.4 | loss_scale 256 | train_wall 510 | gb_free 10.5 | ema_decay 0.9999 | wall 1114
2022-10-10 17:13:43 - trainer.py[line:643] - INFO: loading train data for epoch 3
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 17:13:43 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 17:13:44 - trainer.py[line:707] - INFO: begin training epoch 3
2022-10-10 17:13:44 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 17:13:54 - progress_bar.py[line:274] - INFO: epoch 003:      6 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=69.9, ups=0.62, wpb=112.5, bsz=40, num_updates=830, lr=4.99848e-05, gnorm=0.567, clip=20, loss_scale=256, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=1125
2022-10-10 17:14:07 - progress_bar.py[line:274] - INFO: epoch 003:     16 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=83.7, ups=0.76, wpb=110.5, bsz=40, num_updates=840, lr=4.99595e-05, gnorm=0.476, clip=0, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1138
2022-10-10 17:14:20 - progress_bar.py[line:274] - INFO: epoch 003:     26 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=92.4, ups=0.82, wpb=112.2, bsz=40, num_updates=850, lr=4.99343e-05, gnorm=0.747, clip=30, loss_scale=256, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=1150
2022-10-10 17:14:32 - progress_bar.py[line:274] - INFO: epoch 003:     36 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.8, ups=0.8, wpb=111.6, bsz=40, num_updates=860, lr=4.9909e-05, gnorm=0.586, clip=10, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=1163
2022-10-10 17:14:45 - progress_bar.py[line:274] - INFO: epoch 003:     46 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=85.3, ups=0.77, wpb=110.3, bsz=40, num_updates=870, lr=4.98837e-05, gnorm=0.442, clip=20, loss_scale=256, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=1176
2022-10-10 17:14:57 - progress_bar.py[line:274] - INFO: epoch 003:     56 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=92.6, ups=0.83, wpb=111.3, bsz=40, num_updates=880, lr=4.98584e-05, gnorm=0.636, clip=10, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1188
2022-10-10 17:15:10 - progress_bar.py[line:274] - INFO: epoch 003:     66 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.5, ups=0.8, wpb=111.2, bsz=40, num_updates=890, lr=4.98331e-05, gnorm=0.862, clip=30, loss_scale=256, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=1200
2022-10-10 17:15:21 - progress_bar.py[line:274] - INFO: epoch 003:     76 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=93.6, ups=0.85, wpb=110.8, bsz=40, num_updates=900, lr=4.98078e-05, gnorm=0.775, clip=30, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1212
2022-10-10 17:15:34 - progress_bar.py[line:274] - INFO: epoch 003:     86 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.2, ups=0.79, wpb=112.1, bsz=40, num_updates=910, lr=4.97826e-05, gnorm=0.71, clip=20, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1225
2022-10-10 17:15:47 - progress_bar.py[line:274] - INFO: epoch 003:     96 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.2, ups=0.78, wpb=112.1, bsz=40, num_updates=920, lr=4.97573e-05, gnorm=0.639, clip=10, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1238
2022-10-10 17:15:59 - progress_bar.py[line:274] - INFO: epoch 003:    106 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.8, ups=0.81, wpb=111.5, bsz=40, num_updates=930, lr=4.9732e-05, gnorm=0.552, clip=20, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1250
2022-10-10 17:16:12 - progress_bar.py[line:274] - INFO: epoch 003:    116 / 412 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=91.2, ups=0.81, wpb=112.3, bsz=40, num_updates=940, lr=4.97067e-05, gnorm=0.827, clip=40, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=1263
2022-10-10 17:16:25 - progress_bar.py[line:274] - INFO: epoch 003:    126 / 412 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.4, ups=0.78, wpb=110.1, bsz=40, num_updates=950, lr=4.96814e-05, gnorm=0.655, clip=20, loss_scale=256, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=1275
2022-10-10 17:16:38 - progress_bar.py[line:274] - INFO: epoch 003:    136 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=84.2, ups=0.77, wpb=110.1, bsz=40, num_updates=960, lr=4.96561e-05, gnorm=0.904, clip=40, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1289
2022-10-10 17:16:51 - progress_bar.py[line:274] - INFO: epoch 003:    146 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.2, ups=0.78, wpb=110.8, bsz=40, num_updates=970, lr=4.96309e-05, gnorm=0.658, clip=30, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1301
2022-10-10 17:17:03 - progress_bar.py[line:274] - INFO: epoch 003:    156 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.9, ups=0.8, wpb=111.9, bsz=40, num_updates=980, lr=4.96056e-05, gnorm=0.934, clip=40, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1314
2022-10-10 17:17:16 - progress_bar.py[line:274] - INFO: epoch 003:    166 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89, ups=0.8, wpb=111.3, bsz=40, num_updates=990, lr=4.95803e-05, gnorm=0.538, clip=10, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=1326
2022-10-10 17:17:28 - progress_bar.py[line:274] - INFO: epoch 003:    176 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.7, ups=0.83, wpb=110.8, bsz=40, num_updates=1000, lr=4.9555e-05, gnorm=0.805, clip=40, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1338
2022-10-10 17:17:28 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 17:17:28 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 17:17:30 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 17:17:30 - train.py[line:551] - INFO: load:1.97 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 17:20:32 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 17:20:32 - train.py[line:551] - INFO: load:2.04 valid_run:182.01 task_valid:172.01 collect_output:7.29
2022-10-10 17:23:24 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 17:23:24 - train.py[line:551] - INFO: load:2.11 valid_run:353.87 task_valid:333.37 collect_output:15.08
2022-10-10 17:26:20 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 17:26:20 - train.py[line:551] - INFO: load:2.14 valid_run:529.40 task_valid:494.76 collect_output:26.77
2022-10-10 17:29:15 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 17:29:15 - train.py[line:551] - INFO: load:2.26 valid_run:704.25 task_valid:661.06 collect_output:32.77
2022-10-10 17:32:14 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 17:32:14 - train.py[line:551] - INFO: load:2.32 valid_run:883.36 task_valid:829.42 collect_output:41.06
2022-10-10 17:35:12 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 17:35:12 - train.py[line:551] - INFO: load:2.36 valid_run:1060.83 task_valid:996.26 collect_output:49.25
2022-10-10 17:38:11 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 17:38:11 - train.py[line:551] - INFO: load:2.46 valid_run:1239.85 task_valid:1164.30 collect_output:57.69
2022-10-10 17:41:07 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 17:41:07 - train.py[line:551] - INFO: load:2.54 valid_run:1416.15 task_valid:1326.44 collect_output:69.20
2022-10-10 17:44:05 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 17:44:05 - train.py[line:551] - INFO: load:2.60 valid_run:1593.29 task_valid:1492.19 collect_output:78.13
2022-10-10 17:47:01 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 17:47:01 - train.py[line:551] - INFO: load:2.68 valid_run:1769.33 task_valid:1659.21 collect_output:84.74
2022-10-10 17:49:57 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 17:49:57 - train.py[line:551] - INFO: load:2.71 valid_run:1945.68 task_valid:1825.96 collect_output:91.96
2022-10-10 17:52:51 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 17:52:51 - train.py[line:551] - INFO: load:2.79 valid_run:2119.37 task_valid:1990.34 collect_output:98.69
2022-10-10 17:55:48 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 17:55:48 - train.py[line:551] - INFO: load:2.86 valid_run:2295.70 task_valid:2153.53 collect_output:109.24
2022-10-10 17:58:43 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 17:58:43 - train.py[line:551] - INFO: load:2.92 valid_run:2471.53 task_valid:2318.08 collect_output:117.83
2022-10-10 18:01:38 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 18:01:38 - train.py[line:551] - INFO: load:2.97 valid_run:2646.23 task_valid:2483.87 collect_output:124.20
2022-10-10 18:04:41 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 18:04:41 - train.py[line:551] - INFO: load:3.01 valid_run:2829.26 task_valid:2656.44 collect_output:132.33
2022-10-10 18:08:04 - train.py[line:549] - INFO: 3400 / 4988
2022-10-10 18:08:04 - train.py[line:551] - INFO: load:3.04 valid_run:3031.39 task_valid:2845.28 collect_output:143.18
2022-10-10 18:11:25 - train.py[line:549] - INFO: 3600 / 4988
2022-10-10 18:11:25 - train.py[line:551] - INFO: load:3.09 valid_run:3232.29 task_valid:3036.33 collect_output:150.47
2022-10-10 18:14:46 - train.py[line:549] - INFO: 3800 / 4988
2022-10-10 18:14:46 - train.py[line:551] - INFO: load:3.13 valid_run:3433.77 task_valid:3223.38 collect_output:162.35
2022-10-10 18:18:08 - train.py[line:549] - INFO: 4000 / 4988
2022-10-10 18:18:08 - train.py[line:551] - INFO: load:3.17 valid_run:3635.68 task_valid:3413.16 collect_output:171.91
2022-10-10 18:21:35 - train.py[line:549] - INFO: 4200 / 4988
2022-10-10 18:21:35 - train.py[line:551] - INFO: load:3.21 valid_run:3841.95 task_valid:3604.09 collect_output:184.76
2022-10-10 18:24:54 - train.py[line:549] - INFO: 4400 / 4988
2022-10-10 18:24:54 - train.py[line:551] - INFO: load:3.30 valid_run:4041.06 task_valid:3790.43 collect_output:194.96
2022-10-10 18:28:12 - train.py[line:549] - INFO: 4600 / 4988
2022-10-10 18:28:12 - train.py[line:551] - INFO: load:3.36 valid_run:4239.54 task_valid:3980.71 collect_output:200.52
2022-10-10 18:31:30 - train.py[line:549] - INFO: 4800 / 4988
2022-10-10 18:31:30 - train.py[line:551] - INFO: load:3.38 valid_run:4436.96 task_valid:4168.85 collect_output:207.38

====================================================================================================
SGG eval:     R @ 50: 0.6748;     R @ 100: 0.7022;     R @ 500: 0.7258;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4645;    mR @ 100: 0.4995;    mR @ 500: 0.5415;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.8125) (covering:0.4429) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9369) (says:0.0000) (sitting on:0.7636) (standing on:0.4693) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 18:34:51 - train.py[line:487] - INFO: 0.7022104150751209

====================================================================================================
SGG eval:     R @ 50: 0.6748;     R @ 100: 0.7022;     R @ 500: 0.7258;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4645;    mR @ 100: 0.4995;    mR @ 500: 0.5415;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.8125) (covering:0.4429) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9369) (says:0.0000) (sitting on:0.7636) (standing on:0.4693) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 18:34:51 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-10 18:34:51 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.238 | loss_v1 0 | loss_v2 0 | nll_loss 0.066 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.70221 | ppl 1.05 | vqa_score 0.5608 | wps 96.7 | wpb 89.9 | bsz 30 | num_updates 1000
2022-10-10 18:34:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 1000 updates
2022-10-10 18:34:51 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_3_1000.pt
2022-10-10 18:35:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_3_1000.pt
2022-10-10 18:35:11 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_3_1000.pt (epoch 3 @ 1000 updates, score 0.7022104150751209) (writing took 19.762471267953515 seconds)
2022-10-10 18:35:23 - progress_bar.py[line:274] - INFO: epoch 003:    186 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=0.2, ups=0, wpb=112.3, bsz=40, num_updates=1010, lr=4.95297e-05, gnorm=1.045, clip=40, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6014
2022-10-10 18:35:36 - progress_bar.py[line:274] - INFO: epoch 003:    196 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.2, ups=0.78, wpb=111.3, bsz=40, num_updates=1020, lr=4.95044e-05, gnorm=0.749, clip=20, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6027
2022-10-10 18:35:49 - progress_bar.py[line:274] - INFO: epoch 003:    206 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89, ups=0.81, wpb=109.8, bsz=40, num_updates=1030, lr=4.94792e-05, gnorm=0.636, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6039
2022-10-10 18:36:01 - progress_bar.py[line:274] - INFO: epoch 003:    216 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.1, ups=0.79, wpb=111.5, bsz=40, num_updates=1040, lr=4.94539e-05, gnorm=1.132, clip=50, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=6052
2022-10-10 18:36:14 - progress_bar.py[line:274] - INFO: epoch 003:    226 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.1, ups=0.8, wpb=111.4, bsz=40, num_updates=1050, lr=4.94286e-05, gnorm=0.59, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6064
2022-10-10 18:36:26 - progress_bar.py[line:274] - INFO: epoch 003:    236 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.9, ups=0.81, wpb=110, bsz=40, num_updates=1060, lr=4.94033e-05, gnorm=0.755, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6077
2022-10-10 18:36:39 - progress_bar.py[line:274] - INFO: epoch 003:    246 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88, ups=0.79, wpb=110.9, bsz=40, num_updates=1070, lr=4.9378e-05, gnorm=0.447, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6089
2022-10-10 18:36:52 - progress_bar.py[line:274] - INFO: epoch 003:    256 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.9, ups=0.78, wpb=111.3, bsz=40, num_updates=1080, lr=4.93528e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=6102
2022-10-10 18:37:04 - progress_bar.py[line:274] - INFO: epoch 003:    266 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.8, ups=0.78, wpb=111.5, bsz=40, num_updates=1090, lr=4.93275e-05, gnorm=0.578, clip=20, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=6115
2022-10-10 18:37:17 - progress_bar.py[line:274] - INFO: epoch 003:    276 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.9, ups=0.78, wpb=112.1, bsz=40, num_updates=1100, lr=4.93022e-05, gnorm=0.733, clip=30, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=6128
2022-10-10 18:37:30 - progress_bar.py[line:274] - INFO: epoch 003:    286 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.5, ups=0.81, wpb=111.1, bsz=40, num_updates=1110, lr=4.92769e-05, gnorm=0.676, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6140
2022-10-10 18:37:43 - progress_bar.py[line:274] - INFO: epoch 003:    296 / 412 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85, ups=0.77, wpb=110.1, bsz=40, num_updates=1120, lr=4.92516e-05, gnorm=0.656, clip=30, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=6153
2022-10-10 18:37:55 - progress_bar.py[line:274] - INFO: epoch 003:    306 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.4, ups=0.81, wpb=110.2, bsz=40, num_updates=1130, lr=4.92263e-05, gnorm=0.917, clip=50, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=6166
2022-10-10 18:38:07 - progress_bar.py[line:274] - INFO: epoch 003:    316 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89, ups=0.8, wpb=111.4, bsz=40, num_updates=1140, lr=4.92011e-05, gnorm=0.477, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6178
2022-10-10 18:38:20 - progress_bar.py[line:274] - INFO: epoch 003:    326 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.1, ups=0.82, wpb=110.5, bsz=40, num_updates=1150, lr=4.91758e-05, gnorm=0.766, clip=30, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=6190
2022-10-10 18:38:32 - progress_bar.py[line:274] - INFO: epoch 003:    336 / 412 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=88.4, ups=0.79, wpb=111.3, bsz=40, num_updates=1160, lr=4.91505e-05, gnorm=0.858, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6203
2022-10-10 18:38:45 - progress_bar.py[line:274] - INFO: epoch 003:    346 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.1, ups=0.8, wpb=111.2, bsz=40, num_updates=1170, lr=4.91252e-05, gnorm=0.718, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6215
2022-10-10 18:38:57 - progress_bar.py[line:274] - INFO: epoch 003:    356 / 412 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=89.2, ups=0.8, wpb=111.2, bsz=40, num_updates=1180, lr=4.90999e-05, gnorm=0.918, clip=50, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=6228
2022-10-10 18:39:09 - progress_bar.py[line:274] - INFO: epoch 003:    366 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.8, ups=0.82, wpb=110.5, bsz=40, num_updates=1190, lr=4.90746e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6240
2022-10-10 18:39:22 - progress_bar.py[line:274] - INFO: epoch 003:    376 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.1, ups=0.77, wpb=110.3, bsz=40, num_updates=1200, lr=4.90494e-05, gnorm=0.632, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6253
2022-10-10 18:39:35 - progress_bar.py[line:274] - INFO: epoch 003:    386 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.6, ups=0.78, wpb=111.7, bsz=40, num_updates=1210, lr=4.90241e-05, gnorm=0.647, clip=20, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6266
2022-10-10 18:39:47 - progress_bar.py[line:274] - INFO: epoch 003:    396 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=94.7, ups=0.85, wpb=112.1, bsz=40, num_updates=1220, lr=4.89988e-05, gnorm=0.744, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=6278
2022-10-10 18:39:59 - progress_bar.py[line:274] - INFO: epoch 003:    406 / 412 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89, ups=0.81, wpb=109.6, bsz=40, num_updates=1230, lr=4.89735e-05, gnorm=0.811, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6290
2022-10-10 18:40:06 - train.py[line:339] - INFO: end of epoch 3 (average epoch stats below)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 18:40:07 - progress_bar.py[line:282] - INFO: epoch 003 | loss 0.251 | loss_v1 0 | loss_v2 0 | nll_loss 0.067 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.05 | wps 8.8 | ups 0.08 | wpb 111.1 | bsz 40 | num_updates 1236 | lr 4.89583e-05 | gnorm 0.715 | clip 24.8 | loss_scale 512 | train_wall 513 | gb_free 10.7 | ema_decay 0.9999 | wall 6297
2022-10-10 18:40:07 - trainer.py[line:643] - INFO: loading train data for epoch 4
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 18:40:07 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 18:40:08 - trainer.py[line:707] - INFO: begin training epoch 4
2022-10-10 18:40:08 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 18:40:15 - progress_bar.py[line:274] - INFO: epoch 004:      4 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=67.7, ups=0.62, wpb=110, bsz=40, num_updates=1240, lr=4.89482e-05, gnorm=0.872, clip=20, loss_scale=512, train_wall=13, gb_free=11.1, ema_decay=0.9999, wall=6306
2022-10-10 18:40:28 - progress_bar.py[line:274] - INFO: epoch 004:     14 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.1, ups=0.78, wpb=112.7, bsz=40, num_updates=1250, lr=4.89229e-05, gnorm=0.998, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6319
2022-10-10 18:40:41 - progress_bar.py[line:274] - INFO: epoch 004:     24 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.9, ups=0.77, wpb=110.5, bsz=40, num_updates=1260, lr=4.88977e-05, gnorm=0.521, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6332
2022-10-10 18:40:54 - progress_bar.py[line:274] - INFO: epoch 004:     34 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.8, wpb=111.7, bsz=40, num_updates=1270, lr=4.88724e-05, gnorm=0.466, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6345
2022-10-10 18:41:07 - progress_bar.py[line:274] - INFO: epoch 004:     44 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.8, ups=0.79, wpb=109.9, bsz=40, num_updates=1280, lr=4.88471e-05, gnorm=0.759, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6357
2022-10-10 18:41:20 - progress_bar.py[line:274] - INFO: epoch 004:     54 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.1, ups=0.77, wpb=111.1, bsz=40, num_updates=1290, lr=4.88218e-05, gnorm=0.695, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6370
2022-10-10 18:41:32 - progress_bar.py[line:274] - INFO: epoch 004:     64 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.1, ups=0.81, wpb=111.9, bsz=40, num_updates=1300, lr=4.87965e-05, gnorm=0.835, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6383
2022-10-10 18:41:45 - progress_bar.py[line:274] - INFO: epoch 004:     74 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.3, ups=0.78, wpb=111.6, bsz=40, num_updates=1310, lr=4.87712e-05, gnorm=0.743, clip=20, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=6396
2022-10-10 18:41:58 - progress_bar.py[line:274] - INFO: epoch 004:     84 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.4, ups=0.8, wpb=109.6, bsz=40, num_updates=1320, lr=4.8746e-05, gnorm=0.665, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6408
2022-10-10 18:42:10 - progress_bar.py[line:274] - INFO: epoch 004:     94 / 412 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=86.4, ups=0.78, wpb=111.1, bsz=40, num_updates=1330, lr=4.87207e-05, gnorm=0.731, clip=30, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=6421
2022-10-10 18:42:23 - progress_bar.py[line:274] - INFO: epoch 004:    104 / 412 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=91.7, ups=0.83, wpb=110.7, bsz=40, num_updates=1340, lr=4.86954e-05, gnorm=0.905, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6433
2022-10-10 18:42:35 - progress_bar.py[line:274] - INFO: epoch 004:    114 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.2, ups=0.81, wpb=111.6, bsz=40, num_updates=1350, lr=4.86701e-05, gnorm=0.665, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6446
2022-10-10 18:42:48 - progress_bar.py[line:274] - INFO: epoch 004:    124 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.6, ups=0.78, wpb=112, bsz=40, num_updates=1360, lr=4.86448e-05, gnorm=0.699, clip=20, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6458
2022-10-10 18:43:00 - progress_bar.py[line:274] - INFO: epoch 004:    134 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.3, ups=0.8, wpb=110.4, bsz=40, num_updates=1370, lr=4.86195e-05, gnorm=0.549, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6471
2022-10-10 18:43:13 - progress_bar.py[line:274] - INFO: epoch 004:    144 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.8, wpb=110.7, bsz=40, num_updates=1380, lr=4.85943e-05, gnorm=0.518, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=6483
2022-10-10 18:43:25 - progress_bar.py[line:274] - INFO: epoch 004:    154 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.8, wpb=111.3, bsz=40, num_updates=1390, lr=4.8569e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6496
2022-10-10 18:43:38 - progress_bar.py[line:274] - INFO: epoch 004:    164 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.3, ups=0.81, wpb=112, bsz=40, num_updates=1400, lr=4.85437e-05, gnorm=0.705, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6508
2022-10-10 18:43:50 - progress_bar.py[line:274] - INFO: epoch 004:    174 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.7, ups=0.8, wpb=112.1, bsz=40, num_updates=1410, lr=4.85184e-05, gnorm=0.818, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6521
2022-10-10 18:44:03 - progress_bar.py[line:274] - INFO: epoch 004:    184 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.6, ups=0.79, wpb=111.5, bsz=40, num_updates=1420, lr=4.84931e-05, gnorm=0.747, clip=30, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=6534
2022-10-10 18:44:15 - progress_bar.py[line:274] - INFO: epoch 004:    194 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.3, ups=0.8, wpb=112.3, bsz=40, num_updates=1430, lr=4.84678e-05, gnorm=0.491, clip=0, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=6546
2022-10-10 18:44:28 - progress_bar.py[line:274] - INFO: epoch 004:    204 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.3, ups=0.78, wpb=111, bsz=40, num_updates=1440, lr=4.84426e-05, gnorm=0.428, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6559
2022-10-10 18:44:41 - progress_bar.py[line:274] - INFO: epoch 004:    214 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.1, ups=0.77, wpb=112.5, bsz=40, num_updates=1450, lr=4.84173e-05, gnorm=0.695, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=6572
2022-10-10 18:44:53 - progress_bar.py[line:274] - INFO: epoch 004:    224 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.7, ups=0.81, wpb=112.6, bsz=40, num_updates=1460, lr=4.8392e-05, gnorm=0.76, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6584
2022-10-10 18:45:06 - progress_bar.py[line:274] - INFO: epoch 004:    234 / 412 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.088, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=86.2, ups=0.78, wpb=110.1, bsz=40, num_updates=1470, lr=4.83667e-05, gnorm=0.753, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6597
2022-10-10 18:45:19 - progress_bar.py[line:274] - INFO: epoch 004:    244 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.8, ups=0.81, wpb=111.6, bsz=40, num_updates=1480, lr=4.83414e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=6609
2022-10-10 18:45:31 - progress_bar.py[line:274] - INFO: epoch 004:    254 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.9, ups=0.78, wpb=110.1, bsz=40, num_updates=1490, lr=4.83161e-05, gnorm=0.572, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6622
2022-10-10 18:45:44 - progress_bar.py[line:274] - INFO: epoch 004:    264 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.6, ups=0.79, wpb=111.5, bsz=40, num_updates=1500, lr=4.82909e-05, gnorm=0.871, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6635
2022-10-10 18:45:57 - progress_bar.py[line:274] - INFO: epoch 004:    274 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=84.5, ups=0.77, wpb=110.4, bsz=40, num_updates=1510, lr=4.82656e-05, gnorm=0.707, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6648
2022-10-10 18:46:10 - progress_bar.py[line:274] - INFO: epoch 004:    284 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.6, ups=0.81, wpb=110.7, bsz=40, num_updates=1520, lr=4.82403e-05, gnorm=0.662, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6660
2022-10-10 18:46:22 - progress_bar.py[line:274] - INFO: epoch 004:    294 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91, ups=0.81, wpb=111.9, bsz=40, num_updates=1530, lr=4.8215e-05, gnorm=0.694, clip=40, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=6673
2022-10-10 18:46:35 - progress_bar.py[line:274] - INFO: epoch 004:    304 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.6, ups=0.77, wpb=111.7, bsz=40, num_updates=1540, lr=4.81897e-05, gnorm=0.777, clip=30, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=6686
2022-10-10 18:46:47 - progress_bar.py[line:274] - INFO: epoch 004:    314 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.9, ups=0.82, wpb=111.1, bsz=40, num_updates=1550, lr=4.81644e-05, gnorm=0.755, clip=10, loss_scale=1024, train_wall=12, gb_free=11, ema_decay=0.9999, wall=6698
2022-10-10 18:47:00 - progress_bar.py[line:274] - INFO: epoch 004:    324 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.4, ups=0.79, wpb=110.9, bsz=40, num_updates=1560, lr=4.81392e-05, gnorm=0.597, clip=20, loss_scale=1024, train_wall=13, gb_free=11, ema_decay=0.9999, wall=6711
2022-10-10 18:47:13 - progress_bar.py[line:274] - INFO: epoch 004:    334 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.6, ups=0.78, wpb=110.5, bsz=40, num_updates=1570, lr=4.81139e-05, gnorm=0.84, clip=20, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6723
2022-10-10 18:47:25 - progress_bar.py[line:274] - INFO: epoch 004:    344 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.4, ups=0.79, wpb=111.2, bsz=40, num_updates=1580, lr=4.80886e-05, gnorm=0.791, clip=30, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6736
2022-10-10 18:47:38 - progress_bar.py[line:274] - INFO: epoch 004:    354 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.3, ups=0.77, wpb=111.4, bsz=40, num_updates=1590, lr=4.80633e-05, gnorm=0.64, clip=20, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6749
2022-10-10 18:47:51 - progress_bar.py[line:274] - INFO: epoch 004:    364 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.1, ups=0.79, wpb=111.2, bsz=40, num_updates=1600, lr=4.8038e-05, gnorm=0.599, clip=10, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=6762
2022-10-10 18:48:04 - progress_bar.py[line:274] - INFO: epoch 004:    374 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.9, ups=0.8, wpb=110.4, bsz=40, num_updates=1610, lr=4.80127e-05, gnorm=0.96, clip=50, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6774
2022-10-10 18:48:10 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 18:48:17 - progress_bar.py[line:274] - INFO: epoch 004:    385 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=80, ups=0.73, wpb=109.5, bsz=40, num_updates=1620, lr=4.79875e-05, gnorm=0.646, clip=30, loss_scale=512, train_wall=14, gb_free=10.8, ema_decay=0.9999, wall=6788
2022-10-10 18:48:30 - progress_bar.py[line:274] - INFO: epoch 004:    395 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.1, ups=0.81, wpb=111.4, bsz=40, num_updates=1630, lr=4.79622e-05, gnorm=0.696, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6800
2022-10-10 18:48:42 - progress_bar.py[line:274] - INFO: epoch 004:    405 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.6, ups=0.79, wpb=109.6, bsz=40, num_updates=1640, lr=4.79369e-05, gnorm=0.72, clip=30, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6813
2022-10-10 18:48:51 - train.py[line:339] - INFO: end of epoch 4 (average epoch stats below)
2022-10-10 18:48:51 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.249 | loss_v1 0 | loss_v2 0 | nll_loss 0.065 | ntokens 111.131 | nsentences 40 | sample_size 111.131 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.05 | wps 87.2 | ups 0.78 | wpb 111.1 | bsz 40 | num_updates 1647 | lr 4.79192e-05 | gnorm 0.71 | clip 21.7 | loss_scale 512 | train_wall 517 | gb_free 10.9 | ema_decay 0.9999 | wall 6822
2022-10-10 18:48:51 - trainer.py[line:643] - INFO: loading train data for epoch 5
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 18:48:51 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 18:48:52 - trainer.py[line:707] - INFO: begin training epoch 5
2022-10-10 18:48:52 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 18:48:58 - progress_bar.py[line:274] - INFO: epoch 005:      3 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=70.1, ups=0.63, wpb=111, bsz=40, num_updates=1650, lr=4.79116e-05, gnorm=0.662, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6829
2022-10-10 18:49:11 - progress_bar.py[line:274] - INFO: epoch 005:     13 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.7, ups=0.81, wpb=112.3, bsz=40, num_updates=1660, lr=4.78863e-05, gnorm=0.531, clip=10, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=6841
2022-10-10 18:49:23 - progress_bar.py[line:274] - INFO: epoch 005:     23 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.7, ups=0.81, wpb=110.8, bsz=40, num_updates=1670, lr=4.7861e-05, gnorm=0.755, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6854
2022-10-10 18:49:36 - progress_bar.py[line:274] - INFO: epoch 005:     33 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.4, ups=0.78, wpb=111.1, bsz=40, num_updates=1680, lr=4.78358e-05, gnorm=0.496, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=6867
2022-10-10 18:49:48 - progress_bar.py[line:274] - INFO: epoch 005:     43 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.2, ups=0.82, wpb=110.8, bsz=40, num_updates=1690, lr=4.78105e-05, gnorm=0.551, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6879
2022-10-10 18:50:00 - progress_bar.py[line:274] - INFO: epoch 005:     53 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.1, ups=0.82, wpb=110.5, bsz=40, num_updates=1700, lr=4.77852e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6891
2022-10-10 18:50:13 - progress_bar.py[line:274] - INFO: epoch 005:     63 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=85.1, ups=0.77, wpb=110.9, bsz=40, num_updates=1710, lr=4.77599e-05, gnorm=0.282, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6904
2022-10-10 18:50:26 - progress_bar.py[line:274] - INFO: epoch 005:     73 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.2, ups=0.78, wpb=110.6, bsz=40, num_updates=1720, lr=4.77346e-05, gnorm=0.632, clip=20, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=6917
2022-10-10 18:50:38 - progress_bar.py[line:274] - INFO: epoch 005:     83 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.2, ups=0.81, wpb=111, bsz=40, num_updates=1730, lr=4.77093e-05, gnorm=0.604, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6929
2022-10-10 18:50:51 - progress_bar.py[line:274] - INFO: epoch 005:     93 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.8, ups=0.79, wpb=111.7, bsz=40, num_updates=1740, lr=4.76841e-05, gnorm=0.331, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6942
2022-10-10 18:51:03 - progress_bar.py[line:274] - INFO: epoch 005:    103 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.8, wpb=111.6, bsz=40, num_updates=1750, lr=4.76588e-05, gnorm=0.399, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6954
2022-10-10 18:51:16 - progress_bar.py[line:274] - INFO: epoch 005:    113 / 412 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=91.7, ups=0.83, wpb=110.8, bsz=40, num_updates=1760, lr=4.76335e-05, gnorm=0.757, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6966
2022-10-10 18:51:29 - progress_bar.py[line:274] - INFO: epoch 005:    123 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83.8, ups=0.75, wpb=112, bsz=40, num_updates=1770, lr=4.76082e-05, gnorm=0.634, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6980
2022-10-10 18:51:42 - progress_bar.py[line:274] - INFO: epoch 005:    133 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.8, ups=0.76, wpb=111.7, bsz=40, num_updates=1780, lr=4.75829e-05, gnorm=0.6, clip=30, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=6993
2022-10-10 18:51:54 - progress_bar.py[line:274] - INFO: epoch 005:    143 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.6, ups=0.83, wpb=112.2, bsz=40, num_updates=1790, lr=4.75576e-05, gnorm=0.478, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=7005
2022-10-10 18:52:07 - progress_bar.py[line:274] - INFO: epoch 005:    153 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.2, ups=0.81, wpb=110.1, bsz=40, num_updates=1800, lr=4.75324e-05, gnorm=0.759, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=7017
2022-10-10 18:52:19 - progress_bar.py[line:274] - INFO: epoch 005:    163 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.2, ups=0.82, wpb=111.8, bsz=40, num_updates=1810, lr=4.75071e-05, gnorm=0.821, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=7030
2022-10-10 18:52:31 - progress_bar.py[line:274] - INFO: epoch 005:    173 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.4, ups=0.8, wpb=111.5, bsz=40, num_updates=1820, lr=4.74818e-05, gnorm=0.686, clip=20, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=7042
2022-10-10 18:52:44 - progress_bar.py[line:274] - INFO: epoch 005:    183 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.2, ups=0.82, wpb=111.1, bsz=40, num_updates=1830, lr=4.74565e-05, gnorm=0.711, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=7054
2022-10-10 18:52:56 - progress_bar.py[line:274] - INFO: epoch 005:    193 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.6, ups=0.79, wpb=110.5, bsz=40, num_updates=1840, lr=4.74312e-05, gnorm=0.836, clip=30, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=7067
2022-10-10 18:53:09 - progress_bar.py[line:274] - INFO: epoch 005:    203 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=83.4, ups=0.76, wpb=110.4, bsz=40, num_updates=1850, lr=4.74059e-05, gnorm=0.601, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=7080
2022-10-10 18:53:22 - progress_bar.py[line:274] - INFO: epoch 005:    213 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92, ups=0.82, wpb=112.3, bsz=40, num_updates=1860, lr=4.73807e-05, gnorm=0.528, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=7092
2022-10-10 18:53:34 - progress_bar.py[line:274] - INFO: epoch 005:    223 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87, ups=0.79, wpb=110.7, bsz=40, num_updates=1870, lr=4.73554e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=7105
2022-10-10 18:53:47 - progress_bar.py[line:274] - INFO: epoch 005:    233 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.1, ups=0.81, wpb=111.3, bsz=40, num_updates=1880, lr=4.73301e-05, gnorm=0.984, clip=40, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=7117
2022-10-10 18:53:59 - progress_bar.py[line:274] - INFO: epoch 005:    243 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.2, ups=0.82, wpb=111.8, bsz=40, num_updates=1890, lr=4.73048e-05, gnorm=0.675, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=7130
2022-10-10 18:54:12 - progress_bar.py[line:274] - INFO: epoch 005:    253 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.3, ups=0.79, wpb=110.4, bsz=40, num_updates=1900, lr=4.72795e-05, gnorm=0.407, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=7142
2022-10-10 18:54:24 - progress_bar.py[line:274] - INFO: epoch 005:    263 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.3, ups=0.8, wpb=110.5, bsz=40, num_updates=1910, lr=4.72542e-05, gnorm=0.556, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=7155
2022-10-10 18:54:37 - progress_bar.py[line:274] - INFO: epoch 005:    273 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.1, ups=0.81, wpb=112.9, bsz=40, num_updates=1920, lr=4.7229e-05, gnorm=0.632, clip=20, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=7167
2022-10-10 18:54:49 - progress_bar.py[line:274] - INFO: epoch 005:    283 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.5, ups=0.8, wpb=110.8, bsz=40, num_updates=1930, lr=4.72037e-05, gnorm=0.527, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=7180
2022-10-10 18:55:02 - progress_bar.py[line:274] - INFO: epoch 005:    293 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.8, ups=0.78, wpb=110.7, bsz=40, num_updates=1940, lr=4.71784e-05, gnorm=0.947, clip=30, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=7193
2022-10-10 18:55:15 - progress_bar.py[line:274] - INFO: epoch 005:    303 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.9, ups=0.78, wpb=112.8, bsz=40, num_updates=1950, lr=4.71531e-05, gnorm=0.425, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=7206
2022-10-10 18:55:27 - progress_bar.py[line:274] - INFO: epoch 005:    313 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.8, wpb=111.5, bsz=40, num_updates=1960, lr=4.71278e-05, gnorm=0.398, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=7218
2022-10-10 18:55:40 - progress_bar.py[line:274] - INFO: epoch 005:    323 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.5, ups=0.82, wpb=110.6, bsz=40, num_updates=1970, lr=4.71025e-05, gnorm=0.692, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=7230
2022-10-10 18:55:53 - progress_bar.py[line:274] - INFO: epoch 005:    333 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83.5, ups=0.76, wpb=109.7, bsz=40, num_updates=1980, lr=4.70773e-05, gnorm=0.475, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=7243
2022-10-10 18:56:05 - progress_bar.py[line:274] - INFO: epoch 005:    343 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.9, ups=0.8, wpb=110.5, bsz=40, num_updates=1990, lr=4.7052e-05, gnorm=0.53, clip=10, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=7256
2022-10-10 18:56:18 - progress_bar.py[line:274] - INFO: epoch 005:    353 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.6, ups=0.79, wpb=109, bsz=40, num_updates=2000, lr=4.70267e-05, gnorm=0.65, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=7269
2022-10-10 18:56:18 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 18:56:20 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 18:56:20 - train.py[line:551] - INFO: load:1.32 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 18:56:40 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.90 GiB already allocated; 6.01 GiB free; 31.10 GiB reserved in total by PyTorch)
2022-10-10 18:56:40 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 10        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9109 MB |   14340 MB |     880 TB |     880 TB |
|       from large pool |    8965 MB |   14195 MB |     880 TB |     880 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9109 MB |   14340 MB |     880 TB |     880 TB |
|       from large pool |    8965 MB |   14195 MB |     880 TB |     880 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31846 MB |   37492 MB |  153534 MB |  121688 MB |
|       from large pool |   31700 MB |   37346 MB |  153250 MB |  121550 MB |
|       from small pool |     146 MB |     152 MB |     284 MB |     138 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22736 MB |   27366 MB |     954 TB |     954 TB |
|       from large pool |   22734 MB |   27364 MB |     954 TB |     954 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |   38607 K  |   38604 K  |
|       from large pool |     563    |     575    |   13299 K  |   13298 K  |
|       from small pool |    3106    |    3116    |   25308 K  |   25305 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |   38607 K  |   38604 K  |
|       from large pool |     563    |     575    |   13299 K  |   13298 K  |
|       from small pool |    3106    |    3116    |   25308 K  |   25305 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     190    |     201    |     536    |     346    |
|       from large pool |     117    |     125    |     394    |     277    |
|       from small pool |      73    |      76    |     142    |      69    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     126    |     143    |   26267 K  |   26267 K  |
|       from large pool |      91    |      96    |    5066 K  |    5066 K  |
|       from small pool |      35    |      51    |   21200 K  |   21200 K  |
|===========================================================================|

2022-10-10 18:56:40 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-10 18:56:40 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-10 18:59:24 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 18:59:24 - train.py[line:551] - INFO: load:1.36 valid_run:184.52 task_valid:171.96 collect_output:8.84
2022-10-10 19:02:23 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 19:02:23 - train.py[line:551] - INFO: load:1.43 valid_run:363.17 task_valid:337.51 collect_output:19.45
2022-10-10 19:05:25 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 19:05:25 - train.py[line:551] - INFO: load:1.51 valid_run:544.71 task_valid:502.32 collect_output:34.09
2022-10-10 19:08:22 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 19:08:22 - train.py[line:551] - INFO: load:1.59 valid_run:722.44 task_valid:670.40 collect_output:41.42
2022-10-10 19:11:21 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 19:11:22 - train.py[line:551] - INFO: load:1.63 valid_run:901.32 task_valid:838.07 collect_output:50.43
2022-10-10 19:14:20 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 19:14:20 - train.py[line:551] - INFO: load:1.68 valid_run:1079.28 task_valid:1004.49 collect_output:59.95
2022-10-10 19:17:18 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 19:17:18 - train.py[line:551] - INFO: load:1.72 valid_run:1257.21 task_valid:1168.97 collect_output:71.12
2022-10-10 19:20:14 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 19:20:14 - train.py[line:551] - INFO: load:1.76 valid_run:1433.88 task_valid:1331.70 collect_output:82.76
2022-10-10 19:23:13 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 19:23:13 - train.py[line:551] - INFO: load:1.81 valid_run:1612.14 task_valid:1498.53 collect_output:91.92
2022-10-10 19:26:10 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 19:26:10 - train.py[line:551] - INFO: load:1.86 valid_run:1789.64 task_valid:1664.89 collect_output:100.95
2022-10-10 19:29:06 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 19:29:06 - train.py[line:551] - INFO: load:1.91 valid_run:1965.11 task_valid:1830.11 collect_output:109.05
2022-10-10 19:32:03 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 19:32:03 - train.py[line:551] - INFO: load:1.97 valid_run:2142.34 task_valid:1997.04 collect_output:117.12
2022-10-10 19:35:06 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 19:35:06 - train.py[line:551] - INFO: load:2.06 valid_run:2325.25 task_valid:2166.38 collect_output:128.55
2022-10-10 19:38:20 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 19:38:20 - train.py[line:551] - INFO: load:2.11 valid_run:2518.67 task_valid:2349.98 collect_output:136.28
2022-10-10 19:41:32 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 19:41:32 - train.py[line:551] - INFO: load:2.20 valid_run:2710.59 task_valid:2531.23 collect_output:144.93
2022-10-10 19:44:45 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 19:44:45 - train.py[line:551] - INFO: load:2.25 valid_run:2903.52 task_valid:2713.36 collect_output:153.38
2022-10-10 19:48:02 - train.py[line:549] - INFO: 3400 / 4988
2022-10-10 19:48:02 - train.py[line:551] - INFO: load:2.35 valid_run:3099.96 task_valid:2896.82 collect_output:164.11
2022-10-10 19:51:20 - train.py[line:549] - INFO: 3600 / 4988
2022-10-10 19:51:20 - train.py[line:551] - INFO: load:2.40 valid_run:3298.57 task_valid:3085.76 collect_output:171.76
2022-10-10 19:54:37 - train.py[line:549] - INFO: 3800 / 4988
2022-10-10 19:54:37 - train.py[line:551] - INFO: load:2.43 valid_run:3495.20 task_valid:3270.36 collect_output:181.87
2022-10-10 19:57:59 - train.py[line:549] - INFO: 4000 / 4988
2022-10-10 19:57:59 - train.py[line:551] - INFO: load:2.46 valid_run:3696.80 task_valid:3459.34 collect_output:192.41
2022-10-10 20:01:21 - train.py[line:549] - INFO: 4200 / 4988
2022-10-10 20:01:21 - train.py[line:551] - INFO: load:2.50 valid_run:3898.54 task_valid:3647.49 collect_output:203.71
2022-10-10 20:04:38 - train.py[line:549] - INFO: 4400 / 4988
2022-10-10 20:04:38 - train.py[line:551] - INFO: load:2.58 valid_run:4095.53 task_valid:3836.50 collect_output:209.57
2022-10-10 20:07:36 - train.py[line:549] - INFO: 4600 / 4988
2022-10-10 20:07:36 - train.py[line:551] - INFO: load:2.62 valid_run:4273.47 task_valid:4003.80 collect_output:218.13
2022-10-10 20:10:36 - train.py[line:549] - INFO: 4800 / 4988
2022-10-10 20:10:36 - train.py[line:551] - INFO: load:2.68 valid_run:4453.71 task_valid:4173.32 collect_output:226.83

====================================================================================================
SGG eval:     R @ 50: 0.6715;     R @ 100: 0.7042;     R @ 500: 0.7277;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4605;    mR @ 100: 0.4981;    mR @ 500: 0.5413;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.8125) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9402) (says:0.0000) (sitting on:0.7602) (standing on:0.4760) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6715;     R @ 100: 0.7042;     R @ 500: 0.7277;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4605;    mR @ 100: 0.4981;    mR @ 500: 0.5413;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.8125) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9402) (says:0.0000) (sitting on:0.7602) (standing on:0.4760) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 20:13:35 - train.py[line:487] - INFO: 0.7042104150751208
2022-10-10 20:13:35 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-10 20:13:35 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 0.237 | loss_v1 0 | loss_v2 0 | nll_loss 0.067 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.70421 | ppl 1.05 | vqa_score 0.5586 | wps 96.8 | wpb 89.9 | bsz 30 | num_updates 2000 | best_R@100 0.70421
2022-10-10 20:13:35 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 2000 updates
2022-10-10 20:13:35 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_5_2000.pt
2022-10-10 20:13:42 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_5_2000.pt
2022-10-10 20:13:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_5_2000.pt (epoch 5 @ 2000 updates, score 0.7042104150751208) (writing took 14.344188202172518 seconds)
2022-10-10 20:14:04 - progress_bar.py[line:274] - INFO: epoch 005:    363 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=0.2, ups=0, wpb=111.4, bsz=40, num_updates=2010, lr=4.70014e-05, gnorm=0.901, clip=40, loss_scale=512, train_wall=14, gb_free=10, ema_decay=0.9999, wall=11935
2022-10-10 20:14:17 - progress_bar.py[line:274] - INFO: epoch 005:    373 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.4, ups=0.76, wpb=112, bsz=40, num_updates=2020, lr=4.69761e-05, gnorm=0.628, clip=20, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=11948
2022-10-10 20:14:30 - progress_bar.py[line:274] - INFO: epoch 005:    383 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.8, ups=0.81, wpb=110.9, bsz=40, num_updates=2030, lr=4.69508e-05, gnorm=0.697, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11960
2022-10-10 20:14:42 - progress_bar.py[line:274] - INFO: epoch 005:    393 / 412 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=92, ups=0.83, wpb=110.9, bsz=40, num_updates=2040, lr=4.69256e-05, gnorm=0.777, clip=20, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=11972
2022-10-10 20:14:54 - progress_bar.py[line:274] - INFO: epoch 005:    403 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.4, ups=0.79, wpb=111.7, bsz=40, num_updates=2050, lr=4.69003e-05, gnorm=0.356, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=11985
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 20:15:05 - train.py[line:339] - INFO: end of epoch 5 (average epoch stats below)
2022-10-10 20:15:06 - progress_bar.py[line:282] - INFO: epoch 005 | loss 0.246 | loss_v1 0 | loss_v2 0 | nll_loss 0.061 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 8.8 | ups 0.08 | wpb 111.1 | bsz 40 | num_updates 2059 | lr 4.68775e-05 | gnorm 0.621 | clip 17.2 | loss_scale 512 | train_wall 516 | gb_free 10.7 | ema_decay 0.9999 | wall 11996
2022-10-10 20:15:06 - trainer.py[line:643] - INFO: loading train data for epoch 6
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 20:15:06 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 20:15:06 - trainer.py[line:707] - INFO: begin training epoch 6
2022-10-10 20:15:06 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 20:15:10 - progress_bar.py[line:274] - INFO: epoch 006:      1 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=69.2, ups=0.63, wpb=110, bsz=40, num_updates=2060, lr=4.6875e-05, gnorm=0.539, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12001
2022-10-10 20:15:23 - progress_bar.py[line:274] - INFO: epoch 006:     11 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.4, ups=0.78, wpb=111.8, bsz=40, num_updates=2070, lr=4.68497e-05, gnorm=0.676, clip=20, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=12014
2022-10-10 20:15:36 - progress_bar.py[line:274] - INFO: epoch 006:     21 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.4, ups=0.8, wpb=110.7, bsz=40, num_updates=2080, lr=4.68244e-05, gnorm=0.441, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12026
2022-10-10 20:15:48 - progress_bar.py[line:274] - INFO: epoch 006:     31 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.6, ups=0.79, wpb=110.5, bsz=40, num_updates=2090, lr=4.67992e-05, gnorm=0.41, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12039
2022-10-10 20:16:01 - progress_bar.py[line:274] - INFO: epoch 006:     41 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.2, ups=0.79, wpb=111.1, bsz=40, num_updates=2100, lr=4.67739e-05, gnorm=0.541, clip=20, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=12052
2022-10-10 20:16:13 - progress_bar.py[line:274] - INFO: epoch 006:     51 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.5, ups=0.8, wpb=111.7, bsz=40, num_updates=2110, lr=4.67486e-05, gnorm=0.475, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=12064
2022-10-10 20:16:26 - progress_bar.py[line:274] - INFO: epoch 006:     61 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.4, ups=0.79, wpb=111.9, bsz=40, num_updates=2120, lr=4.67233e-05, gnorm=0.651, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12077
2022-10-10 20:16:39 - progress_bar.py[line:274] - INFO: epoch 006:     71 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.1, ups=0.78, wpb=110.5, bsz=40, num_updates=2130, lr=4.6698e-05, gnorm=0.897, clip=40, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=12090
2022-10-10 20:16:52 - progress_bar.py[line:274] - INFO: epoch 006:     81 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.6, ups=0.77, wpb=109.5, bsz=40, num_updates=2140, lr=4.66727e-05, gnorm=0.433, clip=0, loss_scale=1024, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=12102
2022-10-10 20:17:05 - progress_bar.py[line:274] - INFO: epoch 006:     91 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=84.6, ups=0.77, wpb=110.4, bsz=40, num_updates=2150, lr=4.66475e-05, gnorm=0.477, clip=20, loss_scale=1024, train_wall=13, gb_free=11.1, ema_decay=0.9999, wall=12116
2022-10-10 20:17:17 - progress_bar.py[line:274] - INFO: epoch 006:    101 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.4, ups=0.79, wpb=111, bsz=40, num_updates=2160, lr=4.66222e-05, gnorm=0.503, clip=20, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12128
2022-10-10 20:17:30 - progress_bar.py[line:274] - INFO: epoch 006:    111 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.1, ups=0.78, wpb=112.5, bsz=40, num_updates=2170, lr=4.65969e-05, gnorm=1.239, clip=50, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12141
2022-10-10 20:17:43 - progress_bar.py[line:274] - INFO: epoch 006:    121 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.3, ups=0.79, wpb=112.8, bsz=40, num_updates=2180, lr=4.65716e-05, gnorm=0.899, clip=30, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12154
2022-10-10 20:17:56 - progress_bar.py[line:274] - INFO: epoch 006:    131 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.7, ups=0.77, wpb=111.2, bsz=40, num_updates=2190, lr=4.65463e-05, gnorm=0.532, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12167
2022-10-10 20:18:09 - progress_bar.py[line:274] - INFO: epoch 006:    141 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.7, ups=0.78, wpb=111.1, bsz=40, num_updates=2200, lr=4.6521e-05, gnorm=0.474, clip=10, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12179
2022-10-10 20:18:22 - progress_bar.py[line:274] - INFO: epoch 006:    151 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.5, ups=0.77, wpb=110.7, bsz=40, num_updates=2210, lr=4.64958e-05, gnorm=0.524, clip=20, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12192
2022-10-10 20:18:35 - progress_bar.py[line:274] - INFO: epoch 006:    161 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.7, ups=0.78, wpb=111.7, bsz=40, num_updates=2220, lr=4.64705e-05, gnorm=0.856, clip=30, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=12205
2022-10-10 20:18:47 - progress_bar.py[line:274] - INFO: epoch 006:    171 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.4, ups=0.82, wpb=110.7, bsz=40, num_updates=2230, lr=4.64452e-05, gnorm=0.467, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12218
2022-10-10 20:19:00 - progress_bar.py[line:274] - INFO: epoch 006:    181 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.1, ups=0.78, wpb=111.7, bsz=40, num_updates=2240, lr=4.64199e-05, gnorm=0.689, clip=30, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12230
2022-10-10 20:19:13 - progress_bar.py[line:274] - INFO: epoch 006:    191 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83.9, ups=0.77, wpb=109.2, bsz=40, num_updates=2250, lr=4.63946e-05, gnorm=0.549, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12243
2022-10-10 20:19:26 - progress_bar.py[line:274] - INFO: epoch 006:    201 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=83.7, ups=0.75, wpb=110.9, bsz=40, num_updates=2260, lr=4.63693e-05, gnorm=0.506, clip=10, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12257
2022-10-10 20:19:39 - progress_bar.py[line:274] - INFO: epoch 006:    211 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.5, ups=0.79, wpb=110.9, bsz=40, num_updates=2270, lr=4.63441e-05, gnorm=0.373, clip=0, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12269
2022-10-10 20:19:52 - progress_bar.py[line:274] - INFO: epoch 006:    221 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.7, ups=0.75, wpb=112.8, bsz=40, num_updates=2280, lr=4.63188e-05, gnorm=0.53, clip=10, loss_scale=1024, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=12283
2022-10-10 20:20:05 - progress_bar.py[line:274] - INFO: epoch 006:    231 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.79, wpb=112.6, bsz=40, num_updates=2290, lr=4.62935e-05, gnorm=0.454, clip=10, loss_scale=1024, train_wall=13, gb_free=11, ema_decay=0.9999, wall=12295
2022-10-10 20:20:17 - progress_bar.py[line:274] - INFO: epoch 006:    241 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.5, ups=0.79, wpb=111.8, bsz=40, num_updates=2300, lr=4.62682e-05, gnorm=0.568, clip=10, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12308
2022-10-10 20:20:30 - progress_bar.py[line:274] - INFO: epoch 006:    251 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.5, ups=0.8, wpb=109.7, bsz=40, num_updates=2310, lr=4.62429e-05, gnorm=0.787, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12321
2022-10-10 20:20:42 - progress_bar.py[line:274] - INFO: epoch 006:    261 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.6, ups=0.83, wpb=110.9, bsz=40, num_updates=2320, lr=4.62176e-05, gnorm=0.687, clip=30, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12333
2022-10-10 20:20:54 - progress_bar.py[line:274] - INFO: epoch 006:    271 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.9, ups=0.8, wpb=110.6, bsz=40, num_updates=2330, lr=4.61924e-05, gnorm=0.609, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12345
2022-10-10 20:21:07 - progress_bar.py[line:274] - INFO: epoch 006:    281 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.5, ups=0.79, wpb=110.9, bsz=40, num_updates=2340, lr=4.61671e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12358
2022-10-10 20:21:20 - progress_bar.py[line:274] - INFO: epoch 006:    291 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.7, ups=0.77, wpb=111.2, bsz=40, num_updates=2350, lr=4.61418e-05, gnorm=0.447, clip=0, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12371
2022-10-10 20:21:33 - progress_bar.py[line:274] - INFO: epoch 006:    301 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.4, ups=0.8, wpb=111.7, bsz=40, num_updates=2360, lr=4.61165e-05, gnorm=0.308, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=12383
2022-10-10 20:21:45 - progress_bar.py[line:274] - INFO: epoch 006:    311 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.3, ups=0.79, wpb=111.6, bsz=40, num_updates=2370, lr=4.60912e-05, gnorm=0.535, clip=20, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=12396
2022-10-10 20:21:58 - progress_bar.py[line:274] - INFO: epoch 006:    321 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88, ups=0.78, wpb=112.7, bsz=40, num_updates=2380, lr=4.60659e-05, gnorm=0.858, clip=30, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12409
2022-10-10 20:22:11 - progress_bar.py[line:274] - INFO: epoch 006:    331 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.6, ups=0.81, wpb=111.2, bsz=40, num_updates=2390, lr=4.60407e-05, gnorm=0.547, clip=10, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12421
2022-10-10 20:22:24 - progress_bar.py[line:274] - INFO: epoch 006:    341 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.9, ups=0.78, wpb=110, bsz=40, num_updates=2400, lr=4.60154e-05, gnorm=0.446, clip=10, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=12434
2022-10-10 20:22:36 - progress_bar.py[line:274] - INFO: epoch 006:    351 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.2, ups=0.8, wpb=109.6, bsz=40, num_updates=2410, lr=4.59901e-05, gnorm=0.729, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12447
2022-10-10 20:22:48 - progress_bar.py[line:274] - INFO: epoch 006:    361 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.8, ups=0.81, wpb=110.1, bsz=40, num_updates=2420, lr=4.59648e-05, gnorm=0.937, clip=50, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12459
2022-10-10 20:23:00 - progress_bar.py[line:274] - INFO: epoch 006:    371 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.5, ups=0.83, wpb=111.4, bsz=40, num_updates=2430, lr=4.59395e-05, gnorm=0.942, clip=40, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12471
2022-10-10 20:23:13 - progress_bar.py[line:274] - INFO: epoch 006:    381 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.7, ups=0.8, wpb=112.1, bsz=40, num_updates=2440, lr=4.59142e-05, gnorm=0.557, clip=20, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=12484
2022-10-10 20:23:25 - progress_bar.py[line:274] - INFO: epoch 006:    391 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91, ups=0.82, wpb=111.1, bsz=40, num_updates=2450, lr=4.5889e-05, gnorm=0.543, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12496
2022-10-10 20:23:37 - progress_bar.py[line:274] - INFO: epoch 006:    401 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.7, ups=0.83, wpb=110.7, bsz=40, num_updates=2460, lr=4.58637e-05, gnorm=0.724, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12508
2022-10-10 20:23:49 - progress_bar.py[line:274] - INFO: epoch 006:    411 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=93.9, ups=0.85, wpb=110.7, bsz=40, num_updates=2470, lr=4.58384e-05, gnorm=0.826, clip=50, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12520
2022-10-10 20:23:50 - train.py[line:339] - INFO: end of epoch 6 (average epoch stats below)
2022-10-10 20:23:50 - progress_bar.py[line:282] - INFO: epoch 006 | loss 0.244 | loss_v1 0 | loss_v2 0 | nll_loss 0.059 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 87.2 | ups 0.79 | wpb 111.1 | bsz 40 | num_updates 2471 | lr 4.58359e-05 | gnorm 0.621 | clip 18 | loss_scale 1024 | train_wall 517 | gb_free 10 | ema_decay 0.9999 | wall 12521
2022-10-10 20:23:50 - trainer.py[line:643] - INFO: loading train data for epoch 7
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 20:23:50 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 20:23:51 - trainer.py[line:707] - INFO: begin training epoch 7
2022-10-10 20:23:51 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 20:24:05 - progress_bar.py[line:274] - INFO: epoch 007:      9 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=72, ups=0.64, wpb=112.8, bsz=40, num_updates=2480, lr=4.58131e-05, gnorm=0.795, clip=30, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12535
2022-10-10 20:24:14 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 20:24:18 - progress_bar.py[line:274] - INFO: epoch 007:     20 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=81.3, ups=0.73, wpb=111.8, bsz=40, num_updates=2490, lr=4.57878e-05, gnorm=0.574, clip=10, loss_scale=512, train_wall=14, gb_free=10.9, ema_decay=0.9999, wall=12549
2022-10-10 20:24:31 - progress_bar.py[line:274] - INFO: epoch 007:     30 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.7, ups=0.79, wpb=110.5, bsz=40, num_updates=2500, lr=4.57625e-05, gnorm=0.886, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12562
2022-10-10 20:24:44 - progress_bar.py[line:274] - INFO: epoch 007:     40 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.2, ups=0.78, wpb=111.3, bsz=40, num_updates=2510, lr=4.57373e-05, gnorm=0.749, clip=40, loss_scale=512, train_wall=13, gb_free=11.4, ema_decay=0.9999, wall=12575
2022-10-10 20:24:56 - progress_bar.py[line:274] - INFO: epoch 007:     50 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.2, ups=0.8, wpb=111.1, bsz=40, num_updates=2520, lr=4.5712e-05, gnorm=0.721, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12587
2022-10-10 20:25:09 - progress_bar.py[line:274] - INFO: epoch 007:     60 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88, ups=0.79, wpb=111.3, bsz=40, num_updates=2530, lr=4.56867e-05, gnorm=0.332, clip=0, loss_scale=512, train_wall=13, gb_free=10, ema_decay=0.9999, wall=12600
2022-10-10 20:25:22 - progress_bar.py[line:274] - INFO: epoch 007:     70 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.1, ups=0.77, wpb=109.8, bsz=40, num_updates=2540, lr=4.56614e-05, gnorm=0.639, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12613
2022-10-10 20:25:35 - progress_bar.py[line:274] - INFO: epoch 007:     80 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87, ups=0.79, wpb=110.5, bsz=40, num_updates=2550, lr=4.56361e-05, gnorm=0.326, clip=0, loss_scale=512, train_wall=13, gb_free=10, ema_decay=0.9999, wall=12625
2022-10-10 20:25:47 - progress_bar.py[line:274] - INFO: epoch 007:     90 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.5, ups=0.8, wpb=111, bsz=40, num_updates=2560, lr=4.56108e-05, gnorm=0.729, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12638
2022-10-10 20:26:00 - progress_bar.py[line:274] - INFO: epoch 007:    100 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=84.5, ups=0.77, wpb=110.2, bsz=40, num_updates=2570, lr=4.55856e-05, gnorm=0.488, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12651
2022-10-10 20:26:13 - progress_bar.py[line:274] - INFO: epoch 007:    110 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89, ups=0.8, wpb=111.4, bsz=40, num_updates=2580, lr=4.55603e-05, gnorm=0.403, clip=0, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=12663
2022-10-10 20:26:26 - progress_bar.py[line:274] - INFO: epoch 007:    120 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.3, ups=0.78, wpb=111.8, bsz=40, num_updates=2590, lr=4.5535e-05, gnorm=0.684, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12676
2022-10-10 20:26:38 - progress_bar.py[line:274] - INFO: epoch 007:    130 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.3, ups=0.81, wpb=110.6, bsz=40, num_updates=2600, lr=4.55097e-05, gnorm=0.543, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12689
2022-10-10 20:26:51 - progress_bar.py[line:274] - INFO: epoch 007:    140 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.4, ups=0.77, wpb=111.6, bsz=40, num_updates=2610, lr=4.54844e-05, gnorm=0.467, clip=10, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=12702
2022-10-10 20:27:04 - progress_bar.py[line:274] - INFO: epoch 007:    150 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.9, ups=0.77, wpb=111.4, bsz=40, num_updates=2620, lr=4.54591e-05, gnorm=0.705, clip=30, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=12715
2022-10-10 20:27:16 - progress_bar.py[line:274] - INFO: epoch 007:    160 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89, ups=0.8, wpb=111.7, bsz=40, num_updates=2630, lr=4.54339e-05, gnorm=0.295, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=12727
2022-10-10 20:27:29 - progress_bar.py[line:274] - INFO: epoch 007:    170 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.4, ups=0.8, wpb=112.2, bsz=40, num_updates=2640, lr=4.54086e-05, gnorm=1.181, clip=40, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=12740
2022-10-10 20:27:42 - progress_bar.py[line:274] - INFO: epoch 007:    180 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.7, ups=0.8, wpb=111.3, bsz=40, num_updates=2650, lr=4.53833e-05, gnorm=0.576, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12752
2022-10-10 20:27:54 - progress_bar.py[line:274] - INFO: epoch 007:    190 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.4, ups=0.81, wpb=111.7, bsz=40, num_updates=2660, lr=4.5358e-05, gnorm=0.689, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12765
2022-10-10 20:28:06 - progress_bar.py[line:274] - INFO: epoch 007:    200 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.2, ups=0.8, wpb=111.5, bsz=40, num_updates=2670, lr=4.53327e-05, gnorm=1.101, clip=40, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=12777
2022-10-10 20:28:19 - progress_bar.py[line:274] - INFO: epoch 007:    210 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.6, ups=0.81, wpb=110.6, bsz=40, num_updates=2680, lr=4.53074e-05, gnorm=0.518, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12790
2022-10-10 20:28:31 - progress_bar.py[line:274] - INFO: epoch 007:    220 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.6, ups=0.81, wpb=110.9, bsz=40, num_updates=2690, lr=4.52822e-05, gnorm=1.055, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12802
2022-10-10 20:28:45 - progress_bar.py[line:274] - INFO: epoch 007:    230 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=81.4, ups=0.74, wpb=109.9, bsz=40, num_updates=2700, lr=4.52569e-05, gnorm=0.707, clip=30, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=12815
2022-10-10 20:28:58 - progress_bar.py[line:274] - INFO: epoch 007:    240 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.4, ups=0.78, wpb=109.5, bsz=40, num_updates=2710, lr=4.52316e-05, gnorm=0.428, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12828
2022-10-10 20:29:10 - progress_bar.py[line:274] - INFO: epoch 007:    250 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.6, ups=0.79, wpb=108.7, bsz=40, num_updates=2720, lr=4.52063e-05, gnorm=0.633, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12841
2022-10-10 20:29:23 - progress_bar.py[line:274] - INFO: epoch 007:    260 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=84.8, ups=0.77, wpb=110.6, bsz=40, num_updates=2730, lr=4.5181e-05, gnorm=0.219, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12854
2022-10-10 20:29:37 - progress_bar.py[line:274] - INFO: epoch 007:    270 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.4, ups=0.76, wpb=111.7, bsz=40, num_updates=2740, lr=4.51557e-05, gnorm=0.398, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12867
2022-10-10 20:29:49 - progress_bar.py[line:274] - INFO: epoch 007:    280 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.1, ups=0.79, wpb=111.4, bsz=40, num_updates=2750, lr=4.51305e-05, gnorm=0.418, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12880
2022-10-10 20:30:02 - progress_bar.py[line:274] - INFO: epoch 007:    290 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.8, ups=0.78, wpb=111.2, bsz=40, num_updates=2760, lr=4.51052e-05, gnorm=0.613, clip=20, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=12893
2022-10-10 20:30:15 - progress_bar.py[line:274] - INFO: epoch 007:    300 / 412 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.4, ups=0.8, wpb=111.6, bsz=40, num_updates=2770, lr=4.50799e-05, gnorm=0.357, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12905
2022-10-10 20:30:26 - progress_bar.py[line:274] - INFO: epoch 007:    310 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=94.3, ups=0.84, wpb=112.2, bsz=40, num_updates=2780, lr=4.50546e-05, gnorm=0.752, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12917
2022-10-10 20:30:39 - progress_bar.py[line:274] - INFO: epoch 007:    320 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.4, ups=0.79, wpb=111.4, bsz=40, num_updates=2790, lr=4.50293e-05, gnorm=0.731, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12930
2022-10-10 20:30:52 - progress_bar.py[line:274] - INFO: epoch 007:    330 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.6, ups=0.77, wpb=110.3, bsz=40, num_updates=2800, lr=4.5004e-05, gnorm=0.608, clip=10, loss_scale=512, train_wall=13, gb_free=11.1, ema_decay=0.9999, wall=12943
2022-10-10 20:31:05 - progress_bar.py[line:274] - INFO: epoch 007:    340 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.8, ups=0.78, wpb=111.7, bsz=40, num_updates=2810, lr=4.49788e-05, gnorm=0.555, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12956
2022-10-10 20:31:18 - progress_bar.py[line:274] - INFO: epoch 007:    350 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.5, ups=0.8, wpb=110.8, bsz=40, num_updates=2820, lr=4.49535e-05, gnorm=0.782, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12968
2022-10-10 20:31:30 - progress_bar.py[line:274] - INFO: epoch 007:    360 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.3, ups=0.79, wpb=112, bsz=40, num_updates=2830, lr=4.49282e-05, gnorm=0.722, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12981
2022-10-10 20:31:43 - progress_bar.py[line:274] - INFO: epoch 007:    370 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.8, ups=0.77, wpb=111.4, bsz=40, num_updates=2840, lr=4.49029e-05, gnorm=0.41, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12994
2022-10-10 20:31:57 - progress_bar.py[line:274] - INFO: epoch 007:    380 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=82.2, ups=0.75, wpb=110, bsz=40, num_updates=2850, lr=4.48776e-05, gnorm=0.452, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=13007
2022-10-10 20:32:09 - progress_bar.py[line:274] - INFO: epoch 007:    390 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.8, ups=0.78, wpb=113, bsz=40, num_updates=2860, lr=4.48523e-05, gnorm=0.474, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13020
2022-10-10 20:32:22 - progress_bar.py[line:274] - INFO: epoch 007:    400 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.9, ups=0.82, wpb=111.8, bsz=40, num_updates=2870, lr=4.48271e-05, gnorm=0.51, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13032
2022-10-10 20:32:34 - progress_bar.py[line:274] - INFO: epoch 007:    410 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.3, ups=0.8, wpb=110.4, bsz=40, num_updates=2880, lr=4.48018e-05, gnorm=0.485, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=13045
2022-10-10 20:32:37 - train.py[line:339] - INFO: end of epoch 7 (average epoch stats below)
2022-10-10 20:32:37 - progress_bar.py[line:282] - INFO: epoch 007 | loss 0.245 | loss_v1 0 | loss_v2 0 | nll_loss 0.06 | ntokens 111.122 | nsentences 40 | sample_size 111.122 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 86.8 | ups 0.78 | wpb 111.1 | bsz 40 | num_updates 2882 | lr 4.47967e-05 | gnorm 0.602 | clip 16.3 | loss_scale 512 | train_wall 519 | gb_free 11.1 | ema_decay 0.9999 | wall 13047
2022-10-10 20:32:37 - trainer.py[line:643] - INFO: loading train data for epoch 8
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 20:32:37 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 20:32:37 - trainer.py[line:707] - INFO: begin training epoch 8
2022-10-10 20:32:37 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 20:32:50 - progress_bar.py[line:274] - INFO: epoch 008:      8 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=68.5, ups=0.62, wpb=111.3, bsz=40, num_updates=2890, lr=4.47765e-05, gnorm=0.555, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=13061
2022-10-10 20:33:03 - progress_bar.py[line:274] - INFO: epoch 008:     18 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.4, ups=0.8, wpb=111.4, bsz=40, num_updates=2900, lr=4.47512e-05, gnorm=0.401, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=13074
2022-10-10 20:33:16 - progress_bar.py[line:274] - INFO: epoch 008:     28 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=85.7, ups=0.77, wpb=111.3, bsz=40, num_updates=2910, lr=4.47259e-05, gnorm=0.437, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=13087
2022-10-10 20:33:29 - progress_bar.py[line:274] - INFO: epoch 008:     38 / 412 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83.7, ups=0.76, wpb=110.4, bsz=40, num_updates=2920, lr=4.47006e-05, gnorm=0.411, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=13100
2022-10-10 20:33:42 - progress_bar.py[line:274] - INFO: epoch 008:     48 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.1, ups=0.78, wpb=108.5, bsz=40, num_updates=2930, lr=4.46754e-05, gnorm=0.393, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=13113
2022-10-10 20:33:55 - progress_bar.py[line:274] - INFO: epoch 008:     58 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.4, ups=0.77, wpb=110.5, bsz=40, num_updates=2940, lr=4.46501e-05, gnorm=0.371, clip=10, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=13126
2022-10-10 20:34:07 - progress_bar.py[line:274] - INFO: epoch 008:     68 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.4, ups=0.8, wpb=111.3, bsz=40, num_updates=2950, lr=4.46248e-05, gnorm=0.525, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=13138
2022-10-10 20:34:20 - progress_bar.py[line:274] - INFO: epoch 008:     78 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.4, ups=0.77, wpb=111.7, bsz=40, num_updates=2960, lr=4.45995e-05, gnorm=0.375, clip=0, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=13151
2022-10-10 20:34:33 - progress_bar.py[line:274] - INFO: epoch 008:     88 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.2, ups=0.77, wpb=111.1, bsz=40, num_updates=2970, lr=4.45742e-05, gnorm=0.566, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=13164
2022-10-10 20:34:46 - progress_bar.py[line:274] - INFO: epoch 008:     98 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.7, ups=0.77, wpb=111.6, bsz=40, num_updates=2980, lr=4.45489e-05, gnorm=0.333, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=13177
2022-10-10 20:34:59 - progress_bar.py[line:274] - INFO: epoch 008:    108 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=85.5, ups=0.77, wpb=110.7, bsz=40, num_updates=2990, lr=4.45237e-05, gnorm=0.46, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=13190
2022-10-10 20:35:12 - progress_bar.py[line:274] - INFO: epoch 008:    118 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.6, ups=0.78, wpb=111.8, bsz=40, num_updates=3000, lr=4.44984e-05, gnorm=0.492, clip=10, loss_scale=1024, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=13203
2022-10-10 20:35:12 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 20:35:14 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 20:35:14 - train.py[line:551] - INFO: load:1.46 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 20:35:15 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 39.59 GiB total capacity; 8.40 GiB already allocated; 5.22 GiB free; 31.89 GiB reserved in total by PyTorch)
2022-10-10 20:35:15 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8603 MB |    9735 MB |    1586 TB |    1586 TB |
|       from large pool |    8458 MB |    9590 MB |    1586 TB |    1586 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8603 MB |    9735 MB |    1586 TB |    1586 TB |
|       from large pool |    8458 MB |    9590 MB |    1586 TB |    1586 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32652 MB |   32652 MB |  172770 MB |  140118 MB |
|       from large pool |   32506 MB |   32506 MB |  172462 MB |  139956 MB |
|       from small pool |     146 MB |     146 MB |     308 MB |     162 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24048 MB |   28123 MB |    1669 TB |    1669 TB |
|       from large pool |   24047 MB |   28121 MB |    1669 TB |    1669 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |   71674 K  |   71670 K  |
|       from large pool |     563    |     575    |   23833 K  |   23833 K  |
|       from small pool |    3095    |    3114    |   47840 K  |   47837 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |   71674 K  |   71670 K  |
|       from large pool |     563    |     575    |   23833 K  |   23833 K  |
|       from small pool |    3095    |    3114    |   47840 K  |   47837 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     142    |     142    |     554    |     412    |
|       from large pool |      69    |      69    |     400    |     331    |
|       from small pool |      73    |      73    |     154    |      81    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      94    |      98    |   52314 K  |   52314 K  |
|       from large pool |      53    |      55    |   11446 K  |   11446 K  |
|       from small pool |      41    |      48    |   40867 K  |   40867 K  |
|===========================================================================|

2022-10-10 20:35:15 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-10 20:35:15 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-10 20:35:15 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.86 GiB already allocated; 5.76 GiB free; 31.34 GiB reserved in total by PyTorch)
2022-10-10 20:35:15 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-10 20:35:15 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 15        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9072 MB |   10296 MB |    1590 TB |    1590 TB |
|       from large pool |    8927 MB |   10151 MB |    1589 TB |    1589 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9072 MB |   10296 MB |    1590 TB |    1590 TB |
|       from large pool |    8927 MB |   10151 MB |    1589 TB |    1589 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32096 MB |   32648 MB |  177520 MB |  145424 MB |
|       from large pool |   31950 MB |   32496 MB |  177194 MB |  145244 MB |
|       from small pool |     146 MB |     152 MB |     326 MB |     180 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   23023 MB |   27534 MB |    1590 TB |    1590 TB |
|       from large pool |   23022 MB |   27532 MB |    1589 TB |    1589 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |   71667 K  |   71663 K  |
|       from large pool |     563    |     575    |   23831 K  |   23831 K  |
|       from small pool |    3095    |    3114    |   47835 K  |   47832 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |   71667 K  |   71663 K  |
|       from large pool |     563    |     575    |   23831 K  |   23831 K  |
|       from small pool |    3095    |    3114    |   47835 K  |   47832 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     190    |     198    |     512    |     322    |
|       from large pool |     117    |     122    |     349    |     232    |
|       from small pool |      73    |      76    |     163    |      90    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     124    |     130    |   49691 K  |   49691 K  |
|       from large pool |      93    |      96    |    8275 K  |    8275 K  |
|       from small pool |      31    |      37    |   41416 K  |   41416 K  |
|===========================================================================|

2022-10-10 20:35:15 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-10 20:38:14 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 20:38:14 - train.py[line:551] - INFO: load:1.50 valid_run:180.24 task_valid:169.61 collect_output:7.05
2022-10-10 20:41:08 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 20:41:08 - train.py[line:551] - INFO: load:1.56 valid_run:353.58 task_valid:329.78 collect_output:18.23
2022-10-10 20:44:06 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 20:44:06 - train.py[line:551] - INFO: load:1.59 valid_run:531.51 task_valid:492.98 collect_output:31.03
2022-10-10 20:47:02 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 20:47:02 - train.py[line:551] - INFO: load:1.63 valid_run:707.36 task_valid:658.64 collect_output:39.01
2022-10-10 20:50:00 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 20:50:00 - train.py[line:551] - INFO: load:1.69 valid_run:885.69 task_valid:826.70 collect_output:47.32
2022-10-10 20:52:58 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 20:52:58 - train.py[line:551] - INFO: load:1.74 valid_run:1063.98 task_valid:993.04 collect_output:57.30
2022-10-10 20:56:01 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 20:56:01 - train.py[line:551] - INFO: load:1.81 valid_run:1246.72 task_valid:1161.72 collect_output:69.25
2022-10-10 20:59:00 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 20:59:00 - train.py[line:551] - INFO: load:1.86 valid_run:1425.76 task_valid:1322.61 collect_output:85.47
2022-10-10 21:01:55 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 21:01:55 - train.py[line:551] - INFO: load:1.93 valid_run:1600.28 task_valid:1484.08 collect_output:96.46
2022-10-10 21:05:03 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 21:05:03 - train.py[line:551] - INFO: load:1.97 valid_run:1787.68 task_valid:1642.10 collect_output:123.72
2022-10-10 21:08:14 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 21:08:14 - train.py[line:551] - INFO: load:2.02 valid_run:1978.94 task_valid:1800.05 collect_output:154.85
2022-10-10 21:11:26 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 21:11:26 - train.py[line:551] - INFO: load:2.08 valid_run:2170.86 task_valid:1962.25 collect_output:182.25
2022-10-10 21:14:41 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 21:14:41 - train.py[line:551] - INFO: load:2.12 valid_run:2365.31 task_valid:2125.00 collect_output:211.73
2022-10-10 21:17:56 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 21:17:56 - train.py[line:551] - INFO: load:2.17 valid_run:2560.80 task_valid:2288.53 collect_output:241.33
2022-10-10 21:21:05 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 21:21:05 - train.py[line:551] - INFO: load:2.24 valid_run:2749.82 task_valid:2449.71 collect_output:267.02
2022-10-10 21:24:19 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 21:24:19 - train.py[line:551] - INFO: load:2.30 valid_run:2943.19 task_valid:2611.89 collect_output:295.99
2022-10-10 21:27:31 - train.py[line:549] - INFO: 3400 / 4988
2022-10-10 21:27:31 - train.py[line:551] - INFO: load:2.35 valid_run:3135.24 task_valid:2773.43 collect_output:324.23
2022-10-10 21:30:45 - train.py[line:549] - INFO: 3600 / 4988
2022-10-10 21:30:45 - train.py[line:551] - INFO: load:2.42 valid_run:3328.83 task_valid:2939.53 collect_output:349.39
2022-10-10 21:33:57 - train.py[line:549] - INFO: 3800 / 4988
2022-10-10 21:33:57 - train.py[line:551] - INFO: load:2.46 valid_run:3520.76 task_valid:3097.11 collect_output:381.46
2022-10-10 21:36:54 - train.py[line:549] - INFO: 4000 / 4988
2022-10-10 21:36:54 - train.py[line:551] - INFO: load:2.52 valid_run:3697.66 task_valid:3263.60 collect_output:389.52
2022-10-10 21:39:54 - train.py[line:549] - INFO: 4200 / 4988
2022-10-10 21:39:54 - train.py[line:551] - INFO: load:2.58 valid_run:3878.37 task_valid:3429.07 collect_output:402.49
2022-10-10 21:42:52 - train.py[line:549] - INFO: 4400 / 4988
2022-10-10 21:42:52 - train.py[line:551] - INFO: load:2.63 valid_run:4055.57 task_valid:3594.88 collect_output:411.75
2022-10-10 21:45:49 - train.py[line:549] - INFO: 4600 / 4988
2022-10-10 21:45:49 - train.py[line:551] - INFO: load:2.70 valid_run:4232.87 task_valid:3762.26 collect_output:419.37
2022-10-10 21:48:47 - train.py[line:549] - INFO: 4800 / 4988
2022-10-10 21:48:47 - train.py[line:551] - INFO: load:2.76 valid_run:4410.65 task_valid:3928.36 collect_output:428.80

====================================================================================================
SGG eval:     R @ 50: 0.6688;     R @ 100: 0.6975;     R @ 500: 0.7222;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4821;    mR @ 100: 0.5174;    mR @ 500: 0.5644;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9392) (says:0.0000) (sitting on:0.7398) (standing on:0.4860) (using:0.6000) (walking in:0.3333) (walking on:0.6216) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 21:51:44 - train.py[line:487] - INFO: 0.6975104150751209
2022-10-10 21:51:44 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.6688;     R @ 100: 0.6975;     R @ 500: 0.7222;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4821;    mR @ 100: 0.5174;    mR @ 500: 0.5644;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9392) (says:0.0000) (sitting on:0.7398) (standing on:0.4860) (using:0.6000) (walking in:0.3333) (walking on:0.6216) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 21:51:44 - progress_bar.py[line:282] - INFO: epoch 008 | valid on 'valid' subset | loss 0.239 | loss_v1 0 | loss_v2 0 | nll_loss 0.072 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.69751 | ppl 1.05 | vqa_score 0.5327 | wps 97.8 | wpb 89.9 | bsz 30 | num_updates 3000 | best_R@100 0.70421
2022-10-10 21:51:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 3000 updates
2022-10-10 21:51:44 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_8_3000.pt
2022-10-10 21:51:51 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_8_3000.pt
2022-10-10 21:51:55 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_8_3000.pt (epoch 8 @ 3000 updates, score 0.6975104150751209) (writing took 11.013105283956975 seconds)
2022-10-10 21:52:08 - progress_bar.py[line:274] - INFO: epoch 008:    128 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=0.2, ups=0, wpb=111.5, bsz=40, num_updates=3010, lr=4.44731e-05, gnorm=0.603, clip=20, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=17819
2022-10-10 21:52:21 - progress_bar.py[line:274] - INFO: epoch 008:    138 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.8, ups=0.8, wpb=111.3, bsz=40, num_updates=3020, lr=4.44478e-05, gnorm=0.597, clip=10, loss_scale=1024, train_wall=12, gb_free=11, ema_decay=0.9999, wall=17832
2022-10-10 21:52:33 - progress_bar.py[line:274] - INFO: epoch 008:    148 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.5, ups=0.79, wpb=110.4, bsz=40, num_updates=3030, lr=4.44225e-05, gnorm=0.797, clip=30, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=17844
2022-10-10 21:52:46 - progress_bar.py[line:274] - INFO: epoch 008:    158 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=87.7, ups=0.79, wpb=110.7, bsz=40, num_updates=3040, lr=4.43972e-05, gnorm=0.28, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=17857
2022-10-10 21:52:58 - progress_bar.py[line:274] - INFO: epoch 008:    168 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.9, ups=0.82, wpb=110.7, bsz=40, num_updates=3050, lr=4.4372e-05, gnorm=0.411, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17869
2022-10-10 21:53:11 - progress_bar.py[line:274] - INFO: epoch 008:    178 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.8, ups=0.78, wpb=111.4, bsz=40, num_updates=3060, lr=4.43467e-05, gnorm=0.395, clip=20, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=17882
2022-10-10 21:53:24 - progress_bar.py[line:274] - INFO: epoch 008:    188 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.8, ups=0.79, wpb=111, bsz=40, num_updates=3070, lr=4.43214e-05, gnorm=0.435, clip=0, loss_scale=1024, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=17894
2022-10-10 21:53:37 - progress_bar.py[line:274] - INFO: epoch 008:    198 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=84.7, ups=0.77, wpb=109.8, bsz=40, num_updates=3080, lr=4.42961e-05, gnorm=0.541, clip=10, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=17907
2022-10-10 21:53:49 - progress_bar.py[line:274] - INFO: epoch 008:    208 / 412 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.5, ups=0.81, wpb=110.9, bsz=40, num_updates=3090, lr=4.42708e-05, gnorm=0.892, clip=30, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=17920
2022-10-10 21:54:01 - progress_bar.py[line:274] - INFO: epoch 008:    218 / 412 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.1, ups=0.82, wpb=110.3, bsz=40, num_updates=3100, lr=4.42456e-05, gnorm=0.518, clip=0, loss_scale=1024, train_wall=12, gb_free=10, ema_decay=0.9999, wall=17932
2022-10-10 21:54:14 - progress_bar.py[line:274] - INFO: epoch 008:    228 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.8, wpb=111.6, bsz=40, num_updates=3110, lr=4.42203e-05, gnorm=0.568, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17945
2022-10-10 21:54:26 - progress_bar.py[line:274] - INFO: epoch 008:    238 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90, ups=0.81, wpb=111.8, bsz=40, num_updates=3120, lr=4.4195e-05, gnorm=0.707, clip=10, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17957
2022-10-10 21:54:39 - progress_bar.py[line:274] - INFO: epoch 008:    248 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.3, ups=0.81, wpb=111.2, bsz=40, num_updates=3130, lr=4.41697e-05, gnorm=0.714, clip=30, loss_scale=1024, train_wall=12, gb_free=11, ema_decay=0.9999, wall=17969
2022-10-10 21:54:52 - progress_bar.py[line:274] - INFO: epoch 008:    258 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.6, ups=0.78, wpb=112.4, bsz=40, num_updates=3140, lr=4.41444e-05, gnorm=0.611, clip=20, loss_scale=1024, train_wall=13, gb_free=10, ema_decay=0.9999, wall=17982
2022-10-10 21:55:04 - progress_bar.py[line:274] - INFO: epoch 008:    268 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.3, ups=0.77, wpb=110.4, bsz=40, num_updates=3150, lr=4.41191e-05, gnorm=0.43, clip=10, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=17995
2022-10-10 21:55:17 - progress_bar.py[line:274] - INFO: epoch 008:    278 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90, ups=0.8, wpb=112.1, bsz=40, num_updates=3160, lr=4.40939e-05, gnorm=0.765, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18008
2022-10-10 21:55:30 - progress_bar.py[line:274] - INFO: epoch 008:    288 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.1, ups=0.79, wpb=110.9, bsz=40, num_updates=3170, lr=4.40686e-05, gnorm=0.537, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18020
2022-10-10 21:55:38 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 21:55:43 - progress_bar.py[line:274] - INFO: epoch 008:    299 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83.5, ups=0.74, wpb=112.3, bsz=40, num_updates=3180, lr=4.40433e-05, gnorm=0.423, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18034
2022-10-10 21:55:55 - progress_bar.py[line:274] - INFO: epoch 008:    309 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.6, ups=0.82, wpb=110.9, bsz=40, num_updates=3190, lr=4.4018e-05, gnorm=0.734, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18046
2022-10-10 21:56:08 - progress_bar.py[line:274] - INFO: epoch 008:    319 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87, ups=0.79, wpb=110.8, bsz=40, num_updates=3200, lr=4.39927e-05, gnorm=0.676, clip=30, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=18059
2022-10-10 21:56:20 - progress_bar.py[line:274] - INFO: epoch 008:    329 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.3, ups=0.81, wpb=112.8, bsz=40, num_updates=3210, lr=4.39674e-05, gnorm=0.64, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18071
2022-10-10 21:56:33 - progress_bar.py[line:274] - INFO: epoch 008:    339 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.2, ups=0.8, wpb=111, bsz=40, num_updates=3220, lr=4.39422e-05, gnorm=0.593, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=18084
2022-10-10 21:56:45 - progress_bar.py[line:274] - INFO: epoch 008:    349 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.8, wpb=110.5, bsz=40, num_updates=3230, lr=4.39169e-05, gnorm=0.585, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18096
2022-10-10 21:56:57 - progress_bar.py[line:274] - INFO: epoch 008:    359 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.8, ups=0.82, wpb=110.8, bsz=40, num_updates=3240, lr=4.38916e-05, gnorm=0.841, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18108
2022-10-10 21:57:10 - progress_bar.py[line:274] - INFO: epoch 008:    369 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.4, ups=0.81, wpb=110.1, bsz=40, num_updates=3250, lr=4.38663e-05, gnorm=0.983, clip=50, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=18121
2022-10-10 21:57:22 - progress_bar.py[line:274] - INFO: epoch 008:    379 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.6, ups=0.79, wpb=111.6, bsz=40, num_updates=3260, lr=4.3841e-05, gnorm=0.608, clip=20, loss_scale=512, train_wall=13, gb_free=10, ema_decay=0.9999, wall=18133
2022-10-10 21:57:35 - progress_bar.py[line:274] - INFO: epoch 008:    389 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.2, ups=0.81, wpb=111, bsz=40, num_updates=3270, lr=4.38157e-05, gnorm=0.672, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=18145
2022-10-10 21:57:47 - progress_bar.py[line:274] - INFO: epoch 008:    399 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.7, ups=0.78, wpb=112, bsz=40, num_updates=3280, lr=4.37905e-05, gnorm=0.518, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18158
2022-10-10 21:58:00 - progress_bar.py[line:274] - INFO: epoch 008:    409 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.4, ups=0.79, wpb=111.6, bsz=40, num_updates=3290, lr=4.37652e-05, gnorm=0.532, clip=20, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=18171
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 21:58:04 - train.py[line:339] - INFO: end of epoch 8 (average epoch stats below)
2022-10-10 21:58:04 - progress_bar.py[line:282] - INFO: epoch 008 | loss 0.245 | loss_v1 0 | loss_v2 0 | nll_loss 0.061 | ntokens 111.124 | nsentences 40 | sample_size 111.124 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 8.9 | ups 0.08 | wpb 111.1 | bsz 40 | num_updates 3293 | lr 4.37576e-05 | gnorm 0.562 | clip 14.6 | loss_scale 512 | train_wall 517 | gb_free 10.6 | ema_decay 0.9999 | wall 18175
2022-10-10 21:58:04 - trainer.py[line:643] - INFO: loading train data for epoch 9
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 21:58:04 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 21:58:04 - trainer.py[line:707] - INFO: begin training epoch 9
2022-10-10 21:58:04 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 21:58:16 - progress_bar.py[line:274] - INFO: epoch 009:      7 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=73, ups=0.65, wpb=112.6, bsz=40, num_updates=3300, lr=4.37399e-05, gnorm=0.578, clip=30, loss_scale=512, train_wall=13, gb_free=9.9, ema_decay=0.9999, wall=18186
2022-10-10 21:58:28 - progress_bar.py[line:274] - INFO: epoch 009:     17 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.5, ups=0.8, wpb=110.8, bsz=40, num_updates=3310, lr=4.37146e-05, gnorm=0.433, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18199
2022-10-10 21:58:40 - progress_bar.py[line:274] - INFO: epoch 009:     27 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=93.8, ups=0.84, wpb=111.8, bsz=40, num_updates=3320, lr=4.36893e-05, gnorm=0.618, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18211
2022-10-10 21:58:52 - progress_bar.py[line:274] - INFO: epoch 009:     37 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.5, ups=0.82, wpb=112.7, bsz=40, num_updates=3330, lr=4.3664e-05, gnorm=0.699, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18223
2022-10-10 21:59:05 - progress_bar.py[line:274] - INFO: epoch 009:     47 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.5, ups=0.81, wpb=111.9, bsz=40, num_updates=3340, lr=4.36388e-05, gnorm=0.811, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18235
2022-10-10 21:59:17 - progress_bar.py[line:274] - INFO: epoch 009:     57 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90, ups=0.81, wpb=110.9, bsz=40, num_updates=3350, lr=4.36135e-05, gnorm=0.703, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18248
2022-10-10 21:59:30 - progress_bar.py[line:274] - INFO: epoch 009:     67 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.4, ups=0.78, wpb=111.4, bsz=40, num_updates=3360, lr=4.35882e-05, gnorm=0.66, clip=20, loss_scale=512, train_wall=13, gb_free=10, ema_decay=0.9999, wall=18260
2022-10-10 21:59:42 - progress_bar.py[line:274] - INFO: epoch 009:     77 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.5, ups=0.82, wpb=110.9, bsz=40, num_updates=3370, lr=4.35629e-05, gnorm=0.754, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18273
2022-10-10 21:59:54 - progress_bar.py[line:274] - INFO: epoch 009:     87 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.5, ups=0.8, wpb=111.7, bsz=40, num_updates=3380, lr=4.35376e-05, gnorm=0.358, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=18285
2022-10-10 22:00:07 - progress_bar.py[line:274] - INFO: epoch 009:     97 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.8, ups=0.78, wpb=111.9, bsz=40, num_updates=3390, lr=4.35123e-05, gnorm=0.467, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18298
2022-10-10 22:00:20 - progress_bar.py[line:274] - INFO: epoch 009:    107 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.8, ups=0.77, wpb=112.3, bsz=40, num_updates=3400, lr=4.34871e-05, gnorm=0.566, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18311
2022-10-10 22:00:32 - progress_bar.py[line:274] - INFO: epoch 009:    117 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.1, ups=0.81, wpb=110, bsz=40, num_updates=3410, lr=4.34618e-05, gnorm=0.476, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=18323
2022-10-10 22:00:45 - progress_bar.py[line:274] - INFO: epoch 009:    127 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.4, ups=0.8, wpb=110.6, bsz=40, num_updates=3420, lr=4.34365e-05, gnorm=0.354, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18336
2022-10-10 22:00:58 - progress_bar.py[line:274] - INFO: epoch 009:    137 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.7, ups=0.8, wpb=112.2, bsz=40, num_updates=3430, lr=4.34112e-05, gnorm=0.854, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18348
2022-10-10 22:01:10 - progress_bar.py[line:274] - INFO: epoch 009:    147 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.7, ups=0.83, wpb=112.3, bsz=40, num_updates=3440, lr=4.33859e-05, gnorm=0.591, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18360
2022-10-10 22:01:22 - progress_bar.py[line:274] - INFO: epoch 009:    157 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.8, ups=0.81, wpb=110.3, bsz=40, num_updates=3450, lr=4.33606e-05, gnorm=0.362, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18373
2022-10-10 22:01:35 - progress_bar.py[line:274] - INFO: epoch 009:    167 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.3, ups=0.8, wpb=110.4, bsz=40, num_updates=3460, lr=4.33354e-05, gnorm=0.228, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18385
2022-10-10 22:01:47 - progress_bar.py[line:274] - INFO: epoch 009:    177 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.1, ups=0.81, wpb=111.7, bsz=40, num_updates=3470, lr=4.33101e-05, gnorm=0.487, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18398
2022-10-10 22:01:59 - progress_bar.py[line:274] - INFO: epoch 009:    187 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=93.3, ups=0.83, wpb=112.7, bsz=40, num_updates=3480, lr=4.32848e-05, gnorm=0.584, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18410
2022-10-10 22:02:12 - progress_bar.py[line:274] - INFO: epoch 009:    197 / 412 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=86.5, ups=0.78, wpb=111.1, bsz=40, num_updates=3490, lr=4.32595e-05, gnorm=0.856, clip=30, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=18423
2022-10-10 22:02:25 - progress_bar.py[line:274] - INFO: epoch 009:    207 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.6, ups=0.77, wpb=111, bsz=40, num_updates=3500, lr=4.32342e-05, gnorm=0.507, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18436
2022-10-10 22:02:38 - progress_bar.py[line:274] - INFO: epoch 009:    217 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.8, ups=0.79, wpb=110.5, bsz=40, num_updates=3510, lr=4.32089e-05, gnorm=0.291, clip=0, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=18448
2022-10-10 22:02:50 - progress_bar.py[line:274] - INFO: epoch 009:    227 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=87.5, ups=0.79, wpb=110.5, bsz=40, num_updates=3520, lr=4.31837e-05, gnorm=0.474, clip=20, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=18461
2022-10-10 22:03:03 - progress_bar.py[line:274] - INFO: epoch 009:    237 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.8, ups=0.77, wpb=111.4, bsz=40, num_updates=3530, lr=4.31584e-05, gnorm=0.781, clip=30, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=18474
2022-10-10 22:03:16 - progress_bar.py[line:274] - INFO: epoch 009:    247 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.2, ups=0.78, wpb=111.1, bsz=40, num_updates=3540, lr=4.31331e-05, gnorm=0.529, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18487
2022-10-10 22:03:29 - progress_bar.py[line:274] - INFO: epoch 009:    257 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.9, ups=0.79, wpb=110.1, bsz=40, num_updates=3550, lr=4.31078e-05, gnorm=0.899, clip=40, loss_scale=512, train_wall=13, gb_free=10, ema_decay=0.9999, wall=18499
2022-10-10 22:03:41 - progress_bar.py[line:274] - INFO: epoch 009:    267 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.1, ups=0.8, wpb=108.8, bsz=40, num_updates=3560, lr=4.30825e-05, gnorm=0.722, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=18512
2022-10-10 22:03:53 - progress_bar.py[line:274] - INFO: epoch 009:    277 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.8, ups=0.83, wpb=110.9, bsz=40, num_updates=3570, lr=4.30572e-05, gnorm=0.554, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=18524
2022-10-10 22:04:06 - progress_bar.py[line:274] - INFO: epoch 009:    287 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.6, ups=0.78, wpb=111.8, bsz=40, num_updates=3580, lr=4.3032e-05, gnorm=0.737, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18537
2022-10-10 22:04:18 - progress_bar.py[line:274] - INFO: epoch 009:    297 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.4, ups=0.82, wpb=110.4, bsz=40, num_updates=3590, lr=4.30067e-05, gnorm=0.32, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18549
2022-10-10 22:04:31 - progress_bar.py[line:274] - INFO: epoch 009:    307 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.8, ups=0.79, wpb=109.5, bsz=40, num_updates=3600, lr=4.29814e-05, gnorm=0.73, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18562
2022-10-10 22:04:44 - progress_bar.py[line:274] - INFO: epoch 009:    317 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.2, ups=0.77, wpb=109.8, bsz=40, num_updates=3610, lr=4.29561e-05, gnorm=0.526, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18575
2022-10-10 22:04:57 - progress_bar.py[line:274] - INFO: epoch 009:    327 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.6, ups=0.78, wpb=110, bsz=40, num_updates=3620, lr=4.29308e-05, gnorm=0.609, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18588
2022-10-10 22:05:09 - progress_bar.py[line:274] - INFO: epoch 009:    337 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.6, ups=0.8, wpb=111.5, bsz=40, num_updates=3630, lr=4.29055e-05, gnorm=0.265, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18600
2022-10-10 22:05:22 - progress_bar.py[line:274] - INFO: epoch 009:    347 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.8, ups=0.78, wpb=110.6, bsz=40, num_updates=3640, lr=4.28803e-05, gnorm=0.491, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18613
2022-10-10 22:05:35 - progress_bar.py[line:274] - INFO: epoch 009:    357 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.5, ups=0.8, wpb=111.2, bsz=40, num_updates=3650, lr=4.2855e-05, gnorm=0.956, clip=20, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=18626
2022-10-10 22:05:48 - progress_bar.py[line:274] - INFO: epoch 009:    367 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.6, ups=0.76, wpb=110.7, bsz=40, num_updates=3660, lr=4.28297e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18639
2022-10-10 22:06:00 - progress_bar.py[line:274] - INFO: epoch 009:    377 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.2, ups=0.8, wpb=111.2, bsz=40, num_updates=3670, lr=4.28044e-05, gnorm=0.707, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=18651
2022-10-10 22:06:13 - progress_bar.py[line:274] - INFO: epoch 009:    387 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.2, ups=0.78, wpb=111.1, bsz=40, num_updates=3680, lr=4.27791e-05, gnorm=0.495, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18664
2022-10-10 22:06:26 - progress_bar.py[line:274] - INFO: epoch 009:    397 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.6, ups=0.8, wpb=112.7, bsz=40, num_updates=3690, lr=4.27538e-05, gnorm=0.513, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=18676
2022-10-10 22:06:38 - progress_bar.py[line:274] - INFO: epoch 009:    407 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.8, ups=0.83, wpb=111.6, bsz=40, num_updates=3700, lr=4.27286e-05, gnorm=0.477, clip=10, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18688
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 22:06:44 - train.py[line:339] - INFO: end of epoch 9 (average epoch stats below)
2022-10-10 22:06:44 - progress_bar.py[line:282] - INFO: epoch 009 | loss 0.245 | loss_v1 0 | loss_v2 0 | nll_loss 0.06 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 88.1 | ups 0.79 | wpb 111.1 | bsz 40 | num_updates 3705 | lr 4.27159e-05 | gnorm 0.574 | clip 14.3 | loss_scale 1024 | train_wall 513 | gb_free 10.6 | ema_decay 0.9999 | wall 18694
2022-10-10 22:06:44 - trainer.py[line:643] - INFO: loading train data for epoch 10
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 22:06:44 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 22:06:44 - trainer.py[line:707] - INFO: begin training epoch 10
2022-10-10 22:06:44 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 22:06:54 - progress_bar.py[line:274] - INFO: epoch 010:      5 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=69.2, ups=0.62, wpb=111.6, bsz=40, num_updates=3710, lr=4.27033e-05, gnorm=0.459, clip=10, loss_scale=1024, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=18705
2022-10-10 22:07:06 - progress_bar.py[line:274] - INFO: epoch 010:     15 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.7, ups=0.81, wpb=112.4, bsz=40, num_updates=3720, lr=4.2678e-05, gnorm=1.007, clip=40, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18717
2022-10-10 22:07:19 - progress_bar.py[line:274] - INFO: epoch 010:     25 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.4, ups=0.79, wpb=110.3, bsz=40, num_updates=3730, lr=4.26527e-05, gnorm=1.111, clip=50, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18730
2022-10-10 22:07:31 - progress_bar.py[line:274] - INFO: epoch 010:     35 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.6, ups=0.79, wpb=111.6, bsz=40, num_updates=3740, lr=4.26274e-05, gnorm=0.69, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18742
2022-10-10 22:07:44 - progress_bar.py[line:274] - INFO: epoch 010:     45 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.9, ups=0.79, wpb=110.2, bsz=40, num_updates=3750, lr=4.26021e-05, gnorm=0.284, clip=0, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18755
2022-10-10 22:07:56 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 22:07:57 - progress_bar.py[line:274] - INFO: epoch 010:     56 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=82.7, ups=0.75, wpb=110.6, bsz=40, num_updates=3760, lr=4.25769e-05, gnorm=0.775, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18768
2022-10-10 22:08:10 - progress_bar.py[line:274] - INFO: epoch 010:     66 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.5, ups=0.77, wpb=110, bsz=40, num_updates=3770, lr=4.25516e-05, gnorm=0.403, clip=10, loss_scale=512, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=18781
2022-10-10 22:08:23 - progress_bar.py[line:274] - INFO: epoch 010:     76 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89, ups=0.81, wpb=109.7, bsz=40, num_updates=3780, lr=4.25263e-05, gnorm=0.65, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=18794
2022-10-10 22:08:35 - progress_bar.py[line:274] - INFO: epoch 010:     86 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.2, ups=0.82, wpb=111.4, bsz=40, num_updates=3790, lr=4.2501e-05, gnorm=0.32, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18806
2022-10-10 22:08:48 - progress_bar.py[line:274] - INFO: epoch 010:     96 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83.9, ups=0.76, wpb=110.1, bsz=40, num_updates=3800, lr=4.24757e-05, gnorm=0.562, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18819
2022-10-10 22:09:00 - progress_bar.py[line:274] - INFO: epoch 010:    106 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.3, ups=0.81, wpb=110.8, bsz=40, num_updates=3810, lr=4.24504e-05, gnorm=0.394, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=18831
2022-10-10 22:09:13 - progress_bar.py[line:274] - INFO: epoch 010:    116 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.3, ups=0.82, wpb=111.9, bsz=40, num_updates=3820, lr=4.24252e-05, gnorm=0.391, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18843
2022-10-10 22:09:25 - progress_bar.py[line:274] - INFO: epoch 010:    126 / 412 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.7, ups=0.82, wpb=109.9, bsz=40, num_updates=3830, lr=4.23999e-05, gnorm=0.561, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18856
2022-10-10 22:09:38 - progress_bar.py[line:274] - INFO: epoch 010:    136 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88, ups=0.79, wpb=111.9, bsz=40, num_updates=3840, lr=4.23746e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18868
2022-10-10 22:09:50 - progress_bar.py[line:274] - INFO: epoch 010:    146 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.6, ups=0.79, wpb=111.6, bsz=40, num_updates=3850, lr=4.23493e-05, gnorm=0.33, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18881
2022-10-10 22:10:03 - progress_bar.py[line:274] - INFO: epoch 010:    156 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.4, ups=0.8, wpb=111.7, bsz=40, num_updates=3860, lr=4.2324e-05, gnorm=0.4, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=18894
2022-10-10 22:10:15 - progress_bar.py[line:274] - INFO: epoch 010:    166 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.5, ups=0.81, wpb=111.8, bsz=40, num_updates=3870, lr=4.22987e-05, gnorm=0.773, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18906
2022-10-10 22:10:27 - progress_bar.py[line:274] - INFO: epoch 010:    176 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.5, ups=0.82, wpb=111.5, bsz=40, num_updates=3880, lr=4.22735e-05, gnorm=0.408, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18918
2022-10-10 22:10:40 - progress_bar.py[line:274] - INFO: epoch 010:    186 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.3, ups=0.79, wpb=111, bsz=40, num_updates=3890, lr=4.22482e-05, gnorm=0.619, clip=20, loss_scale=512, train_wall=13, gb_free=10.3, ema_decay=0.9999, wall=18931
2022-10-10 22:10:53 - progress_bar.py[line:274] - INFO: epoch 010:    196 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.8, ups=0.8, wpb=110.7, bsz=40, num_updates=3900, lr=4.22229e-05, gnorm=0.799, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=18943
2022-10-10 22:11:05 - progress_bar.py[line:274] - INFO: epoch 010:    206 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.8, wpb=111.7, bsz=40, num_updates=3910, lr=4.21976e-05, gnorm=0.376, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18956
2022-10-10 22:11:17 - progress_bar.py[line:274] - INFO: epoch 010:    216 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91, ups=0.82, wpb=110.6, bsz=40, num_updates=3920, lr=4.21723e-05, gnorm=0.613, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18968
2022-10-10 22:11:30 - progress_bar.py[line:274] - INFO: epoch 010:    226 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.7, ups=0.81, wpb=110.6, bsz=40, num_updates=3930, lr=4.2147e-05, gnorm=0.443, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=18980
2022-10-10 22:11:42 - progress_bar.py[line:274] - INFO: epoch 010:    236 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.4, ups=0.82, wpb=111.5, bsz=40, num_updates=3940, lr=4.21218e-05, gnorm=0.847, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18993
2022-10-10 22:11:55 - progress_bar.py[line:274] - INFO: epoch 010:    246 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.7, ups=0.78, wpb=111.4, bsz=40, num_updates=3950, lr=4.20965e-05, gnorm=0.631, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=19005
2022-10-10 22:12:07 - progress_bar.py[line:274] - INFO: epoch 010:    256 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=89.7, ups=0.8, wpb=111.6, bsz=40, num_updates=3960, lr=4.20712e-05, gnorm=0.679, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=19018
2022-10-10 22:12:19 - progress_bar.py[line:274] - INFO: epoch 010:    266 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=92, ups=0.82, wpb=111.9, bsz=40, num_updates=3970, lr=4.20459e-05, gnorm=0.618, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=19030
2022-10-10 22:12:32 - progress_bar.py[line:274] - INFO: epoch 010:    276 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.2, ups=0.81, wpb=109.5, bsz=40, num_updates=3980, lr=4.20206e-05, gnorm=0.686, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19043
2022-10-10 22:12:44 - progress_bar.py[line:274] - INFO: epoch 010:    286 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.7, ups=0.79, wpb=111, bsz=40, num_updates=3990, lr=4.19953e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=19055
2022-10-10 22:12:57 - progress_bar.py[line:274] - INFO: epoch 010:    296 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.8, ups=0.82, wpb=111.4, bsz=40, num_updates=4000, lr=4.19701e-05, gnorm=0.604, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=19067
2022-10-10 22:12:57 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 22:12:59 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 22:12:59 - train.py[line:551] - INFO: load:1.45 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 22:13:00 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.85 GiB already allocated; 4.28 GiB free; 32.82 GiB reserved in total by PyTorch)
2022-10-10 22:13:00 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-10 22:13:00 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 16        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9063 MB |   10288 MB |    2300 TB |    2300 TB |
|       from large pool |    8918 MB |   10143 MB |    2299 TB |    2299 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9063 MB |   10288 MB |    2300 TB |    2300 TB |
|       from large pool |    8918 MB |   10143 MB |    2299 TB |    2299 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   33612 MB |   34800 MB |  193490 MB |  159878 MB |
|       from large pool |   33466 MB |   34654 MB |  193140 MB |  159674 MB |
|       from small pool |     146 MB |     146 MB |     350 MB |     204 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24548 MB |   25719 MB |    2973 TB |    2973 TB |
|       from large pool |   24547 MB |   25717 MB |    2972 TB |    2972 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  104847 K  |  104844 K  |
|       from large pool |     563    |     575    |   34399 K  |   34399 K  |
|       from small pool |    3095    |    3114    |   70447 K  |   70444 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  104847 K  |  104844 K  |
|       from large pool |     563    |     575    |   34399 K  |   34399 K  |
|       from small pool |    3095    |    3114    |   70447 K  |   70444 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     165    |     176    |     565    |     400    |
|       from large pool |      92    |     103    |     390    |     298    |
|       from small pool |      73    |      73    |     175    |     102    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     109    |     113    |   75719 K  |   75719 K  |
|       from large pool |      68    |      71    |   14561 K  |   14561 K  |
|       from small pool |      41    |      48    |   61158 K  |   61158 K  |
|===========================================================================|

2022-10-10 22:13:00 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-10 22:16:00 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 22:16:00 - train.py[line:551] - INFO: load:1.52 valid_run:180.89 task_valid:167.84 collect_output:10.86
2022-10-10 22:18:54 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 22:18:54 - train.py[line:551] - INFO: load:1.58 valid_run:355.16 task_valid:329.66 collect_output:21.33
2022-10-10 22:21:53 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 22:21:53 - train.py[line:551] - INFO: load:1.66 valid_run:533.81 task_valid:488.20 collect_output:39.59
2022-10-10 22:24:47 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 22:24:47 - train.py[line:551] - INFO: load:1.71 valid_run:707.75 task_valid:649.22 collect_output:50.62
2022-10-10 22:27:42 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 22:27:42 - train.py[line:551] - INFO: load:1.78 valid_run:883.10 task_valid:811.84 collect_output:61.45
2022-10-10 22:30:39 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 22:30:39 - train.py[line:551] - INFO: load:1.83 valid_run:1059.98 task_valid:975.06 collect_output:73.10
2022-10-10 22:33:54 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 22:33:54 - train.py[line:551] - INFO: load:1.90 valid_run:1254.86 task_valid:1139.65 collect_output:101.16
2022-10-10 22:37:15 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 22:37:15 - train.py[line:551] - INFO: load:1.94 valid_run:1455.69 task_valid:1297.62 collect_output:142.05
2022-10-10 22:40:35 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 22:40:35 - train.py[line:551] - INFO: load:2.01 valid_run:1655.49 task_valid:1461.69 collect_output:175.81
2022-10-10 22:43:49 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 22:43:49 - train.py[line:551] - INFO: load:2.09 valid_run:1848.96 task_valid:1622.92 collect_output:205.94
2022-10-10 22:46:49 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 22:46:49 - train.py[line:551] - INFO: load:2.15 valid_run:2029.48 task_valid:1777.08 collect_output:230.72
2022-10-10 22:49:21 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 22:49:21 - train.py[line:551] - INFO: load:2.18 valid_run:2180.66 task_valid:1922.35 collect_output:235.49
2022-10-10 22:51:52 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 22:51:52 - train.py[line:551] - INFO: load:2.21 valid_run:2332.31 task_valid:2064.36 collect_output:244.00
2022-10-10 22:54:24 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 22:54:24 - train.py[line:551] - INFO: load:2.24 valid_run:2483.54 task_valid:2209.96 collect_output:248.51
2022-10-10 22:56:54 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 22:56:54 - train.py[line:551] - INFO: load:2.27 valid_run:2634.17 task_valid:2356.35 collect_output:251.56
2022-10-10 22:59:25 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 22:59:25 - train.py[line:551] - INFO: load:2.30 valid_run:2784.49 task_valid:2500.12 collect_output:257.01
2022-10-10 23:01:57 - train.py[line:549] - INFO: 3400 / 4988
2022-10-10 23:01:57 - train.py[line:551] - INFO: load:2.33 valid_run:2936.43 task_valid:2645.25 collect_output:262.72
2022-10-10 23:04:27 - train.py[line:549] - INFO: 3600 / 4988
2022-10-10 23:04:27 - train.py[line:551] - INFO: load:2.36 valid_run:3087.17 task_valid:2791.91 collect_output:265.71
2022-10-10 23:06:57 - train.py[line:549] - INFO: 3800 / 4988
2022-10-10 23:06:57 - train.py[line:551] - INFO: load:2.39 valid_run:3236.28 task_valid:2933.26 collect_output:272.39
2022-10-10 23:09:27 - train.py[line:549] - INFO: 4000 / 4988
2022-10-10 23:09:27 - train.py[line:551] - INFO: load:2.42 valid_run:3386.85 task_valid:3077.89 collect_output:277.22
2022-10-10 23:12:00 - train.py[line:549] - INFO: 4200 / 4988
2022-10-10 23:12:00 - train.py[line:551] - INFO: load:2.45 valid_run:3539.48 task_valid:3221.94 collect_output:284.69
2022-10-10 23:14:30 - train.py[line:549] - INFO: 4400 / 4988
2022-10-10 23:14:30 - train.py[line:551] - INFO: load:2.48 valid_run:3689.33 task_valid:3366.28 collect_output:289.08
2022-10-10 23:17:02 - train.py[line:549] - INFO: 4600 / 4988
2022-10-10 23:17:02 - train.py[line:551] - INFO: load:2.51 valid_run:3840.92 task_valid:3512.26 collect_output:293.58
2022-10-10 23:19:33 - train.py[line:549] - INFO: 4800 / 4988
2022-10-10 23:19:33 - train.py[line:551] - INFO: load:2.54 valid_run:3992.74 task_valid:3658.74 collect_output:297.79

====================================================================================================
SGG eval:     R @ 50: 0.6694;     R @ 100: 0.6973;     R @ 500: 0.7198;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4759;    mR @ 100: 0.5170;    mR @ 500: 0.5635;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9441) (says:0.0000) (sitting on:0.7321) (standing on:0.5060) (using:0.6000) (walking in:0.3333) (walking on:0.5946) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 23:22:04 - train.py[line:487] - INFO: 0.697310415075121

====================================================================================================
SGG eval:     R @ 50: 0.6694;     R @ 100: 0.6973;     R @ 500: 0.7198;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4759;    mR @ 100: 0.5170;    mR @ 500: 0.5635;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9441) (says:0.0000) (sitting on:0.7321) (standing on:0.5060) (using:0.6000) (walking in:0.3333) (walking on:0.5946) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 23:22:05 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-10 23:22:05 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 0.23 | loss_v1 0 | loss_v2 0 | nll_loss 0.058 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.69731 | ppl 1.04 | vqa_score 0.5169 | wps 108.2 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.70421
2022-10-10 23:22:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 4000 updates
2022-10-10 23:22:05 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_10_4000.pt
2022-10-10 23:22:11 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_10_4000.pt
2022-10-10 23:22:13 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_10_4000.pt (epoch 10 @ 4000 updates, score 0.697310415075121) (writing took 8.589290231000632 seconds)
2022-10-10 23:22:25 - progress_bar.py[line:274] - INFO: epoch 010:    306 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=0.3, ups=0, wpb=110.7, bsz=40, num_updates=4010, lr=4.19448e-05, gnorm=0.686, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23235
2022-10-10 23:22:36 - progress_bar.py[line:274] - INFO: epoch 010:    316 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.1, ups=0.92, wpb=110.8, bsz=40, num_updates=4020, lr=4.19195e-05, gnorm=0.299, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=23246
2022-10-10 23:22:47 - progress_bar.py[line:274] - INFO: epoch 010:    326 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.5, ups=0.87, wpb=111.6, bsz=40, num_updates=4030, lr=4.18942e-05, gnorm=0.645, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=23258
2022-10-10 23:22:58 - progress_bar.py[line:274] - INFO: epoch 010:    336 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.2, ups=0.89, wpb=111.5, bsz=40, num_updates=4040, lr=4.18689e-05, gnorm=0.36, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23269
2022-10-10 23:23:09 - progress_bar.py[line:274] - INFO: epoch 010:    346 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.9, wpb=111.6, bsz=40, num_updates=4050, lr=4.18436e-05, gnorm=1.012, clip=40, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=23280
2022-10-10 23:23:21 - progress_bar.py[line:274] - INFO: epoch 010:    356 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.6, ups=0.88, wpb=112.3, bsz=40, num_updates=4060, lr=4.18184e-05, gnorm=0.675, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23291
2022-10-10 23:23:32 - progress_bar.py[line:274] - INFO: epoch 010:    366 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.9, wpb=111.5, bsz=40, num_updates=4070, lr=4.17931e-05, gnorm=0.625, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23303
2022-10-10 23:23:43 - progress_bar.py[line:274] - INFO: epoch 010:    376 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=96.8, ups=0.88, wpb=110.2, bsz=40, num_updates=4080, lr=4.17678e-05, gnorm=0.439, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23314
2022-10-10 23:23:54 - progress_bar.py[line:274] - INFO: epoch 010:    386 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.5, ups=0.92, wpb=111.8, bsz=40, num_updates=4090, lr=4.17425e-05, gnorm=0.544, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=23325
2022-10-10 23:24:05 - progress_bar.py[line:274] - INFO: epoch 010:    396 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.91, wpb=112.4, bsz=40, num_updates=4100, lr=4.17172e-05, gnorm=0.504, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=23336
2022-10-10 23:24:16 - progress_bar.py[line:274] - INFO: epoch 010:    406 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.1, ups=0.88, wpb=110.5, bsz=40, num_updates=4110, lr=4.16919e-05, gnorm=0.415, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=23347
2022-10-10 23:24:23 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 23:24:25 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 23:24:25 - train.py[line:551] - INFO: load:1.06 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 23:24:26 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.84 GiB already allocated; 4.62 GiB free; 32.49 GiB reserved in total by PyTorch)
2022-10-10 23:24:26 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-10 23:24:26 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 18        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9053 MB |   10278 MB |    2859 TB |    2859 TB |
|       from large pool |    8908 MB |   10133 MB |    2858 TB |    2858 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9053 MB |   10278 MB |    2859 TB |    2859 TB |
|       from large pool |    8908 MB |   10133 MB |    2858 TB |    2858 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   33266 MB |   33266 MB |  232318 MB |  199052 MB |
|       from large pool |   33120 MB |   33120 MB |  231942 MB |  198822 MB |
|       from small pool |     146 MB |     146 MB |     376 MB |     230 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24212 MB |   28582 MB |    3546 TB |    3546 TB |
|       from large pool |   24211 MB |   28580 MB |    3545 TB |    3545 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3670    |    3684    |  133323 K  |  133320 K  |
|       from large pool |     563    |     575    |   42575 K  |   42574 K  |
|       from small pool |    3107    |    3114    |   90748 K  |   90745 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3670    |    3684    |  133323 K  |  133320 K  |
|       from large pool |     563    |     575    |   42575 K  |   42574 K  |
|       from small pool |    3107    |    3114    |   90748 K  |   90745 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     136    |     136    |     584    |     448    |
|       from large pool |      63    |      63    |     396    |     333    |
|       from small pool |      73    |      73    |     188    |     115    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      95    |      97    |   99044 K  |   99044 K  |
|       from large pool |      58    |      58    |   19446 K  |   19446 K  |
|       from small pool |      37    |      44    |   79598 K  |   79598 K  |
|===========================================================================|

2022-10-10 23:24:26 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-10 23:26:58 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 23:26:58 - train.py[line:551] - INFO: load:1.09 valid_run:152.90 task_valid:147.78 collect_output:4.07
2022-10-10 23:29:26 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 23:29:26 - train.py[line:551] - INFO: load:1.11 valid_run:301.75 task_valid:290.84 collect_output:8.86
2022-10-10 23:32:00 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 23:32:00 - train.py[line:551] - INFO: load:1.14 valid_run:454.74 task_valid:433.66 collect_output:18.01
2022-10-10 23:34:29 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 23:34:29 - train.py[line:551] - INFO: load:1.16 valid_run:604.14 task_valid:578.52 collect_output:21.54
2022-10-10 23:37:02 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 23:37:02 - train.py[line:551] - INFO: load:1.19 valid_run:757.04 task_valid:726.15 collect_output:25.78
2022-10-10 23:39:34 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 23:39:34 - train.py[line:551] - INFO: load:1.22 valid_run:909.33 task_valid:871.54 collect_output:31.65
2022-10-10 23:42:08 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 23:42:08 - train.py[line:551] - INFO: load:1.24 valid_run:1063.32 task_valid:1017.44 collect_output:38.73
2022-10-10 23:44:40 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 23:44:40 - train.py[line:551] - INFO: load:1.27 valid_run:1215.36 task_valid:1158.75 collect_output:48.37
2022-10-10 23:47:11 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 23:47:11 - train.py[line:551] - INFO: load:1.29 valid_run:1365.71 task_valid:1303.61 collect_output:52.77
2022-10-10 23:49:41 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 23:49:41 - train.py[line:551] - INFO: load:1.32 valid_run:1515.41 task_valid:1446.89 collect_output:58.08
2022-10-10 23:52:11 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 23:52:11 - train.py[line:551] - INFO: load:1.35 valid_run:1665.99 task_valid:1591.94 collect_output:62.58
2022-10-10 23:54:42 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 23:54:42 - train.py[line:551] - INFO: load:1.37 valid_run:1816.69 task_valid:1736.83 collect_output:67.26
2022-10-10 23:57:13 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 23:57:13 - train.py[line:551] - INFO: load:1.40 valid_run:1967.50 task_valid:1878.59 collect_output:75.20
2022-10-10 23:59:44 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 23:59:44 - train.py[line:551] - INFO: load:1.43 valid_run:2118.49 task_valid:2023.93 collect_output:79.78
2022-10-11 00:02:14 - train.py[line:549] - INFO: 3000 / 4988
2022-10-11 00:02:14 - train.py[line:551] - INFO: load:1.46 valid_run:2268.95 task_valid:2170.09 collect_output:82.93
2022-10-11 00:04:45 - train.py[line:549] - INFO: 3200 / 4988
2022-10-11 00:04:45 - train.py[line:551] - INFO: load:1.49 valid_run:2419.64 task_valid:2314.29 collect_output:88.35
2022-10-11 00:07:17 - train.py[line:549] - INFO: 3400 / 4988
2022-10-11 00:07:17 - train.py[line:551] - INFO: load:1.52 valid_run:2571.80 task_valid:2459.49 collect_output:94.28
2022-10-11 00:09:48 - train.py[line:549] - INFO: 3600 / 4988
2022-10-11 00:09:48 - train.py[line:551] - INFO: load:1.54 valid_run:2722.53 task_valid:2606.15 collect_output:97.31
2022-10-11 00:12:17 - train.py[line:549] - INFO: 3800 / 4988
2022-10-11 00:12:17 - train.py[line:551] - INFO: load:1.57 valid_run:2871.48 task_valid:2747.43 collect_output:103.95
2022-10-11 00:14:48 - train.py[line:549] - INFO: 4000 / 4988
2022-10-11 00:14:48 - train.py[line:551] - INFO: load:1.60 valid_run:3022.19 task_valid:2892.14 collect_output:108.94
2022-10-11 00:17:21 - train.py[line:549] - INFO: 4200 / 4988
2022-10-11 00:17:21 - train.py[line:551] - INFO: load:1.62 valid_run:3174.91 task_valid:3036.28 collect_output:116.48
2022-10-11 00:19:50 - train.py[line:549] - INFO: 4400 / 4988
2022-10-11 00:19:50 - train.py[line:551] - INFO: load:1.65 valid_run:3324.31 task_valid:3180.35 collect_output:120.76
2022-10-11 00:22:22 - train.py[line:549] - INFO: 4600 / 4988
2022-10-11 00:22:22 - train.py[line:551] - INFO: load:1.68 valid_run:3475.86 task_valid:3325.94 collect_output:125.71
2022-10-11 00:24:53 - train.py[line:549] - INFO: 4800 / 4988
2022-10-11 00:24:53 - train.py[line:551] - INFO: load:1.70 valid_run:3627.33 task_valid:3472.08 collect_output:130.03

====================================================================================================
SGG eval:     R @ 50: 0.6674;     R @ 100: 0.6983;     R @ 500: 0.7208;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4759;    mR @ 100: 0.5187;    mR @ 500: 0.5653;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:1.0000) (playing:0.0000) (riding:0.9441) (says:0.0000) (sitting on:0.7253) (standing on:0.5060) (using:0.6000) (walking in:0.3333) (walking on:0.5946) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-11 00:27:24 - train.py[line:487] - INFO: 0.698310415075121

====================================================================================================
SGG eval:     R @ 50: 0.6674;     R @ 100: 0.6983;     R @ 500: 0.7208;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4759;    mR @ 100: 0.5187;    mR @ 500: 0.5653;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:1.0000) (playing:0.0000) (riding:0.9441) (says:0.0000) (sitting on:0.7253) (standing on:0.5060) (using:0.6000) (walking in:0.3333) (walking on:0.5946) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-11 00:27:24 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-11 00:27:24 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 0.234 | loss_v1 0 | loss_v2 0 | nll_loss 0.062 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.69831 | ppl 1.04 | vqa_score 0.5146 | wps 118.7 | wpb 89.9 | bsz 30 | num_updates 4116 | best_R@100 0.70421
2022-10-11 00:27:24 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 4116 updates
2022-10-11 00:27:24 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint10.pt
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv slice_id 1 row count 8240 total row count 16480
2022-10-11 00:27:30 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint10.pt
2022-10-11 00:27:33 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint10.pt (epoch 10 @ 4116 updates, score 0.698310415075121) (writing took 8.46733673568815 seconds)
2022-10-11 00:27:33 - train.py[line:339] - INFO: end of epoch 10 (average epoch stats below)
2022-10-11 00:27:33 - progress_bar.py[line:282] - INFO: epoch 010 | loss 0.244 | loss_v1 0 | loss_v2 0 | nll_loss 0.06 | ntokens 111.127 | nsentences 40 | sample_size 111.127 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 5.4 | ups 0.05 | wpb 111.1 | bsz 40 | num_updates 4116 | lr 4.16768e-05 | gnorm 0.577 | clip 16.5 | loss_scale 512 | train_wall 497 | gb_free 10.7 | ema_decay 0.9999 | wall 27144
2022-10-11 00:27:33 - trainer.py[line:643] - INFO: loading train data for epoch 11
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv slice_id 0 row count 8240 total row count 16480
2022-10-11 00:27:33 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-11 00:27:33 - trainer.py[line:707] - INFO: begin training epoch 11
2022-10-11 00:27:33 - train.py[line:312] - INFO: Start iterating over samples
2022-10-11 00:27:39 - progress_bar.py[line:274] - INFO: epoch 011:      4 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=0.3, ups=0, wpb=110.3, bsz=40, num_updates=4120, lr=4.16667e-05, gnorm=0.709, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27150
2022-10-11 00:27:51 - progress_bar.py[line:274] - INFO: epoch 011:     14 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99, ups=0.88, wpb=112.9, bsz=40, num_updates=4130, lr=4.16414e-05, gnorm=0.948, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27162
2022-10-11 00:28:02 - progress_bar.py[line:274] - INFO: epoch 011:     24 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.91, wpb=109.6, bsz=40, num_updates=4140, lr=4.16161e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27173
2022-10-11 00:28:13 - progress_bar.py[line:274] - INFO: epoch 011:     34 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.89, wpb=111.5, bsz=40, num_updates=4150, lr=4.15908e-05, gnorm=0.608, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27184
2022-10-11 00:28:24 - progress_bar.py[line:274] - INFO: epoch 011:     44 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.5, ups=0.89, wpb=111.2, bsz=40, num_updates=4160, lr=4.15655e-05, gnorm=0.427, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27195
2022-10-11 00:28:35 - progress_bar.py[line:274] - INFO: epoch 011:     54 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=4170, lr=4.15403e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27206
2022-10-11 00:28:46 - progress_bar.py[line:274] - INFO: epoch 011:     64 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.3, ups=0.93, wpb=110.2, bsz=40, num_updates=4180, lr=4.1515e-05, gnorm=0.434, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=27217
2022-10-11 00:28:57 - progress_bar.py[line:274] - INFO: epoch 011:     74 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=4190, lr=4.14897e-05, gnorm=0.365, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27228
2022-10-11 00:29:08 - progress_bar.py[line:274] - INFO: epoch 011:     84 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.9, wpb=112, bsz=40, num_updates=4200, lr=4.14644e-05, gnorm=0.521, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27239
2022-10-11 00:29:20 - progress_bar.py[line:274] - INFO: epoch 011:     94 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.9, wpb=111.9, bsz=40, num_updates=4210, lr=4.14391e-05, gnorm=0.46, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=27250
2022-10-11 00:29:31 - progress_bar.py[line:274] - INFO: epoch 011:    104 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=4220, lr=4.14138e-05, gnorm=0.592, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27262
2022-10-11 00:29:42 - progress_bar.py[line:274] - INFO: epoch 011:    114 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.9, ups=0.88, wpb=111.2, bsz=40, num_updates=4230, lr=4.13886e-05, gnorm=0.454, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=27273
2022-10-11 00:29:53 - progress_bar.py[line:274] - INFO: epoch 011:    124 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.89, wpb=111.1, bsz=40, num_updates=4240, lr=4.13633e-05, gnorm=0.545, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27284
2022-10-11 00:30:05 - progress_bar.py[line:274] - INFO: epoch 011:    134 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97, ups=0.88, wpb=110.4, bsz=40, num_updates=4250, lr=4.1338e-05, gnorm=0.479, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27296
2022-10-11 00:30:16 - progress_bar.py[line:274] - INFO: epoch 011:    144 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97, ups=0.87, wpb=111.7, bsz=40, num_updates=4260, lr=4.13127e-05, gnorm=0.801, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27307
2022-10-11 00:30:28 - progress_bar.py[line:274] - INFO: epoch 011:    154 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.8, ups=0.89, wpb=110.4, bsz=40, num_updates=4270, lr=4.12874e-05, gnorm=0.501, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=27318
2022-10-11 00:30:39 - progress_bar.py[line:274] - INFO: epoch 011:    164 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.1, ups=0.91, wpb=112, bsz=40, num_updates=4280, lr=4.12621e-05, gnorm=0.453, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27329
2022-10-11 00:30:50 - progress_bar.py[line:274] - INFO: epoch 011:    174 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.8, ups=0.9, wpb=111.7, bsz=40, num_updates=4290, lr=4.12369e-05, gnorm=0.355, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27340
2022-10-11 00:31:01 - progress_bar.py[line:274] - INFO: epoch 011:    184 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.6, ups=0.92, wpb=113.2, bsz=40, num_updates=4300, lr=4.12116e-05, gnorm=0.606, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27352
2022-10-11 00:31:12 - progress_bar.py[line:274] - INFO: epoch 011:    194 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.88, wpb=111.6, bsz=40, num_updates=4310, lr=4.11863e-05, gnorm=0.795, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27363
2022-10-11 00:31:23 - progress_bar.py[line:274] - INFO: epoch 011:    204 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.89, wpb=112.3, bsz=40, num_updates=4320, lr=4.1161e-05, gnorm=0.569, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27374
2022-10-11 00:31:35 - progress_bar.py[line:274] - INFO: epoch 011:    214 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=4330, lr=4.11357e-05, gnorm=0.456, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27385
2022-10-11 00:31:46 - progress_bar.py[line:274] - INFO: epoch 011:    224 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.4, ups=0.91, wpb=111.1, bsz=40, num_updates=4340, lr=4.11104e-05, gnorm=0.526, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27396
2022-10-11 00:31:57 - progress_bar.py[line:274] - INFO: epoch 011:    234 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.2, ups=0.88, wpb=111.6, bsz=40, num_updates=4350, lr=4.10852e-05, gnorm=0.639, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27408
2022-10-11 00:32:08 - progress_bar.py[line:274] - INFO: epoch 011:    244 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=111.7, bsz=40, num_updates=4360, lr=4.10599e-05, gnorm=0.529, clip=20, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=27419
2022-10-11 00:32:19 - progress_bar.py[line:274] - INFO: epoch 011:    254 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.91, wpb=109.9, bsz=40, num_updates=4370, lr=4.10346e-05, gnorm=0.684, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27430
2022-10-11 00:32:31 - progress_bar.py[line:274] - INFO: epoch 011:    264 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.9, wpb=111.6, bsz=40, num_updates=4380, lr=4.10093e-05, gnorm=0.537, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27441
2022-10-11 00:32:42 - progress_bar.py[line:274] - INFO: epoch 011:    274 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.4, ups=0.88, wpb=111.8, bsz=40, num_updates=4390, lr=4.0984e-05, gnorm=0.353, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27453
2022-10-11 00:32:53 - progress_bar.py[line:274] - INFO: epoch 011:    284 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=4400, lr=4.09587e-05, gnorm=0.582, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27464
2022-10-11 00:33:04 - progress_bar.py[line:274] - INFO: epoch 011:    294 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.9, wpb=111.7, bsz=40, num_updates=4410, lr=4.09335e-05, gnorm=0.442, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27475
2022-10-11 00:33:15 - progress_bar.py[line:274] - INFO: epoch 011:    304 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=4420, lr=4.09082e-05, gnorm=0.494, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27486
2022-10-11 00:33:26 - progress_bar.py[line:274] - INFO: epoch 011:    314 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=110.9, bsz=40, num_updates=4430, lr=4.08829e-05, gnorm=0.783, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27497
2022-10-11 00:33:38 - progress_bar.py[line:274] - INFO: epoch 011:    324 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=95.8, ups=0.87, wpb=110.2, bsz=40, num_updates=4440, lr=4.08576e-05, gnorm=0.644, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27509
2022-10-11 00:33:49 - progress_bar.py[line:274] - INFO: epoch 011:    334 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.2, ups=0.89, wpb=109.2, bsz=40, num_updates=4450, lr=4.08323e-05, gnorm=0.378, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27520
2022-10-11 00:34:00 - progress_bar.py[line:274] - INFO: epoch 011:    344 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.7, ups=0.91, wpb=110.2, bsz=40, num_updates=4460, lr=4.0807e-05, gnorm=0.416, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27531
2022-10-11 00:34:11 - progress_bar.py[line:274] - INFO: epoch 011:    354 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102, ups=0.92, wpb=111.3, bsz=40, num_updates=4470, lr=4.07818e-05, gnorm=0.424, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27542
2022-10-11 00:34:18 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-11 00:34:23 - progress_bar.py[line:274] - INFO: epoch 011:    365 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.9, ups=0.82, wpb=111, bsz=40, num_updates=4480, lr=4.07565e-05, gnorm=0.456, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=27554
2022-10-11 00:34:35 - progress_bar.py[line:274] - INFO: epoch 011:    375 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.88, wpb=110.9, bsz=40, num_updates=4490, lr=4.07312e-05, gnorm=0.397, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27565
2022-10-11 00:34:46 - progress_bar.py[line:274] - INFO: epoch 011:    385 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.9, wpb=110.5, bsz=40, num_updates=4500, lr=4.07059e-05, gnorm=0.761, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27576
2022-10-11 00:34:56 - progress_bar.py[line:274] - INFO: epoch 011:    395 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.2, ups=0.93, wpb=111.3, bsz=40, num_updates=4510, lr=4.06806e-05, gnorm=0.297, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27587
2022-10-11 00:35:07 - progress_bar.py[line:274] - INFO: epoch 011:    405 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.6, ups=0.93, wpb=111.6, bsz=40, num_updates=4520, lr=4.06553e-05, gnorm=0.518, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27598
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv slice_id 1 row count 8240 total row count 16480
2022-10-11 00:35:15 - train.py[line:339] - INFO: end of epoch 11 (average epoch stats below)
2022-10-11 00:35:15 - progress_bar.py[line:282] - INFO: epoch 011 | loss 0.243 | loss_v1 0 | loss_v2 0 | nll_loss 0.058 | ntokens 111.127 | nsentences 40 | sample_size 111.127 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 98.8 | ups 0.89 | wpb 111.1 | bsz 40 | num_updates 4527 | lr 4.06376e-05 | gnorm 0.534 | clip 12.9 | loss_scale 512 | train_wall 458 | gb_free 10.4 | ema_decay 0.9999 | wall 27606
2022-10-11 00:35:15 - trainer.py[line:643] - INFO: loading train data for epoch 12
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv slice_id 0 row count 8240 total row count 16480
2022-10-11 00:35:15 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-11 00:35:16 - trainer.py[line:707] - INFO: begin training epoch 12
2022-10-11 00:35:16 - train.py[line:312] - INFO: Start iterating over samples
2022-10-11 00:35:21 - progress_bar.py[line:274] - INFO: epoch 012:      3 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=82.3, ups=0.75, wpb=109.9, bsz=40, num_updates=4530, lr=4.06301e-05, gnorm=0.583, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27611
2022-10-11 00:35:32 - progress_bar.py[line:274] - INFO: epoch 012:     13 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=4540, lr=4.06048e-05, gnorm=0.282, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=27623
2022-10-11 00:35:43 - progress_bar.py[line:274] - INFO: epoch 012:     23 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=4550, lr=4.05795e-05, gnorm=0.258, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27634
2022-10-11 00:35:54 - progress_bar.py[line:274] - INFO: epoch 012:     33 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.88, wpb=112.2, bsz=40, num_updates=4560, lr=4.05542e-05, gnorm=0.904, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27645
2022-10-11 00:36:06 - progress_bar.py[line:274] - INFO: epoch 012:     43 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.2, ups=0.87, wpb=110.9, bsz=40, num_updates=4570, lr=4.05289e-05, gnorm=0.322, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27657
2022-10-11 00:36:17 - progress_bar.py[line:274] - INFO: epoch 012:     53 / 412 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.4, ups=0.88, wpb=111.5, bsz=40, num_updates=4580, lr=4.05036e-05, gnorm=0.259, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27668
2022-10-11 00:36:28 - progress_bar.py[line:274] - INFO: epoch 012:     63 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.8, ups=0.88, wpb=111, bsz=40, num_updates=4590, lr=4.04784e-05, gnorm=0.653, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=27679
2022-10-11 00:36:40 - progress_bar.py[line:274] - INFO: epoch 012:     73 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.9, wpb=111.5, bsz=40, num_updates=4600, lr=4.04531e-05, gnorm=0.644, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27690
2022-10-11 00:36:51 - progress_bar.py[line:274] - INFO: epoch 012:     83 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.89, wpb=112.5, bsz=40, num_updates=4610, lr=4.04278e-05, gnorm=0.868, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27702
2022-10-11 00:37:02 - progress_bar.py[line:274] - INFO: epoch 012:     93 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.88, wpb=111.6, bsz=40, num_updates=4620, lr=4.04025e-05, gnorm=0.371, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27713
2022-10-11 00:37:13 - progress_bar.py[line:274] - INFO: epoch 012:    103 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98, ups=0.88, wpb=111, bsz=40, num_updates=4630, lr=4.03772e-05, gnorm=0.726, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=27724
2022-10-11 00:37:25 - progress_bar.py[line:274] - INFO: epoch 012:    113 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=4640, lr=4.03519e-05, gnorm=0.565, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=27735
2022-10-11 00:37:36 - progress_bar.py[line:274] - INFO: epoch 012:    123 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=4650, lr=4.03267e-05, gnorm=0.635, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27747
2022-10-11 00:37:47 - progress_bar.py[line:274] - INFO: epoch 012:    133 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.89, wpb=111.9, bsz=40, num_updates=4660, lr=4.03014e-05, gnorm=0.458, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27758
2022-10-11 00:37:58 - progress_bar.py[line:274] - INFO: epoch 012:    143 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.7, ups=0.89, wpb=111, bsz=40, num_updates=4670, lr=4.02761e-05, gnorm=0.324, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27769
2022-10-11 00:38:10 - progress_bar.py[line:274] - INFO: epoch 012:    153 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.88, wpb=110.9, bsz=40, num_updates=4680, lr=4.02508e-05, gnorm=0.376, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27780
2022-10-11 00:38:21 - progress_bar.py[line:274] - INFO: epoch 012:    163 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.89, wpb=110, bsz=40, num_updates=4690, lr=4.02255e-05, gnorm=0.515, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27792
2022-10-11 00:38:32 - progress_bar.py[line:274] - INFO: epoch 012:    173 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=4700, lr=4.02002e-05, gnorm=0.977, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27803
2022-10-11 00:38:43 - progress_bar.py[line:274] - INFO: epoch 012:    183 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.9, wpb=109.8, bsz=40, num_updates=4710, lr=4.0175e-05, gnorm=0.335, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27814
2022-10-11 00:38:54 - progress_bar.py[line:274] - INFO: epoch 012:    193 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.4, ups=0.89, wpb=110.5, bsz=40, num_updates=4720, lr=4.01497e-05, gnorm=0.818, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27825
2022-10-11 00:39:06 - progress_bar.py[line:274] - INFO: epoch 012:    203 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.9, ups=0.88, wpb=111.4, bsz=40, num_updates=4730, lr=4.01244e-05, gnorm=0.477, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27836
2022-10-11 00:39:17 - progress_bar.py[line:274] - INFO: epoch 012:    213 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.89, wpb=110.8, bsz=40, num_updates=4740, lr=4.00991e-05, gnorm=0.261, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27848
2022-10-11 00:39:28 - progress_bar.py[line:274] - INFO: epoch 012:    223 / 412 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.91, wpb=112.4, bsz=40, num_updates=4750, lr=4.00738e-05, gnorm=0.203, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27859
2022-10-11 00:39:38 - progress_bar.py[line:274] - INFO: epoch 012:    233 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.6, ups=0.94, wpb=110.2, bsz=40, num_updates=4760, lr=4.00485e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27869
2022-10-11 00:39:50 - progress_bar.py[line:274] - INFO: epoch 012:    243 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.9, wpb=111.4, bsz=40, num_updates=4770, lr=4.00233e-05, gnorm=0.387, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=27880
2022-10-11 00:40:00 - progress_bar.py[line:274] - INFO: epoch 012:    253 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.93, wpb=110.9, bsz=40, num_updates=4780, lr=3.9998e-05, gnorm=0.453, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27891
2022-10-11 00:40:11 - progress_bar.py[line:274] - INFO: epoch 012:    263 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.9, ups=0.9, wpb=112.1, bsz=40, num_updates=4790, lr=3.99727e-05, gnorm=0.235, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27902
2022-10-11 00:40:23 - progress_bar.py[line:274] - INFO: epoch 012:    273 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.87, wpb=111.3, bsz=40, num_updates=4800, lr=3.99474e-05, gnorm=0.629, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=27914
2022-10-11 00:40:34 - progress_bar.py[line:274] - INFO: epoch 012:    283 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111.5, bsz=40, num_updates=4810, lr=3.99221e-05, gnorm=0.317, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27925
2022-10-11 00:40:45 - progress_bar.py[line:274] - INFO: epoch 012:    293 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.89, wpb=110.5, bsz=40, num_updates=4820, lr=3.98968e-05, gnorm=0.575, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27936
2022-10-11 00:40:57 - progress_bar.py[line:274] - INFO: epoch 012:    303 / 412 loss=0.227, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.8, ups=0.88, wpb=112.4, bsz=40, num_updates=4830, lr=3.98716e-05, gnorm=0.193, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27948
2022-10-11 00:41:08 - progress_bar.py[line:274] - INFO: epoch 012:    313 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.9, wpb=110.7, bsz=40, num_updates=4840, lr=3.98463e-05, gnorm=0.787, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=27959
2022-10-11 00:41:19 - progress_bar.py[line:274] - INFO: epoch 012:    323 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=4850, lr=3.9821e-05, gnorm=0.308, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=27970
2022-10-11 00:41:30 - progress_bar.py[line:274] - INFO: epoch 012:    333 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.89, wpb=112.2, bsz=40, num_updates=4860, lr=3.97957e-05, gnorm=0.745, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27981
2022-10-11 00:41:42 - progress_bar.py[line:274] - INFO: epoch 012:    343 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.8, ups=0.87, wpb=111.4, bsz=40, num_updates=4870, lr=3.97704e-05, gnorm=0.337, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27992
2022-10-11 00:41:53 - progress_bar.py[line:274] - INFO: epoch 012:    353 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111.6, bsz=40, num_updates=4880, lr=3.97451e-05, gnorm=0.449, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=28004
2022-10-11 00:42:04 - progress_bar.py[line:274] - INFO: epoch 012:    363 / 412 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=4890, lr=3.97199e-05, gnorm=0.275, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=28015
2022-10-11 00:42:16 - progress_bar.py[line:274] - INFO: epoch 012:    373 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97, ups=0.87, wpb=111.1, bsz=40, num_updates=4900, lr=3.96946e-05, gnorm=0.414, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=28026
2022-10-11 00:42:27 - progress_bar.py[line:274] - INFO: epoch 012:    383 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=4910, lr=3.96693e-05, gnorm=0.615, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=28038
2022-10-11 00:42:38 - progress_bar.py[line:274] - INFO: epoch 012:    393 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=4920, lr=3.9644e-05, gnorm=0.35, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=28049
2022-10-11 00:42:49 - progress_bar.py[line:274] - INFO: epoch 012:    403 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=4930, lr=3.96187e-05, gnorm=0.408, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=28060
2022-10-11 00:42:59 - train.py[line:339] - INFO: end of epoch 12 (average epoch stats below)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv slice_id 1 row count 8240 total row count 16480
2022-10-11 00:42:59 - progress_bar.py[line:282] - INFO: epoch 012 | loss 0.241 | loss_v1 0 | loss_v2 0 | nll_loss 0.056 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 98.7 | ups 0.89 | wpb 111.1 | bsz 40 | num_updates 4939 | lr 3.9596e-05 | gnorm 0.489 | clip 12.9 | loss_scale 512 | train_wall 460 | gb_free 10.7 | ema_decay 0.9999 | wall 28070
2022-10-11 00:42:59 - trainer.py[line:643] - INFO: loading train data for epoch 13
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv slice_id 0 row count 8240 total row count 16480
2022-10-11 00:42:59 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-11 00:43:00 - trainer.py[line:707] - INFO: begin training epoch 13
2022-10-11 00:43:00 - train.py[line:312] - INFO: Start iterating over samples
2022-10-11 00:43:02 - progress_bar.py[line:274] - INFO: epoch 013:      1 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.1, ups=0.77, wpb=111.1, bsz=40, num_updates=4940, lr=3.95934e-05, gnorm=0.775, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=28073
2022-10-11 00:43:13 - progress_bar.py[line:274] - INFO: epoch 013:     11 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.89, wpb=111.4, bsz=40, num_updates=4950, lr=3.95682e-05, gnorm=0.421, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=28084
2022-10-11 00:43:24 - progress_bar.py[line:274] - INFO: epoch 013:     21 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.91, wpb=111.8, bsz=40, num_updates=4960, lr=3.95429e-05, gnorm=0.308, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=28095
2022-10-11 00:43:35 - progress_bar.py[line:274] - INFO: epoch 013:     31 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.9, wpb=111.2, bsz=40, num_updates=4970, lr=3.95176e-05, gnorm=0.443, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=28106
2022-10-11 00:43:47 - progress_bar.py[line:274] - INFO: epoch 013:     41 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.89, wpb=109.6, bsz=40, num_updates=4980, lr=3.94923e-05, gnorm=0.444, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=28117
2022-10-11 00:43:58 - progress_bar.py[line:274] - INFO: epoch 013:     51 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=4990, lr=3.9467e-05, gnorm=0.377, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=28129
2022-10-11 00:44:09 - progress_bar.py[line:274] - INFO: epoch 013:     61 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.1, ups=0.93, wpb=110.3, bsz=40, num_updates=5000, lr=3.94417e-05, gnorm=0.296, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=28139
2022-10-11 00:44:09 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-11 00:44:10 - train.py[line:549] - INFO: 0 / 4988
2022-10-11 00:44:10 - train.py[line:551] - INFO: load:1.03 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-11 00:44:11 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.84 GiB already allocated; 4.77 GiB free; 32.33 GiB reserved in total by PyTorch)
2022-10-11 00:44:11 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-11 00:44:11 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 19        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9053 MB |   10278 MB |    3549 TB |    3549 TB |
|       from large pool |    8908 MB |   10133 MB |    3548 TB |    3548 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9053 MB |   10278 MB |    3549 TB |    3549 TB |
|       from large pool |    8908 MB |   10133 MB |    3548 TB |    3548 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   33106 MB |   33108 MB |  232344 MB |  199238 MB |
|       from large pool |   32960 MB |   32960 MB |  231942 MB |  198982 MB |
|       from small pool |     146 MB |     148 MB |     402 MB |     256 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24052 MB |   28444 MB |    4536 TB |    4536 TB |
|       from large pool |   24051 MB |   28442 MB |    4535 TB |    4535 TB |
|       from small pool |       1 MB |       2 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  165884 K  |  165880 K  |
|       from large pool |     563    |     575    |   52827 K  |   52827 K  |
|       from small pool |    3095    |    3114    |  113056 K  |  113053 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  165884 K  |  165880 K  |
|       from large pool |     563    |     575    |   52827 K  |   52827 K  |
|       from small pool |    3095    |    3114    |  113056 K  |  113053 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     132    |     133    |     597    |     465    |
|       from large pool |      59    |      59    |     396    |     337    |
|       from small pool |      73    |      74    |     201    |     128    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      84    |      87    |  123920 K  |  123920 K  |
|       from large pool |      42    |      43    |   24709 K  |   24708 K  |
|       from small pool |      42    |      49    |   99211 K  |   99211 K  |
|===========================================================================|

2022-10-11 00:44:11 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-11 00:46:44 - train.py[line:549] - INFO: 200 / 4988
2022-10-11 00:46:44 - train.py[line:551] - INFO: load:1.06 valid_run:154.08 task_valid:149.21 collect_output:3.82
2022-10-11 00:49:13 - train.py[line:549] - INFO: 400 / 4988
2022-10-11 00:49:13 - train.py[line:551] - INFO: load:1.08 valid_run:303.14 task_valid:292.34 collect_output:8.74
2022-10-11 00:51:47 - train.py[line:549] - INFO: 600 / 4988
2022-10-11 00:51:47 - train.py[line:551] - INFO: load:1.11 valid_run:456.48 task_valid:435.70 collect_output:17.64
2022-10-11 00:54:17 - train.py[line:549] - INFO: 800 / 4988
2022-10-11 00:54:17 - train.py[line:551] - INFO: load:1.13 valid_run:606.51 task_valid:580.97 collect_output:21.31
2022-10-11 00:56:50 - train.py[line:549] - INFO: 1000 / 4988
2022-10-11 00:56:50 - train.py[line:551] - INFO: load:1.16 valid_run:759.95 task_valid:729.06 collect_output:25.45
2022-10-11 00:59:23 - train.py[line:549] - INFO: 1200 / 4988
2022-10-11 00:59:23 - train.py[line:551] - INFO: load:1.18 valid_run:912.64 task_valid:874.69 collect_output:31.39
2022-10-11 01:01:58 - train.py[line:549] - INFO: 1400 / 4988
2022-10-11 01:01:58 - train.py[line:551] - INFO: load:1.21 valid_run:1067.21 task_valid:1020.95 collect_output:38.58
2022-10-11 01:04:30 - train.py[line:549] - INFO: 1600 / 4988
2022-10-11 01:04:30 - train.py[line:551] - INFO: load:1.23 valid_run:1219.53 task_valid:1162.48 collect_output:48.19
2022-10-11 01:07:01 - train.py[line:549] - INFO: 1800 / 4988
2022-10-11 01:07:01 - train.py[line:551] - INFO: load:1.26 valid_run:1370.08 task_valid:1307.32 collect_output:52.80
2022-10-11 01:09:30 - train.py[line:549] - INFO: 2000 / 4988
2022-10-11 01:09:30 - train.py[line:551] - INFO: load:1.29 valid_run:1519.74 task_valid:1450.53 collect_output:58.18
2022-10-11 01:12:01 - train.py[line:549] - INFO: 2200 / 4988
2022-10-11 01:12:01 - train.py[line:551] - INFO: load:1.31 valid_run:1670.03 task_valid:1595.37 collect_output:62.57
2022-10-11 01:14:31 - train.py[line:549] - INFO: 2400 / 4988
2022-10-11 01:14:31 - train.py[line:551] - INFO: load:1.34 valid_run:1820.69 task_valid:1740.32 collect_output:67.26
2022-10-11 01:17:02 - train.py[line:549] - INFO: 2600 / 4988
2022-10-11 01:17:02 - train.py[line:551] - INFO: load:1.36 valid_run:1971.15 task_valid:1881.96 collect_output:75.08
2022-10-11 01:19:33 - train.py[line:549] - INFO: 2800 / 4988
2022-10-11 01:19:33 - train.py[line:551] - INFO: load:1.39 valid_run:2121.99 task_valid:2027.39 collect_output:79.43
2022-10-11 01:22:03 - train.py[line:549] - INFO: 3000 / 4988
2022-10-11 01:22:03 - train.py[line:551] - INFO: load:1.42 valid_run:2272.21 task_valid:2173.41 collect_output:82.62
2022-10-11 01:24:33 - train.py[line:549] - INFO: 3200 / 4988
2022-10-11 01:24:33 - train.py[line:551] - INFO: load:1.44 valid_run:2422.33 task_valid:2317.12 collect_output:88.04
2022-10-11 01:27:05 - train.py[line:549] - INFO: 3400 / 4988
2022-10-11 01:27:05 - train.py[line:551] - INFO: load:1.47 valid_run:2574.46 task_valid:2462.52 collect_output:93.72
2022-10-11 01:29:36 - train.py[line:549] - INFO: 3600 / 4988
2022-10-11 01:29:36 - train.py[line:551] - INFO: load:1.49 valid_run:2724.95 task_valid:2608.92 collect_output:96.82
2022-10-11 01:32:05 - train.py[line:549] - INFO: 3800 / 4988
2022-10-11 01:32:05 - train.py[line:551] - INFO: load:1.52 valid_run:2874.11 task_valid:2750.28 collect_output:103.60
2022-10-11 01:34:36 - train.py[line:549] - INFO: 4000 / 4988
2022-10-11 01:34:36 - train.py[line:551] - INFO: load:1.54 valid_run:3024.83 task_valid:2895.40 collect_output:108.17
2022-10-11 01:37:08 - train.py[line:549] - INFO: 4200 / 4988
2022-10-11 01:37:08 - train.py[line:551] - INFO: load:1.57 valid_run:3177.19 task_valid:3039.60 collect_output:115.32
2022-10-11 01:39:38 - train.py[line:549] - INFO: 4400 / 4988
2022-10-11 01:39:38 - train.py[line:551] - INFO: load:1.60 valid_run:3326.72 task_valid:3183.55 collect_output:119.87
2022-10-11 01:42:10 - train.py[line:549] - INFO: 4600 / 4988
2022-10-11 01:42:10 - train.py[line:551] - INFO: load:1.62 valid_run:3478.26 task_valid:3329.11 collect_output:124.84
2022-10-11 01:44:41 - train.py[line:549] - INFO: 4800 / 4988
2022-10-11 01:44:41 - train.py[line:551] - INFO: load:1.65 valid_run:3629.80 task_valid:3475.13 collect_output:129.33

====================================================================================================
SGG eval:     R @ 50: 0.6618;     R @ 100: 0.6937;     R @ 500: 0.7148;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4728;    mR @ 100: 0.5158;    mR @ 500: 0.5609;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:1.0000) (playing:0.0000) (riding:0.9412) (says:0.0000) (sitting on:0.7185) (standing on:0.5110) (using:0.6000) (walking in:0.3333) (walking on:0.5405) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6618;     R @ 100: 0.6937;     R @ 500: 0.7148;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4728;    mR @ 100: 0.5158;    mR @ 500: 0.5609;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.8235) (flying in:0.5909) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:1.0000) (playing:0.0000) (riding:0.9412) (says:0.0000) (sitting on:0.7185) (standing on:0.5110) (using:0.6000) (walking in:0.3333) (walking on:0.5405) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-11 01:47:12 - train.py[line:487] - INFO: 0.693710415075121
2022-10-11 01:47:12 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-11 01:47:12 - progress_bar.py[line:282] - INFO: epoch 013 | valid on 'valid' subset | loss 0.226 | loss_v1 0 | loss_v2 0 | nll_loss 0.056 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.69371 | ppl 1.04 | vqa_score 0.5023 | wps 118.6 | wpb 89.9 | bsz 30 | num_updates 5000 | best_R@100 0.70421
2022-10-11 01:47:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 13 @ 5000 updates
2022-10-11 01:47:12 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.50-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_13_5000.pt
