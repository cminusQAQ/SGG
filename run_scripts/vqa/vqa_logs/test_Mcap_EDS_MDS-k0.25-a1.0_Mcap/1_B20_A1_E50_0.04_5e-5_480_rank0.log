2022-10-10 16:49:51 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-10 16:49:51 - utils.py[line:261] - INFO: Start init
2022-10-10 16:49:51 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-10 16:49:51 - utils.py[line:261] - INFO: Start init
2022-10-10 16:49:51 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-10 16:49:51 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-10 16:49:51 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-10 16:49:51 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-10 16:50:00 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 50, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k25alpha1.0__with_caption_init/1_B20_A1_E4_0.04_5e-5_480/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=50, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k25alpha1.0__with_caption_init/1_B20_A1_E4_0.04_5e-5_480/checkpoint_best.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-10 16:50:01 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-10 16:50:01 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
Traceback (most recent call last):
  File "../../train.py", line 632, in <module>
    cli_main()
  File "../../train.py", line 625, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
Traceback (most recent call last):
  File "../../train.py", line 632, in <module>
    cli_main()
  File "../../train.py", line 625, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 97, in main
    task = tasks.setup_task(cfg.task)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/tasks/__init__.py", line 46, in setup_task
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 97, in main
    task = tasks.setup_task(cfg.task)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/tasks/__init__.py", line 46, in setup_task
    return task.setup_task(cfg, **kwargs)
  File "/data/private/yutianyu/OFA/tasks/ofa_task.py", line 113, in setup_task
    return task.setup_task(cfg, **kwargs)
  File "/data/private/yutianyu/OFA/tasks/ofa_task.py", line 113, in setup_task
    return cls(cfg, src_dict, tgt_dict)
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 103, in __init__
    return cls(cfg, src_dict, tgt_dict)
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 103, in __init__
    self.ans2label_dict = pickle.load(open(self.cfg.ans2label_file, "rb"))
FileNotFoundError: [Errno 2] No such file or directory: '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl'    
self.ans2label_dict = pickle.load(open(self.cfg.ans2label_file, "rb"))
FileNotFoundError: [Errno 2] No such file or directory: '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl'
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k25alpha1.0__with_caption_init/1_B20_A1_E4_0.04_5e-5_480/checkpoint_best.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=15', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=5e-5', '--max-epoch=50', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=1000', '--validate-interval-updates=1000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=5']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 4144805
Killing subprocess 4144806
2022-10-10 16:50:52 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-10 16:50:52 - utils.py[line:261] - INFO: Start init
2022-10-10 16:50:53 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-10 16:50:53 - utils.py[line:261] - INFO: Start init
2022-10-10 16:50:53 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-10 16:50:53 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-10 16:50:53 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-10 16:50:53 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-10 16:51:02 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 50, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k25alpha1.0__with_caption_init/1_B20_A1_E4_0.04_5e-5_480/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=50, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k25alpha1.0__with_caption_init/1_B20_A1_E4_0.04_5e-5_480/checkpoint_best.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-10 16:51:03 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-10 16:51:03 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
Traceback (most recent call last):
  File "../../train.py", line 632, in <module>
    cli_main()
  File "../../train.py", line 625, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 142, in main
    task.load_dataset(valid_sub_split, combine=False, epoch=1)
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 121, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/private/yutianyu/OFA/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv not exists!
Exception ignored in: <function FileDataset.__del__ at 0x7f11d0180b00>
Traceback (most recent call last):
  File "/data/private/yutianyu/OFA/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
2022-10-10 16:51:08 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-10 16:51:08 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-10 16:51:08 - train.py[line:119] - INFO: model: OFAModel
2022-10-10 16:51:08 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-10 16:51:08 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-10 16:51:08 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
Traceback (most recent call last):
  File "../../train.py", line 632, in <module>
    cli_main()
  File "../../train.py", line 625, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 374, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/fairseq/distributed/utils.py", line 348, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 142, in main
    task.load_dataset(valid_sub_split, combine=False, epoch=1)
  File "/data/private/yutianyu/OFA/tasks/mm_tasks/vqa_gen.py", line 121, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/private/yutianyu/OFA/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv not exists!
Exception ignored in: <function FileDataset.__del__ at 0x7f908fc10b00>
Traceback (most recent call last):
  File "/data/private/yutianyu/OFA/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k25alpha1.0__with_caption_init/1_B20_A1_E4_0.04_5e-5_480/checkpoint_best.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=15', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=5e-5', '--max-epoch=50', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=1000', '--validate-interval-updates=1000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=5']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 4159763
Killing subprocess 4159764
2022-10-10 16:51:33 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-10 16:51:33 - utils.py[line:261] - INFO: Start init
2022-10-10 16:51:33 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-10 16:51:33 - utils.py[line:261] - INFO: Start init
2022-10-10 16:51:33 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-10 16:51:33 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-10 16:51:33 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-10 16:51:33 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-10 16:51:43 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 5, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 50, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k25alpha1.0__with_caption_init/1_B20_A1_E4_0.04_5e-5_480/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=50, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=5, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k25alpha1.0__with_caption_init/1_B20_A1_E4_0.04_5e-5_480/checkpoint_best.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-10 16:51:43 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-10 16:51:43 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
2022-10-10 16:51:48 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-10 16:51:48 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-10 16:51:48 - train.py[line:119] - INFO: model: OFAModel
2022-10-10 16:51:48 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-10 16:51:48 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-10 16:51:48 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-10 16:51:49 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-10 16:51:49 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-10 16:51:49 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-10 16:51:49 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-10 16:51:49 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-10 16:51:49 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-10 16:51:49 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-10 16:51:49 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-10-10 16:51:49 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k25alpha1.0__with_caption_init/1_B20_A1_E4_0.04_5e-5_480/checkpoint_best.pt
2022-10-10 16:52:16 - trainer.py[line:605] - INFO: Loading EMA from checkpoint
2022-10-10 16:52:17 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-10-10 16:52:17 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-10-10 16:52:18 - trainer.py[line:612] - INFO: Loading EMA fp32 params from checkpoint
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 16:52:18 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k25alpha1.0__with_caption_init/1_B20_A1_E4_0.04_5e-5_480/checkpoint_best.pt (epoch 1 @ 0 updates)
2022-10-10 16:52:18 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 16:52:18 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 20600, warmup steps 824, warmup_factor 0.0012135922330097086
Total steps 20600, warmup steps 824, warmup_factor 0.0012135922330097086
2022-10-10 16:52:19 - trainer.py[line:707] - INFO: begin training epoch 1
2022-10-10 16:52:19 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 16:52:43 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 412 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=66.6, ups=0.61, wpb=109.8, bsz=40, num_updates=10, lr=6.06796e-07, gnorm=1.846, clip=90, loss_scale=128, train_wall=22, gb_free=10.8, ema_decay=0.9999, wall=54
2022-10-10 16:52:57 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 412 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=83.9, ups=0.75, wpb=111.9, bsz=40, num_updates=20, lr=1.21359e-06, gnorm=1.579, clip=100, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=67
2022-10-10 16:53:10 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 412 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=84, ups=0.75, wpb=111.5, bsz=40, num_updates=30, lr=1.82039e-06, gnorm=1.602, clip=100, loss_scale=128, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=81
2022-10-10 16:53:24 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 412 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=81, ups=0.73, wpb=110.8, bsz=40, num_updates=40, lr=2.42718e-06, gnorm=1.719, clip=90, loss_scale=128, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=94
2022-10-10 16:53:37 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 412 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=85, ups=0.76, wpb=111.4, bsz=40, num_updates=50, lr=3.03398e-06, gnorm=1.738, clip=90, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=107
2022-10-10 16:53:50 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 412 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.222, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=81.8, ups=0.74, wpb=110.7, bsz=40, num_updates=60, lr=3.64078e-06, gnorm=1.476, clip=80, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=121
2022-10-10 16:54:03 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 412 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=88.2, ups=0.79, wpb=111.3, bsz=40, num_updates=70, lr=4.24757e-06, gnorm=1.017, clip=50, loss_scale=128, train_wall=13, gb_free=11.2, ema_decay=0.9999, wall=134
2022-10-10 16:54:05 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-10 16:54:05 - utils.py[line:261] - INFO: Start init
2022-10-10 16:54:05 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-10 16:54:06 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-10 16:54:06 - utils.py[line:261] - INFO: Start init
Retry: 1, with value error <class 'RuntimeError'>
Traceback (most recent call last):
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/yutianyu/miniconda3/envs/OFA/bin/python3', '-u', '../../train.py', '--local_rank=1', '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', '--selected-cols=0,5,2,3,4', '--data-buffer-size', '10', '--tensorboard-logdir=./vqa_tensorboard/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap', '--bpe-dir=../../utils/BPE', '--user-dir=../../ofa_module', '--restore-file=/data/private/yutianyu/OFA/run_scripts/vqa/vqa_checkpoints/test_EM_optNew_caption_trained_visual_DS-k50alpha1.0__with_caption_init/1_B20_A1_E2_0.04_5e-5_480/checkpoint_best.pt', '--reset-optimizer', '--reset-dataloader', '--reset-meters', '--save-dir=./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480', '--task=vqa_gen', '--arch=ofa_base', '--criterion=adjust_label_smoothed_cross_entropy', '--label-smoothing=0.1', '--label-proxy', 'answer', '--batch-size=20', '--batch-size-valid=15', '--update-freq=1', '--encoder-normalize-before', '--decoder-normalize-before', '--share-decoder-input-output-embed', '--share-all-embeddings', '--layernorm-embedding', '--patch-layernorm-embedding', '--code-layernorm-embedding', '--resnet-drop-path-rate=0.0', '--encoder-drop-path-rate=0.1', '--decoder-drop-path-rate=0.1', '--dropout=0.1', '--attention-dropout=0.0', '--weight-decay=0.01', '--optimizer=adam', '--adam-betas=(0.9,0.999)', '--adam-eps=1e-08', '--clip-norm=1.0', '--lr-scheduler=polynomial_decay', '--lr=5e-5', '--max-epoch=50', '--warmup-ratio=0.04', '--log-format=simple', '--log-interval=10', '--fixed-validation-seed=7', '--save-interval=10', '--validate-interval=10', '--save-interval-updates=1000', '--validate-interval-updates=1000', '--best-checkpoint-metric=R@100', '--maximize-best-checkpoint-metric', '--max-src-length=128', '--max-object-length=30', '--max-tgt-length=30', '--find-unused-parameters', '--freeze-encoder-embedding', '--freeze-decoder-embedding', '--ans2label-file=/data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', '--valid-batch-size=51', '--add-type-embedding', '--scale-attn', '--scale-fc', '--scale-heads', '--disable-entangle', '--num-bins=1000', '--patch-image-size=480', '--prompt-type=prev_output', '--fp16', '--fp16-scale-window=512', '--add-object', '--uses-ema', '--store-ema', '--ema-fp32', '--ema-decay=0.9999', '--ema-start-update=0', '--val-inference-type=allcand', '--num-workers=5']' returned non-zero exit status 255.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 4190540
Killing subprocess 4190541
2022-10-10 16:54:15 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 412 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.199, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=88.9, ups=0.81, wpb=110.4, bsz=40, num_updates=80, lr=4.85437e-06, gnorm=1.309, clip=80, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=146
2022-10-10 16:54:28 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 412 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.6, ups=0.79, wpb=111.5, bsz=40, num_updates=90, lr=5.46117e-06, gnorm=1.086, clip=70, loss_scale=128, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=159
2022-10-10 16:54:41 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 412 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=87.3, ups=0.79, wpb=111.2, bsz=40, num_updates=100, lr=6.06796e-06, gnorm=1.202, clip=80, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=172
2022-10-10 16:54:53 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 412 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.143, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=87.9, ups=0.8, wpb=110.1, bsz=40, num_updates=110, lr=6.67476e-06, gnorm=1.136, clip=70, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=184
2022-10-10 16:55:07 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 412 loss=0.315, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=84.5, ups=0.77, wpb=110, bsz=40, num_updates=120, lr=7.28155e-06, gnorm=0.911, clip=40, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=197
2022-10-10 16:55:20 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 412 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.113, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=84.5, ups=0.76, wpb=111.5, bsz=40, num_updates=130, lr=7.88835e-06, gnorm=0.874, clip=40, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=210
2022-10-10 16:55:33 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 412 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.114, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=86, ups=0.77, wpb=112.2, bsz=40, num_updates=140, lr=8.49515e-06, gnorm=0.804, clip=20, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=223
2022-10-10 16:55:47 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 412 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.093, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=78.3, ups=0.7, wpb=111.2, bsz=40, num_updates=150, lr=9.10194e-06, gnorm=0.757, clip=10, loss_scale=128, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=238
2022-10-10 16:56:00 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 412 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.098, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=85.3, ups=0.76, wpb=112.2, bsz=40, num_updates=160, lr=9.70874e-06, gnorm=0.842, clip=30, loss_scale=128, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=251
2022-10-10 16:56:13 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 412 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=86.2, ups=0.77, wpb=111.3, bsz=40, num_updates=170, lr=1.03155e-05, gnorm=0.686, clip=10, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=264
2022-10-10 16:56:26 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.9, ups=0.79, wpb=111.1, bsz=40, num_updates=180, lr=1.09223e-05, gnorm=0.53, clip=10, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=276
2022-10-10 16:56:38 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=88.5, ups=0.78, wpb=112.8, bsz=40, num_updates=190, lr=1.15291e-05, gnorm=0.605, clip=0, loss_scale=128, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=289
2022-10-10 16:56:51 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.5, ups=0.78, wpb=111.5, bsz=40, num_updates=200, lr=1.21359e-05, gnorm=0.746, clip=30, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=302
2022-10-10 16:57:04 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.2, ups=0.77, wpb=111.3, bsz=40, num_updates=210, lr=1.27427e-05, gnorm=0.734, clip=10, loss_scale=128, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=315
2022-10-10 16:57:17 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89, ups=0.8, wpb=111.5, bsz=40, num_updates=220, lr=1.33495e-05, gnorm=0.447, clip=0, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=328
2022-10-10 16:57:29 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.6, ups=0.83, wpb=110.8, bsz=40, num_updates=230, lr=1.39563e-05, gnorm=0.683, clip=0, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=340
2022-10-10 16:57:42 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=84.3, ups=0.75, wpb=111.8, bsz=40, num_updates=240, lr=1.45631e-05, gnorm=0.625, clip=20, loss_scale=128, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=353
2022-10-10 16:57:55 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.5, ups=0.78, wpb=110.4, bsz=40, num_updates=250, lr=1.51699e-05, gnorm=0.393, clip=0, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=366
2022-10-10 16:58:08 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.1, ups=0.77, wpb=111.4, bsz=40, num_updates=260, lr=1.57767e-05, gnorm=0.52, clip=0, loss_scale=128, train_wall=13, gb_free=11.3, ema_decay=0.9999, wall=379
2022-10-10 16:58:21 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.3, ups=0.8, wpb=111.1, bsz=40, num_updates=270, lr=1.63835e-05, gnorm=0.713, clip=10, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=391
2022-10-10 16:58:34 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=81.9, ups=0.74, wpb=110.6, bsz=40, num_updates=280, lr=1.69903e-05, gnorm=0.613, clip=20, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=405
2022-10-10 16:58:48 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=80.5, ups=0.73, wpb=109.8, bsz=40, num_updates=290, lr=1.75971e-05, gnorm=0.569, clip=10, loss_scale=128, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=418
2022-10-10 16:59:00 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.7, ups=0.78, wpb=110.8, bsz=40, num_updates=300, lr=1.82039e-05, gnorm=0.701, clip=10, loss_scale=128, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=431
2022-10-10 16:59:14 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=83, ups=0.75, wpb=111.1, bsz=40, num_updates=310, lr=1.88107e-05, gnorm=0.49, clip=10, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=444
2022-10-10 16:59:27 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.4, ups=0.77, wpb=111.7, bsz=40, num_updates=320, lr=1.94175e-05, gnorm=0.6, clip=10, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=457
2022-10-10 16:59:39 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.2, ups=0.8, wpb=112.8, bsz=40, num_updates=330, lr=2.00243e-05, gnorm=0.623, clip=20, loss_scale=128, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=470
2022-10-10 16:59:51 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.7, ups=0.83, wpb=110.1, bsz=40, num_updates=340, lr=2.06311e-05, gnorm=0.527, clip=10, loss_scale=128, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=482
2022-10-10 17:00:04 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.9, ups=0.79, wpb=111.7, bsz=40, num_updates=350, lr=2.12379e-05, gnorm=0.641, clip=10, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=495
2022-10-10 17:00:17 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=82.4, ups=0.75, wpb=110.3, bsz=40, num_updates=360, lr=2.18447e-05, gnorm=0.699, clip=30, loss_scale=128, train_wall=13, gb_free=11, ema_decay=0.9999, wall=508
2022-10-10 17:00:30 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.9, ups=0.82, wpb=110.7, bsz=40, num_updates=370, lr=2.24515e-05, gnorm=0.804, clip=20, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=520
2022-10-10 17:00:43 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83.7, ups=0.76, wpb=109.7, bsz=40, num_updates=380, lr=2.30583e-05, gnorm=0.765, clip=30, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=533
2022-10-10 17:00:56 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.9, ups=0.77, wpb=111.4, bsz=40, num_updates=390, lr=2.3665e-05, gnorm=0.657, clip=20, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=546
2022-10-10 17:01:09 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.2, ups=0.77, wpb=111.4, bsz=40, num_updates=400, lr=2.42718e-05, gnorm=0.719, clip=20, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=559
2022-10-10 17:01:21 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.8, ups=0.82, wpb=111.6, bsz=40, num_updates=410, lr=2.48786e-05, gnorm=0.561, clip=20, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=571
2022-10-10 17:01:23 - train.py[line:339] - INFO: end of epoch 1 (average epoch stats below)
2022-10-10 17:01:23 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.291 | loss_v1 0 | loss_v2 0 | nll_loss 0.114 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.08 | wps 85.5 | ups 0.77 | wpb 111.1 | bsz 40 | num_updates 412 | lr 2.5e-05 | gnorm 0.866 | clip 33.3 | loss_scale 128 | train_wall 537 | gb_free 10.7 | ema_decay 0.9999 | wall 573
2022-10-10 17:01:23 - trainer.py[line:643] - INFO: loading train data for epoch 2
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv slice_id 1 row count 8240 total row count 16480
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E1.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 17:01:23 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 17:01:24 - trainer.py[line:707] - INFO: begin training epoch 2
2022-10-10 17:01:24 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 17:01:37 - progress_bar.py[line:274] - INFO: epoch 002:      8 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=69.8, ups=0.63, wpb=110, bsz=40, num_updates=420, lr=2.54854e-05, gnorm=0.688, clip=30, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=587
2022-10-10 17:01:50 - progress_bar.py[line:274] - INFO: epoch 002:     18 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=85.1, ups=0.77, wpb=111.2, bsz=40, num_updates=430, lr=2.60922e-05, gnorm=0.337, clip=10, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=600
2022-10-10 17:02:03 - progress_bar.py[line:274] - INFO: epoch 002:     28 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=82.1, ups=0.74, wpb=110.3, bsz=40, num_updates=440, lr=2.6699e-05, gnorm=0.554, clip=10, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=614
2022-10-10 17:02:16 - progress_bar.py[line:274] - INFO: epoch 002:     38 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.4, ups=0.77, wpb=111.7, bsz=40, num_updates=450, lr=2.73058e-05, gnorm=0.564, clip=10, loss_scale=128, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=627
2022-10-10 17:02:29 - progress_bar.py[line:274] - INFO: epoch 002:     48 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.7, ups=0.78, wpb=109.4, bsz=40, num_updates=460, lr=2.79126e-05, gnorm=0.472, clip=10, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=639
2022-10-10 17:02:41 - progress_bar.py[line:274] - INFO: epoch 002:     58 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.5, ups=0.8, wpb=111.1, bsz=40, num_updates=470, lr=2.85194e-05, gnorm=0.481, clip=10, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=652
2022-10-10 17:02:55 - progress_bar.py[line:274] - INFO: epoch 002:     68 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83.3, ups=0.75, wpb=111.3, bsz=40, num_updates=480, lr=2.91262e-05, gnorm=0.641, clip=20, loss_scale=128, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=665
2022-10-10 17:03:08 - progress_bar.py[line:274] - INFO: epoch 002:     78 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=84.5, ups=0.76, wpb=111.1, bsz=40, num_updates=490, lr=2.9733e-05, gnorm=1.017, clip=50, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=678
2022-10-10 17:03:20 - progress_bar.py[line:274] - INFO: epoch 002:     88 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.7, ups=0.79, wpb=111.1, bsz=40, num_updates=500, lr=3.03398e-05, gnorm=0.495, clip=20, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=691
2022-10-10 17:03:33 - progress_bar.py[line:274] - INFO: epoch 002:     98 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.4, ups=0.79, wpb=109.8, bsz=40, num_updates=510, lr=3.09466e-05, gnorm=0.666, clip=30, loss_scale=128, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=704
2022-10-10 17:03:46 - progress_bar.py[line:274] - INFO: epoch 002:    108 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.8, ups=0.81, wpb=111.4, bsz=40, num_updates=520, lr=3.15534e-05, gnorm=0.481, clip=20, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=716
2022-10-10 17:03:58 - progress_bar.py[line:274] - INFO: epoch 002:    118 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.4, ups=0.81, wpb=111, bsz=40, num_updates=530, lr=3.21602e-05, gnorm=1.018, clip=50, loss_scale=256, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=729
2022-10-10 17:04:11 - progress_bar.py[line:274] - INFO: epoch 002:    128 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.8, ups=0.76, wpb=111.5, bsz=40, num_updates=540, lr=3.2767e-05, gnorm=0.756, clip=20, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=742
2022-10-10 17:04:24 - progress_bar.py[line:274] - INFO: epoch 002:    138 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88, ups=0.79, wpb=111.3, bsz=40, num_updates=550, lr=3.33738e-05, gnorm=0.616, clip=10, loss_scale=256, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=754
2022-10-10 17:04:36 - progress_bar.py[line:274] - INFO: epoch 002:    148 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.8, ups=0.82, wpb=112.4, bsz=40, num_updates=560, lr=3.39806e-05, gnorm=0.664, clip=10, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=767
2022-10-10 17:04:49 - progress_bar.py[line:274] - INFO: epoch 002:    158 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.3, ups=0.8, wpb=111.4, bsz=40, num_updates=570, lr=3.45874e-05, gnorm=0.809, clip=30, loss_scale=256, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=779
2022-10-10 17:05:01 - progress_bar.py[line:274] - INFO: epoch 002:    168 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.7, ups=0.8, wpb=112.5, bsz=40, num_updates=580, lr=3.51942e-05, gnorm=0.414, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=792
2022-10-10 17:05:14 - progress_bar.py[line:274] - INFO: epoch 002:    178 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.6, ups=0.77, wpb=111.1, bsz=40, num_updates=590, lr=3.5801e-05, gnorm=0.404, clip=10, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=805
2022-10-10 17:05:27 - progress_bar.py[line:274] - INFO: epoch 002:    188 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.9, ups=0.81, wpb=110, bsz=40, num_updates=600, lr=3.64078e-05, gnorm=0.563, clip=20, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=817
2022-10-10 17:05:39 - progress_bar.py[line:274] - INFO: epoch 002:    198 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.1, ups=0.8, wpb=112.2, bsz=40, num_updates=610, lr=3.70146e-05, gnorm=0.847, clip=30, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=830
2022-10-10 17:05:51 - progress_bar.py[line:274] - INFO: epoch 002:    208 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.1, ups=0.81, wpb=111.5, bsz=40, num_updates=620, lr=3.76214e-05, gnorm=0.589, clip=10, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=842
2022-10-10 17:06:04 - progress_bar.py[line:274] - INFO: epoch 002:    218 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.1, ups=0.81, wpb=110.8, bsz=40, num_updates=630, lr=3.82282e-05, gnorm=0.76, clip=20, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=854
2022-10-10 17:06:16 - progress_bar.py[line:274] - INFO: epoch 002:    228 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89, ups=0.81, wpb=110.1, bsz=40, num_updates=640, lr=3.8835e-05, gnorm=0.482, clip=10, loss_scale=256, train_wall=12, gb_free=11, ema_decay=0.9999, wall=867
2022-10-10 17:06:29 - progress_bar.py[line:274] - INFO: epoch 002:    238 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.6, ups=0.8, wpb=111.8, bsz=40, num_updates=650, lr=3.94417e-05, gnorm=0.477, clip=10, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=879
2022-10-10 17:06:41 - progress_bar.py[line:274] - INFO: epoch 002:    248 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.6, ups=0.78, wpb=111.1, bsz=40, num_updates=660, lr=4.00485e-05, gnorm=0.809, clip=30, loss_scale=256, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=892
2022-10-10 17:06:54 - progress_bar.py[line:274] - INFO: epoch 002:    258 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.9, ups=0.81, wpb=111.1, bsz=40, num_updates=670, lr=4.06553e-05, gnorm=0.517, clip=10, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=904
2022-10-10 17:07:06 - progress_bar.py[line:274] - INFO: epoch 002:    268 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.8, ups=0.81, wpb=110.6, bsz=40, num_updates=680, lr=4.12621e-05, gnorm=0.645, clip=30, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=917
2022-10-10 17:07:18 - progress_bar.py[line:274] - INFO: epoch 002:    278 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.7, ups=0.81, wpb=111.4, bsz=40, num_updates=690, lr=4.18689e-05, gnorm=0.502, clip=10, loss_scale=256, train_wall=12, gb_free=11.2, ema_decay=0.9999, wall=929
2022-10-10 17:07:31 - progress_bar.py[line:274] - INFO: epoch 002:    288 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.8, ups=0.78, wpb=112, bsz=40, num_updates=700, lr=4.24757e-05, gnorm=0.742, clip=30, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=942
2022-10-10 17:07:44 - progress_bar.py[line:274] - INFO: epoch 002:    298 / 412 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.8, ups=0.79, wpb=110.1, bsz=40, num_updates=710, lr=4.30825e-05, gnorm=0.709, clip=20, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=955
2022-10-10 17:07:57 - progress_bar.py[line:274] - INFO: epoch 002:    308 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.5, ups=0.78, wpb=111.7, bsz=40, num_updates=720, lr=4.36893e-05, gnorm=0.705, clip=10, loss_scale=256, train_wall=13, gb_free=10.2, ema_decay=0.9999, wall=968
2022-10-10 17:08:09 - progress_bar.py[line:274] - INFO: epoch 002:    318 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=88.6, ups=0.8, wpb=111.3, bsz=40, num_updates=730, lr=4.42961e-05, gnorm=0.621, clip=30, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=980
2022-10-10 17:08:22 - progress_bar.py[line:274] - INFO: epoch 002:    328 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88, ups=0.8, wpb=110.5, bsz=40, num_updates=740, lr=4.49029e-05, gnorm=0.705, clip=10, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=993
2022-10-10 17:08:34 - progress_bar.py[line:274] - INFO: epoch 002:    338 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=93.6, ups=0.84, wpb=111.4, bsz=40, num_updates=750, lr=4.55097e-05, gnorm=0.774, clip=20, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1005
2022-10-10 17:08:47 - progress_bar.py[line:274] - INFO: epoch 002:    348 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89, ups=0.8, wpb=111.8, bsz=40, num_updates=760, lr=4.61165e-05, gnorm=0.633, clip=0, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1017
2022-10-10 17:08:59 - progress_bar.py[line:274] - INFO: epoch 002:    358 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.8, ups=0.79, wpb=110.6, bsz=40, num_updates=770, lr=4.67233e-05, gnorm=0.502, clip=0, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1030
2022-10-10 17:09:12 - progress_bar.py[line:274] - INFO: epoch 002:    368 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.2, ups=0.78, wpb=111.1, bsz=40, num_updates=780, lr=4.73301e-05, gnorm=0.816, clip=30, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1043
2022-10-10 17:09:25 - progress_bar.py[line:274] - INFO: epoch 002:    378 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.3, ups=0.8, wpb=111.3, bsz=40, num_updates=790, lr=4.79369e-05, gnorm=0.67, clip=30, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1055
2022-10-10 17:09:37 - progress_bar.py[line:274] - INFO: epoch 002:    388 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.7, ups=0.82, wpb=110.3, bsz=40, num_updates=800, lr=4.85437e-05, gnorm=0.551, clip=20, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1067
2022-10-10 17:09:49 - progress_bar.py[line:274] - INFO: epoch 002:    398 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=92.9, ups=0.83, wpb=112.4, bsz=40, num_updates=810, lr=4.91505e-05, gnorm=0.878, clip=30, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1079
2022-10-10 17:10:01 - progress_bar.py[line:274] - INFO: epoch 002:    408 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=94.6, ups=0.85, wpb=111.4, bsz=40, num_updates=820, lr=4.97573e-05, gnorm=0.616, clip=10, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=1091
2022-10-10 17:10:06 - train.py[line:339] - INFO: end of epoch 2 (average epoch stats below)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 17:10:06 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.248 | loss_v1 0 | loss_v2 0 | nll_loss 0.063 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 87.6 | ups 0.79 | wpb 111.1 | bsz 40 | num_updates 824 | lr 5e-05 | gnorm 0.643 | clip 19.2 | loss_scale 256 | train_wall 516 | gb_free 10.5 | ema_decay 0.9999 | wall 1096
2022-10-10 17:10:06 - trainer.py[line:643] - INFO: loading train data for epoch 3
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E2.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 17:10:06 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 17:10:06 - trainer.py[line:707] - INFO: begin training epoch 3
2022-10-10 17:10:06 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 17:10:16 - progress_bar.py[line:274] - INFO: epoch 003:      6 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=72, ups=0.64, wpb=112.5, bsz=40, num_updates=830, lr=4.99848e-05, gnorm=0.804, clip=30, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1107
2022-10-10 17:10:29 - progress_bar.py[line:274] - INFO: epoch 003:     16 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.3, ups=0.78, wpb=110.5, bsz=40, num_updates=840, lr=4.99595e-05, gnorm=0.637, clip=20, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1120
2022-10-10 17:10:41 - progress_bar.py[line:274] - INFO: epoch 003:     26 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=92.6, ups=0.83, wpb=112.2, bsz=40, num_updates=850, lr=4.99343e-05, gnorm=0.669, clip=20, loss_scale=256, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=1132
2022-10-10 17:10:53 - progress_bar.py[line:274] - INFO: epoch 003:     36 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.7, ups=0.81, wpb=111.6, bsz=40, num_updates=860, lr=4.9909e-05, gnorm=0.545, clip=10, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=1144
2022-10-10 17:11:06 - progress_bar.py[line:274] - INFO: epoch 003:     46 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.5, ups=0.8, wpb=110.3, bsz=40, num_updates=870, lr=4.98837e-05, gnorm=0.394, clip=10, loss_scale=256, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=1157
2022-10-10 17:11:18 - progress_bar.py[line:274] - INFO: epoch 003:     56 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.7, ups=0.81, wpb=111.3, bsz=40, num_updates=880, lr=4.98584e-05, gnorm=0.638, clip=30, loss_scale=256, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=1169
2022-10-10 17:11:30 - progress_bar.py[line:274] - INFO: epoch 003:     66 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=92, ups=0.83, wpb=111.2, bsz=40, num_updates=890, lr=4.98331e-05, gnorm=0.558, clip=10, loss_scale=256, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=1181
2022-10-10 17:11:43 - progress_bar.py[line:274] - INFO: epoch 003:     76 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.4, ups=0.82, wpb=110.8, bsz=40, num_updates=900, lr=4.98078e-05, gnorm=0.967, clip=30, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1193
2022-10-10 17:11:55 - progress_bar.py[line:274] - INFO: epoch 003:     86 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.9, ups=0.8, wpb=112.1, bsz=40, num_updates=910, lr=4.97826e-05, gnorm=0.645, clip=20, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1206
2022-10-10 17:12:08 - progress_bar.py[line:274] - INFO: epoch 003:     96 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.79, wpb=112.1, bsz=40, num_updates=920, lr=4.97573e-05, gnorm=0.546, clip=10, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=1218
2022-10-10 17:12:20 - progress_bar.py[line:274] - INFO: epoch 003:    106 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=93.2, ups=0.84, wpb=111.5, bsz=40, num_updates=930, lr=4.9732e-05, gnorm=0.488, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1230
2022-10-10 17:12:32 - progress_bar.py[line:274] - INFO: epoch 003:    116 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=92.3, ups=0.82, wpb=112.3, bsz=40, num_updates=940, lr=4.97067e-05, gnorm=1.315, clip=50, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=1242
2022-10-10 17:12:44 - progress_bar.py[line:274] - INFO: epoch 003:    126 / 412 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=87.5, ups=0.79, wpb=110.1, bsz=40, num_updates=950, lr=4.96814e-05, gnorm=0.771, clip=20, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=1255
2022-10-10 17:12:57 - progress_bar.py[line:274] - INFO: epoch 003:    136 / 412 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=89.6, ups=0.81, wpb=110.1, bsz=40, num_updates=960, lr=4.96561e-05, gnorm=1.039, clip=50, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1267
2022-10-10 17:13:09 - progress_bar.py[line:274] - INFO: epoch 003:    146 / 412 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=92.7, ups=0.84, wpb=110.8, bsz=40, num_updates=970, lr=4.96309e-05, gnorm=0.947, clip=50, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1279
2022-10-10 17:13:21 - progress_bar.py[line:274] - INFO: epoch 003:    156 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.6, ups=0.82, wpb=111.9, bsz=40, num_updates=980, lr=4.96056e-05, gnorm=0.557, clip=10, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1292
2022-10-10 17:13:33 - progress_bar.py[line:274] - INFO: epoch 003:    166 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.4, ups=0.81, wpb=111.3, bsz=40, num_updates=990, lr=4.95803e-05, gnorm=1.133, clip=60, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=1304
2022-10-10 17:13:45 - progress_bar.py[line:274] - INFO: epoch 003:    176 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.1, ups=0.83, wpb=110.8, bsz=40, num_updates=1000, lr=4.9555e-05, gnorm=0.654, clip=0, loss_scale=256, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=1316
2022-10-10 17:13:45 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 17:13:45 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 17:13:47 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 17:13:47 - train.py[line:551] - INFO: load:1.65 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 17:16:47 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 17:16:47 - train.py[line:551] - INFO: load:1.68 valid_run:179.81 task_valid:170.53 collect_output:7.01
2022-10-10 17:19:42 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 17:19:42 - train.py[line:551] - INFO: load:1.73 valid_run:354.50 task_valid:333.13 collect_output:16.97
2022-10-10 17:22:39 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 17:22:39 - train.py[line:551] - INFO: load:1.76 valid_run:530.85 task_valid:495.09 collect_output:29.04
2022-10-10 17:25:32 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 17:25:32 - train.py[line:551] - INFO: load:1.80 valid_run:704.48 task_valid:658.28 collect_output:37.56
2022-10-10 17:28:28 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 17:28:28 - train.py[line:551] - INFO: load:1.87 valid_run:880.06 task_valid:822.43 collect_output:47.28
2022-10-10 17:31:23 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 17:31:23 - train.py[line:551] - INFO: load:1.90 valid_run:1054.99 task_valid:985.08 collect_output:57.82
2022-10-10 17:34:21 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 17:34:21 - train.py[line:551] - INFO: load:1.95 valid_run:1232.53 task_valid:1149.91 collect_output:68.75
2022-10-10 17:37:13 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 17:37:13 - train.py[line:551] - INFO: load:2.00 valid_run:1404.64 task_valid:1307.26 collect_output:81.66
2022-10-10 17:40:02 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 17:40:02 - train.py[line:551] - INFO: load:2.08 valid_run:1574.06 task_valid:1466.44 collect_output:90.00
2022-10-10 17:42:54 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 17:42:54 - train.py[line:551] - INFO: load:2.14 valid_run:1745.52 task_valid:1626.86 collect_output:99.06
2022-10-10 17:45:49 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 17:45:49 - train.py[line:551] - INFO: load:2.17 valid_run:1920.23 task_valid:1792.18 collect_output:106.42
2022-10-10 17:48:40 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 17:48:40 - train.py[line:551] - INFO: load:2.21 valid_run:2091.30 task_valid:1952.93 collect_output:114.72
2022-10-10 17:51:34 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 17:51:34 - train.py[line:551] - INFO: load:2.24 valid_run:2265.21 task_valid:2112.78 collect_output:126.81
2022-10-10 17:54:27 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 17:54:27 - train.py[line:551] - INFO: load:2.32 valid_run:2437.95 task_valid:2275.88 collect_output:134.65
2022-10-10 17:57:20 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 17:57:20 - train.py[line:551] - INFO: load:2.39 valid_run:2610.78 task_valid:2439.76 collect_output:141.75
2022-10-10 18:00:13 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 18:00:13 - train.py[line:551] - INFO: load:2.42 valid_run:2783.66 task_valid:2602.15 collect_output:150.59
2022-10-10 18:03:06 - train.py[line:549] - INFO: 3400 / 4988
2022-10-10 18:03:06 - train.py[line:551] - INFO: load:2.46 valid_run:2957.25 task_valid:2763.95 collect_output:160.53
2022-10-10 18:06:06 - train.py[line:549] - INFO: 3600 / 4988
2022-10-10 18:06:06 - train.py[line:551] - INFO: load:2.50 valid_run:3136.36 task_valid:2934.86 collect_output:166.79
2022-10-10 18:09:04 - train.py[line:549] - INFO: 3800 / 4988
2022-10-10 18:09:04 - train.py[line:551] - INFO: load:2.56 valid_run:3314.13 task_valid:3099.06 collect_output:178.26
2022-10-10 18:12:05 - train.py[line:549] - INFO: 4000 / 4988
2022-10-10 18:12:05 - train.py[line:551] - INFO: load:2.62 valid_run:3495.89 task_valid:3268.82 collect_output:188.42
2022-10-10 18:15:08 - train.py[line:549] - INFO: 4200 / 4988
2022-10-10 18:15:08 - train.py[line:551] - INFO: load:2.68 valid_run:3678.83 task_valid:3436.86 collect_output:201.37
2022-10-10 18:18:07 - train.py[line:549] - INFO: 4400 / 4988
2022-10-10 18:18:07 - train.py[line:551] - INFO: load:2.73 valid_run:3856.94 task_valid:3605.09 collect_output:209.09
2022-10-10 18:21:10 - train.py[line:549] - INFO: 4600 / 4988
2022-10-10 18:21:10 - train.py[line:551] - INFO: load:2.76 valid_run:4040.00 task_valid:3775.93 collect_output:219.46
2022-10-10 18:24:11 - train.py[line:549] - INFO: 4800 / 4988
2022-10-10 18:24:11 - train.py[line:551] - INFO: load:2.80 valid_run:4221.50 task_valid:3946.55 collect_output:228.28

====================================================================================================
SGG eval:     R @ 50: 0.6718;     R @ 100: 0.7012;     R @ 500: 0.7205;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4751;    mR @ 100: 0.5106;    mR @ 500: 0.5463;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.8125) (covering:0.4429) (eating:0.8235) (flying in:0.6818) (growing on:0.5000) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7534) (standing on:0.4343) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 18:27:16 - train.py[line:487] - INFO: 0.701240718105424
2022-10-10 18:27:16 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-10 18:27:16 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.24 | loss_v1 0 | loss_v2 0 | nll_loss 0.065 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.701241 | ppl 1.05 | vqa_score 0.5563 | wps 101.8 | wpb 89.9 | bsz 30 | num_updates 1000
2022-10-10 18:27:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 1000 updates
2022-10-10 18:27:16 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_3_1000.pt

====================================================================================================
SGG eval:     R @ 50: 0.6718;     R @ 100: 0.7012;     R @ 500: 0.7205;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4751;    mR @ 100: 0.5106;    mR @ 500: 0.5463;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.8125) (covering:0.4429) (eating:0.8235) (flying in:0.6818) (growing on:0.5000) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.3333) (parked on:0.9583) (playing:0.0000) (riding:0.9614) (says:0.0000) (sitting on:0.7534) (standing on:0.4343) (using:0.6000) (walking in:0.0000) (walking on:0.6757) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 18:27:24 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_3_1000.pt
2022-10-10 18:27:32 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_3_1000.pt (epoch 3 @ 1000 updates, score 0.701240718105424) (writing took 16.098526180256158 seconds)
2022-10-10 18:27:45 - progress_bar.py[line:274] - INFO: epoch 003:    186 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=0.3, ups=0, wpb=112.3, bsz=40, num_updates=1010, lr=4.95297e-05, gnorm=0.904, clip=40, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=5756
2022-10-10 18:27:58 - progress_bar.py[line:274] - INFO: epoch 003:    196 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.9, ups=0.78, wpb=111.3, bsz=40, num_updates=1020, lr=4.95044e-05, gnorm=0.613, clip=20, loss_scale=256, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=5769
2022-10-10 18:28:10 - progress_bar.py[line:274] - INFO: epoch 003:    206 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.5, ups=0.81, wpb=109.8, bsz=40, num_updates=1030, lr=4.94792e-05, gnorm=0.575, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=5781
2022-10-10 18:28:23 - progress_bar.py[line:274] - INFO: epoch 003:    216 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.1, ups=0.8, wpb=111.5, bsz=40, num_updates=1040, lr=4.94539e-05, gnorm=1.024, clip=30, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=5793
2022-10-10 18:28:35 - progress_bar.py[line:274] - INFO: epoch 003:    226 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.2, ups=0.8, wpb=111.4, bsz=40, num_updates=1050, lr=4.94286e-05, gnorm=0.92, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5806
2022-10-10 18:28:48 - progress_bar.py[line:274] - INFO: epoch 003:    236 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89, ups=0.81, wpb=110, bsz=40, num_updates=1060, lr=4.94033e-05, gnorm=0.706, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=5818
2022-10-10 18:29:01 - progress_bar.py[line:274] - INFO: epoch 003:    246 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.3, ups=0.76, wpb=110.9, bsz=40, num_updates=1070, lr=4.9378e-05, gnorm=0.571, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=5832
2022-10-10 18:29:14 - progress_bar.py[line:274] - INFO: epoch 003:    256 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.8, ups=0.8, wpb=111.3, bsz=40, num_updates=1080, lr=4.93528e-05, gnorm=0.907, clip=40, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5844
2022-10-10 18:29:26 - progress_bar.py[line:274] - INFO: epoch 003:    266 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.9, ups=0.82, wpb=111.5, bsz=40, num_updates=1090, lr=4.93275e-05, gnorm=0.655, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=5856
2022-10-10 18:29:38 - progress_bar.py[line:274] - INFO: epoch 003:    276 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.8, ups=0.81, wpb=112.1, bsz=40, num_updates=1100, lr=4.93022e-05, gnorm=0.756, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5869
2022-10-10 18:29:50 - progress_bar.py[line:274] - INFO: epoch 003:    286 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.6, ups=0.82, wpb=111.1, bsz=40, num_updates=1110, lr=4.92769e-05, gnorm=0.646, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5881
2022-10-10 18:30:03 - progress_bar.py[line:274] - INFO: epoch 003:    296 / 412 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88, ups=0.8, wpb=110.1, bsz=40, num_updates=1120, lr=4.92516e-05, gnorm=0.676, clip=20, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=5893
2022-10-10 18:30:16 - progress_bar.py[line:274] - INFO: epoch 003:    306 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83.9, ups=0.76, wpb=110.2, bsz=40, num_updates=1130, lr=4.92263e-05, gnorm=0.829, clip=30, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=5907
2022-10-10 18:30:28 - progress_bar.py[line:274] - INFO: epoch 003:    316 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.7, ups=0.83, wpb=111.4, bsz=40, num_updates=1140, lr=4.92011e-05, gnorm=0.563, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5919
2022-10-10 18:30:40 - progress_bar.py[line:274] - INFO: epoch 003:    326 / 412 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.8, ups=0.82, wpb=110.5, bsz=40, num_updates=1150, lr=4.91758e-05, gnorm=0.771, clip=20, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=5931
2022-10-10 18:30:52 - progress_bar.py[line:274] - INFO: epoch 003:    336 / 412 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=91.4, ups=0.82, wpb=111.3, bsz=40, num_updates=1160, lr=4.91505e-05, gnorm=0.748, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=5943
2022-10-10 18:31:05 - progress_bar.py[line:274] - INFO: epoch 003:    346 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.9, ups=0.83, wpb=111.2, bsz=40, num_updates=1170, lr=4.91252e-05, gnorm=0.426, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5955
2022-10-10 18:31:17 - progress_bar.py[line:274] - INFO: epoch 003:    356 / 412 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=91.5, ups=0.82, wpb=111.2, bsz=40, num_updates=1180, lr=4.90999e-05, gnorm=0.793, clip=20, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=5967
2022-10-10 18:31:29 - progress_bar.py[line:274] - INFO: epoch 003:    366 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90, ups=0.81, wpb=110.5, bsz=40, num_updates=1190, lr=4.90746e-05, gnorm=0.583, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5980
2022-10-10 18:31:42 - progress_bar.py[line:274] - INFO: epoch 003:    376 / 412 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88, ups=0.8, wpb=110.3, bsz=40, num_updates=1200, lr=4.90494e-05, gnorm=0.838, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=5992
2022-10-10 18:31:55 - progress_bar.py[line:274] - INFO: epoch 003:    386 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.2, ups=0.77, wpb=111.7, bsz=40, num_updates=1210, lr=4.90241e-05, gnorm=0.726, clip=30, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6005
2022-10-10 18:32:06 - progress_bar.py[line:274] - INFO: epoch 003:    396 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=94.7, ups=0.84, wpb=112.1, bsz=40, num_updates=1220, lr=4.89988e-05, gnorm=0.501, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=6017
2022-10-10 18:32:19 - progress_bar.py[line:274] - INFO: epoch 003:    406 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.3, ups=0.82, wpb=109.6, bsz=40, num_updates=1230, lr=4.89735e-05, gnorm=0.683, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6029
2022-10-10 18:32:26 - train.py[line:339] - INFO: end of epoch 3 (average epoch stats below)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 18:32:26 - progress_bar.py[line:282] - INFO: epoch 003 | loss 0.252 | loss_v1 0 | loss_v2 0 | nll_loss 0.068 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.05 | wps 9.3 | ups 0.08 | wpb 111.1 | bsz 40 | num_updates 1236 | lr 4.89583e-05 | gnorm 0.724 | clip 21.6 | loss_scale 512 | train_wall 507 | gb_free 10.7 | ema_decay 0.9999 | wall 6036
2022-10-10 18:32:26 - trainer.py[line:643] - INFO: loading train data for epoch 4
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E3.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 18:32:26 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 18:32:27 - trainer.py[line:707] - INFO: begin training epoch 4
2022-10-10 18:32:27 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 18:32:35 - progress_bar.py[line:274] - INFO: epoch 004:      4 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=67.3, ups=0.61, wpb=110, bsz=40, num_updates=1240, lr=4.89482e-05, gnorm=1.129, clip=30, loss_scale=512, train_wall=13, gb_free=11.1, ema_decay=0.9999, wall=6046
2022-10-10 18:32:47 - progress_bar.py[line:274] - INFO: epoch 004:     14 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.8, ups=0.8, wpb=112.7, bsz=40, num_updates=1250, lr=4.89229e-05, gnorm=1.044, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6058
2022-10-10 18:33:00 - progress_bar.py[line:274] - INFO: epoch 004:     24 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.7, ups=0.78, wpb=110.5, bsz=40, num_updates=1260, lr=4.88977e-05, gnorm=0.685, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6071
2022-10-10 18:33:13 - progress_bar.py[line:274] - INFO: epoch 004:     34 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.6, ups=0.8, wpb=111.7, bsz=40, num_updates=1270, lr=4.88724e-05, gnorm=0.529, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6083
2022-10-10 18:33:26 - progress_bar.py[line:274] - INFO: epoch 004:     44 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.4, ups=0.78, wpb=109.9, bsz=40, num_updates=1280, lr=4.88471e-05, gnorm=0.673, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6096
2022-10-10 18:33:38 - progress_bar.py[line:274] - INFO: epoch 004:     54 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.9, ups=0.82, wpb=111.1, bsz=40, num_updates=1290, lr=4.88218e-05, gnorm=1.013, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6108
2022-10-10 18:33:51 - progress_bar.py[line:274] - INFO: epoch 004:     64 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.5, ups=0.77, wpb=111.9, bsz=40, num_updates=1300, lr=4.87965e-05, gnorm=0.751, clip=20, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6121
2022-10-10 18:34:03 - progress_bar.py[line:274] - INFO: epoch 004:     74 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.4, ups=0.79, wpb=111.6, bsz=40, num_updates=1310, lr=4.87712e-05, gnorm=0.424, clip=0, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=6134
2022-10-10 18:34:16 - progress_bar.py[line:274] - INFO: epoch 004:     84 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.5, ups=0.78, wpb=109.6, bsz=40, num_updates=1320, lr=4.8746e-05, gnorm=0.624, clip=30, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6147
2022-10-10 18:34:29 - progress_bar.py[line:274] - INFO: epoch 004:     94 / 412 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=87.4, ups=0.79, wpb=111.1, bsz=40, num_updates=1330, lr=4.87207e-05, gnorm=1.041, clip=70, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=6160
2022-10-10 18:34:42 - progress_bar.py[line:274] - INFO: epoch 004:    104 / 412 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=87.6, ups=0.79, wpb=110.7, bsz=40, num_updates=1340, lr=4.86954e-05, gnorm=0.703, clip=20, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6172
2022-10-10 18:34:54 - progress_bar.py[line:274] - INFO: epoch 004:    114 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.4, ups=0.8, wpb=111.6, bsz=40, num_updates=1350, lr=4.86701e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6185
2022-10-10 18:35:06 - progress_bar.py[line:274] - INFO: epoch 004:    124 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.9, ups=0.82, wpb=112, bsz=40, num_updates=1360, lr=4.86448e-05, gnorm=0.68, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6197
2022-10-10 18:35:19 - progress_bar.py[line:274] - INFO: epoch 004:    134 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88, ups=0.8, wpb=110.4, bsz=40, num_updates=1370, lr=4.86195e-05, gnorm=0.563, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6209
2022-10-10 18:35:34 - progress_bar.py[line:274] - INFO: epoch 004:    144 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.7, ups=0.81, wpb=110.7, bsz=40, num_updates=1380, lr=4.85943e-05, gnorm=0.543, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=6222
2022-10-10 18:35:46 - progress_bar.py[line:274] - INFO: epoch 004:    154 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.1, ups=0.81, wpb=111.3, bsz=40, num_updates=1390, lr=4.8569e-05, gnorm=0.528, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6237
2022-10-10 18:35:58 - progress_bar.py[line:274] - INFO: epoch 004:    164 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=93.7, ups=0.84, wpb=112, bsz=40, num_updates=1400, lr=4.85437e-05, gnorm=0.926, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6249
2022-10-10 18:36:11 - progress_bar.py[line:274] - INFO: epoch 004:    174 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.7, ups=0.78, wpb=112.1, bsz=40, num_updates=1410, lr=4.85184e-05, gnorm=0.667, clip=40, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6261
2022-10-10 18:36:23 - progress_bar.py[line:274] - INFO: epoch 004:    184 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.3, ups=0.81, wpb=111.5, bsz=40, num_updates=1420, lr=4.84931e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=6274
2022-10-10 18:36:36 - progress_bar.py[line:274] - INFO: epoch 004:    194 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.1, ups=0.78, wpb=112.3, bsz=40, num_updates=1430, lr=4.84678e-05, gnorm=0.474, clip=0, loss_scale=512, train_wall=13, gb_free=10, ema_decay=0.9999, wall=6286
2022-10-10 18:36:48 - progress_bar.py[line:274] - INFO: epoch 004:    204 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.3, ups=0.8, wpb=111, bsz=40, num_updates=1440, lr=4.84426e-05, gnorm=0.408, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6299
2022-10-10 18:37:01 - progress_bar.py[line:274] - INFO: epoch 004:    214 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.2, ups=0.78, wpb=112.5, bsz=40, num_updates=1450, lr=4.84173e-05, gnorm=0.744, clip=30, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=6312
2022-10-10 18:37:14 - progress_bar.py[line:274] - INFO: epoch 004:    224 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.1, ups=0.78, wpb=112.6, bsz=40, num_updates=1460, lr=4.8392e-05, gnorm=0.551, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=6325
2022-10-10 18:37:27 - progress_bar.py[line:274] - INFO: epoch 004:    234 / 412 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=85, ups=0.77, wpb=110.1, bsz=40, num_updates=1470, lr=4.83667e-05, gnorm=0.847, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6338
2022-10-10 18:37:39 - progress_bar.py[line:274] - INFO: epoch 004:    244 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.1, ups=0.81, wpb=111.6, bsz=40, num_updates=1480, lr=4.83414e-05, gnorm=0.41, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=6350
2022-10-10 18:37:52 - progress_bar.py[line:274] - INFO: epoch 004:    254 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.4, ups=0.79, wpb=110.1, bsz=40, num_updates=1490, lr=4.83161e-05, gnorm=0.584, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6363
2022-10-10 18:38:05 - progress_bar.py[line:274] - INFO: epoch 004:    264 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.8, ups=0.77, wpb=111.5, bsz=40, num_updates=1500, lr=4.82909e-05, gnorm=0.608, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6376
2022-10-10 18:38:18 - progress_bar.py[line:274] - INFO: epoch 004:    274 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.1, ups=0.77, wpb=110.4, bsz=40, num_updates=1510, lr=4.82656e-05, gnorm=0.713, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6389
2022-10-10 18:38:30 - progress_bar.py[line:274] - INFO: epoch 004:    284 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.8, wpb=110.7, bsz=40, num_updates=1520, lr=4.82403e-05, gnorm=0.786, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6401
2022-10-10 18:38:43 - progress_bar.py[line:274] - INFO: epoch 004:    294 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.9, ups=0.82, wpb=111.9, bsz=40, num_updates=1530, lr=4.8215e-05, gnorm=0.53, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=6413
2022-10-10 18:38:55 - progress_bar.py[line:274] - INFO: epoch 004:    304 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.6, ups=0.79, wpb=111.7, bsz=40, num_updates=1540, lr=4.81897e-05, gnorm=0.61, clip=10, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=6426
2022-10-10 18:39:08 - progress_bar.py[line:274] - INFO: epoch 004:    314 / 412 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=88.2, ups=0.79, wpb=111.1, bsz=40, num_updates=1550, lr=4.81644e-05, gnorm=1.303, clip=60, loss_scale=1024, train_wall=12, gb_free=11, ema_decay=0.9999, wall=6438
2022-10-10 18:39:21 - progress_bar.py[line:274] - INFO: epoch 004:    324 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.7, ups=0.78, wpb=110.9, bsz=40, num_updates=1560, lr=4.81392e-05, gnorm=0.727, clip=20, loss_scale=1024, train_wall=13, gb_free=11, ema_decay=0.9999, wall=6451
2022-10-10 18:39:33 - progress_bar.py[line:274] - INFO: epoch 004:    334 / 412 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=90.2, ups=0.82, wpb=110.5, bsz=40, num_updates=1570, lr=4.81139e-05, gnorm=1.029, clip=70, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6464
2022-10-10 18:39:45 - progress_bar.py[line:274] - INFO: epoch 004:    344 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.8, ups=0.83, wpb=111.2, bsz=40, num_updates=1580, lr=4.80886e-05, gnorm=0.581, clip=10, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6476
2022-10-10 18:39:58 - progress_bar.py[line:274] - INFO: epoch 004:    354 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.6, ups=0.79, wpb=111.4, bsz=40, num_updates=1590, lr=4.80633e-05, gnorm=0.54, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6488
2022-10-10 18:40:11 - progress_bar.py[line:274] - INFO: epoch 004:    364 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.7, ups=0.77, wpb=111.2, bsz=40, num_updates=1600, lr=4.8038e-05, gnorm=0.888, clip=20, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=6501
2022-10-10 18:40:23 - progress_bar.py[line:274] - INFO: epoch 004:    374 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.5, ups=0.79, wpb=110.4, bsz=40, num_updates=1610, lr=4.80127e-05, gnorm=0.873, clip=30, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6514
2022-10-10 18:40:36 - progress_bar.py[line:274] - INFO: epoch 004:    384 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.9, ups=0.8, wpb=109.3, bsz=40, num_updates=1620, lr=4.79875e-05, gnorm=0.607, clip=10, loss_scale=1024, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=6527
2022-10-10 18:40:48 - progress_bar.py[line:274] - INFO: epoch 004:    394 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.8, ups=0.82, wpb=111.2, bsz=40, num_updates=1630, lr=4.79622e-05, gnorm=0.879, clip=40, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6539
2022-10-10 18:41:00 - progress_bar.py[line:274] - INFO: epoch 004:    404 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.7, ups=0.82, wpb=109.8, bsz=40, num_updates=1640, lr=4.79369e-05, gnorm=0.589, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6551
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 18:41:11 - train.py[line:339] - INFO: end of epoch 4 (average epoch stats below)
2022-10-10 18:41:11 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.25 | loss_v1 0 | loss_v2 0 | nll_loss 0.066 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.05 | wps 87.2 | ups 0.78 | wpb 111.1 | bsz 40 | num_updates 1648 | lr 4.79167e-05 | gnorm 0.713 | clip 23.8 | loss_scale 1024 | train_wall 515 | gb_free 10.9 | ema_decay 0.9999 | wall 6561
2022-10-10 18:41:11 - trainer.py[line:643] - INFO: loading train data for epoch 5
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E4.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 18:41:11 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 18:41:11 - trainer.py[line:707] - INFO: begin training epoch 5
2022-10-10 18:41:11 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 18:41:16 - progress_bar.py[line:274] - INFO: epoch 005:      2 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=69.4, ups=0.63, wpb=110.6, bsz=40, num_updates=1650, lr=4.79116e-05, gnorm=0.854, clip=40, loss_scale=1024, train_wall=14, gb_free=10.8, ema_decay=0.9999, wall=6567
2022-10-10 18:41:29 - progress_bar.py[line:274] - INFO: epoch 005:     12 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91, ups=0.81, wpb=112.9, bsz=40, num_updates=1660, lr=4.78863e-05, gnorm=0.526, clip=10, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=6579
2022-10-10 18:41:41 - progress_bar.py[line:274] - INFO: epoch 005:     22 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.6, ups=0.81, wpb=110.9, bsz=40, num_updates=1670, lr=4.7861e-05, gnorm=0.664, clip=30, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=6592
2022-10-10 18:41:54 - progress_bar.py[line:274] - INFO: epoch 005:     32 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.7, ups=0.79, wpb=110.6, bsz=40, num_updates=1680, lr=4.78358e-05, gnorm=0.709, clip=30, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6604
2022-10-10 18:42:06 - progress_bar.py[line:274] - INFO: epoch 005:     42 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.4, ups=0.81, wpb=111.3, bsz=40, num_updates=1690, lr=4.78105e-05, gnorm=0.757, clip=40, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6617
2022-10-10 18:42:19 - progress_bar.py[line:274] - INFO: epoch 005:     52 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.3, ups=0.81, wpb=110.1, bsz=40, num_updates=1700, lr=4.77852e-05, gnorm=0.618, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6629
2022-10-10 18:42:31 - progress_bar.py[line:274] - INFO: epoch 005:     62 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.5, ups=0.81, wpb=111.3, bsz=40, num_updates=1710, lr=4.77599e-05, gnorm=0.602, clip=20, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6641
2022-10-10 18:42:43 - progress_bar.py[line:274] - INFO: epoch 005:     72 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88, ups=0.8, wpb=110.1, bsz=40, num_updates=1720, lr=4.77346e-05, gnorm=0.488, clip=0, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=6654
2022-10-10 18:42:56 - progress_bar.py[line:274] - INFO: epoch 005:     82 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90, ups=0.81, wpb=111.2, bsz=40, num_updates=1730, lr=4.77093e-05, gnorm=0.793, clip=40, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6666
2022-10-10 18:43:08 - progress_bar.py[line:274] - INFO: epoch 005:     92 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.79, wpb=111.8, bsz=40, num_updates=1740, lr=4.76841e-05, gnorm=0.507, clip=0, loss_scale=1024, train_wall=12, gb_free=11, ema_decay=0.9999, wall=6679
2022-10-10 18:43:21 - progress_bar.py[line:274] - INFO: epoch 005:    102 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.1, ups=0.78, wpb=111.6, bsz=40, num_updates=1750, lr=4.76588e-05, gnorm=0.38, clip=0, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6692
2022-10-10 18:43:33 - progress_bar.py[line:274] - INFO: epoch 005:    112 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=93.6, ups=0.84, wpb=111.2, bsz=40, num_updates=1760, lr=4.76335e-05, gnorm=1.056, clip=40, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6704
2022-10-10 18:43:46 - progress_bar.py[line:274] - INFO: epoch 005:    122 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.5, ups=0.78, wpb=111.5, bsz=40, num_updates=1770, lr=4.76082e-05, gnorm=0.722, clip=10, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6716
2022-10-10 18:43:59 - progress_bar.py[line:274] - INFO: epoch 005:    132 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.7, ups=0.78, wpb=111.4, bsz=40, num_updates=1780, lr=4.75829e-05, gnorm=0.557, clip=20, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6729
2022-10-10 18:44:11 - progress_bar.py[line:274] - INFO: epoch 005:    142 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.9, ups=0.81, wpb=112.7, bsz=40, num_updates=1790, lr=4.75576e-05, gnorm=0.882, clip=30, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6742
2022-10-10 18:44:23 - progress_bar.py[line:274] - INFO: epoch 005:    152 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.8, ups=0.81, wpb=110.1, bsz=40, num_updates=1800, lr=4.75324e-05, gnorm=0.753, clip=30, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6754
2022-10-10 18:44:35 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 18:44:37 - progress_bar.py[line:274] - INFO: epoch 005:    163 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=82.5, ups=0.74, wpb=111.8, bsz=40, num_updates=1810, lr=4.75071e-05, gnorm=0.629, clip=20, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6768
2022-10-10 18:44:50 - progress_bar.py[line:274] - INFO: epoch 005:    173 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.8, wpb=111.5, bsz=40, num_updates=1820, lr=4.74818e-05, gnorm=0.651, clip=30, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=6780
2022-10-10 18:45:02 - progress_bar.py[line:274] - INFO: epoch 005:    183 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.6, ups=0.82, wpb=111.1, bsz=40, num_updates=1830, lr=4.74565e-05, gnorm=0.375, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6792
2022-10-10 18:45:14 - progress_bar.py[line:274] - INFO: epoch 005:    193 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.6, ups=0.8, wpb=110.5, bsz=40, num_updates=1840, lr=4.74312e-05, gnorm=0.982, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6805
2022-10-10 18:45:27 - progress_bar.py[line:274] - INFO: epoch 005:    203 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.5, ups=0.8, wpb=110.4, bsz=40, num_updates=1850, lr=4.74059e-05, gnorm=0.557, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6817
2022-10-10 18:45:39 - progress_bar.py[line:274] - INFO: epoch 005:    213 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=93.6, ups=0.83, wpb=112.3, bsz=40, num_updates=1860, lr=4.73807e-05, gnorm=0.487, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6829
2022-10-10 18:45:51 - progress_bar.py[line:274] - INFO: epoch 005:    223 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.8, ups=0.79, wpb=110.7, bsz=40, num_updates=1870, lr=4.73554e-05, gnorm=0.777, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6842
2022-10-10 18:46:04 - progress_bar.py[line:274] - INFO: epoch 005:    233 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.2, ups=0.82, wpb=111.3, bsz=40, num_updates=1880, lr=4.73301e-05, gnorm=0.793, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6854
2022-10-10 18:46:16 - progress_bar.py[line:274] - INFO: epoch 005:    243 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.2, ups=0.81, wpb=111.8, bsz=40, num_updates=1890, lr=4.73048e-05, gnorm=0.746, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6867
2022-10-10 18:46:29 - progress_bar.py[line:274] - INFO: epoch 005:    253 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87, ups=0.79, wpb=110.4, bsz=40, num_updates=1900, lr=4.72795e-05, gnorm=0.849, clip=30, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6879
2022-10-10 18:46:42 - progress_bar.py[line:274] - INFO: epoch 005:    263 / 412 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.1, ups=0.77, wpb=110.5, bsz=40, num_updates=1910, lr=4.72542e-05, gnorm=0.791, clip=40, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=6892
2022-10-10 18:46:54 - progress_bar.py[line:274] - INFO: epoch 005:    273 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.6, ups=0.81, wpb=112.9, bsz=40, num_updates=1920, lr=4.7229e-05, gnorm=0.75, clip=40, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=6905
2022-10-10 18:47:07 - progress_bar.py[line:274] - INFO: epoch 005:    283 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.2, ups=0.8, wpb=110.8, bsz=40, num_updates=1930, lr=4.72037e-05, gnorm=0.71, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=6917
2022-10-10 18:47:19 - progress_bar.py[line:274] - INFO: epoch 005:    293 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.1, ups=0.81, wpb=110.7, bsz=40, num_updates=1940, lr=4.71784e-05, gnorm=0.651, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=6930
2022-10-10 18:47:32 - progress_bar.py[line:274] - INFO: epoch 005:    303 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.1, ups=0.79, wpb=112.8, bsz=40, num_updates=1950, lr=4.71531e-05, gnorm=0.66, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=6942
2022-10-10 18:47:44 - progress_bar.py[line:274] - INFO: epoch 005:    313 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.1, ups=0.81, wpb=111.5, bsz=40, num_updates=1960, lr=4.71278e-05, gnorm=1.157, clip=60, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6955
2022-10-10 18:47:57 - progress_bar.py[line:274] - INFO: epoch 005:    323 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.8, ups=0.78, wpb=110.6, bsz=40, num_updates=1970, lr=4.71025e-05, gnorm=0.622, clip=10, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=6967
2022-10-10 18:48:09 - progress_bar.py[line:274] - INFO: epoch 005:    333 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.5, ups=0.8, wpb=109.7, bsz=40, num_updates=1980, lr=4.70773e-05, gnorm=0.986, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=6980
2022-10-10 18:48:22 - progress_bar.py[line:274] - INFO: epoch 005:    343 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.2, ups=0.8, wpb=110.5, bsz=40, num_updates=1990, lr=4.7052e-05, gnorm=0.726, clip=30, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=6992
2022-10-10 18:48:34 - progress_bar.py[line:274] - INFO: epoch 005:    353 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.5, ups=0.81, wpb=109, bsz=40, num_updates=2000, lr=4.70267e-05, gnorm=0.401, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=7005
2022-10-10 18:48:34 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 18:48:36 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 18:48:36 - train.py[line:551] - INFO: load:1.55 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 18:48:56 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.90 GiB already allocated; 6.01 GiB free; 31.10 GiB reserved in total by PyTorch)
2022-10-10 18:48:56 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 10        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9109 MB |   14340 MB |     880 TB |     880 TB |
|       from large pool |    8965 MB |   14195 MB |     880 TB |     880 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9109 MB |   14340 MB |     880 TB |     880 TB |
|       from large pool |    8965 MB |   14195 MB |     880 TB |     880 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   31846 MB |   37492 MB |  153534 MB |  121688 MB |
|       from large pool |   31700 MB |   37346 MB |  153250 MB |  121550 MB |
|       from small pool |     146 MB |     152 MB |     284 MB |     138 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   22736 MB |   27366 MB |     954 TB |     954 TB |
|       from large pool |   22734 MB |   27364 MB |     953 TB |     953 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |   38607 K  |   38604 K  |
|       from large pool |     563    |     575    |   13299 K  |   13298 K  |
|       from small pool |    3106    |    3116    |   25308 K  |   25305 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |   38607 K  |   38604 K  |
|       from large pool |     563    |     575    |   13299 K  |   13298 K  |
|       from small pool |    3106    |    3116    |   25308 K  |   25305 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     190    |     201    |     536    |     346    |
|       from large pool |     117    |     125    |     394    |     277    |
|       from small pool |      73    |      76    |     142    |      69    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     128    |     143    |   26269 K  |   26269 K  |
|       from large pool |      91    |      95    |    5074 K  |    5074 K  |
|       from small pool |      37    |      52    |   21194 K  |   21194 K  |
|===========================================================================|

2022-10-10 18:48:56 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-10 18:48:56 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-10 18:51:37 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 18:51:37 - train.py[line:551] - INFO: load:1.61 valid_run:180.87 task_valid:169.41 collect_output:7.55
2022-10-10 18:54:33 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 18:54:33 - train.py[line:551] - INFO: load:1.67 valid_run:356.97 task_valid:332.76 collect_output:18.23
2022-10-10 18:57:33 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 18:57:33 - train.py[line:551] - INFO: load:1.75 valid_run:536.16 task_valid:495.86 collect_output:32.19
2022-10-10 19:00:28 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 19:00:28 - train.py[line:551] - INFO: load:1.80 valid_run:711.60 task_valid:660.65 collect_output:41.14
2022-10-10 19:03:26 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 19:03:26 - train.py[line:551] - INFO: load:1.87 valid_run:888.93 task_valid:826.66 collect_output:50.59
2022-10-10 19:06:24 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 19:06:24 - train.py[line:551] - INFO: load:1.90 valid_run:1067.05 task_valid:992.17 collect_output:61.39
2022-10-10 19:09:23 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 19:09:23 - train.py[line:551] - INFO: load:1.96 valid_run:1246.34 task_valid:1158.51 collect_output:72.69
2022-10-10 19:12:20 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 19:12:20 - train.py[line:551] - INFO: load:2.00 valid_run:1422.81 task_valid:1320.02 collect_output:85.88
2022-10-10 19:15:16 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 19:15:16 - train.py[line:551] - INFO: load:2.06 valid_run:1599.40 task_valid:1485.98 collect_output:94.60
2022-10-10 19:18:12 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 19:18:12 - train.py[line:551] - INFO: load:2.12 valid_run:1774.33 task_valid:1650.40 collect_output:103.24
2022-10-10 19:21:09 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 19:21:09 - train.py[line:551] - INFO: load:2.16 valid_run:1951.78 task_valid:1816.78 collect_output:112.16
2022-10-10 19:24:06 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 19:24:06 - train.py[line:551] - INFO: load:2.22 valid_run:2128.79 task_valid:1983.90 collect_output:120.17
2022-10-10 19:27:02 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 19:27:02 - train.py[line:551] - INFO: load:2.26 valid_run:2304.28 task_valid:2146.64 collect_output:130.68
2022-10-10 19:29:57 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 19:29:57 - train.py[line:551] - INFO: load:2.31 valid_run:2479.55 task_valid:2312.56 collect_output:138.03
2022-10-10 19:32:52 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 19:32:52 - train.py[line:551] - INFO: load:2.34 valid_run:2654.00 task_valid:2479.06 collect_output:144.20
2022-10-10 19:35:53 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 19:35:53 - train.py[line:551] - INFO: load:2.39 valid_run:2835.05 task_valid:2650.46 collect_output:151.73
2022-10-10 19:38:51 - train.py[line:549] - INFO: 3400 / 4988
2022-10-10 19:38:51 - train.py[line:551] - INFO: load:2.45 valid_run:3013.33 task_valid:2818.04 collect_output:160.37
2022-10-10 19:41:50 - train.py[line:549] - INFO: 3600 / 4988
2022-10-10 19:41:50 - train.py[line:551] - INFO: load:2.48 valid_run:3191.94 task_valid:2986.88 collect_output:168.20
2022-10-10 19:44:44 - train.py[line:549] - INFO: 3800 / 4988
2022-10-10 19:44:44 - train.py[line:551] - INFO: load:2.56 valid_run:3365.47 task_valid:3148.99 collect_output:177.44
2022-10-10 19:47:40 - train.py[line:549] - INFO: 4000 / 4988
2022-10-10 19:47:40 - train.py[line:551] - INFO: load:2.59 valid_run:3541.46 task_valid:3313.58 collect_output:186.77
2022-10-10 19:50:40 - train.py[line:549] - INFO: 4200 / 4988
2022-10-10 19:50:40 - train.py[line:551] - INFO: load:2.65 valid_run:3721.47 task_valid:3478.88 collect_output:199.31
2022-10-10 19:53:32 - train.py[line:549] - INFO: 4400 / 4988
2022-10-10 19:53:32 - train.py[line:551] - INFO: load:2.68 valid_run:3894.05 task_valid:3641.87 collect_output:206.84
2022-10-10 19:56:29 - train.py[line:549] - INFO: 4600 / 4988
2022-10-10 19:56:29 - train.py[line:551] - INFO: load:2.74 valid_run:4070.54 task_valid:3807.59 collect_output:215.67
2022-10-10 19:59:25 - train.py[line:549] - INFO: 4800 / 4988
2022-10-10 19:59:25 - train.py[line:551] - INFO: load:2.82 valid_run:4245.88 task_valid:3973.95 collect_output:222.58

====================================================================================================
SGG eval:     R @ 50: 0.6627;     R @ 100: 0.6972;     R @ 500: 0.7193;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4609;    mR @ 100: 0.4993;    mR @ 500: 0.5533;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.9375) (covering:0.3000) (eating:0.7647) (flying in:0.5909) (growing on:0.3750) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9647) (says:0.0000) (sitting on:0.7364) (standing on:0.4593) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 20:02:16 - train.py[line:487] - INFO: 0.6972104150751208

====================================================================================================
SGG eval:     R @ 50: 0.6627;     R @ 100: 0.6972;     R @ 500: 0.7193;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4609;    mR @ 100: 0.4993;    mR @ 500: 0.5533;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.9375) (covering:0.3000) (eating:0.7647) (flying in:0.5909) (growing on:0.3750) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9647) (says:0.0000) (sitting on:0.7364) (standing on:0.4593) (using:0.6000) (walking in:0.0000) (walking on:0.6486) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 20:02:17 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-10 20:02:17 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 0.238 | loss_v1 0 | loss_v2 0 | nll_loss 0.067 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.69721 | ppl 1.05 | vqa_score 0.5495 | wps 101.5 | wpb 89.9 | bsz 30 | num_updates 2000 | best_R@100 0.701241
2022-10-10 20:02:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 2000 updates
2022-10-10 20:02:17 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_5_2000.pt
2022-10-10 20:02:24 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_5_2000.pt
2022-10-10 20:02:27 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_5_2000.pt (epoch 5 @ 2000 updates, score 0.6972104150751208) (writing took 9.941359783057123 seconds)
2022-10-10 20:02:39 - progress_bar.py[line:274] - INFO: epoch 005:    363 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=0.3, ups=0, wpb=111.4, bsz=40, num_updates=2010, lr=4.70014e-05, gnorm=0.754, clip=40, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=11449
2022-10-10 20:02:51 - progress_bar.py[line:274] - INFO: epoch 005:    373 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.4, ups=0.8, wpb=112, bsz=40, num_updates=2020, lr=4.69761e-05, gnorm=0.586, clip=10, loss_scale=512, train_wall=12, gb_free=10.3, ema_decay=0.9999, wall=11462
2022-10-10 20:03:04 - progress_bar.py[line:274] - INFO: epoch 005:    383 / 412 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.7, ups=0.78, wpb=110.9, bsz=40, num_updates=2030, lr=4.69508e-05, gnorm=0.564, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=11475
2022-10-10 20:03:17 - progress_bar.py[line:274] - INFO: epoch 005:    393 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.6, ups=0.8, wpb=110.9, bsz=40, num_updates=2040, lr=4.69256e-05, gnorm=0.653, clip=10, loss_scale=512, train_wall=12, gb_free=10.1, ema_decay=0.9999, wall=11487
2022-10-10 20:03:29 - progress_bar.py[line:274] - INFO: epoch 005:    403 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.5, ups=0.8, wpb=111.7, bsz=40, num_updates=2050, lr=4.69003e-05, gnorm=0.613, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11500
2022-10-10 20:03:39 - train.py[line:339] - INFO: end of epoch 5 (average epoch stats below)
2022-10-10 20:03:39 - progress_bar.py[line:282] - INFO: epoch 005 | loss 0.247 | loss_v1 0 | loss_v2 0 | nll_loss 0.062 | ntokens 111.131 | nsentences 40 | sample_size 111.131 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 9.2 | ups 0.08 | wpb 111.1 | bsz 40 | num_updates 2059 | lr 4.68775e-05 | gnorm 0.685 | clip 22.4 | loss_scale 512 | train_wall 510 | gb_free 10.7 | ema_decay 0.9999 | wall 11510
2022-10-10 20:03:39 - trainer.py[line:643] - INFO: loading train data for epoch 6
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv slice_id 1 row count 8240 total row count 16480
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E5.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 20:03:40 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 20:03:40 - trainer.py[line:707] - INFO: begin training epoch 6
2022-10-10 20:03:40 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 20:03:44 - progress_bar.py[line:274] - INFO: epoch 006:      1 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=74.4, ups=0.68, wpb=110, bsz=40, num_updates=2060, lr=4.6875e-05, gnorm=0.615, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11514
2022-10-10 20:03:57 - progress_bar.py[line:274] - INFO: epoch 006:     11 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.7, ups=0.78, wpb=111.8, bsz=40, num_updates=2070, lr=4.68497e-05, gnorm=0.531, clip=20, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=11527
2022-10-10 20:04:09 - progress_bar.py[line:274] - INFO: epoch 006:     21 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.9, ups=0.79, wpb=110.7, bsz=40, num_updates=2080, lr=4.68244e-05, gnorm=0.342, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11540
2022-10-10 20:04:22 - progress_bar.py[line:274] - INFO: epoch 006:     31 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.2, ups=0.79, wpb=110.5, bsz=40, num_updates=2090, lr=4.67992e-05, gnorm=0.511, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=11553
2022-10-10 20:04:34 - progress_bar.py[line:274] - INFO: epoch 006:     41 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.7, ups=0.82, wpb=111.1, bsz=40, num_updates=2100, lr=4.67739e-05, gnorm=0.512, clip=10, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=11565
2022-10-10 20:04:46 - progress_bar.py[line:274] - INFO: epoch 006:     51 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.2, ups=0.83, wpb=111.7, bsz=40, num_updates=2110, lr=4.67486e-05, gnorm=0.547, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=11577
2022-10-10 20:04:59 - progress_bar.py[line:274] - INFO: epoch 006:     61 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.9, ups=0.81, wpb=111.9, bsz=40, num_updates=2120, lr=4.67233e-05, gnorm=0.559, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11589
2022-10-10 20:05:12 - progress_bar.py[line:274] - INFO: epoch 006:     71 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.9, ups=0.78, wpb=110.5, bsz=40, num_updates=2130, lr=4.6698e-05, gnorm=0.611, clip=20, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=11602
2022-10-10 20:05:24 - progress_bar.py[line:274] - INFO: epoch 006:     81 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.4, ups=0.78, wpb=109.5, bsz=40, num_updates=2140, lr=4.66727e-05, gnorm=0.372, clip=0, loss_scale=512, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=11615
2022-10-10 20:05:37 - progress_bar.py[line:274] - INFO: epoch 006:     91 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.3, ups=0.81, wpb=110.4, bsz=40, num_updates=2150, lr=4.66475e-05, gnorm=0.461, clip=10, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=11627
2022-10-10 20:05:50 - progress_bar.py[line:274] - INFO: epoch 006:    101 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.5, ups=0.77, wpb=111, bsz=40, num_updates=2160, lr=4.66222e-05, gnorm=0.552, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11640
2022-10-10 20:06:02 - progress_bar.py[line:274] - INFO: epoch 006:    111 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.3, ups=0.79, wpb=112.5, bsz=40, num_updates=2170, lr=4.65969e-05, gnorm=0.504, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11653
2022-10-10 20:06:15 - progress_bar.py[line:274] - INFO: epoch 006:    121 / 412 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.1, ups=0.78, wpb=112.8, bsz=40, num_updates=2180, lr=4.65716e-05, gnorm=0.619, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11666
2022-10-10 20:06:28 - progress_bar.py[line:274] - INFO: epoch 006:    131 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.8, ups=0.78, wpb=111.2, bsz=40, num_updates=2190, lr=4.65463e-05, gnorm=0.417, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11679
2022-10-10 20:06:40 - progress_bar.py[line:274] - INFO: epoch 006:    141 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.2, ups=0.81, wpb=111.1, bsz=40, num_updates=2200, lr=4.6521e-05, gnorm=0.491, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11691
2022-10-10 20:06:54 - progress_bar.py[line:274] - INFO: epoch 006:    151 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=82.5, ups=0.75, wpb=110.7, bsz=40, num_updates=2210, lr=4.64958e-05, gnorm=0.598, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11704
2022-10-10 20:07:06 - progress_bar.py[line:274] - INFO: epoch 006:    161 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.2, ups=0.79, wpb=111.7, bsz=40, num_updates=2220, lr=4.64705e-05, gnorm=0.668, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=11717
2022-10-10 20:07:19 - progress_bar.py[line:274] - INFO: epoch 006:    171 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=87.5, ups=0.79, wpb=110.7, bsz=40, num_updates=2230, lr=4.64452e-05, gnorm=0.376, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11730
2022-10-10 20:07:32 - progress_bar.py[line:274] - INFO: epoch 006:    181 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.8, wpb=111.7, bsz=40, num_updates=2240, lr=4.64199e-05, gnorm=0.449, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11742
2022-10-10 20:07:44 - progress_bar.py[line:274] - INFO: epoch 006:    191 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.7, ups=0.78, wpb=109.2, bsz=40, num_updates=2250, lr=4.63946e-05, gnorm=0.616, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11755
2022-10-10 20:07:58 - progress_bar.py[line:274] - INFO: epoch 006:    201 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=82.7, ups=0.75, wpb=110.9, bsz=40, num_updates=2260, lr=4.63693e-05, gnorm=0.696, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11768
2022-10-10 20:08:11 - progress_bar.py[line:274] - INFO: epoch 006:    211 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=84.7, ups=0.76, wpb=110.9, bsz=40, num_updates=2270, lr=4.63441e-05, gnorm=0.236, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=11782
2022-10-10 20:08:26 - progress_bar.py[line:274] - INFO: epoch 006:    221 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=75.6, ups=0.67, wpb=112.8, bsz=40, num_updates=2280, lr=4.63188e-05, gnorm=0.757, clip=20, loss_scale=512, train_wall=15, gb_free=10.9, ema_decay=0.9999, wall=11796
2022-10-10 20:08:39 - progress_bar.py[line:274] - INFO: epoch 006:    231 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.2, ups=0.78, wpb=112.6, bsz=40, num_updates=2290, lr=4.62935e-05, gnorm=0.428, clip=0, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=11809
2022-10-10 20:08:51 - progress_bar.py[line:274] - INFO: epoch 006:    241 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.9, ups=0.79, wpb=111.8, bsz=40, num_updates=2300, lr=4.62682e-05, gnorm=0.684, clip=30, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=11822
2022-10-10 20:09:04 - progress_bar.py[line:274] - INFO: epoch 006:    251 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=84.2, ups=0.77, wpb=109.7, bsz=40, num_updates=2310, lr=4.62429e-05, gnorm=0.508, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11835
2022-10-10 20:09:17 - progress_bar.py[line:274] - INFO: epoch 006:    261 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.3, ups=0.8, wpb=110.9, bsz=40, num_updates=2320, lr=4.62176e-05, gnorm=0.39, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11848
2022-10-10 20:09:30 - progress_bar.py[line:274] - INFO: epoch 006:    271 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.9, ups=0.79, wpb=110.6, bsz=40, num_updates=2330, lr=4.61924e-05, gnorm=1.041, clip=40, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11860
2022-10-10 20:09:43 - progress_bar.py[line:274] - INFO: epoch 006:    281 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.3, ups=0.76, wpb=110.9, bsz=40, num_updates=2340, lr=4.61671e-05, gnorm=0.376, clip=0, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=11873
2022-10-10 20:09:55 - progress_bar.py[line:274] - INFO: epoch 006:    291 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.9, ups=0.79, wpb=111.2, bsz=40, num_updates=2350, lr=4.61418e-05, gnorm=0.493, clip=10, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=11886
2022-10-10 20:10:08 - progress_bar.py[line:274] - INFO: epoch 006:    301 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.1, ups=0.81, wpb=111.7, bsz=40, num_updates=2360, lr=4.61165e-05, gnorm=0.341, clip=0, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=11898
2022-10-10 20:10:20 - progress_bar.py[line:274] - INFO: epoch 006:    311 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.8, wpb=111.6, bsz=40, num_updates=2370, lr=4.60912e-05, gnorm=0.452, clip=20, loss_scale=1024, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=11911
2022-10-10 20:10:33 - progress_bar.py[line:274] - INFO: epoch 006:    321 / 412 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.8, ups=0.79, wpb=112.7, bsz=40, num_updates=2380, lr=4.60659e-05, gnorm=0.563, clip=30, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=11924
2022-10-10 20:10:46 - progress_bar.py[line:274] - INFO: epoch 006:    331 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.8, wpb=111.2, bsz=40, num_updates=2390, lr=4.60407e-05, gnorm=0.497, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11936
2022-10-10 20:10:58 - progress_bar.py[line:274] - INFO: epoch 006:    341 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.1, ups=0.81, wpb=110, bsz=40, num_updates=2400, lr=4.60154e-05, gnorm=0.709, clip=30, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=11949
2022-10-10 20:11:11 - progress_bar.py[line:274] - INFO: epoch 006:    351 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=84.9, ups=0.77, wpb=109.6, bsz=40, num_updates=2410, lr=4.59901e-05, gnorm=0.818, clip=30, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=11962
2022-10-10 20:11:23 - progress_bar.py[line:274] - INFO: epoch 006:    361 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88, ups=0.8, wpb=110.1, bsz=40, num_updates=2420, lr=4.59648e-05, gnorm=0.827, clip=30, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11974
2022-10-10 20:11:36 - progress_bar.py[line:274] - INFO: epoch 006:    371 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.5, ups=0.8, wpb=111.4, bsz=40, num_updates=2430, lr=4.59395e-05, gnorm=0.75, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=11986
2022-10-10 20:11:49 - progress_bar.py[line:274] - INFO: epoch 006:    381 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.4, ups=0.75, wpb=112.1, bsz=40, num_updates=2440, lr=4.59142e-05, gnorm=0.794, clip=20, loss_scale=1024, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=12000
2022-10-10 20:12:02 - progress_bar.py[line:274] - INFO: epoch 006:    391 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.6, ups=0.78, wpb=111.1, bsz=40, num_updates=2450, lr=4.5889e-05, gnorm=0.577, clip=10, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12013
2022-10-10 20:12:15 - progress_bar.py[line:274] - INFO: epoch 006:    401 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.4, ups=0.79, wpb=110.7, bsz=40, num_updates=2460, lr=4.58637e-05, gnorm=0.465, clip=10, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12025
2022-10-10 20:12:27 - progress_bar.py[line:274] - INFO: epoch 006:    411 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.1, ups=0.81, wpb=110.7, bsz=40, num_updates=2470, lr=4.58384e-05, gnorm=0.51, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12038
2022-10-10 20:12:28 - train.py[line:339] - INFO: end of epoch 6 (average epoch stats below)
2022-10-10 20:12:28 - progress_bar.py[line:282] - INFO: epoch 006 | loss 0.244 | loss_v1 0 | loss_v2 0 | nll_loss 0.059 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 86.6 | ups 0.78 | wpb 111.1 | bsz 40 | num_updates 2471 | lr 4.58359e-05 | gnorm 0.552 | clip 13.8 | loss_scale 1024 | train_wall 522 | gb_free 10 | ema_decay 0.9999 | wall 12039
2022-10-10 20:12:28 - trainer.py[line:643] - INFO: loading train data for epoch 7
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv slice_id 1 row count 8240 total row count 16480
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E6.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 20:12:28 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 20:12:29 - trainer.py[line:707] - INFO: begin training epoch 7
2022-10-10 20:12:29 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 20:12:43 - progress_bar.py[line:274] - INFO: epoch 007:      9 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=72.3, ups=0.64, wpb=112.8, bsz=40, num_updates=2480, lr=4.58131e-05, gnorm=0.311, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12053
2022-10-10 20:12:55 - progress_bar.py[line:274] - INFO: epoch 007:     19 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.8, ups=0.8, wpb=111.6, bsz=40, num_updates=2490, lr=4.57878e-05, gnorm=0.523, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12066
2022-10-10 20:13:05 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 20:13:09 - progress_bar.py[line:274] - INFO: epoch 007:     30 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=81.9, ups=0.74, wpb=110.7, bsz=40, num_updates=2500, lr=4.57625e-05, gnorm=0.559, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12079
2022-10-10 20:13:21 - progress_bar.py[line:274] - INFO: epoch 007:     40 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.7, ups=0.81, wpb=111.3, bsz=40, num_updates=2510, lr=4.57373e-05, gnorm=0.453, clip=10, loss_scale=512, train_wall=12, gb_free=11.4, ema_decay=0.9999, wall=12092
2022-10-10 20:13:34 - progress_bar.py[line:274] - INFO: epoch 007:     50 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.8, wpb=111.1, bsz=40, num_updates=2520, lr=4.5712e-05, gnorm=0.639, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12104
2022-10-10 20:13:47 - progress_bar.py[line:274] - INFO: epoch 007:     60 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.9, ups=0.78, wpb=111.3, bsz=40, num_updates=2530, lr=4.56867e-05, gnorm=0.471, clip=10, loss_scale=512, train_wall=13, gb_free=10, ema_decay=0.9999, wall=12117
2022-10-10 20:13:59 - progress_bar.py[line:274] - INFO: epoch 007:     70 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.7, ups=0.78, wpb=109.8, bsz=40, num_updates=2540, lr=4.56614e-05, gnorm=0.638, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12130
2022-10-10 20:14:14 - progress_bar.py[line:274] - INFO: epoch 007:     80 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=74, ups=0.67, wpb=110.5, bsz=40, num_updates=2550, lr=4.56361e-05, gnorm=0.486, clip=10, loss_scale=512, train_wall=15, gb_free=10, ema_decay=0.9999, wall=12145
2022-10-10 20:14:27 - progress_bar.py[line:274] - INFO: epoch 007:     90 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.1, ups=0.77, wpb=111, bsz=40, num_updates=2560, lr=4.56108e-05, gnorm=0.599, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12158
2022-10-10 20:14:40 - progress_bar.py[line:274] - INFO: epoch 007:    100 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.3, ups=0.8, wpb=110.2, bsz=40, num_updates=2570, lr=4.55856e-05, gnorm=0.456, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12170
2022-10-10 20:14:52 - progress_bar.py[line:274] - INFO: epoch 007:    110 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89, ups=0.8, wpb=111.4, bsz=40, num_updates=2580, lr=4.55603e-05, gnorm=0.393, clip=10, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=12183
2022-10-10 20:15:05 - progress_bar.py[line:274] - INFO: epoch 007:    120 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.4, ups=0.82, wpb=111.8, bsz=40, num_updates=2590, lr=4.5535e-05, gnorm=0.588, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12195
2022-10-10 20:15:18 - progress_bar.py[line:274] - INFO: epoch 007:    130 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=83.7, ups=0.76, wpb=110.6, bsz=40, num_updates=2600, lr=4.55097e-05, gnorm=0.535, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12208
2022-10-10 20:15:31 - progress_bar.py[line:274] - INFO: epoch 007:    140 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87, ups=0.78, wpb=111.6, bsz=40, num_updates=2610, lr=4.54844e-05, gnorm=0.363, clip=10, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=12221
2022-10-10 20:15:43 - progress_bar.py[line:274] - INFO: epoch 007:    150 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87, ups=0.78, wpb=111.4, bsz=40, num_updates=2620, lr=4.54591e-05, gnorm=0.71, clip=20, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=12234
2022-10-10 20:15:56 - progress_bar.py[line:274] - INFO: epoch 007:    160 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.7, ups=0.8, wpb=111.7, bsz=40, num_updates=2630, lr=4.54339e-05, gnorm=0.539, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=12247
2022-10-10 20:16:08 - progress_bar.py[line:274] - INFO: epoch 007:    170 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.1, ups=0.81, wpb=112.2, bsz=40, num_updates=2640, lr=4.54086e-05, gnorm=0.812, clip=30, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=12259
2022-10-10 20:16:20 - progress_bar.py[line:274] - INFO: epoch 007:    180 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.3, ups=0.82, wpb=111.3, bsz=40, num_updates=2650, lr=4.53833e-05, gnorm=0.717, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12271
2022-10-10 20:16:33 - progress_bar.py[line:274] - INFO: epoch 007:    190 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.5, ups=0.79, wpb=111.7, bsz=40, num_updates=2660, lr=4.5358e-05, gnorm=0.364, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12284
2022-10-10 20:16:46 - progress_bar.py[line:274] - INFO: epoch 007:    200 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88, ups=0.79, wpb=111.5, bsz=40, num_updates=2670, lr=4.53327e-05, gnorm=0.613, clip=30, loss_scale=512, train_wall=13, gb_free=11.1, ema_decay=0.9999, wall=12296
2022-10-10 20:16:58 - progress_bar.py[line:274] - INFO: epoch 007:    210 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.6, ups=0.82, wpb=110.6, bsz=40, num_updates=2680, lr=4.53074e-05, gnorm=0.312, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12309
2022-10-10 20:17:10 - progress_bar.py[line:274] - INFO: epoch 007:    220 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.4, ups=0.81, wpb=110.9, bsz=40, num_updates=2690, lr=4.52822e-05, gnorm=0.45, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12321
2022-10-10 20:17:24 - progress_bar.py[line:274] - INFO: epoch 007:    230 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=82.9, ups=0.75, wpb=109.9, bsz=40, num_updates=2700, lr=4.52569e-05, gnorm=0.289, clip=0, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=12334
2022-10-10 20:17:36 - progress_bar.py[line:274] - INFO: epoch 007:    240 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.7, ups=0.79, wpb=109.5, bsz=40, num_updates=2710, lr=4.52316e-05, gnorm=0.816, clip=30, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12347
2022-10-10 20:17:48 - progress_bar.py[line:274] - INFO: epoch 007:    250 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.3, ups=0.81, wpb=108.7, bsz=40, num_updates=2720, lr=4.52063e-05, gnorm=0.324, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12359
2022-10-10 20:18:01 - progress_bar.py[line:274] - INFO: epoch 007:    260 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.3, ups=0.77, wpb=110.6, bsz=40, num_updates=2730, lr=4.5181e-05, gnorm=0.315, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12372
2022-10-10 20:18:14 - progress_bar.py[line:274] - INFO: epoch 007:    270 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.6, ups=0.78, wpb=111.7, bsz=40, num_updates=2740, lr=4.51557e-05, gnorm=0.368, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12385
2022-10-10 20:18:27 - progress_bar.py[line:274] - INFO: epoch 007:    280 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.9, ups=0.76, wpb=111.4, bsz=40, num_updates=2750, lr=4.51305e-05, gnorm=0.535, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12398
2022-10-10 20:18:40 - progress_bar.py[line:274] - INFO: epoch 007:    290 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86, ups=0.77, wpb=111.2, bsz=40, num_updates=2760, lr=4.51052e-05, gnorm=0.595, clip=20, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=12411
2022-10-10 20:18:53 - progress_bar.py[line:274] - INFO: epoch 007:    300 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.6, ups=0.78, wpb=111.6, bsz=40, num_updates=2770, lr=4.50799e-05, gnorm=0.579, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12424
2022-10-10 20:19:06 - progress_bar.py[line:274] - INFO: epoch 007:    310 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.6, ups=0.81, wpb=112.2, bsz=40, num_updates=2780, lr=4.50546e-05, gnorm=0.678, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12436
2022-10-10 20:19:19 - progress_bar.py[line:274] - INFO: epoch 007:    320 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=84.5, ups=0.76, wpb=111.4, bsz=40, num_updates=2790, lr=4.50293e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=12450
2022-10-10 20:19:33 - progress_bar.py[line:274] - INFO: epoch 007:    330 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=82.3, ups=0.75, wpb=110.3, bsz=40, num_updates=2800, lr=4.5004e-05, gnorm=0.4, clip=10, loss_scale=512, train_wall=13, gb_free=11.1, ema_decay=0.9999, wall=12463
2022-10-10 20:19:46 - progress_bar.py[line:274] - INFO: epoch 007:    340 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.8, ups=0.79, wpb=111.7, bsz=40, num_updates=2810, lr=4.49788e-05, gnorm=0.476, clip=10, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12477
2022-10-10 20:19:59 - progress_bar.py[line:274] - INFO: epoch 007:    350 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.8, ups=0.79, wpb=110.8, bsz=40, num_updates=2820, lr=4.49535e-05, gnorm=0.662, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12489
2022-10-10 20:20:11 - progress_bar.py[line:274] - INFO: epoch 007:    360 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.2, ups=0.81, wpb=112, bsz=40, num_updates=2830, lr=4.49282e-05, gnorm=0.825, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12502
2022-10-10 20:20:24 - progress_bar.py[line:274] - INFO: epoch 007:    370 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.3, ups=0.77, wpb=111.4, bsz=40, num_updates=2840, lr=4.49029e-05, gnorm=0.55, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12515
2022-10-10 20:20:37 - progress_bar.py[line:274] - INFO: epoch 007:    380 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.6, ups=0.8, wpb=110, bsz=40, num_updates=2850, lr=4.48776e-05, gnorm=0.773, clip=40, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12527
2022-10-10 20:20:49 - progress_bar.py[line:274] - INFO: epoch 007:    390 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.8, ups=0.8, wpb=113, bsz=40, num_updates=2860, lr=4.48523e-05, gnorm=0.659, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12540
2022-10-10 20:21:01 - progress_bar.py[line:274] - INFO: epoch 007:    400 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=94.3, ups=0.84, wpb=111.8, bsz=40, num_updates=2870, lr=4.48271e-05, gnorm=0.699, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12552
2022-10-10 20:21:13 - progress_bar.py[line:274] - INFO: epoch 007:    410 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90, ups=0.81, wpb=110.4, bsz=40, num_updates=2880, lr=4.48018e-05, gnorm=0.629, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12564
2022-10-10 20:21:16 - train.py[line:339] - INFO: end of epoch 7 (average epoch stats below)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv slice_id 1 row count 8240 total row count 16480
2022-10-10 20:21:16 - progress_bar.py[line:282] - INFO: epoch 007 | loss 0.244 | loss_v1 0 | loss_v2 0 | nll_loss 0.06 | ntokens 111.122 | nsentences 40 | sample_size 111.122 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 86.6 | ups 0.78 | wpb 111.1 | bsz 40 | num_updates 2882 | lr 4.47967e-05 | gnorm 0.556 | clip 14.8 | loss_scale 512 | train_wall 520 | gb_free 11.1 | ema_decay 0.9999 | wall 12566
2022-10-10 20:21:16 - trainer.py[line:643] - INFO: loading train data for epoch 8
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E7.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 20:21:16 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 20:21:17 - trainer.py[line:707] - INFO: begin training epoch 8
2022-10-10 20:21:17 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 20:21:30 - progress_bar.py[line:274] - INFO: epoch 008:      8 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=67.6, ups=0.61, wpb=111.3, bsz=40, num_updates=2890, lr=4.47765e-05, gnorm=0.87, clip=40, loss_scale=512, train_wall=14, gb_free=10.6, ema_decay=0.9999, wall=12580
2022-10-10 20:21:42 - progress_bar.py[line:274] - INFO: epoch 008:     18 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.6, ups=0.8, wpb=111.4, bsz=40, num_updates=2900, lr=4.47512e-05, gnorm=0.502, clip=10, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=12593
2022-10-10 20:21:55 - progress_bar.py[line:274] - INFO: epoch 008:     28 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.2, ups=0.8, wpb=111.3, bsz=40, num_updates=2910, lr=4.47259e-05, gnorm=0.525, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12605
2022-10-10 20:22:08 - progress_bar.py[line:274] - INFO: epoch 008:     38 / 412 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.5, ups=0.77, wpb=110.4, bsz=40, num_updates=2920, lr=4.47006e-05, gnorm=0.462, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=12618
2022-10-10 20:22:20 - progress_bar.py[line:274] - INFO: epoch 008:     48 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.5, ups=0.82, wpb=108.5, bsz=40, num_updates=2930, lr=4.46754e-05, gnorm=0.528, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12630
2022-10-10 20:22:33 - progress_bar.py[line:274] - INFO: epoch 008:     58 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.3, ups=0.76, wpb=110.5, bsz=40, num_updates=2940, lr=4.46501e-05, gnorm=0.525, clip=10, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=12644
2022-10-10 20:22:45 - progress_bar.py[line:274] - INFO: epoch 008:     68 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.7, ups=0.81, wpb=111.3, bsz=40, num_updates=2950, lr=4.46248e-05, gnorm=0.544, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=12656
2022-10-10 20:22:58 - progress_bar.py[line:274] - INFO: epoch 008:     78 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.6, ups=0.81, wpb=111.7, bsz=40, num_updates=2960, lr=4.45995e-05, gnorm=0.46, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=12668
2022-10-10 20:23:10 - progress_bar.py[line:274] - INFO: epoch 008:     88 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.7, ups=0.81, wpb=111.1, bsz=40, num_updates=2970, lr=4.45742e-05, gnorm=0.703, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=12681
2022-10-10 20:23:23 - progress_bar.py[line:274] - INFO: epoch 008:     98 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.5, ups=0.8, wpb=111.6, bsz=40, num_updates=2980, lr=4.45489e-05, gnorm=1.003, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12693
2022-10-10 20:23:35 - progress_bar.py[line:274] - INFO: epoch 008:    108 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.2, ups=0.81, wpb=110.7, bsz=40, num_updates=2990, lr=4.45237e-05, gnorm=0.404, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=12706
2022-10-10 20:23:47 - progress_bar.py[line:274] - INFO: epoch 008:    118 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.2, ups=0.81, wpb=111.8, bsz=40, num_updates=3000, lr=4.44984e-05, gnorm=0.631, clip=20, loss_scale=512, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=12718
2022-10-10 20:23:47 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 20:23:49 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 20:23:49 - train.py[line:551] - INFO: load:1.06 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 20:23:50 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 5.37 GiB (GPU 0; 39.59 GiB total capacity; 8.40 GiB already allocated; 5.22 GiB free; 31.89 GiB reserved in total by PyTorch)
2022-10-10 20:23:50 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    8604 MB |    9736 MB |    1586 TB |    1586 TB |
|       from large pool |    8459 MB |    9591 MB |    1586 TB |    1586 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    8604 MB |    9736 MB |    1586 TB |    1586 TB |
|       from large pool |    8459 MB |    9591 MB |    1586 TB |    1586 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   32652 MB |   32652 MB |  172770 MB |  140118 MB |
|       from large pool |   32506 MB |   32506 MB |  172462 MB |  139956 MB |
|       from small pool |     146 MB |     146 MB |     308 MB |     162 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24047 MB |   28121 MB |    1669 TB |    1669 TB |
|       from large pool |   24046 MB |   28119 MB |    1668 TB |    1668 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |   71674 K  |   71670 K  |
|       from large pool |     563    |     575    |   23833 K  |   23833 K  |
|       from small pool |    3095    |    3114    |   47840 K  |   47837 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |   71674 K  |   71670 K  |
|       from large pool |     563    |     575    |   23833 K  |   23833 K  |
|       from small pool |    3095    |    3114    |   47840 K  |   47837 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     142    |     142    |     554    |     412    |
|       from large pool |      69    |      69    |     400    |     331    |
|       from small pool |      73    |      73    |     154    |      81    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      98    |     103    |   52035 K  |   52035 K  |
|       from large pool |      61    |      63    |   11427 K  |   11427 K  |
|       from small pool |      37    |      44    |   40608 K  |   40608 K  |
|===========================================================================|

2022-10-10 20:23:50 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-10 20:23:50 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-10 20:23:50 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.86 GiB already allocated; 1.66 GiB free; 33.27 GiB reserved in total by PyTorch)
2022-10-10 20:23:50 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-10 20:23:50 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 18        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9077 MB |   10301 MB |    1590 TB |    1589 TB |
|       from large pool |    8932 MB |   10156 MB |    1589 TB |    1589 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9077 MB |   10301 MB |    1590 TB |    1589 TB |
|       from large pool |    8932 MB |   10156 MB |    1589 TB |    1589 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   34070 MB |   34308 MB |  191226 MB |  157156 MB |
|       from large pool |   33924 MB |   34156 MB |  190896 MB |  156972 MB |
|       from small pool |     146 MB |     152 MB |     330 MB |     184 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24992 MB |   28527 MB |    1642 TB |    1642 TB |
|       from large pool |   24991 MB |   28525 MB |    1641 TB |    1641 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |   71667 K  |   71663 K  |
|       from large pool |     563    |     575    |   23831 K  |   23831 K  |
|       from small pool |    3095    |    3114    |   47835 K  |   47832 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |   71667 K  |   71663 K  |
|       from large pool |     563    |     575    |   23831 K  |   23831 K  |
|       from small pool |    3095    |    3114    |   47835 K  |   47832 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     195    |     199    |     567    |     372    |
|       from large pool |     122    |     123    |     402    |     280    |
|       from small pool |      73    |      76    |     165    |      92    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     126    |     133    |   49310 K  |   49310 K  |
|       from large pool |      89    |      91    |    8525 K  |    8525 K  |
|       from small pool |      37    |      45    |   40785 K  |   40785 K  |
|===========================================================================|

2022-10-10 20:23:50 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-10 20:26:53 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 20:26:53 - train.py[line:551] - INFO: load:1.13 valid_run:183.89 task_valid:171.55 collect_output:9.14
2022-10-10 20:29:53 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 20:29:53 - train.py[line:551] - INFO: load:1.21 valid_run:364.31 task_valid:339.50 collect_output:19.42
2022-10-10 20:32:52 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 20:32:52 - train.py[line:551] - INFO: load:1.25 valid_run:542.46 task_valid:502.42 collect_output:32.35
2022-10-10 20:35:46 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 20:35:46 - train.py[line:551] - INFO: load:1.28 valid_run:716.66 task_valid:666.94 collect_output:40.18
2022-10-10 20:38:41 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 20:38:41 - train.py[line:551] - INFO: load:1.36 valid_run:891.18 task_valid:832.99 collect_output:46.69
2022-10-10 20:41:35 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 20:41:35 - train.py[line:551] - INFO: load:1.41 valid_run:1065.31 task_valid:994.99 collect_output:56.54
2022-10-10 20:44:34 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 20:44:34 - train.py[line:551] - INFO: load:1.44 valid_run:1244.08 task_valid:1159.60 collect_output:68.62
2022-10-10 20:47:27 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 20:47:27 - train.py[line:551] - INFO: load:1.53 valid_run:1417.17 task_valid:1317.62 collect_output:81.63
2022-10-10 20:50:18 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 20:50:18 - train.py[line:551] - INFO: load:1.59 valid_run:1588.21 task_valid:1479.05 collect_output:89.07
2022-10-10 20:53:12 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 20:53:12 - train.py[line:551] - INFO: load:1.65 valid_run:1761.94 task_valid:1641.05 collect_output:98.56
2022-10-10 20:56:08 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 20:56:08 - train.py[line:551] - INFO: load:1.71 valid_run:1937.38 task_valid:1806.28 collect_output:106.69
2022-10-10 20:59:04 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 20:59:04 - train.py[line:551] - INFO: load:1.77 valid_run:2113.82 task_valid:1971.92 collect_output:115.34
2022-10-10 21:02:01 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 21:02:01 - train.py[line:551] - INFO: load:1.88 valid_run:2290.13 task_valid:2135.05 collect_output:126.34
2022-10-10 21:04:55 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 21:04:55 - train.py[line:551] - INFO: load:1.94 valid_run:2464.40 task_valid:2299.59 collect_output:133.82
2022-10-10 21:07:48 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 21:07:48 - train.py[line:551] - INFO: load:2.00 valid_run:2637.54 task_valid:2465.24 collect_output:139.21
2022-10-10 21:10:39 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 21:10:39 - train.py[line:551] - INFO: load:2.07 valid_run:2807.75 task_valid:2625.69 collect_output:147.03
2022-10-10 21:13:36 - train.py[line:549] - INFO: 3400 / 4988
2022-10-10 21:13:36 - train.py[line:551] - INFO: load:2.14 valid_run:2984.92 task_valid:2792.30 collect_output:155.41
2022-10-10 21:16:30 - train.py[line:549] - INFO: 3600 / 4988
2022-10-10 21:16:30 - train.py[line:551] - INFO: load:2.19 valid_run:3158.74 task_valid:2958.13 collect_output:161.47
2022-10-10 21:19:18 - train.py[line:549] - INFO: 3800 / 4988
2022-10-10 21:19:18 - train.py[line:551] - INFO: load:2.24 valid_run:3327.11 task_valid:3115.41 collect_output:170.55
2022-10-10 21:22:07 - train.py[line:549] - INFO: 4000 / 4988
2022-10-10 21:22:07 - train.py[line:551] - INFO: load:2.28 valid_run:3495.57 task_valid:3274.46 collect_output:177.91
2022-10-10 21:24:57 - train.py[line:549] - INFO: 4200 / 4988
2022-10-10 21:24:57 - train.py[line:551] - INFO: load:2.31 valid_run:3665.84 task_valid:3433.98 collect_output:186.58
2022-10-10 21:27:53 - train.py[line:549] - INFO: 4400 / 4988
2022-10-10 21:27:53 - train.py[line:551] - INFO: load:2.40 valid_run:3841.05 task_valid:3599.90 collect_output:193.88
2022-10-10 21:30:53 - train.py[line:549] - INFO: 4600 / 4988
2022-10-10 21:30:53 - train.py[line:551] - INFO: load:2.43 valid_run:4020.95 task_valid:3768.93 collect_output:202.80
2022-10-10 21:33:57 - train.py[line:549] - INFO: 4800 / 4988
2022-10-10 21:33:57 - train.py[line:551] - INFO: load:2.47 valid_run:4204.96 task_valid:3941.93 collect_output:211.89

====================================================================================================
SGG eval:     R @ 50: 0.6615;     R @ 100: 0.6925;     R @ 500: 0.7182;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4837;    mR @ 100: 0.5143;    mR @ 500: 0.5708;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.9375) (covering:0.3000) (eating:0.7647) (flying in:0.5909) (growing on:0.3750) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9451) (says:0.0000) (sitting on:0.7219) (standing on:0.4860) (using:0.6000) (walking in:0.3333) (walking on:0.6216) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6615;     R @ 100: 0.6925;     R @ 500: 0.7182;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4837;    mR @ 100: 0.5143;    mR @ 500: 0.5708;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.9375) (covering:0.3000) (eating:0.7647) (flying in:0.5909) (growing on:0.3750) (hanging from:0.4032) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9451) (says:0.0000) (sitting on:0.7219) (standing on:0.4860) (using:0.6000) (walking in:0.3333) (walking on:0.6216) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 21:36:53 - train.py[line:487] - INFO: 0.6925104150751209
2022-10-10 21:36:53 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-10 21:36:53 - progress_bar.py[line:282] - INFO: epoch 008 | valid on 'valid' subset | loss 0.232 | loss_v1 0 | loss_v2 0 | nll_loss 0.065 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.69251 | ppl 1.05 | vqa_score 0.5349 | wps 102.4 | wpb 89.9 | bsz 30 | num_updates 3000 | best_R@100 0.701241
2022-10-10 21:36:53 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 3000 updates
2022-10-10 21:36:53 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_8_3000.pt
2022-10-10 21:37:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_8_3000.pt
2022-10-10 21:37:03 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_8_3000.pt (epoch 8 @ 3000 updates, score 0.6925104150751209) (writing took 10.146456401795149 seconds)
2022-10-10 21:37:16 - progress_bar.py[line:274] - INFO: epoch 008:    128 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=0.3, ups=0, wpb=111.5, bsz=40, num_updates=3010, lr=4.44731e-05, gnorm=0.659, clip=30, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17126
2022-10-10 21:37:28 - progress_bar.py[line:274] - INFO: epoch 008:    138 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88, ups=0.79, wpb=111.3, bsz=40, num_updates=3020, lr=4.44478e-05, gnorm=0.564, clip=10, loss_scale=1024, train_wall=13, gb_free=11, ema_decay=0.9999, wall=17139
2022-10-10 21:37:41 - progress_bar.py[line:274] - INFO: epoch 008:    148 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88, ups=0.8, wpb=110.4, bsz=40, num_updates=3030, lr=4.44225e-05, gnorm=0.822, clip=30, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=17151
2022-10-10 21:37:53 - progress_bar.py[line:274] - INFO: epoch 008:    158 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=87.8, ups=0.79, wpb=110.7, bsz=40, num_updates=3040, lr=4.43972e-05, gnorm=0.425, clip=20, loss_scale=1024, train_wall=13, gb_free=10.5, ema_decay=0.9999, wall=17164
2022-10-10 21:38:05 - progress_bar.py[line:274] - INFO: epoch 008:    168 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.3, ups=0.83, wpb=110.7, bsz=40, num_updates=3050, lr=4.4372e-05, gnorm=0.401, clip=0, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17176
2022-10-10 21:38:18 - progress_bar.py[line:274] - INFO: epoch 008:    178 / 412 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.6, ups=0.8, wpb=111.4, bsz=40, num_updates=3060, lr=4.43467e-05, gnorm=0.298, clip=10, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=17189
2022-10-10 21:38:30 - progress_bar.py[line:274] - INFO: epoch 008:    188 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.6, ups=0.82, wpb=111, bsz=40, num_updates=3070, lr=4.43214e-05, gnorm=0.435, clip=10, loss_scale=1024, train_wall=12, gb_free=10.9, ema_decay=0.9999, wall=17201
2022-10-10 21:38:43 - progress_bar.py[line:274] - INFO: epoch 008:    198 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.6, ups=0.79, wpb=109.8, bsz=40, num_updates=3080, lr=4.42961e-05, gnorm=0.779, clip=20, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=17214
2022-10-10 21:38:55 - progress_bar.py[line:274] - INFO: epoch 008:    208 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.1, ups=0.81, wpb=110.9, bsz=40, num_updates=3090, lr=4.42708e-05, gnorm=0.78, clip=30, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=17226
2022-10-10 21:39:08 - progress_bar.py[line:274] - INFO: epoch 008:    218 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.8, ups=0.8, wpb=110.3, bsz=40, num_updates=3100, lr=4.42456e-05, gnorm=0.855, clip=40, loss_scale=1024, train_wall=12, gb_free=10, ema_decay=0.9999, wall=17238
2022-10-10 21:39:20 - progress_bar.py[line:274] - INFO: epoch 008:    228 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.8, ups=0.8, wpb=111.6, bsz=40, num_updates=3110, lr=4.42203e-05, gnorm=0.716, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17251
2022-10-10 21:39:33 - progress_bar.py[line:274] - INFO: epoch 008:    238 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90, ups=0.8, wpb=111.8, bsz=40, num_updates=3120, lr=4.4195e-05, gnorm=0.802, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17263
2022-10-10 21:39:45 - progress_bar.py[line:274] - INFO: epoch 008:    248 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91, ups=0.82, wpb=111.2, bsz=40, num_updates=3130, lr=4.41697e-05, gnorm=0.581, clip=30, loss_scale=1024, train_wall=12, gb_free=11, ema_decay=0.9999, wall=17276
2022-10-10 21:39:57 - progress_bar.py[line:274] - INFO: epoch 008:    258 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.1, ups=0.8, wpb=112.4, bsz=40, num_updates=3140, lr=4.41444e-05, gnorm=0.631, clip=20, loss_scale=1024, train_wall=12, gb_free=10, ema_decay=0.9999, wall=17288
2022-10-10 21:40:10 - progress_bar.py[line:274] - INFO: epoch 008:    268 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.8, ups=0.82, wpb=110.4, bsz=40, num_updates=3150, lr=4.41191e-05, gnorm=0.605, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17300
2022-10-10 21:40:22 - progress_bar.py[line:274] - INFO: epoch 008:    278 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89, ups=0.79, wpb=112.1, bsz=40, num_updates=3160, lr=4.40939e-05, gnorm=0.433, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17313
2022-10-10 21:40:34 - progress_bar.py[line:274] - INFO: epoch 008:    288 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.8, ups=0.83, wpb=110.9, bsz=40, num_updates=3170, lr=4.40686e-05, gnorm=0.594, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17325
2022-10-10 21:40:47 - progress_bar.py[line:274] - INFO: epoch 008:    298 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.6, ups=0.81, wpb=112.1, bsz=40, num_updates=3180, lr=4.40433e-05, gnorm=0.517, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17337
2022-10-10 21:40:59 - progress_bar.py[line:274] - INFO: epoch 008:    308 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.6, ups=0.8, wpb=111.5, bsz=40, num_updates=3190, lr=4.4018e-05, gnorm=0.517, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17350
2022-10-10 21:41:12 - progress_bar.py[line:274] - INFO: epoch 008:    318 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.9, ups=0.77, wpb=110.7, bsz=40, num_updates=3200, lr=4.39927e-05, gnorm=0.421, clip=0, loss_scale=1024, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=17363
2022-10-10 21:41:25 - progress_bar.py[line:274] - INFO: epoch 008:    328 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.6, ups=0.81, wpb=112.4, bsz=40, num_updates=3210, lr=4.39674e-05, gnorm=0.506, clip=10, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17375
2022-10-10 21:41:37 - progress_bar.py[line:274] - INFO: epoch 008:    338 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.5, ups=0.82, wpb=111.1, bsz=40, num_updates=3220, lr=4.39422e-05, gnorm=0.442, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17387
2022-10-10 21:41:49 - progress_bar.py[line:274] - INFO: epoch 008:    348 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.4, ups=0.82, wpb=111, bsz=40, num_updates=3230, lr=4.39169e-05, gnorm=0.742, clip=20, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=17400
2022-10-10 21:41:51 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 21:42:03 - progress_bar.py[line:274] - INFO: epoch 008:    359 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=80.6, ups=0.73, wpb=110.1, bsz=40, num_updates=3240, lr=4.38916e-05, gnorm=0.549, clip=10, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=17413
2022-10-10 21:42:15 - progress_bar.py[line:274] - INFO: epoch 008:    369 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.4, ups=0.79, wpb=110.1, bsz=40, num_updates=3250, lr=4.38663e-05, gnorm=0.701, clip=30, loss_scale=512, train_wall=13, gb_free=10.4, ema_decay=0.9999, wall=17426
2022-10-10 21:42:27 - progress_bar.py[line:274] - INFO: epoch 008:    379 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.8, ups=0.81, wpb=111.6, bsz=40, num_updates=3260, lr=4.3841e-05, gnorm=0.529, clip=20, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=17438
2022-10-10 21:42:40 - progress_bar.py[line:274] - INFO: epoch 008:    389 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=87.9, ups=0.79, wpb=111, bsz=40, num_updates=3270, lr=4.38157e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=17451
2022-10-10 21:42:52 - progress_bar.py[line:274] - INFO: epoch 008:    399 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=92.8, ups=0.83, wpb=112, bsz=40, num_updates=3280, lr=4.37905e-05, gnorm=0.551, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17463
2022-10-10 21:43:05 - progress_bar.py[line:274] - INFO: epoch 008:    409 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88, ups=0.79, wpb=111.6, bsz=40, num_updates=3290, lr=4.37652e-05, gnorm=0.615, clip=20, loss_scale=512, train_wall=13, gb_free=11, ema_decay=0.9999, wall=17475
2022-10-10 21:43:08 - train.py[line:339] - INFO: end of epoch 8 (average epoch stats below)
2022-10-10 21:43:08 - progress_bar.py[line:282] - INFO: epoch 008 | loss 0.245 | loss_v1 0 | loss_v2 0 | nll_loss 0.06 | ntokens 111.119 | nsentences 40 | sample_size 111.119 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 9.3 | ups 0.08 | wpb 111.1 | bsz 40 | num_updates 3293 | lr 4.37576e-05 | gnorm 0.593 | clip 16.8 | loss_scale 512 | train_wall 509 | gb_free 10.6 | ema_decay 0.9999 | wall 17479
2022-10-10 21:43:08 - trainer.py[line:643] - INFO: loading train data for epoch 9
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv slice_id 1 row count 8240 total row count 16480
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E8.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 21:43:08 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 21:43:09 - trainer.py[line:707] - INFO: begin training epoch 9
2022-10-10 21:43:09 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 21:43:20 - progress_bar.py[line:274] - INFO: epoch 009:      7 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=72.6, ups=0.64, wpb=112.6, bsz=40, num_updates=3300, lr=4.37399e-05, gnorm=0.327, clip=0, loss_scale=512, train_wall=13, gb_free=9.9, ema_decay=0.9999, wall=17491
2022-10-10 21:43:33 - progress_bar.py[line:274] - INFO: epoch 009:     17 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.8, wpb=110.8, bsz=40, num_updates=3310, lr=4.37146e-05, gnorm=0.668, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17503
2022-10-10 21:43:45 - progress_bar.py[line:274] - INFO: epoch 009:     27 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=94.1, ups=0.84, wpb=111.8, bsz=40, num_updates=3320, lr=4.36893e-05, gnorm=0.376, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17515
2022-10-10 21:43:57 - progress_bar.py[line:274] - INFO: epoch 009:     37 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.5, ups=0.8, wpb=112.7, bsz=40, num_updates=3330, lr=4.3664e-05, gnorm=0.454, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17528
2022-10-10 21:44:10 - progress_bar.py[line:274] - INFO: epoch 009:     47 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.8, ups=0.79, wpb=111.9, bsz=40, num_updates=3340, lr=4.36388e-05, gnorm=0.363, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17540
2022-10-10 21:44:23 - progress_bar.py[line:274] - INFO: epoch 009:     57 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.6, ups=0.77, wpb=110.9, bsz=40, num_updates=3350, lr=4.36135e-05, gnorm=0.454, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=17553
2022-10-10 21:44:35 - progress_bar.py[line:274] - INFO: epoch 009:     67 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.9, ups=0.82, wpb=111.4, bsz=40, num_updates=3360, lr=4.35882e-05, gnorm=0.404, clip=0, loss_scale=512, train_wall=12, gb_free=10, ema_decay=0.9999, wall=17566
2022-10-10 21:44:47 - progress_bar.py[line:274] - INFO: epoch 009:     77 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.4, ups=0.82, wpb=110.9, bsz=40, num_updates=3370, lr=4.35629e-05, gnorm=0.521, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17578
2022-10-10 21:45:00 - progress_bar.py[line:274] - INFO: epoch 009:     87 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.5, ups=0.8, wpb=111.7, bsz=40, num_updates=3380, lr=4.35376e-05, gnorm=0.428, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=17590
2022-10-10 21:45:12 - progress_bar.py[line:274] - INFO: epoch 009:     97 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.79, wpb=111.9, bsz=40, num_updates=3390, lr=4.35123e-05, gnorm=0.474, clip=10, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=17603
2022-10-10 21:45:24 - progress_bar.py[line:274] - INFO: epoch 009:    107 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=93, ups=0.83, wpb=112.3, bsz=40, num_updates=3400, lr=4.34871e-05, gnorm=0.361, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17615
2022-10-10 21:45:37 - progress_bar.py[line:274] - INFO: epoch 009:    117 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.7, ups=0.82, wpb=110, bsz=40, num_updates=3410, lr=4.34618e-05, gnorm=0.417, clip=10, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=17627
2022-10-10 21:45:49 - progress_bar.py[line:274] - INFO: epoch 009:    127 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.4, ups=0.82, wpb=110.6, bsz=40, num_updates=3420, lr=4.34365e-05, gnorm=0.519, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17640
2022-10-10 21:46:02 - progress_bar.py[line:274] - INFO: epoch 009:    137 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.8, ups=0.78, wpb=112.2, bsz=40, num_updates=3430, lr=4.34112e-05, gnorm=0.577, clip=20, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=17652
2022-10-10 21:46:14 - progress_bar.py[line:274] - INFO: epoch 009:    147 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=95.3, ups=0.85, wpb=112.3, bsz=40, num_updates=3440, lr=4.33859e-05, gnorm=0.408, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17664
2022-10-10 21:46:26 - progress_bar.py[line:274] - INFO: epoch 009:    157 / 412 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=92.3, ups=0.84, wpb=110.3, bsz=40, num_updates=3450, lr=4.33606e-05, gnorm=0.753, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17676
2022-10-10 21:46:38 - progress_bar.py[line:274] - INFO: epoch 009:    167 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.8, wpb=110.4, bsz=40, num_updates=3460, lr=4.33354e-05, gnorm=0.349, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17689
2022-10-10 21:46:50 - progress_bar.py[line:274] - INFO: epoch 009:    177 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.8, ups=0.8, wpb=111.7, bsz=40, num_updates=3470, lr=4.33101e-05, gnorm=0.634, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17701
2022-10-10 21:47:02 - progress_bar.py[line:274] - INFO: epoch 009:    187 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.4, ups=0.86, wpb=112.7, bsz=40, num_updates=3480, lr=4.32848e-05, gnorm=0.461, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17713
2022-10-10 21:47:14 - progress_bar.py[line:274] - INFO: epoch 009:    197 / 412 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.084, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=90.1, ups=0.81, wpb=111.1, bsz=40, num_updates=3490, lr=4.32595e-05, gnorm=0.655, clip=30, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=17725
2022-10-10 21:47:27 - progress_bar.py[line:274] - INFO: epoch 009:    207 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.7, ups=0.81, wpb=111, bsz=40, num_updates=3500, lr=4.32342e-05, gnorm=0.593, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17737
2022-10-10 21:47:39 - progress_bar.py[line:274] - INFO: epoch 009:    217 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.8, ups=0.8, wpb=110.5, bsz=40, num_updates=3510, lr=4.32089e-05, gnorm=0.218, clip=0, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=17750
2022-10-10 21:47:52 - progress_bar.py[line:274] - INFO: epoch 009:    227 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.8, wpb=110.5, bsz=40, num_updates=3520, lr=4.31837e-05, gnorm=0.502, clip=20, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=17762
2022-10-10 21:48:04 - progress_bar.py[line:274] - INFO: epoch 009:    237 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.1, ups=0.79, wpb=111.4, bsz=40, num_updates=3530, lr=4.31584e-05, gnorm=0.459, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=17775
2022-10-10 21:48:17 - progress_bar.py[line:274] - INFO: epoch 009:    247 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=91.6, ups=0.82, wpb=111.1, bsz=40, num_updates=3540, lr=4.31331e-05, gnorm=0.72, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17787
2022-10-10 21:48:29 - progress_bar.py[line:274] - INFO: epoch 009:    257 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.2, ups=0.78, wpb=110.1, bsz=40, num_updates=3550, lr=4.31078e-05, gnorm=0.392, clip=10, loss_scale=512, train_wall=13, gb_free=10, ema_decay=0.9999, wall=17800
2022-10-10 21:48:42 - progress_bar.py[line:274] - INFO: epoch 009:    267 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.9, ups=0.79, wpb=108.8, bsz=40, num_updates=3560, lr=4.30825e-05, gnorm=0.558, clip=10, loss_scale=512, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=17813
2022-10-10 21:48:54 - progress_bar.py[line:274] - INFO: epoch 009:    277 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90, ups=0.81, wpb=110.9, bsz=40, num_updates=3570, lr=4.30572e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=17825
2022-10-10 21:49:06 - progress_bar.py[line:274] - INFO: epoch 009:    287 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=94.5, ups=0.84, wpb=111.8, bsz=40, num_updates=3580, lr=4.3032e-05, gnorm=0.446, clip=0, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17837
2022-10-10 21:49:18 - progress_bar.py[line:274] - INFO: epoch 009:    297 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=94.2, ups=0.85, wpb=110.4, bsz=40, num_updates=3590, lr=4.30067e-05, gnorm=0.434, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17848
2022-10-10 21:49:30 - progress_bar.py[line:274] - INFO: epoch 009:    307 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.81, wpb=109.5, bsz=40, num_updates=3600, lr=4.29814e-05, gnorm=0.455, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17861
2022-10-10 21:49:43 - progress_bar.py[line:274] - INFO: epoch 009:    317 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.3, ups=0.8, wpb=109.8, bsz=40, num_updates=3610, lr=4.29561e-05, gnorm=0.401, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17873
2022-10-10 21:49:55 - progress_bar.py[line:274] - INFO: epoch 009:    327 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.9, ups=0.83, wpb=110, bsz=40, num_updates=3620, lr=4.29308e-05, gnorm=0.591, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17885
2022-10-10 21:50:07 - progress_bar.py[line:274] - INFO: epoch 009:    337 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=89.4, ups=0.8, wpb=111.5, bsz=40, num_updates=3630, lr=4.29055e-05, gnorm=0.717, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=17898
2022-10-10 21:50:20 - progress_bar.py[line:274] - INFO: epoch 009:    347 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.7, ups=0.8, wpb=110.6, bsz=40, num_updates=3640, lr=4.28803e-05, gnorm=0.203, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=17910
2022-10-10 21:50:32 - progress_bar.py[line:274] - INFO: epoch 009:    357 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.6, ups=0.8, wpb=111.2, bsz=40, num_updates=3650, lr=4.2855e-05, gnorm=0.484, clip=10, loss_scale=512, train_wall=12, gb_free=9.9, ema_decay=0.9999, wall=17923
2022-10-10 21:50:45 - progress_bar.py[line:274] - INFO: epoch 009:    367 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=84.9, ups=0.77, wpb=110.7, bsz=40, num_updates=3660, lr=4.28297e-05, gnorm=0.595, clip=20, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=17936
2022-10-10 21:50:58 - progress_bar.py[line:274] - INFO: epoch 009:    377 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=88.9, ups=0.8, wpb=111.2, bsz=40, num_updates=3670, lr=4.28044e-05, gnorm=0.553, clip=10, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=17948
2022-10-10 21:51:11 - progress_bar.py[line:274] - INFO: epoch 009:    387 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.3, ups=0.79, wpb=111.1, bsz=40, num_updates=3680, lr=4.27791e-05, gnorm=0.41, clip=0, loss_scale=512, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=17961
2022-10-10 21:51:23 - progress_bar.py[line:274] - INFO: epoch 009:    397 / 412 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=93.6, ups=0.83, wpb=112.7, bsz=40, num_updates=3690, lr=4.27538e-05, gnorm=0.412, clip=20, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=17973
2022-10-10 21:51:34 - progress_bar.py[line:274] - INFO: epoch 009:    407 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.2, ups=0.89, wpb=111.6, bsz=40, num_updates=3700, lr=4.27286e-05, gnorm=0.664, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=17984
2022-10-10 21:51:40 - train.py[line:339] - INFO: end of epoch 9 (average epoch stats below)
2022-10-10 21:51:40 - progress_bar.py[line:282] - INFO: epoch 009 | loss 0.244 | loss_v1 0 | loss_v2 0 | nll_loss 0.06 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 89.5 | ups 0.81 | wpb 111.1 | bsz 40 | num_updates 3705 | lr 4.27159e-05 | gnorm 0.486 | clip 10.7 | loss_scale 512 | train_wall 505 | gb_free 10.6 | ema_decay 0.9999 | wall 17990
2022-10-10 21:51:40 - trainer.py[line:643] - INFO: loading train data for epoch 10
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv slice_id 1 row count 8240 total row count 16480
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E9.tsv slice_id 0 row count 8240 total row count 16480
2022-10-10 21:51:40 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-10 21:51:40 - trainer.py[line:707] - INFO: begin training epoch 10
2022-10-10 21:51:40 - train.py[line:312] - INFO: Start iterating over samples
2022-10-10 21:51:50 - progress_bar.py[line:274] - INFO: epoch 010:      5 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=70.7, ups=0.63, wpb=111.6, bsz=40, num_updates=3710, lr=4.27033e-05, gnorm=0.443, clip=20, loss_scale=512, train_wall=14, gb_free=10.7, ema_decay=0.9999, wall=18000
2022-10-10 21:52:02 - progress_bar.py[line:274] - INFO: epoch 010:     15 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.4, ups=0.81, wpb=112.4, bsz=40, num_updates=3720, lr=4.2678e-05, gnorm=0.471, clip=20, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18013
2022-10-10 21:52:15 - progress_bar.py[line:274] - INFO: epoch 010:     25 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=83.4, ups=0.76, wpb=110.3, bsz=40, num_updates=3730, lr=4.26527e-05, gnorm=0.42, clip=0, loss_scale=512, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18026
2022-10-10 21:52:28 - progress_bar.py[line:274] - INFO: epoch 010:     35 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.4, ups=0.8, wpb=111.6, bsz=40, num_updates=3740, lr=4.26274e-05, gnorm=0.576, clip=20, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18038
2022-10-10 21:52:40 - progress_bar.py[line:274] - INFO: epoch 010:     45 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90, ups=0.82, wpb=110.2, bsz=40, num_updates=3750, lr=4.26021e-05, gnorm=0.348, clip=0, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18051
2022-10-10 21:52:53 - progress_bar.py[line:274] - INFO: epoch 010:     55 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.8, ups=0.78, wpb=110.9, bsz=40, num_updates=3760, lr=4.25769e-05, gnorm=0.776, clip=20, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18063
2022-10-10 21:53:05 - progress_bar.py[line:274] - INFO: epoch 010:     65 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.9, ups=0.78, wpb=109.6, bsz=40, num_updates=3770, lr=4.25516e-05, gnorm=0.682, clip=40, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18076
2022-10-10 21:53:18 - progress_bar.py[line:274] - INFO: epoch 010:     75 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.5, ups=0.8, wpb=110.5, bsz=40, num_updates=3780, lr=4.25263e-05, gnorm=0.594, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18089
2022-10-10 21:53:30 - progress_bar.py[line:274] - INFO: epoch 010:     85 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.8, ups=0.81, wpb=110.5, bsz=40, num_updates=3790, lr=4.2501e-05, gnorm=0.546, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18101
2022-10-10 21:53:43 - progress_bar.py[line:274] - INFO: epoch 010:     95 / 412 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=85.4, ups=0.78, wpb=109.9, bsz=40, num_updates=3800, lr=4.24757e-05, gnorm=0.696, clip=30, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=18114
2022-10-10 21:53:55 - progress_bar.py[line:274] - INFO: epoch 010:    105 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=90.7, ups=0.82, wpb=110.9, bsz=40, num_updates=3810, lr=4.24504e-05, gnorm=0.431, clip=10, loss_scale=1024, train_wall=12, gb_free=10, ema_decay=0.9999, wall=18126
2022-10-10 21:54:08 - progress_bar.py[line:274] - INFO: epoch 010:    115 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=91.4, ups=0.81, wpb=112.4, bsz=40, num_updates=3820, lr=4.24252e-05, gnorm=0.491, clip=10, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18138
2022-10-10 21:54:21 - progress_bar.py[line:274] - INFO: epoch 010:    125 / 412 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=85.6, ups=0.78, wpb=109.5, bsz=40, num_updates=3830, lr=4.23999e-05, gnorm=0.587, clip=10, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18151
2022-10-10 21:54:33 - progress_bar.py[line:274] - INFO: epoch 010:    135 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89.3, ups=0.8, wpb=111.6, bsz=40, num_updates=3840, lr=4.23746e-05, gnorm=0.71, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18164
2022-10-10 21:54:46 - progress_bar.py[line:274] - INFO: epoch 010:    145 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=89, ups=0.79, wpb=112.6, bsz=40, num_updates=3850, lr=4.23493e-05, gnorm=0.305, clip=10, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=18176
2022-10-10 21:54:58 - progress_bar.py[line:274] - INFO: epoch 010:    155 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.5, ups=0.8, wpb=111.1, bsz=40, num_updates=3860, lr=4.2324e-05, gnorm=0.482, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18189
2022-10-10 21:55:11 - progress_bar.py[line:274] - INFO: epoch 010:    165 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.2, ups=0.81, wpb=111.6, bsz=40, num_updates=3870, lr=4.22987e-05, gnorm=0.83, clip=30, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18201
2022-10-10 21:55:23 - progress_bar.py[line:274] - INFO: epoch 010:    175 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.9, ups=0.79, wpb=111.7, bsz=40, num_updates=3880, lr=4.22735e-05, gnorm=0.572, clip=10, loss_scale=1024, train_wall=13, gb_free=10.6, ema_decay=0.9999, wall=18214
2022-10-10 21:55:36 - progress_bar.py[line:274] - INFO: epoch 010:    185 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=86.8, ups=0.78, wpb=110.7, bsz=40, num_updates=3890, lr=4.22482e-05, gnorm=0.539, clip=10, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=18227
2022-10-10 21:55:49 - progress_bar.py[line:274] - INFO: epoch 010:    195 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.9, ups=0.78, wpb=111.4, bsz=40, num_updates=3900, lr=4.22229e-05, gnorm=0.499, clip=20, loss_scale=1024, train_wall=13, gb_free=10.9, ema_decay=0.9999, wall=18240
2022-10-10 21:56:02 - progress_bar.py[line:274] - INFO: epoch 010:    205 / 412 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=87, ups=0.78, wpb=111.4, bsz=40, num_updates=3910, lr=4.21976e-05, gnorm=0.335, clip=0, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18252
2022-10-10 21:56:15 - progress_bar.py[line:274] - INFO: epoch 010:    215 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.7, ups=0.78, wpb=111.4, bsz=40, num_updates=3920, lr=4.21723e-05, gnorm=0.515, clip=10, loss_scale=1024, train_wall=13, gb_free=10.8, ema_decay=0.9999, wall=18265
2022-10-10 21:56:27 - progress_bar.py[line:274] - INFO: epoch 010:    225 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=87.5, ups=0.8, wpb=109.6, bsz=40, num_updates=3930, lr=4.2147e-05, gnorm=0.37, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18278
2022-10-10 21:56:40 - progress_bar.py[line:274] - INFO: epoch 010:    235 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=88.5, ups=0.79, wpb=111.7, bsz=40, num_updates=3940, lr=4.21218e-05, gnorm=0.532, clip=20, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18290
2022-10-10 21:56:52 - progress_bar.py[line:274] - INFO: epoch 010:    245 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=88.8, ups=0.8, wpb=111, bsz=40, num_updates=3950, lr=4.20965e-05, gnorm=0.542, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18303
2022-10-10 21:57:05 - progress_bar.py[line:274] - INFO: epoch 010:    255 / 412 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90.3, ups=0.81, wpb=111.8, bsz=40, num_updates=3960, lr=4.20712e-05, gnorm=0.7, clip=20, loss_scale=1024, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=18315
2022-10-10 21:57:17 - progress_bar.py[line:274] - INFO: epoch 010:    265 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=90, ups=0.8, wpb=112.2, bsz=40, num_updates=3970, lr=4.20459e-05, gnorm=0.557, clip=20, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=18328
2022-10-10 21:57:29 - progress_bar.py[line:274] - INFO: epoch 010:    275 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=92, ups=0.84, wpb=109.6, bsz=40, num_updates=3980, lr=4.20206e-05, gnorm=0.527, clip=10, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18340
2022-10-10 21:57:42 - progress_bar.py[line:274] - INFO: epoch 010:    285 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=86.2, ups=0.78, wpb=110.3, bsz=40, num_updates=3990, lr=4.19953e-05, gnorm=0.316, clip=10, loss_scale=1024, train_wall=13, gb_free=10.7, ema_decay=0.9999, wall=18353
2022-10-10 21:57:54 - progress_bar.py[line:274] - INFO: epoch 010:    295 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.046, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=89.5, ups=0.8, wpb=111.8, bsz=40, num_updates=4000, lr=4.19701e-05, gnorm=0.461, clip=20, loss_scale=1024, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=18365
2022-10-10 21:57:54 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 21:57:56 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 21:57:56 - train.py[line:551] - INFO: load:1.25 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 21:57:57 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.14 GiB (GPU 1; 39.59 GiB total capacity; 8.85 GiB already allocated; 5.46 GiB free; 29.47 GiB reserved in total by PyTorch)
2022-10-10 21:57:57 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-10 21:57:57 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 19        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9064 MB |   10289 MB |    2300 TB |    2299 TB |
|       from large pool |    8919 MB |   10144 MB |    2299 TB |    2299 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9064 MB |   10289 MB |    2300 TB |    2299 TB |
|       from large pool |    8919 MB |   10144 MB |    2299 TB |    2299 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   30178 MB |   32100 MB |  210194 MB |  180016 MB |
|       from large pool |   30032 MB |   31954 MB |  209840 MB |  179808 MB |
|       from small pool |     146 MB |     146 MB |     354 MB |     208 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   21113 MB |   25008 MB |    2315 TB |    2315 TB |
|       from large pool |   21112 MB |   25006 MB |    2314 TB |    2314 TB |
|       from small pool |       1 MB |       1 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3658    |    3672    |  104843 K  |  104839 K  |
|       from large pool |     563    |     575    |   34397 K  |   34396 K  |
|       from small pool |    3095    |    3114    |   70446 K  |   70442 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3658    |    3672    |  104843 K  |  104839 K  |
|       from large pool |     563    |     575    |   34397 K  |   34396 K  |
|       from small pool |    3095    |    3114    |   70446 K  |   70442 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     170    |     179    |     621    |     451    |
|       from large pool |      97    |     106    |     444    |     347    |
|       from small pool |      73    |      73    |     177    |     104    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     106    |     111    |   75766 K  |   75766 K  |
|       from large pool |      70    |      75    |   15157 K  |   15157 K  |
|       from small pool |      36    |      43    |   60609 K  |   60609 K  |
|===========================================================================|

2022-10-10 21:57:57 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-10 22:00:58 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 22:00:58 - train.py[line:551] - INFO: load:1.29 valid_run:182.12 task_valid:171.48 collect_output:8.42
2022-10-10 22:03:52 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 22:03:52 - train.py[line:551] - INFO: load:1.40 valid_run:355.33 task_valid:333.11 collect_output:17.70
2022-10-10 22:06:48 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 22:06:48 - train.py[line:551] - INFO: load:1.44 valid_run:531.10 task_valid:495.07 collect_output:29.49
2022-10-10 22:09:40 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 22:09:40 - train.py[line:551] - INFO: load:1.49 valid_run:703.84 task_valid:657.84 collect_output:37.29
2022-10-10 22:12:38 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 22:12:38 - train.py[line:551] - INFO: load:1.52 valid_run:881.86 task_valid:825.09 collect_output:45.73
2022-10-10 22:15:36 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 22:15:36 - train.py[line:551] - INFO: load:1.57 valid_run:1059.35 task_valid:990.70 collect_output:55.59
2022-10-10 22:18:37 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 22:18:37 - train.py[line:551] - INFO: load:1.61 valid_run:1239.95 task_valid:1157.08 collect_output:67.83
2022-10-10 22:21:36 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 22:21:36 - train.py[line:551] - INFO: load:1.66 valid_run:1418.99 task_valid:1320.75 collect_output:81.09
2022-10-10 22:24:35 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 22:24:35 - train.py[line:551] - INFO: load:1.70 valid_run:1597.96 task_valid:1487.80 collect_output:90.70
2022-10-10 22:27:27 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 22:27:27 - train.py[line:551] - INFO: load:1.74 valid_run:1769.67 task_valid:1649.18 collect_output:99.12
2022-10-10 22:30:20 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 22:30:20 - train.py[line:551] - INFO: load:1.78 valid_run:1943.19 task_valid:1812.00 collect_output:107.76
2022-10-10 22:33:23 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 22:33:23 - train.py[line:551] - INFO: load:1.83 valid_run:2125.72 task_valid:1983.37 collect_output:116.80
2022-10-10 22:36:21 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 22:36:21 - train.py[line:551] - INFO: load:1.90 valid_run:2303.58 task_valid:2146.59 collect_output:129.38
2022-10-10 22:39:21 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 22:39:21 - train.py[line:551] - INFO: load:1.96 valid_run:2482.98 task_valid:2316.61 collect_output:136.25
2022-10-10 22:42:20 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 22:42:20 - train.py[line:551] - INFO: load:2.02 valid_run:2662.13 task_valid:2486.29 collect_output:143.61
2022-10-10 22:45:21 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 22:45:21 - train.py[line:551] - INFO: load:2.09 valid_run:2842.83 task_valid:2653.76 collect_output:154.69
2022-10-10 22:47:58 - train.py[line:549] - INFO: 3400 / 4988
2022-10-10 22:47:58 - train.py[line:551] - INFO: load:2.12 valid_run:2999.69 task_valid:2803.01 collect_output:160.79
2022-10-10 22:50:29 - train.py[line:549] - INFO: 3600 / 4988
2022-10-10 22:50:29 - train.py[line:551] - INFO: load:2.15 valid_run:3151.29 task_valid:2950.45 collect_output:163.80
2022-10-10 22:52:59 - train.py[line:549] - INFO: 3800 / 4988
2022-10-10 22:52:59 - train.py[line:551] - INFO: load:2.18 valid_run:3301.17 task_valid:3092.32 collect_output:170.67
2022-10-10 22:55:31 - train.py[line:549] - INFO: 4000 / 4988
2022-10-10 22:55:31 - train.py[line:551] - INFO: load:2.21 valid_run:3452.69 task_valid:3237.63 collect_output:175.80
2022-10-10 22:58:04 - train.py[line:549] - INFO: 4200 / 4988
2022-10-10 22:58:04 - train.py[line:551] - INFO: load:2.24 valid_run:3605.67 task_valid:3382.38 collect_output:182.92
2022-10-10 23:00:34 - train.py[line:549] - INFO: 4400 / 4988
2022-10-10 23:00:34 - train.py[line:551] - INFO: load:2.27 valid_run:3755.44 task_valid:3526.93 collect_output:187.09
2022-10-10 23:03:05 - train.py[line:549] - INFO: 4600 / 4988
2022-10-10 23:03:05 - train.py[line:551] - INFO: load:2.30 valid_run:3907.02 task_valid:3672.84 collect_output:191.71
2022-10-10 23:05:37 - train.py[line:549] - INFO: 4800 / 4988
2022-10-10 23:05:37 - train.py[line:551] - INFO: load:2.32 valid_run:4058.57 task_valid:3819.15 collect_output:195.92

====================================================================================================
SGG eval:     R @ 50: 0.6663;     R @ 100: 0.6936;     R @ 500: 0.7176;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4644;    mR @ 100: 0.4977;    mR @ 500: 0.5527;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.7647) (flying in:0.5909) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9441) (says:0.0000) (sitting on:0.7299) (standing on:0.4893) (using:0.6000) (walking in:0.0000) (walking on:0.6216) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 23:08:08 - train.py[line:487] - INFO: 0.6936437484084542

====================================================================================================
SGG eval:     R @ 50: 0.6663;     R @ 100: 0.6936;     R @ 500: 0.7176;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4644;    mR @ 100: 0.4977;    mR @ 500: 0.5527;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.7647) (flying in:0.5909) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9441) (says:0.0000) (sitting on:0.7299) (standing on:0.4893) (using:0.6000) (walking in:0.0000) (walking on:0.6216) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-10 23:08:08 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-10 23:08:08 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 0.234 | loss_v1 0 | loss_v2 0 | nll_loss 0.058 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.693644 | ppl 1.04 | vqa_score 0.5225 | wps 106.5 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.701241
2022-10-10 23:08:08 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 4000 updates
2022-10-10 23:08:08 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_10_4000.pt
2022-10-10 23:08:16 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_10_4000.pt
2022-10-10 23:08:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_10_4000.pt (epoch 10 @ 4000 updates, score 0.6936437484084542) (writing took 10.147933048196137 seconds)
2022-10-10 23:08:30 - progress_bar.py[line:274] - INFO: epoch 010:    305 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=0.3, ups=0, wpb=111.2, bsz=40, num_updates=4010, lr=4.19448e-05, gnorm=0.35, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22600
2022-10-10 23:08:40 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-10 23:08:41 - progress_bar.py[line:274] - INFO: epoch 010:    316 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=94.2, ups=0.85, wpb=110.8, bsz=40, num_updates=4020, lr=4.19195e-05, gnorm=0.362, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=22612
2022-10-10 23:08:53 - progress_bar.py[line:274] - INFO: epoch 010:    326 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=111.6, bsz=40, num_updates=4030, lr=4.18942e-05, gnorm=0.387, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=22623
2022-10-10 23:09:04 - progress_bar.py[line:274] - INFO: epoch 010:    336 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.89, wpb=111.5, bsz=40, num_updates=4040, lr=4.18689e-05, gnorm=0.587, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22635
2022-10-10 23:09:15 - progress_bar.py[line:274] - INFO: epoch 010:    346 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.6, ups=0.91, wpb=111.6, bsz=40, num_updates=4050, lr=4.18436e-05, gnorm=0.359, clip=0, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=22646
2022-10-10 23:09:26 - progress_bar.py[line:274] - INFO: epoch 010:    356 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.9, ups=0.88, wpb=112.3, bsz=40, num_updates=4060, lr=4.18184e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22657
2022-10-10 23:09:38 - progress_bar.py[line:274] - INFO: epoch 010:    366 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.9, wpb=111.5, bsz=40, num_updates=4070, lr=4.17931e-05, gnorm=0.366, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22668
2022-10-10 23:09:49 - progress_bar.py[line:274] - INFO: epoch 010:    376 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=4080, lr=4.17678e-05, gnorm=0.366, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22680
2022-10-10 23:10:00 - progress_bar.py[line:274] - INFO: epoch 010:    386 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.8, ups=0.92, wpb=111.8, bsz=40, num_updates=4090, lr=4.17425e-05, gnorm=0.52, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=22690
2022-10-10 23:10:11 - progress_bar.py[line:274] - INFO: epoch 010:    396 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.5, ups=0.92, wpb=112.4, bsz=40, num_updates=4100, lr=4.17172e-05, gnorm=0.645, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=22701
2022-10-10 23:10:22 - progress_bar.py[line:274] - INFO: epoch 010:    406 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.89, wpb=110.5, bsz=40, num_updates=4110, lr=4.16919e-05, gnorm=0.455, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=22713
2022-10-10 23:10:29 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-10 23:10:30 - train.py[line:549] - INFO: 0 / 4988
2022-10-10 23:10:30 - train.py[line:551] - INFO: load:0.92 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-10 23:13:02 - train.py[line:549] - INFO: 200 / 4988
2022-10-10 23:13:02 - train.py[line:551] - INFO: load:0.94 valid_run:152.57 task_valid:148.27 collect_output:3.21
2022-10-10 23:15:31 - train.py[line:549] - INFO: 400 / 4988
2022-10-10 23:15:31 - train.py[line:551] - INFO: load:0.97 valid_run:301.22 task_valid:290.93 collect_output:8.13
2022-10-10 23:18:05 - train.py[line:549] - INFO: 600 / 4988
2022-10-10 23:18:05 - train.py[line:551] - INFO: load:0.99 valid_run:454.72 task_valid:433.76 collect_output:17.77
2022-10-10 23:20:34 - train.py[line:549] - INFO: 800 / 4988
2022-10-10 23:20:34 - train.py[line:551] - INFO: load:1.02 valid_run:603.89 task_valid:578.44 collect_output:21.23
2022-10-10 23:23:07 - train.py[line:549] - INFO: 1000 / 4988
2022-10-10 23:23:07 - train.py[line:551] - INFO: load:1.05 valid_run:756.35 task_valid:725.84 collect_output:25.26
2022-10-10 23:25:38 - train.py[line:549] - INFO: 1200 / 4988
2022-10-10 23:25:38 - train.py[line:551] - INFO: load:1.08 valid_run:907.95 task_valid:870.77 collect_output:30.95
2022-10-10 23:28:12 - train.py[line:549] - INFO: 1400 / 4988
2022-10-10 23:28:12 - train.py[line:551] - INFO: load:1.10 valid_run:1061.47 task_valid:1015.92 collect_output:38.31
2022-10-10 23:30:43 - train.py[line:549] - INFO: 1600 / 4988
2022-10-10 23:30:43 - train.py[line:551] - INFO: load:1.13 valid_run:1212.84 task_valid:1156.24 collect_output:48.34
2022-10-10 23:33:13 - train.py[line:549] - INFO: 1800 / 4988
2022-10-10 23:33:13 - train.py[line:551] - INFO: load:1.15 valid_run:1362.53 task_valid:1300.57 collect_output:52.70
2022-10-10 23:35:42 - train.py[line:549] - INFO: 2000 / 4988
2022-10-10 23:35:42 - train.py[line:551] - INFO: load:1.18 valid_run:1511.06 task_valid:1443.13 collect_output:57.67
2022-10-10 23:38:11 - train.py[line:549] - INFO: 2200 / 4988
2022-10-10 23:38:11 - train.py[line:551] - INFO: load:1.20 valid_run:1660.74 task_valid:1587.40 collect_output:62.06
2022-10-10 23:40:41 - train.py[line:549] - INFO: 2400 / 4988
2022-10-10 23:40:41 - train.py[line:551] - INFO: load:1.23 valid_run:1810.66 task_valid:1731.91 collect_output:66.46
2022-10-10 23:43:12 - train.py[line:549] - INFO: 2600 / 4988
2022-10-10 23:43:12 - train.py[line:551] - INFO: load:1.25 valid_run:1961.04 task_valid:1873.38 collect_output:74.31
2022-10-10 23:45:43 - train.py[line:549] - INFO: 2800 / 4988
2022-10-10 23:45:43 - train.py[line:551] - INFO: load:1.28 valid_run:2112.29 task_valid:2018.77 collect_output:79.10
2022-10-10 23:48:14 - train.py[line:549] - INFO: 3000 / 4988
2022-10-10 23:48:14 - train.py[line:551] - INFO: load:1.30 valid_run:2263.07 task_valid:2165.25 collect_output:82.34
2022-10-10 23:50:45 - train.py[line:549] - INFO: 3200 / 4988
2022-10-10 23:50:45 - train.py[line:551] - INFO: load:1.33 valid_run:2413.93 task_valid:2309.40 collect_output:87.96
2022-10-10 23:53:17 - train.py[line:549] - INFO: 3400 / 4988
2022-10-10 23:53:17 - train.py[line:551] - INFO: load:1.36 valid_run:2566.41 task_valid:2454.91 collect_output:93.82
2022-10-10 23:55:49 - train.py[line:549] - INFO: 3600 / 4988
2022-10-10 23:55:49 - train.py[line:551] - INFO: load:1.38 valid_run:2717.70 task_valid:2602.09 collect_output:96.81
2022-10-10 23:58:18 - train.py[line:549] - INFO: 3800 / 4988
2022-10-10 23:58:18 - train.py[line:551] - INFO: load:1.41 valid_run:2867.39 task_valid:2743.91 collect_output:103.57
2022-10-11 00:00:50 - train.py[line:549] - INFO: 4000 / 4988
2022-10-11 00:00:50 - train.py[line:551] - INFO: load:1.44 valid_run:3018.44 task_valid:2889.10 collect_output:108.34
2022-10-11 00:03:23 - train.py[line:549] - INFO: 4200 / 4988
2022-10-11 00:03:23 - train.py[line:551] - INFO: load:1.47 valid_run:3171.46 task_valid:3033.79 collect_output:115.56
2022-10-11 00:05:52 - train.py[line:549] - INFO: 4400 / 4988
2022-10-11 00:05:52 - train.py[line:551] - INFO: load:1.49 valid_run:3320.83 task_valid:3177.80 collect_output:119.92
2022-10-11 00:08:23 - train.py[line:549] - INFO: 4600 / 4988
2022-10-11 00:08:23 - train.py[line:551] - INFO: load:1.52 valid_run:3471.89 task_valid:3323.28 collect_output:124.48
2022-10-11 00:10:55 - train.py[line:549] - INFO: 4800 / 4988
2022-10-11 00:10:55 - train.py[line:551] - INFO: load:1.54 valid_run:3623.23 task_valid:3469.34 collect_output:128.73

====================================================================================================
SGG eval:     R @ 50: 0.6656;     R @ 100: 0.6938;     R @ 500: 0.7176;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4632;    mR @ 100: 0.5000;    mR @ 500: 0.5527;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.7647) (flying in:0.6364) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9441) (says:0.0000) (sitting on:0.7299) (standing on:0.4893) (using:0.6000) (walking in:0.0000) (walking on:0.6216) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-11 00:13:25 - train.py[line:487] - INFO: 0.6938255665902725
2022-10-11 00:13:25 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-11 00:13:25 - progress_bar.py[line:282] - INFO: epoch 010 | valid on 'valid' subset | loss 0.234 | loss_v1 0 | loss_v2 0 | nll_loss 0.064 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.693826 | ppl 1.05 | vqa_score 0.518 | wps 118.8 | wpb 89.9 | bsz 30 | num_updates 4116 | best_R@100 0.701241

====================================================================================================
SGG eval:     R @ 50: 0.6656;     R @ 100: 0.6938;     R @ 500: 0.7176;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4632;    mR @ 100: 0.5000;    mR @ 500: 0.5527;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.8171) (covered in:0.9375) (covering:0.3000) (eating:0.7647) (flying in:0.6364) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9441) (says:0.0000) (sitting on:0.7299) (standing on:0.4893) (using:0.6000) (walking in:0.0000) (walking on:0.6216) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-11 00:13:25 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 10 @ 4116 updates
2022-10-11 00:13:25 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint10.pt
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv slice_id 1 row count 8240 total row count 16480
2022-10-11 00:13:31 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint10.pt
2022-10-11 00:13:34 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint10.pt (epoch 10 @ 4116 updates, score 0.6938255665902725) (writing took 8.936659983824939 seconds)
2022-10-11 00:13:34 - train.py[line:339] - INFO: end of epoch 10 (average epoch stats below)
2022-10-11 00:13:34 - progress_bar.py[line:282] - INFO: epoch 010 | loss 0.243 | loss_v1 0 | loss_v2 0 | nll_loss 0.058 | ntokens 111.136 | nsentences 40 | sample_size 111.136 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 5.4 | ups 0.05 | wpb 111.1 | bsz 40 | num_updates 4116 | lr 4.16768e-05 | gnorm 0.506 | clip 12.7 | loss_scale 512 | train_wall 499 | gb_free 10.7 | ema_decay 0.9999 | wall 26505
2022-10-11 00:13:34 - trainer.py[line:643] - INFO: loading train data for epoch 11
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E10.tsv slice_id 0 row count 8240 total row count 16480
2022-10-11 00:13:34 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-11 00:13:35 - trainer.py[line:707] - INFO: begin training epoch 11
2022-10-11 00:13:35 - train.py[line:312] - INFO: Start iterating over samples
2022-10-11 00:13:41 - progress_bar.py[line:274] - INFO: epoch 011:      4 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=0.3, ups=0, wpb=110.3, bsz=40, num_updates=4120, lr=4.16667e-05, gnorm=0.541, clip=10, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=26511
2022-10-11 00:13:52 - progress_bar.py[line:274] - INFO: epoch 011:     14 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.88, wpb=112.9, bsz=40, num_updates=4130, lr=4.16414e-05, gnorm=0.863, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26522
2022-10-11 00:14:03 - progress_bar.py[line:274] - INFO: epoch 011:     24 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=4140, lr=4.16161e-05, gnorm=0.244, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26534
2022-10-11 00:14:14 - progress_bar.py[line:274] - INFO: epoch 011:     34 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.1, ups=0.89, wpb=111.5, bsz=40, num_updates=4150, lr=4.15908e-05, gnorm=0.482, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26545
2022-10-11 00:14:25 - progress_bar.py[line:274] - INFO: epoch 011:     44 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.4, ups=0.9, wpb=111.2, bsz=40, num_updates=4160, lr=4.15655e-05, gnorm=0.639, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26556
2022-10-11 00:14:36 - progress_bar.py[line:274] - INFO: epoch 011:     54 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.91, wpb=110.3, bsz=40, num_updates=4170, lr=4.15403e-05, gnorm=0.671, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26567
2022-10-11 00:14:47 - progress_bar.py[line:274] - INFO: epoch 011:     64 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.7, ups=0.93, wpb=110.2, bsz=40, num_updates=4180, lr=4.1515e-05, gnorm=0.464, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26578
2022-10-11 00:14:58 - progress_bar.py[line:274] - INFO: epoch 011:     74 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.1, ups=0.89, wpb=110.2, bsz=40, num_updates=4190, lr=4.14897e-05, gnorm=1.392, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26589
2022-10-11 00:15:09 - progress_bar.py[line:274] - INFO: epoch 011:     84 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.8, ups=0.91, wpb=112, bsz=40, num_updates=4200, lr=4.14644e-05, gnorm=0.423, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26600
2022-10-11 00:15:20 - progress_bar.py[line:274] - INFO: epoch 011:     94 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.91, wpb=111.9, bsz=40, num_updates=4210, lr=4.14391e-05, gnorm=0.248, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=26611
2022-10-11 00:15:32 - progress_bar.py[line:274] - INFO: epoch 011:    104 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=4220, lr=4.14138e-05, gnorm=0.479, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26622
2022-10-11 00:15:43 - progress_bar.py[line:274] - INFO: epoch 011:    114 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.8, ups=0.88, wpb=111.2, bsz=40, num_updates=4230, lr=4.13886e-05, gnorm=0.627, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=26633
2022-10-11 00:15:54 - progress_bar.py[line:274] - INFO: epoch 011:    124 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=4240, lr=4.13633e-05, gnorm=0.456, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26645
2022-10-11 00:16:05 - progress_bar.py[line:274] - INFO: epoch 011:    134 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=4250, lr=4.1338e-05, gnorm=0.349, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26656
2022-10-11 00:16:17 - progress_bar.py[line:274] - INFO: epoch 011:    144 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.87, wpb=111.7, bsz=40, num_updates=4260, lr=4.13127e-05, gnorm=0.271, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26668
2022-10-11 00:16:28 - progress_bar.py[line:274] - INFO: epoch 011:    154 / 412 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.8, ups=0.9, wpb=110.4, bsz=40, num_updates=4270, lr=4.12874e-05, gnorm=0.483, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=26679
2022-10-11 00:16:39 - progress_bar.py[line:274] - INFO: epoch 011:    164 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103, ups=0.92, wpb=112, bsz=40, num_updates=4280, lr=4.12621e-05, gnorm=0.907, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26690
2022-10-11 00:16:50 - progress_bar.py[line:274] - INFO: epoch 011:    174 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.91, wpb=111.7, bsz=40, num_updates=4290, lr=4.12369e-05, gnorm=0.711, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26701
2022-10-11 00:17:01 - progress_bar.py[line:274] - INFO: epoch 011:    184 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=113.2, nsentences=40, sample_size=113.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=102.8, ups=0.91, wpb=113.2, bsz=40, num_updates=4300, lr=4.12116e-05, gnorm=0.45, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26712
2022-10-11 00:17:12 - progress_bar.py[line:274] - INFO: epoch 011:    194 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.88, wpb=111.6, bsz=40, num_updates=4310, lr=4.11863e-05, gnorm=0.497, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26723
2022-10-11 00:17:23 - progress_bar.py[line:274] - INFO: epoch 011:    204 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.6, ups=0.9, wpb=112.3, bsz=40, num_updates=4320, lr=4.1161e-05, gnorm=0.346, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26734
2022-10-11 00:17:35 - progress_bar.py[line:274] - INFO: epoch 011:    214 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=4330, lr=4.11357e-05, gnorm=0.685, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26745
2022-10-11 00:17:46 - progress_bar.py[line:274] - INFO: epoch 011:    224 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.6, ups=0.91, wpb=111.1, bsz=40, num_updates=4340, lr=4.11104e-05, gnorm=0.603, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26756
2022-10-11 00:17:57 - progress_bar.py[line:274] - INFO: epoch 011:    234 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=4350, lr=4.10852e-05, gnorm=0.388, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=26768
2022-10-11 00:18:08 - progress_bar.py[line:274] - INFO: epoch 011:    244 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.1, ups=0.87, wpb=111.7, bsz=40, num_updates=4360, lr=4.10599e-05, gnorm=0.426, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=26779
2022-10-11 00:18:19 - progress_bar.py[line:274] - INFO: epoch 011:    254 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.92, wpb=109.9, bsz=40, num_updates=4370, lr=4.10346e-05, gnorm=0.449, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26790
2022-10-11 00:18:30 - progress_bar.py[line:274] - INFO: epoch 011:    264 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.9, wpb=111.6, bsz=40, num_updates=4380, lr=4.10093e-05, gnorm=0.584, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26801
2022-10-11 00:18:42 - progress_bar.py[line:274] - INFO: epoch 011:    274 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.88, wpb=111.8, bsz=40, num_updates=4390, lr=4.0984e-05, gnorm=0.604, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26812
2022-10-11 00:18:53 - progress_bar.py[line:274] - INFO: epoch 011:    284 / 412 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.4, ups=0.91, wpb=111.2, bsz=40, num_updates=4400, lr=4.09587e-05, gnorm=0.539, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26823
2022-10-11 00:19:04 - progress_bar.py[line:274] - INFO: epoch 011:    294 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.9, wpb=111.7, bsz=40, num_updates=4410, lr=4.09335e-05, gnorm=0.509, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26834
2022-10-11 00:19:15 - progress_bar.py[line:274] - INFO: epoch 011:    304 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=111.1, bsz=40, num_updates=4420, lr=4.09082e-05, gnorm=0.605, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26845
2022-10-11 00:19:26 - progress_bar.py[line:274] - INFO: epoch 011:    314 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.9, wpb=110.9, bsz=40, num_updates=4430, lr=4.08829e-05, gnorm=0.472, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26857
2022-10-11 00:19:37 - progress_bar.py[line:274] - INFO: epoch 011:    324 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.3, ups=0.87, wpb=110.2, bsz=40, num_updates=4440, lr=4.08576e-05, gnorm=0.527, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26868
2022-10-11 00:19:49 - progress_bar.py[line:274] - INFO: epoch 011:    334 / 412 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=97.5, ups=0.89, wpb=109.2, bsz=40, num_updates=4450, lr=4.08323e-05, gnorm=0.734, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26879
2022-10-11 00:20:00 - progress_bar.py[line:274] - INFO: epoch 011:    344 / 412 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.2, bsz=40, num_updates=4460, lr=4.0807e-05, gnorm=0.214, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=26890
2022-10-11 00:20:10 - progress_bar.py[line:274] - INFO: epoch 011:    354 / 412 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.042, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.5, ups=0.92, wpb=111.3, bsz=40, num_updates=4470, lr=4.07818e-05, gnorm=0.319, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26901
2022-10-11 00:20:22 - progress_bar.py[line:274] - INFO: epoch 011:    364 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=4480, lr=4.07565e-05, gnorm=0.78, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26912
2022-10-11 00:20:33 - progress_bar.py[line:274] - INFO: epoch 011:    374 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.88, wpb=110.9, bsz=40, num_updates=4490, lr=4.07312e-05, gnorm=0.538, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26924
2022-10-11 00:20:44 - progress_bar.py[line:274] - INFO: epoch 011:    384 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.91, wpb=110.8, bsz=40, num_updates=4500, lr=4.07059e-05, gnorm=0.752, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26935
2022-10-11 00:20:55 - progress_bar.py[line:274] - INFO: epoch 011:    394 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.5, ups=0.92, wpb=110.6, bsz=40, num_updates=4510, lr=4.06806e-05, gnorm=0.627, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26946
2022-10-11 00:21:06 - progress_bar.py[line:274] - INFO: epoch 011:    404 / 412 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=105.9, ups=0.95, wpb=111.9, bsz=40, num_updates=4520, lr=4.06553e-05, gnorm=0.292, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26956
2022-10-11 00:21:15 - train.py[line:339] - INFO: end of epoch 11 (average epoch stats below)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv slice_id 1 row count 8240 total row count 16480
2022-10-11 00:21:16 - progress_bar.py[line:282] - INFO: epoch 011 | loss 0.243 | loss_v1 0 | loss_v2 0 | nll_loss 0.058 | ntokens 111.126 | nsentences 40 | sample_size 111.126 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 99.4 | ups 0.89 | wpb 111.1 | bsz 40 | num_updates 4528 | lr 4.06351e-05 | gnorm 0.539 | clip 12.1 | loss_scale 512 | train_wall 457 | gb_free 10.4 | ema_decay 0.9999 | wall 26965
2022-10-11 00:21:16 - trainer.py[line:643] - INFO: loading train data for epoch 12
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E11.tsv slice_id 0 row count 8240 total row count 16480
2022-10-11 00:21:16 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-11 00:21:16 - trainer.py[line:707] - INFO: begin training epoch 12
2022-10-11 00:21:16 - train.py[line:312] - INFO: Start iterating over samples
2022-10-11 00:21:20 - progress_bar.py[line:274] - INFO: epoch 012:      2 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=77, ups=0.7, wpb=110.1, bsz=40, num_updates=4530, lr=4.06301e-05, gnorm=0.553, clip=20, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=26971
2022-10-11 00:21:31 - progress_bar.py[line:274] - INFO: epoch 012:     12 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=4540, lr=4.06048e-05, gnorm=0.335, clip=0, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=26982
2022-10-11 00:21:42 - progress_bar.py[line:274] - INFO: epoch 012:     22 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=110.6, bsz=40, num_updates=4550, lr=4.05795e-05, gnorm=0.417, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=26993
2022-10-11 00:21:54 - progress_bar.py[line:274] - INFO: epoch 012:     32 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.89, wpb=112.6, bsz=40, num_updates=4560, lr=4.05542e-05, gnorm=0.551, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27004
2022-10-11 00:22:05 - progress_bar.py[line:274] - INFO: epoch 012:     42 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=95.4, ups=0.86, wpb=110.4, bsz=40, num_updates=4570, lr=4.05289e-05, gnorm=0.221, clip=0, loss_scale=1024, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=27016
2022-10-11 00:22:16 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-11 00:22:17 - progress_bar.py[line:274] - INFO: epoch 012:     53 / 412 loss=0.23, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=90.7, ups=0.81, wpb=111.7, bsz=40, num_updates=4580, lr=4.05036e-05, gnorm=0.201, clip=0, loss_scale=512, train_wall=12, gb_free=10.4, ema_decay=0.9999, wall=27028
2022-10-11 00:22:29 - progress_bar.py[line:274] - INFO: epoch 012:     63 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.4, ups=0.89, wpb=111, bsz=40, num_updates=4590, lr=4.04784e-05, gnorm=0.68, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=27039
2022-10-11 00:22:40 - progress_bar.py[line:274] - INFO: epoch 012:     73 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101, ups=0.91, wpb=111.5, bsz=40, num_updates=4600, lr=4.04531e-05, gnorm=0.528, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27050
2022-10-11 00:22:51 - progress_bar.py[line:274] - INFO: epoch 012:     83 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.9, wpb=112.5, bsz=40, num_updates=4610, lr=4.04278e-05, gnorm=0.486, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27062
2022-10-11 00:23:02 - progress_bar.py[line:274] - INFO: epoch 012:     93 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.88, wpb=111.6, bsz=40, num_updates=4620, lr=4.04025e-05, gnorm=0.518, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27073
2022-10-11 00:23:14 - progress_bar.py[line:274] - INFO: epoch 012:    103 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.89, wpb=111, bsz=40, num_updates=4630, lr=4.03772e-05, gnorm=0.586, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=27084
2022-10-11 00:23:25 - progress_bar.py[line:274] - INFO: epoch 012:    113 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.9, wpb=110.4, bsz=40, num_updates=4640, lr=4.03519e-05, gnorm=0.572, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=27095
2022-10-11 00:23:36 - progress_bar.py[line:274] - INFO: epoch 012:    123 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=4650, lr=4.03267e-05, gnorm=0.496, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27107
2022-10-11 00:23:47 - progress_bar.py[line:274] - INFO: epoch 012:    133 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.4, ups=0.9, wpb=111.9, bsz=40, num_updates=4660, lr=4.03014e-05, gnorm=0.366, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27118
2022-10-11 00:23:58 - progress_bar.py[line:274] - INFO: epoch 012:    143 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=111, bsz=40, num_updates=4670, lr=4.02761e-05, gnorm=0.48, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27129
2022-10-11 00:24:10 - progress_bar.py[line:274] - INFO: epoch 012:    153 / 412 loss=0.231, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.9, ups=0.88, wpb=110.9, bsz=40, num_updates=4680, lr=4.02508e-05, gnorm=0.349, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27140
2022-10-11 00:24:21 - progress_bar.py[line:274] - INFO: epoch 012:    163 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=4690, lr=4.02255e-05, gnorm=0.768, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27152
2022-10-11 00:24:32 - progress_bar.py[line:274] - INFO: epoch 012:    173 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=4700, lr=4.02002e-05, gnorm=0.29, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27163
2022-10-11 00:24:43 - progress_bar.py[line:274] - INFO: epoch 012:    183 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.9, wpb=109.8, bsz=40, num_updates=4710, lr=4.0175e-05, gnorm=0.432, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27174
2022-10-11 00:24:54 - progress_bar.py[line:274] - INFO: epoch 012:    193 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=4720, lr=4.01497e-05, gnorm=0.542, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27185
2022-10-11 00:25:06 - progress_bar.py[line:274] - INFO: epoch 012:    203 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=4730, lr=4.01244e-05, gnorm=0.633, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27196
2022-10-11 00:25:17 - progress_bar.py[line:274] - INFO: epoch 012:    213 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=110.8, bsz=40, num_updates=4740, lr=4.00991e-05, gnorm=0.388, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27207
2022-10-11 00:25:28 - progress_bar.py[line:274] - INFO: epoch 012:    223 / 412 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=102.8, ups=0.91, wpb=112.4, bsz=40, num_updates=4750, lr=4.00738e-05, gnorm=0.333, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27218
2022-10-11 00:25:38 - progress_bar.py[line:274] - INFO: epoch 012:    233 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.9, ups=0.94, wpb=110.2, bsz=40, num_updates=4760, lr=4.00485e-05, gnorm=0.618, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27229
2022-10-11 00:25:49 - progress_bar.py[line:274] - INFO: epoch 012:    243 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.9, wpb=111.4, bsz=40, num_updates=4770, lr=4.00233e-05, gnorm=0.465, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=27240
2022-10-11 00:26:00 - progress_bar.py[line:274] - INFO: epoch 012:    253 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.2, ups=0.92, wpb=110.9, bsz=40, num_updates=4780, lr=3.9998e-05, gnorm=0.388, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27251
2022-10-11 00:26:11 - progress_bar.py[line:274] - INFO: epoch 012:    263 / 412 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.4, ups=0.9, wpb=112.1, bsz=40, num_updates=4790, lr=3.99727e-05, gnorm=0.209, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27262
2022-10-11 00:26:23 - progress_bar.py[line:274] - INFO: epoch 012:    273 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=4800, lr=3.99474e-05, gnorm=0.542, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=27273
2022-10-11 00:26:34 - progress_bar.py[line:274] - INFO: epoch 012:    283 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.7, ups=0.89, wpb=111.5, bsz=40, num_updates=4810, lr=3.99221e-05, gnorm=0.221, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27284
2022-10-11 00:26:45 - progress_bar.py[line:274] - INFO: epoch 012:    293 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=4820, lr=3.98968e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27296
2022-10-11 00:26:56 - progress_bar.py[line:274] - INFO: epoch 012:    303 / 412 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.88, wpb=112.4, bsz=40, num_updates=4830, lr=3.98716e-05, gnorm=0.319, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27307
2022-10-11 00:27:08 - progress_bar.py[line:274] - INFO: epoch 012:    313 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.8, ups=0.9, wpb=110.7, bsz=40, num_updates=4840, lr=3.98463e-05, gnorm=0.493, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=27318
2022-10-11 00:27:18 - progress_bar.py[line:274] - INFO: epoch 012:    323 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.1, ups=0.92, wpb=111, bsz=40, num_updates=4850, lr=3.9821e-05, gnorm=0.425, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=27329
2022-10-11 00:27:30 - progress_bar.py[line:274] - INFO: epoch 012:    333 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.1, ups=0.89, wpb=112.2, bsz=40, num_updates=4860, lr=3.97957e-05, gnorm=0.317, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27340
2022-10-11 00:27:41 - progress_bar.py[line:274] - INFO: epoch 012:    343 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=95.7, ups=0.86, wpb=111.4, bsz=40, num_updates=4870, lr=3.97704e-05, gnorm=0.444, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=27352
2022-10-11 00:27:53 - progress_bar.py[line:274] - INFO: epoch 012:    353 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.3, ups=0.89, wpb=111.6, bsz=40, num_updates=4880, lr=3.97451e-05, gnorm=0.406, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27363
2022-10-11 00:28:04 - progress_bar.py[line:274] - INFO: epoch 012:    363 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.044, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=4890, lr=3.97199e-05, gnorm=0.313, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=27374
2022-10-11 00:28:15 - progress_bar.py[line:274] - INFO: epoch 012:    373 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=95.9, ups=0.86, wpb=111.1, bsz=40, num_updates=4900, lr=3.96946e-05, gnorm=0.765, clip=30, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=27386
2022-10-11 00:28:27 - progress_bar.py[line:274] - INFO: epoch 012:    383 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=99.3, ups=0.89, wpb=111.1, bsz=40, num_updates=4910, lr=3.96693e-05, gnorm=0.434, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27397
2022-10-11 00:28:37 - progress_bar.py[line:274] - INFO: epoch 012:    393 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.3, ups=0.92, wpb=110.4, bsz=40, num_updates=4920, lr=3.9644e-05, gnorm=0.626, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27408
2022-10-11 00:28:49 - progress_bar.py[line:274] - INFO: epoch 012:    403 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=4930, lr=3.96187e-05, gnorm=0.359, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=27419
2022-10-11 00:28:59 - train.py[line:339] - INFO: end of epoch 12 (average epoch stats below)
2022-10-11 00:28:59 - progress_bar.py[line:282] - INFO: epoch 012 | loss 0.241 | loss_v1 0 | loss_v2 0 | nll_loss 0.056 | ntokens 111.127 | nsentences 40 | sample_size 111.127 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 98.7 | ups 0.89 | wpb 111.1 | bsz 40 | num_updates 4939 | lr 3.9596e-05 | gnorm 0.46 | clip 11.2 | loss_scale 512 | train_wall 459 | gb_free 10.7 | ema_decay 0.9999 | wall 27429
2022-10-11 00:28:59 - trainer.py[line:643] - INFO: loading train data for epoch 13
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv slice_id 0 row count 8240 total row count 16480
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E12.tsv slice_id 1 row count 8240 total row count 16480
2022-10-11 00:28:59 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-11 00:28:59 - trainer.py[line:707] - INFO: begin training epoch 13
2022-10-11 00:28:59 - train.py[line:312] - INFO: Start iterating over samples
2022-10-11 00:29:01 - progress_bar.py[line:274] - INFO: epoch 013:      1 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=87.5, ups=0.79, wpb=111.1, bsz=40, num_updates=4940, lr=3.95934e-05, gnorm=0.371, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27432
2022-10-11 00:29:13 - progress_bar.py[line:274] - INFO: epoch 013:     11 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.89, wpb=111.4, bsz=40, num_updates=4950, lr=3.95682e-05, gnorm=0.36, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27443
2022-10-11 00:29:24 - progress_bar.py[line:274] - INFO: epoch 013:     21 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.2, ups=0.91, wpb=111.8, bsz=40, num_updates=4960, lr=3.95429e-05, gnorm=0.512, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27454
2022-10-11 00:29:35 - progress_bar.py[line:274] - INFO: epoch 013:     31 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.9, wpb=111.2, bsz=40, num_updates=4970, lr=3.95176e-05, gnorm=0.321, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=27465
2022-10-11 00:29:46 - progress_bar.py[line:274] - INFO: epoch 013:     41 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=4980, lr=3.94923e-05, gnorm=0.389, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27477
2022-10-11 00:29:57 - progress_bar.py[line:274] - INFO: epoch 013:     51 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.9, wpb=109.9, bsz=40, num_updates=4990, lr=3.9467e-05, gnorm=0.278, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27488
2022-10-11 00:30:08 - progress_bar.py[line:274] - INFO: epoch 013:     61 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.2, ups=0.93, wpb=110.3, bsz=40, num_updates=5000, lr=3.94417e-05, gnorm=0.405, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=27499
2022-10-11 00:30:08 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-11 00:30:09 - train.py[line:549] - INFO: 0 / 4988
2022-10-11 00:30:09 - train.py[line:551] - INFO: load:0.98 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-11 00:30:25 - trainer.py[line:1334] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 6.21 GiB (GPU 0; 39.59 GiB total capacity; 8.88 GiB already allocated; 1.25 GiB free; 35.86 GiB reserved in total by PyTorch)
2022-10-11 00:30:25 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 16        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |    9096 MB |   14327 MB |    3543 TB |    3543 TB |
|       from large pool |    8951 MB |   14182 MB |    3542 TB |    3542 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| Active memory         |    9096 MB |   14327 MB |    3543 TB |    3543 TB |
|       from large pool |    8951 MB |   14182 MB |    3542 TB |    3542 TB |
|       from small pool |     144 MB |     145 MB |       0 TB |       0 TB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |   36718 MB |   37612 MB |  212550 MB |  175832 MB |
|       from large pool |   36572 MB |   37460 MB |  212200 MB |  175628 MB |
|       from small pool |     146 MB |     152 MB |     350 MB |     204 MB |
|---------------------------------------------------------------------------|
| Non-releasable memory |   27621 MB |   27621 MB |    3717 TB |    3717 TB |
|       from large pool |   27620 MB |   27620 MB |    3716 TB |    3716 TB |
|       from small pool |       1 MB |       1 MB |       1 TB |       1 TB |
|---------------------------------------------------------------------------|
| Allocations           |    3669    |    3683    |  166001 K  |  165997 K  |
|       from large pool |     563    |     575    |   52859 K  |   52859 K  |
|       from small pool |    3106    |    3116    |  113141 K  |  113138 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3669    |    3683    |  166001 K  |  165997 K  |
|       from large pool |     563    |     575    |   52859 K  |   52859 K  |
|       from small pool |    3106    |    3116    |  113141 K  |  113138 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     158    |     162    |     608    |     450    |
|       from large pool |      85    |      86    |     433    |     348    |
|       from small pool |      73    |      76    |     175    |     102    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      93    |     100    |  121762 K  |  121762 K  |
|       from large pool |      57    |      59    |   23181 K  |   23181 K  |
|       from small pool |      36    |      45    |   98580 K  |   98580 K  |
|===========================================================================|

2022-10-11 00:30:25 - trainer.py[line:1337] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |
|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |
|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|===========================================================================|

2022-10-11 00:30:25 - trainer.py[line:1083] - WARNING: ran out of memory in validation step, retrying batch
2022-10-11 00:32:42 - train.py[line:549] - INFO: 200 / 4988
2022-10-11 00:32:42 - train.py[line:551] - INFO: load:1.00 valid_run:152.45 task_valid:147.44 collect_output:2.92
2022-10-11 00:35:10 - train.py[line:549] - INFO: 400 / 4988
2022-10-11 00:35:10 - train.py[line:551] - INFO: load:1.03 valid_run:300.76 task_valid:290.05 collect_output:7.56
2022-10-11 00:37:42 - train.py[line:549] - INFO: 600 / 4988
2022-10-11 00:37:42 - train.py[line:551] - INFO: load:1.05 valid_run:453.08 task_valid:432.89 collect_output:15.97
2022-10-11 00:40:12 - train.py[line:549] - INFO: 800 / 4988
2022-10-11 00:40:12 - train.py[line:551] - INFO: load:1.08 valid_run:602.33 task_valid:577.58 collect_output:19.50
2022-10-11 00:42:44 - train.py[line:549] - INFO: 1000 / 4988
2022-10-11 00:42:44 - train.py[line:551] - INFO: load:1.11 valid_run:754.61 task_valid:724.53 collect_output:23.81
2022-10-11 00:45:16 - train.py[line:549] - INFO: 1200 / 4988
2022-10-11 00:45:16 - train.py[line:551] - INFO: load:1.13 valid_run:906.53 task_valid:869.71 collect_output:29.50
2022-10-11 00:47:50 - train.py[line:549] - INFO: 1400 / 4988
2022-10-11 00:47:50 - train.py[line:551] - INFO: load:1.16 valid_run:1060.39 task_valid:1015.39 collect_output:36.65
2022-10-11 00:50:22 - train.py[line:549] - INFO: 1600 / 4988
2022-10-11 00:50:22 - train.py[line:551] - INFO: load:1.18 valid_run:1212.62 task_valid:1156.43 collect_output:46.74
2022-10-11 00:52:53 - train.py[line:549] - INFO: 1800 / 4988
2022-10-11 00:52:53 - train.py[line:551] - INFO: load:1.21 valid_run:1363.03 task_valid:1301.12 collect_output:51.35
2022-10-11 00:55:22 - train.py[line:549] - INFO: 2000 / 4988
2022-10-11 00:55:22 - train.py[line:551] - INFO: load:1.23 valid_run:1512.26 task_valid:1444.49 collect_output:56.09
2022-10-11 00:57:53 - train.py[line:549] - INFO: 2200 / 4988
2022-10-11 00:57:53 - train.py[line:551] - INFO: load:1.26 valid_run:1662.97 task_valid:1589.55 collect_output:60.63
2022-10-11 01:00:24 - train.py[line:549] - INFO: 2400 / 4988
2022-10-11 01:00:24 - train.py[line:551] - INFO: load:1.29 valid_run:1813.63 task_valid:1734.49 collect_output:65.23
2022-10-11 01:02:54 - train.py[line:549] - INFO: 2600 / 4988
2022-10-11 01:02:54 - train.py[line:551] - INFO: load:1.31 valid_run:1964.25 task_valid:1876.42 collect_output:72.83
2022-10-11 01:05:25 - train.py[line:549] - INFO: 2800 / 4988
2022-10-11 01:05:25 - train.py[line:551] - INFO: load:1.34 valid_run:2115.34 task_valid:2021.68 collect_output:77.53
2022-10-11 01:07:56 - train.py[line:549] - INFO: 3000 / 4988
2022-10-11 01:07:56 - train.py[line:551] - INFO: load:1.36 valid_run:2265.67 task_valid:2167.89 collect_output:80.55
2022-10-11 01:10:26 - train.py[line:549] - INFO: 3200 / 4988
2022-10-11 01:10:26 - train.py[line:551] - INFO: load:1.39 valid_run:2415.90 task_valid:2311.43 collect_output:86.14
2022-10-11 01:12:58 - train.py[line:549] - INFO: 3400 / 4988
2022-10-11 01:12:58 - train.py[line:551] - INFO: load:1.41 valid_run:2567.62 task_valid:2456.17 collect_output:92.12
2022-10-11 01:15:28 - train.py[line:549] - INFO: 3600 / 4988
2022-10-11 01:15:28 - train.py[line:551] - INFO: load:1.44 valid_run:2718.01 task_valid:2602.52 collect_output:95.16
2022-10-11 01:17:57 - train.py[line:549] - INFO: 3800 / 4988
2022-10-11 01:17:57 - train.py[line:551] - INFO: load:1.46 valid_run:2866.59 task_valid:2743.52 collect_output:101.73
2022-10-11 01:20:28 - train.py[line:549] - INFO: 4000 / 4988
2022-10-11 01:20:28 - train.py[line:551] - INFO: load:1.48 valid_run:3017.07 task_valid:2888.06 collect_output:106.65
2022-10-11 01:23:00 - train.py[line:549] - INFO: 4200 / 4988
2022-10-11 01:23:00 - train.py[line:551] - INFO: load:1.51 valid_run:3169.33 task_valid:3032.10 collect_output:113.87
2022-10-11 01:25:29 - train.py[line:549] - INFO: 4400 / 4988
2022-10-11 01:25:29 - train.py[line:551] - INFO: load:1.53 valid_run:3318.90 task_valid:3176.17 collect_output:118.35
2022-10-11 01:28:01 - train.py[line:549] - INFO: 4600 / 4988
2022-10-11 01:28:01 - train.py[line:551] - INFO: load:1.56 valid_run:3470.17 task_valid:3321.77 collect_output:123.00
2022-10-11 01:30:32 - train.py[line:549] - INFO: 4800 / 4988
2022-10-11 01:30:32 - train.py[line:551] - INFO: load:1.59 valid_run:3621.57 task_valid:3467.86 collect_output:127.30

====================================================================================================
SGG eval:     R @ 50: 0.6636;     R @ 100: 0.6922;     R @ 500: 0.7156;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4601;    mR @ 100: 0.4975;    mR @ 500: 0.5525;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.9375) (covering:0.3000) (eating:0.7647) (flying in:0.6364) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9539) (says:0.0000) (sitting on:0.7265) (standing on:0.5110) (using:0.6000) (walking in:0.0000) (walking on:0.5676) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-11 01:33:03 - train.py[line:487] - INFO: 0.6921588999236058

====================================================================================================
SGG eval:     R @ 50: 0.6636;     R @ 100: 0.6922;     R @ 500: 0.7156;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4601;    mR @ 100: 0.4975;    mR @ 500: 0.5525;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7927) (covered in:0.9375) (covering:0.3000) (eating:0.7647) (flying in:0.6364) (growing on:0.3750) (hanging from:0.3710) (lying on:0.4000) (mounted on:0.0000) (painted on:0.4167) (parked on:0.9583) (playing:0.0000) (riding:0.9539) (says:0.0000) (sitting on:0.7265) (standing on:0.5110) (using:0.6000) (walking in:0.0000) (walking on:0.5676) (watching:0.6389) 
--------------------------------------------------------
====================================================================================================

2022-10-11 01:33:03 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-11 01:33:03 - progress_bar.py[line:282] - INFO: epoch 013 | valid on 'valid' subset | loss 0.227 | loss_v1 0 | loss_v2 0 | nll_loss 0.058 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.692159 | ppl 1.04 | vqa_score 0.5068 | wps 118.9 | wpb 89.9 | bsz 30 | num_updates 5000 | best_R@100 0.701241
2022-10-11 01:33:03 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 13 @ 5000 updates
2022-10-11 01:33:03 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_13_5000.pt
2022-10-11 01:33:09 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_13_5000.pt
2022-10-11 01:33:12 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_Mcap_EDS_MDS-k0.25-a1.0_Mcap/1_B20_A1_E50_0.04_5e-5_480/checkpoint_13_5000.pt (epoch 13 @ 5000 updates, score 0.6921588999236058) (writing took 8.722572285216302 seconds)
2022-10-11 01:33:24 - progress_bar.py[line:274] - INFO: epoch 013:     71 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=0.3, ups=0, wpb=110.6, bsz=40, num_updates=5010, lr=3.94165e-05, gnorm=0.588, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=31294
2022-10-11 01:33:35 - progress_bar.py[line:274] - INFO: epoch 013:     81 / 412 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=99.6, ups=0.9, wpb=111.1, bsz=40, num_updates=5020, lr=3.93912e-05, gnorm=0.383, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=31305
2022-10-11 01:33:46 - progress_bar.py[line:274] - INFO: epoch 013:     91 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101, ups=0.9, wpb=112.1, bsz=40, num_updates=5030, lr=3.93659e-05, gnorm=0.445, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31316
2022-10-11 01:33:57 - progress_bar.py[line:274] - INFO: epoch 013:    101 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=5040, lr=3.93406e-05, gnorm=0.352, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31328
2022-10-11 01:34:08 - progress_bar.py[line:274] - INFO: epoch 013:    111 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.8, ups=0.92, wpb=110.9, bsz=40, num_updates=5050, lr=3.93153e-05, gnorm=0.366, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31338
2022-10-11 01:34:19 - progress_bar.py[line:274] - INFO: epoch 013:    121 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=5060, lr=3.929e-05, gnorm=0.394, clip=10, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=31350
2022-10-11 01:34:30 - progress_bar.py[line:274] - INFO: epoch 013:    131 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.2, ups=0.89, wpb=111.1, bsz=40, num_updates=5070, lr=3.92648e-05, gnorm=0.201, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31361
2022-10-11 01:34:41 - progress_bar.py[line:274] - INFO: epoch 013:    141 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=5080, lr=3.92395e-05, gnorm=0.41, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31372
2022-10-11 01:34:52 - progress_bar.py[line:274] - INFO: epoch 013:    151 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.8, ups=0.91, wpb=111.2, bsz=40, num_updates=5090, lr=3.92142e-05, gnorm=0.362, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31383
2022-10-11 01:35:03 - progress_bar.py[line:274] - INFO: epoch 013:    161 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.2, ups=0.92, wpb=112.1, bsz=40, num_updates=5100, lr=3.91889e-05, gnorm=0.509, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31394
2022-10-11 01:35:15 - progress_bar.py[line:274] - INFO: epoch 013:    171 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=5110, lr=3.91636e-05, gnorm=0.322, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31405
2022-10-11 01:35:15 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-11 01:35:26 - progress_bar.py[line:274] - INFO: epoch 013:    182 / 412 loss=0.229, loss_v1=0, loss_v2=0, nll_loss=0.043, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=94.2, ups=0.84, wpb=112.2, bsz=40, num_updates=5120, lr=3.91383e-05, gnorm=0.36, clip=10, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=31417
2022-10-11 01:35:38 - progress_bar.py[line:274] - INFO: epoch 013:    192 / 412 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.047, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.9, wpb=112.4, bsz=40, num_updates=5130, lr=3.91131e-05, gnorm=0.68, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31428
2022-10-11 01:35:49 - progress_bar.py[line:274] - INFO: epoch 013:    202 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=5140, lr=3.90878e-05, gnorm=1.65, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31439
2022-10-11 01:36:00 - progress_bar.py[line:274] - INFO: epoch 013:    212 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.2, ups=0.9, wpb=111.9, bsz=40, num_updates=5150, lr=3.90625e-05, gnorm=0.559, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31451
2022-10-11 01:36:11 - progress_bar.py[line:274] - INFO: epoch 013:    222 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.3, ups=0.87, wpb=111.5, bsz=40, num_updates=5160, lr=3.90372e-05, gnorm=0.364, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31462
2022-10-11 01:36:22 - progress_bar.py[line:274] - INFO: epoch 013:    232 / 412 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.045, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=100.6, ups=0.91, wpb=110.6, bsz=40, num_updates=5170, lr=3.90119e-05, gnorm=0.399, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31473
2022-10-11 01:36:33 - progress_bar.py[line:274] - INFO: epoch 013:    242 / 412 loss=0.233, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.7, ups=0.91, wpb=112, bsz=40, num_updates=5180, lr=3.89867e-05, gnorm=0.543, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31484
2022-10-11 01:36:45 - progress_bar.py[line:274] - INFO: epoch 013:    252 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.9, wpb=110.9, bsz=40, num_updates=5190, lr=3.89614e-05, gnorm=0.75, clip=30, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=31495
2022-10-11 01:36:56 - progress_bar.py[line:274] - INFO: epoch 013:    262 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.4, ups=0.89, wpb=110.8, bsz=40, num_updates=5200, lr=3.89361e-05, gnorm=0.704, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31506
2022-10-11 01:37:07 - progress_bar.py[line:274] - INFO: epoch 013:    272 / 412 loss=0.234, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.9, ups=0.92, wpb=111.6, bsz=40, num_updates=5210, lr=3.89108e-05, gnorm=0.444, clip=10, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=31517
2022-10-11 01:37:18 - progress_bar.py[line:274] - INFO: epoch 013:    282 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=98.8, ups=0.88, wpb=112.1, bsz=40, num_updates=5220, lr=3.88855e-05, gnorm=0.877, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31529
2022-10-11 01:37:29 - progress_bar.py[line:274] - INFO: epoch 013:    292 / 412 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=100.9, ups=0.92, wpb=109.6, bsz=40, num_updates=5230, lr=3.88602e-05, gnorm=0.907, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31539
2022-10-11 01:37:40 - progress_bar.py[line:274] - INFO: epoch 013:    302 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.9, wpb=109.9, bsz=40, num_updates=5240, lr=3.8835e-05, gnorm=0.474, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31551
2022-10-11 01:37:51 - progress_bar.py[line:274] - INFO: epoch 013:    312 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.9, ups=0.92, wpb=110.9, bsz=40, num_updates=5250, lr=3.88097e-05, gnorm=0.43, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31561
2022-10-11 01:38:02 - progress_bar.py[line:274] - INFO: epoch 013:    322 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=102.4, ups=0.91, wpb=112.1, bsz=40, num_updates=5260, lr=3.87844e-05, gnorm=0.43, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31572
2022-10-11 01:38:13 - progress_bar.py[line:274] - INFO: epoch 013:    332 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.91, wpb=110.5, bsz=40, num_updates=5270, lr=3.87591e-05, gnorm=0.349, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31583
2022-10-11 01:38:24 - progress_bar.py[line:274] - INFO: epoch 013:    342 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.5, ups=0.91, wpb=111.3, bsz=40, num_updates=5280, lr=3.87338e-05, gnorm=0.495, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31594
2022-10-11 01:38:35 - progress_bar.py[line:274] - INFO: epoch 013:    352 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=5290, lr=3.87085e-05, gnorm=0.202, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31605
2022-10-11 01:38:46 - progress_bar.py[line:274] - INFO: epoch 013:    362 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=5300, lr=3.86833e-05, gnorm=0.557, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31617
2022-10-11 01:38:57 - progress_bar.py[line:274] - INFO: epoch 013:    372 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.8, ups=0.91, wpb=112.4, bsz=40, num_updates=5310, lr=3.8658e-05, gnorm=0.602, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31628
2022-10-11 01:39:08 - progress_bar.py[line:274] - INFO: epoch 013:    382 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.3, ups=0.91, wpb=111.9, bsz=40, num_updates=5320, lr=3.86327e-05, gnorm=0.643, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=31639
2022-10-11 01:39:20 - progress_bar.py[line:274] - INFO: epoch 013:    392 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.89, wpb=112.4, bsz=40, num_updates=5330, lr=3.86074e-05, gnorm=0.432, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=31650
2022-10-11 01:39:31 - progress_bar.py[line:274] - INFO: epoch 013:    402 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.8, ups=0.87, wpb=112.3, bsz=40, num_updates=5340, lr=3.85821e-05, gnorm=0.352, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31662
2022-10-11 01:39:42 - progress_bar.py[line:274] - INFO: epoch 013:    412 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.5, ups=0.9, wpb=109.5, bsz=40, num_updates=5350, lr=3.85568e-05, gnorm=0.576, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31673
2022-10-11 01:39:42 - train.py[line:339] - INFO: end of epoch 13 (average epoch stats below)
2022-10-11 01:39:42 - progress_bar.py[line:282] - INFO: epoch 013 | loss 0.24 | loss_v1 0 | loss_v2 0 | nll_loss 0.056 | ntokens 111.119 | nsentences 40 | sample_size 111.119 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 10.8 | ups 0.1 | wpb 111.1 | bsz 40 | num_updates 5350 | lr 3.85568e-05 | gnorm 0.496 | clip 12.9 | loss_scale 512 | train_wall 456 | gb_free 10.7 | ema_decay 0.9999 | wall 31673
2022-10-11 01:39:42 - trainer.py[line:643] - INFO: loading train data for epoch 14
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv slice_id 0 row count 8240 total row count 16480
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt-new_train_NA1_E13.tsv slice_id 1 row count 8240 total row count 16480
2022-10-11 01:39:42 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-11 01:39:43 - trainer.py[line:707] - INFO: begin training epoch 14
2022-10-11 01:39:43 - train.py[line:312] - INFO: Start iterating over samples
2022-10-11 01:39:55 - progress_bar.py[line:274] - INFO: epoch 014:     10 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=85.9, ups=0.78, wpb=109.6, bsz=40, num_updates=5360, lr=3.85316e-05, gnorm=0.96, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31685
2022-10-11 01:40:06 - progress_bar.py[line:274] - INFO: epoch 014:     20 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.3, ups=0.88, wpb=109.3, bsz=40, num_updates=5370, lr=3.85063e-05, gnorm=0.555, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31697
2022-10-11 01:40:17 - progress_bar.py[line:274] - INFO: epoch 014:     30 / 412 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.3, ups=0.91, wpb=110.5, bsz=40, num_updates=5380, lr=3.8481e-05, gnorm=0.445, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31708
2022-10-11 01:40:29 - progress_bar.py[line:274] - INFO: epoch 014:     40 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.87, wpb=111.7, bsz=40, num_updates=5390, lr=3.84557e-05, gnorm=0.303, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31719
2022-10-11 01:40:40 - progress_bar.py[line:274] - INFO: epoch 014:     50 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98.8, ups=0.89, wpb=110.9, bsz=40, num_updates=5400, lr=3.84304e-05, gnorm=0.423, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31731
2022-10-11 01:40:51 - progress_bar.py[line:274] - INFO: epoch 014:     60 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=5410, lr=3.84051e-05, gnorm=0.258, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31742
2022-10-11 01:41:02 - progress_bar.py[line:274] - INFO: epoch 014:     70 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.048, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.5, ups=0.9, wpb=109.8, bsz=40, num_updates=5420, lr=3.83799e-05, gnorm=0.318, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31753
2022-10-11 01:41:13 - progress_bar.py[line:274] - INFO: epoch 014:     80 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.91, wpb=109.4, bsz=40, num_updates=5430, lr=3.83546e-05, gnorm=0.47, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31764
2022-10-11 01:41:25 - progress_bar.py[line:274] - INFO: epoch 014:     90 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.5, ups=0.9, wpb=112.3, bsz=40, num_updates=5440, lr=3.83293e-05, gnorm=0.587, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31775
2022-10-11 01:41:36 - progress_bar.py[line:274] - INFO: epoch 014:    100 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=5450, lr=3.8304e-05, gnorm=0.365, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31786
2022-10-11 01:41:47 - progress_bar.py[line:274] - INFO: epoch 014:    110 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=113.3, nsentences=40, sample_size=113.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.88, wpb=113.3, bsz=40, num_updates=5460, lr=3.82787e-05, gnorm=0.441, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=31798
2022-10-11 01:41:58 - progress_bar.py[line:274] - INFO: epoch 014:    120 / 412 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=5470, lr=3.82534e-05, gnorm=0.347, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31809
2022-10-11 01:42:09 - progress_bar.py[line:274] - INFO: epoch 014:    130 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100, ups=0.9, wpb=111.6, bsz=40, num_updates=5480, lr=3.82282e-05, gnorm=0.559, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31820
2022-10-11 01:42:21 - progress_bar.py[line:274] - INFO: epoch 014:    140 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.1, ups=0.9, wpb=111.4, bsz=40, num_updates=5490, lr=3.82029e-05, gnorm=0.646, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=31831
2022-10-11 01:42:32 - progress_bar.py[line:274] - INFO: epoch 014:    150 / 412 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.7, ups=0.91, wpb=109.9, bsz=40, num_updates=5500, lr=3.81776e-05, gnorm=0.55, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31842
2022-10-11 01:42:43 - progress_bar.py[line:274] - INFO: epoch 014:    160 / 412 loss=0.232, loss_v1=0, loss_v2=0, nll_loss=0.05, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.9, ups=0.9, wpb=112.6, bsz=40, num_updates=5510, lr=3.81523e-05, gnorm=0.262, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31853
2022-10-11 01:42:54 - progress_bar.py[line:274] - INFO: epoch 014:    170 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=112.8, nsentences=40, sample_size=112.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.5, ups=0.92, wpb=112.8, bsz=40, num_updates=5520, lr=3.8127e-05, gnorm=0.519, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31864
2022-10-11 01:43:05 - progress_bar.py[line:274] - INFO: epoch 014:    180 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.4, ups=0.9, wpb=108.7, bsz=40, num_updates=5530, lr=3.81017e-05, gnorm=0.554, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=31875
2022-10-11 01:43:16 - progress_bar.py[line:274] - INFO: epoch 014:    190 / 412 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.7, ups=0.89, wpb=113, bsz=40, num_updates=5540, lr=3.80765e-05, gnorm=0.608, clip=20, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=31887
2022-10-11 01:43:27 - progress_bar.py[line:274] - INFO: epoch 014:    200 / 412 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=98.2, ups=0.88, wpb=111.4, bsz=40, num_updates=5550, lr=3.80512e-05, gnorm=0.467, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31898
2022-10-11 01:43:39 - progress_bar.py[line:274] - INFO: epoch 014:    210 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.1, ups=0.9, wpb=110.6, bsz=40, num_updates=5560, lr=3.80259e-05, gnorm=0.342, clip=0, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31909
2022-10-11 01:43:50 - progress_bar.py[line:274] - INFO: epoch 014:    220 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=5570, lr=3.80006e-05, gnorm=0.267, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31920
2022-10-11 01:44:01 - progress_bar.py[line:274] - INFO: epoch 014:    230 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.053, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.1, ups=0.92, wpb=110.3, bsz=40, num_updates=5580, lr=3.79753e-05, gnorm=0.247, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=31931
2022-10-11 01:44:12 - progress_bar.py[line:274] - INFO: epoch 014:    240 / 412 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=5590, lr=3.795e-05, gnorm=0.422, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31942
2022-10-11 01:44:23 - progress_bar.py[line:274] - INFO: epoch 014:    250 / 412 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=102.1, ups=0.92, wpb=111.2, bsz=40, num_updates=5600, lr=3.79248e-05, gnorm=0.622, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=31953
2022-10-11 01:44:33 - progress_bar.py[line:274] - INFO: epoch 014:    260 / 412 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.1, ups=0.93, wpb=111.9, bsz=40, num_updates=5610, lr=3.78995e-05, gnorm=0.376, clip=10, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=31964
2022-10-11 01:44:44 - progress_bar.py[line:274] - INFO: epoch 014:    270 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.049, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.03, wps=101.9, ups=0.92, wpb=111.1, bsz=40, num_updates=5620, lr=3.78742e-05, gnorm=0.306, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31975
2022-10-11 01:44:55 - progress_bar.py[line:274] - INFO: epoch 014:    280 / 412 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=113, nsentences=40, sample_size=113, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=103.9, ups=0.92, wpb=113, bsz=40, num_updates=5630, lr=3.78489e-05, gnorm=0.447, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=31986
2022-10-11 01:45:07 - progress_bar.py[line:274] - INFO: epoch 014:    290 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.051, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=96.9, ups=0.88, wpb=110.4, bsz=40, num_updates=5640, lr=3.78236e-05, gnorm=0.288, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=31997
2022-10-11 01:45:18 - progress_bar.py[line:274] - INFO: epoch 014:    300 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.052, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.9, ups=0.9, wpb=111.2, bsz=40, num_updates=5650, lr=3.77983e-05, gnorm=0.348, clip=10, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=32008
2022-10-11 01:45:29 - progress_bar.py[line:274] - INFO: epoch 014:    310 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.6, ups=0.91, wpb=109.9, bsz=40, num_updates=5660, lr=3.77731e-05, gnorm=0.629, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32019
2022-10-11 01:45:40 - progress_bar.py[line:274] - INFO: epoch 014:    320 / 412 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.6, ups=0.88, wpb=111.5, bsz=40, num_updates=5670, lr=3.77478e-05, gnorm=0.564, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32031
2022-10-11 01:45:51 - progress_bar.py[line:274] - INFO: epoch 014:    330 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=5680, lr=3.77225e-05, gnorm=0.681, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32042
2022-10-11 01:46:02 - progress_bar.py[line:274] - INFO: epoch 014:    340 / 412 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=102.9, ups=0.92, wpb=111.8, bsz=40, num_updates=5690, lr=3.76972e-05, gnorm=0.515, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32053
2022-10-11 01:46:13 - progress_bar.py[line:274] - INFO: epoch 014:    350 / 412 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.7, ups=0.91, wpb=111.9, bsz=40, num_updates=5700, lr=3.76719e-05, gnorm=0.75, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32064
2022-10-11 01:46:25 - progress_bar.py[line:274] - INFO: epoch 014:    360 / 412 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=97.2, ups=0.88, wpb=110, bsz=40, num_updates=5710, lr=3.76466e-05, gnorm=0.601, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32075
2022-10-11 01:46:35 - progress_bar.py[line:274] - INFO: epoch 014:    370 / 412 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=101.7, ups=0.92, wpb=110.5, bsz=40, num_updates=5720, lr=3.76214e-05, gnorm=0.456, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=32086
2022-10-11 01:46:46 - progress_bar.py[line:274] - INFO: epoch 014:    380 / 412 loss=0.235, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=104.5, ups=0.93, wpb=112, bsz=40, num_updates=5730, lr=3.75961e-05, gnorm=0.204, clip=0, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=32097
2022-10-11 01:46:57 - progress_bar.py[line:274] - INFO: epoch 014:    390 / 412 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=101.1, ups=0.92, wpb=110, bsz=40, num_updates=5740, lr=3.75708e-05, gnorm=0.495, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=32108
2022-10-11 01:47:08 - progress_bar.py[line:274] - INFO: epoch 014:    400 / 412 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.055, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=99.4, ups=0.89, wpb=112.3, bsz=40, num_updates=5750, lr=3.75455e-05, gnorm=0.359, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=32119
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 4166389
Killing subprocess 4166392
Main process received SIGINT, exiting
