2022-10-13 10:30:43 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-10-13 10:30:43 - utils.py[line:261] - INFO: Start init
2022-10-13 10:30:43 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-10-13 10:30:43 - utils.py[line:261] - INFO: Start init
2022-10-13 10:30:43 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-10-13 10:30:43 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-10-13 10:30:43 - utils.py[line:274] - INFO: initialized host node4 as rank 0
single-machine distributed training is initialized.
2022-10-13 10:30:43 - utils.py[line:274] - INFO: initialized host node4 as rank 1
single-machine distributed training is initialized.
2022-10-13 10:30:49 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './vqa_tensorboard/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 20, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 1000, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 15, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 4, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480', 'restore_file': '/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 1000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=20, batch_size_valid='15', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=4, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='/data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt', sample_patch_num=196, save_dir='./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480', save_interval=10, save_interval_updates=1000, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./vqa_tensorboard/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=1000, wandb_project=None, warmup_ratio=0.04, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E1.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E2.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E3.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E4.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E5.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E6.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E7.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E8.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E9.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E10.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E11.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E12.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E13.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E14.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E15.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E16.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E17.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E18.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E19.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E20.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E21.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E22.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E23.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E24.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E25.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E26.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E27.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E28.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E29.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E30.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E31.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E32.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E33.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E34.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E35.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E36.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E37.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E38.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E39.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E40.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E41.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E42.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E43.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E44.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E45.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E46.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E47.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E48.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E49.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E50.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E51.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E52.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E53.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E54.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E55.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E56.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E57.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E58.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E59.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E60.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E61.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E62.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E63.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E64.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E65.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E66.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E67.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E68.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E69.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E70.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E71.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E72.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E73.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E74.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E75.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E76.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E77.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E78.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E79.tsv,/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer'}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.04, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2022-10-13 10:30:49 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2022-10-13 10:30:49 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
2022-10-13 10:30:54 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 12)
      (1): Embedding(511, 12)
      (2): Embedding(511, 12)
      (3): Embedding(511, 12)
      (4): Embedding(511, 12)
      (5): Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 12)
      (1): Embedding(6892, 12)
      (2): Embedding(6892, 12)
      (3): Embedding(6892, 12)
      (4): Embedding(6892, 12)
      (5): Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2022-10-13 10:30:54 - train.py[line:118] - INFO: task: VqaGenTask
2022-10-13 10:30:54 - train.py[line:119] - INFO: model: OFAModel
2022-10-13 10:30:54 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2022-10-13 10:30:54 - train.py[line:124] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2022-10-13 10:30:54 - train.py[line:131] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 0 row count 74807 total row count 149614
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_val_500.tsv slice_id 1 row count 74807 total row count 149614
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
/home/yutianyu/miniconda3/envs/OFA/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-10-13 10:30:54 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-10-13 10:30:54 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-10-13 10:30:55 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-13 10:30:55 - utils.py[line:765] - INFO: rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-13 10:30:55 - utils.py[line:765] - INFO: rank   1: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          
2022-10-13 10:30:55 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-10-13 10:30:55 - train.py[line:161] - INFO: training on 2 devices (GPUs/TPUs)
2022-10-13 10:30:55 - train.py[line:167] - INFO: max tokens per device = None and max sentences per device = 20
2022-10-13 10:30:55 - trainer.py[line:458] - INFO: Preparing to load checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt
2022-10-13 10:31:03 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-10-13 10:31:03 - trainer.py[line:594] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2022-10-13 10:31:04 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2022-10-13 10:31:04 - trainer.py[line:273] - INFO: Exponential Moving Average Shadow Model is initialized.
2022-10-13 10:31:04 - trainer.py[line:623] - INFO: Loaded checkpoint /data/private/yutianyu/datasets/OFA_data/sgg/../checkpoints/ofa_base.pt (epoch 48 @ 0 updates)
2022-10-13 10:31:04 - trainer.py[line:643] - INFO: loading train data for epoch 1
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 0 row count 578200 total row count 1156400
file /data/private/yutianyu/datasets/OFA_data/sgg/20_way_visualDS/query_optNew_caption_trained_visual_DS-k25alpha1.0_train_NA1_E0.tsv slice_id 1 row count 578200 total row count 1156400
2022-10-13 10:31:05 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 115640, warmup steps 4625, warmup_factor 0.00021621621621621621
Total steps 115640, warmup steps 4625, warmup_factor 0.00021621621621621621
2022-10-13 10:31:06 - trainer.py[line:707] - INFO: begin training epoch 1
2022-10-13 10:31:06 - train.py[line:312] - INFO: Start iterating over samples
2022-10-13 10:31:24 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 28910 loss=0.94, loss_v1=0, loss_v2=0, nll_loss=0.793, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.73, wps=93.4, ups=0.84, wpb=110.8, bsz=40, num_updates=10, lr=1.08108e-07, gnorm=11.093, clip=100, loss_scale=128, train_wall=17, gb_free=10.6, ema_decay=0.9999, wall=29
2022-10-13 10:31:36 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 28910 loss=1.133, loss_v1=0, loss_v2=0, nll_loss=0.994, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.99, wps=94, ups=0.86, wpb=109.6, bsz=40, num_updates=20, lr=2.16216e-07, gnorm=14.828, clip=100, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=41
2022-10-13 10:31:47 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 28910 loss=1.056, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=97.6, ups=0.88, wpb=111.1, bsz=40, num_updates=30, lr=3.24324e-07, gnorm=11.904, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=52
2022-10-13 10:31:58 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 28910 loss=1.037, loss_v1=0, loss_v2=0, nll_loss=0.898, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.86, wps=98.3, ups=0.88, wpb=111.6, bsz=40, num_updates=40, lr=4.32432e-07, gnorm=12.017, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=63
2022-10-13 10:32:10 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 28910 loss=0.967, loss_v1=0, loss_v2=0, nll_loss=0.834, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.78, wps=95.7, ups=0.87, wpb=109.4, bsz=40, num_updates=50, lr=5.40541e-07, gnorm=10.3, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=75
2022-10-13 10:32:21 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 28910 loss=0.928, loss_v1=0, loss_v2=0, nll_loss=0.798, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=96.2, ups=0.87, wpb=111.1, bsz=40, num_updates=60, lr=6.48649e-07, gnorm=10.621, clip=100, loss_scale=128, train_wall=12, gb_free=10.2, ema_decay=0.9999, wall=86
2022-10-13 10:32:33 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 28910 loss=0.87, loss_v1=0, loss_v2=0, nll_loss=0.748, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.68, wps=95.4, ups=0.87, wpb=109.8, bsz=40, num_updates=70, lr=7.56757e-07, gnorm=9.715, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=98
2022-10-13 10:32:44 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 28910 loss=0.855, loss_v1=0, loss_v2=0, nll_loss=0.743, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.67, wps=100.3, ups=0.91, wpb=110, bsz=40, num_updates=80, lr=8.64865e-07, gnorm=8.334, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=109
2022-10-13 10:32:55 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 28910 loss=0.777, loss_v1=0, loss_v2=0, nll_loss=0.66, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=97.7, ups=0.88, wpb=111, bsz=40, num_updates=90, lr=9.72973e-07, gnorm=7.864, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=120
2022-10-13 10:33:07 - progress_bar.py[line:274] - INFO: epoch 001:    100 / 28910 loss=0.789, loss_v1=0, loss_v2=0, nll_loss=0.685, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.61, wps=95.7, ups=0.87, wpb=110.1, bsz=40, num_updates=100, lr=1.08108e-06, gnorm=6.189, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=132
2022-10-13 10:33:18 - progress_bar.py[line:274] - INFO: epoch 001:    110 / 28910 loss=0.774, loss_v1=0, loss_v2=0, nll_loss=0.671, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.59, wps=100.7, ups=0.92, wpb=110, bsz=40, num_updates=110, lr=1.18919e-06, gnorm=6.169, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=143
2022-10-13 10:33:29 - progress_bar.py[line:274] - INFO: epoch 001:    120 / 28910 loss=0.706, loss_v1=0, loss_v2=0, nll_loss=0.607, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97.6, ups=0.88, wpb=111.2, bsz=40, num_updates=120, lr=1.2973e-06, gnorm=5.412, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=154
2022-10-13 10:33:41 - progress_bar.py[line:274] - INFO: epoch 001:    130 / 28910 loss=0.737, loss_v1=0, loss_v2=0, nll_loss=0.641, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=130, lr=1.40541e-06, gnorm=4.714, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=165
2022-10-13 10:33:52 - progress_bar.py[line:274] - INFO: epoch 001:    140 / 28910 loss=0.695, loss_v1=0, loss_v2=0, nll_loss=0.598, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=140, lr=1.51351e-06, gnorm=4.937, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=177
2022-10-13 10:34:03 - progress_bar.py[line:274] - INFO: epoch 001:    150 / 28910 loss=0.697, loss_v1=0, loss_v2=0, nll_loss=0.602, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=150, lr=1.62162e-06, gnorm=4.646, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=188
2022-10-13 10:34:14 - progress_bar.py[line:274] - INFO: epoch 001:    160 / 28910 loss=0.671, loss_v1=0, loss_v2=0, nll_loss=0.576, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=100.7, ups=0.91, wpb=110.5, bsz=40, num_updates=160, lr=1.72973e-06, gnorm=4.274, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=199
2022-10-13 10:34:25 - progress_bar.py[line:274] - INFO: epoch 001:    170 / 28910 loss=0.728, loss_v1=0, loss_v2=0, nll_loss=0.644, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.56, wps=100, ups=0.9, wpb=111, bsz=40, num_updates=170, lr=1.83784e-06, gnorm=4.064, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=210
2022-10-13 10:34:37 - progress_bar.py[line:274] - INFO: epoch 001:    180 / 28910 loss=0.638, loss_v1=0, loss_v2=0, nll_loss=0.54, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=180, lr=1.94595e-06, gnorm=3.754, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=221
2022-10-13 10:34:48 - progress_bar.py[line:274] - INFO: epoch 001:    190 / 28910 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.7, ups=0.9, wpb=111.8, bsz=40, num_updates=190, lr=2.05405e-06, gnorm=3.207, clip=100, loss_scale=128, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=233
2022-10-13 10:34:59 - progress_bar.py[line:274] - INFO: epoch 001:    200 / 28910 loss=0.686, loss_v1=0, loss_v2=0, nll_loss=0.604, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.52, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=200, lr=2.16216e-06, gnorm=3.295, clip=100, loss_scale=128, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=244
2022-10-13 10:35:11 - progress_bar.py[line:274] - INFO: epoch 001:    210 / 28910 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.557, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=93.1, ups=0.84, wpb=110.7, bsz=40, num_updates=210, lr=2.27027e-06, gnorm=3.097, clip=100, loss_scale=128, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=256
2022-10-13 10:35:22 - progress_bar.py[line:274] - INFO: epoch 001:    220 / 28910 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.555, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=220, lr=2.37838e-06, gnorm=2.965, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=267
2022-10-13 10:35:33 - progress_bar.py[line:274] - INFO: epoch 001:    230 / 28910 loss=0.651, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=100.5, ups=0.91, wpb=110.9, bsz=40, num_updates=230, lr=2.48649e-06, gnorm=2.9, clip=100, loss_scale=128, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=278
2022-10-13 10:35:44 - progress_bar.py[line:274] - INFO: epoch 001:    240 / 28910 loss=0.583, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=240, lr=2.59459e-06, gnorm=2.568, clip=100, loss_scale=128, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=289
2022-10-13 10:35:55 - progress_bar.py[line:274] - INFO: epoch 001:    250 / 28910 loss=0.647, loss_v1=0, loss_v2=0, nll_loss=0.562, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=250, lr=2.7027e-06, gnorm=2.78, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=300
2022-10-13 10:36:06 - progress_bar.py[line:274] - INFO: epoch 001:    260 / 28910 loss=0.643, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=103.9, ups=0.94, wpb=110.5, bsz=40, num_updates=260, lr=2.81081e-06, gnorm=2.74, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=311
2022-10-13 10:36:17 - progress_bar.py[line:274] - INFO: epoch 001:    270 / 28910 loss=0.712, loss_v1=0, loss_v2=0, nll_loss=0.63, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.55, wps=96.8, ups=0.89, wpb=108.9, bsz=40, num_updates=270, lr=2.91892e-06, gnorm=3.072, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=322
2022-10-13 10:36:28 - progress_bar.py[line:274] - INFO: epoch 001:    280 / 28910 loss=0.64, loss_v1=0, loss_v2=0, nll_loss=0.558, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=280, lr=3.02703e-06, gnorm=2.439, clip=100, loss_scale=128, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=333
2022-10-13 10:36:39 - progress_bar.py[line:274] - INFO: epoch 001:    290 / 28910 loss=0.632, loss_v1=0, loss_v2=0, nll_loss=0.553, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=99, ups=0.9, wpb=110, bsz=40, num_updates=290, lr=3.13514e-06, gnorm=2.387, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=344
2022-10-13 10:36:51 - progress_bar.py[line:274] - INFO: epoch 001:    300 / 28910 loss=0.625, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=97.9, ups=0.89, wpb=109.8, bsz=40, num_updates=300, lr=3.24324e-06, gnorm=2.289, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=355
2022-10-13 10:37:02 - progress_bar.py[line:274] - INFO: epoch 001:    310 / 28910 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.4, ups=0.88, wpb=110.2, bsz=40, num_updates=310, lr=3.35135e-06, gnorm=2.265, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=367
2022-10-13 10:37:13 - progress_bar.py[line:274] - INFO: epoch 001:    320 / 28910 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=103, ups=0.93, wpb=111.3, bsz=40, num_updates=320, lr=3.45946e-06, gnorm=2.219, clip=100, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=378
2022-10-13 10:37:24 - progress_bar.py[line:274] - INFO: epoch 001:    330 / 28910 loss=0.67, loss_v1=0, loss_v2=0, nll_loss=0.592, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.51, wps=100.2, ups=0.91, wpb=110.5, bsz=40, num_updates=330, lr=3.56757e-06, gnorm=2.45, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=389
2022-10-13 10:37:35 - progress_bar.py[line:274] - INFO: epoch 001:    340 / 28910 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.564, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.48, wps=103, ups=0.93, wpb=111.2, bsz=40, num_updates=340, lr=3.67568e-06, gnorm=2.324, clip=100, loss_scale=128, train_wall=11, gb_free=11, ema_decay=0.9999, wall=400
2022-10-13 10:37:46 - progress_bar.py[line:274] - INFO: epoch 001:    350 / 28910 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.5, ups=0.89, wpb=111.8, bsz=40, num_updates=350, lr=3.78378e-06, gnorm=1.991, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=411
2022-10-13 10:37:57 - progress_bar.py[line:274] - INFO: epoch 001:    360 / 28910 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.544, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=99.2, ups=0.9, wpb=110.2, bsz=40, num_updates=360, lr=3.89189e-06, gnorm=2.06, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=422
2022-10-13 10:38:08 - progress_bar.py[line:274] - INFO: epoch 001:    370 / 28910 loss=0.641, loss_v1=0, loss_v2=0, nll_loss=0.559, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=370, lr=4e-06, gnorm=2.087, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=433
2022-10-13 10:38:19 - progress_bar.py[line:274] - INFO: epoch 001:    380 / 28910 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.549, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=380, lr=4.10811e-06, gnorm=1.982, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=444
2022-10-13 10:38:30 - progress_bar.py[line:274] - INFO: epoch 001:    390 / 28910 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.504, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=390, lr=4.21622e-06, gnorm=1.963, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=455
2022-10-13 10:38:41 - progress_bar.py[line:274] - INFO: epoch 001:    400 / 28910 loss=0.604, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=99.9, ups=0.9, wpb=110.5, bsz=40, num_updates=400, lr=4.32432e-06, gnorm=1.982, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=466
2022-10-13 10:38:53 - progress_bar.py[line:274] - INFO: epoch 001:    410 / 28910 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.5, ups=0.88, wpb=109.5, bsz=40, num_updates=410, lr=4.43243e-06, gnorm=1.98, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=478
2022-10-13 10:39:04 - progress_bar.py[line:274] - INFO: epoch 001:    420 / 28910 loss=0.621, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=101.2, ups=0.92, wpb=110.4, bsz=40, num_updates=420, lr=4.54054e-06, gnorm=1.937, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=489
2022-10-13 10:39:15 - progress_bar.py[line:274] - INFO: epoch 001:    430 / 28910 loss=0.617, loss_v1=0, loss_v2=0, nll_loss=0.535, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=100.6, ups=0.9, wpb=111.3, bsz=40, num_updates=430, lr=4.64865e-06, gnorm=2.209, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=500
2022-10-13 10:39:26 - progress_bar.py[line:274] - INFO: epoch 001:    440 / 28910 loss=0.664, loss_v1=0, loss_v2=0, nll_loss=0.58, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.5, ups=0.9, wpb=109.6, bsz=40, num_updates=440, lr=4.75676e-06, gnorm=2.207, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=511
2022-10-13 10:39:37 - progress_bar.py[line:274] - INFO: epoch 001:    450 / 28910 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.521, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=450, lr=4.86486e-06, gnorm=1.94, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=522
2022-10-13 10:39:48 - progress_bar.py[line:274] - INFO: epoch 001:    460 / 28910 loss=0.633, loss_v1=0, loss_v2=0, nll_loss=0.552, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.47, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=460, lr=4.97297e-06, gnorm=2.046, clip=100, loss_scale=128, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=533
2022-10-13 10:40:00 - progress_bar.py[line:274] - INFO: epoch 001:    470 / 28910 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.512, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=470, lr=5.08108e-06, gnorm=1.962, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=545
2022-10-13 10:40:11 - progress_bar.py[line:274] - INFO: epoch 001:    480 / 28910 loss=0.615, loss_v1=0, loss_v2=0, nll_loss=0.529, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.8, ups=0.9, wpb=109.2, bsz=40, num_updates=480, lr=5.18919e-06, gnorm=1.922, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=556
2022-10-13 10:40:22 - progress_bar.py[line:274] - INFO: epoch 001:    490 / 28910 loss=0.585, loss_v1=0, loss_v2=0, nll_loss=0.501, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=490, lr=5.2973e-06, gnorm=1.784, clip=100, loss_scale=128, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=567
2022-10-13 10:40:34 - progress_bar.py[line:274] - INFO: epoch 001:    500 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.523, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=95.4, ups=0.87, wpb=110, bsz=40, num_updates=500, lr=5.40541e-06, gnorm=1.812, clip=100, loss_scale=128, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=579
2022-10-13 10:40:45 - progress_bar.py[line:274] - INFO: epoch 001:    510 / 28910 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.514, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.5, ups=0.9, wpb=108.7, bsz=40, num_updates=510, lr=5.51351e-06, gnorm=1.705, clip=100, loss_scale=128, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=590
2022-10-13 10:40:56 - progress_bar.py[line:274] - INFO: epoch 001:    520 / 28910 loss=0.587, loss_v1=0, loss_v2=0, nll_loss=0.499, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.6, ups=0.89, wpb=111.5, bsz=40, num_updates=520, lr=5.62162e-06, gnorm=1.741, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=601
2022-10-13 10:41:07 - progress_bar.py[line:274] - INFO: epoch 001:    530 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=103.3, ups=0.93, wpb=111, bsz=40, num_updates=530, lr=5.72973e-06, gnorm=1.779, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=612
2022-10-13 10:41:18 - progress_bar.py[line:274] - INFO: epoch 001:    540 / 28910 loss=0.584, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.6, ups=0.9, wpb=110.1, bsz=40, num_updates=540, lr=5.83784e-06, gnorm=1.766, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=623
2022-10-13 10:41:29 - progress_bar.py[line:274] - INFO: epoch 001:    550 / 28910 loss=0.616, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.4, ups=0.91, wpb=110.9, bsz=40, num_updates=550, lr=5.94595e-06, gnorm=1.818, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=634
2022-10-13 10:41:40 - progress_bar.py[line:274] - INFO: epoch 001:    560 / 28910 loss=0.63, loss_v1=0, loss_v2=0, nll_loss=0.546, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=102.4, ups=0.93, wpb=110.1, bsz=40, num_updates=560, lr=6.05405e-06, gnorm=1.805, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=645
2022-10-13 10:41:51 - progress_bar.py[line:274] - INFO: epoch 001:    570 / 28910 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.505, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=570, lr=6.16216e-06, gnorm=1.562, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=656
2022-10-13 10:42:02 - progress_bar.py[line:274] - INFO: epoch 001:    580 / 28910 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.4, ups=0.89, wpb=111.1, bsz=40, num_updates=580, lr=6.27027e-06, gnorm=1.614, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=667
2022-10-13 10:42:13 - progress_bar.py[line:274] - INFO: epoch 001:    590 / 28910 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.506, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=101.4, ups=0.9, wpb=112.1, bsz=40, num_updates=590, lr=6.37838e-06, gnorm=1.94, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=678
2022-10-13 10:42:25 - progress_bar.py[line:274] - INFO: epoch 001:    600 / 28910 loss=0.598, loss_v1=0, loss_v2=0, nll_loss=0.515, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=96.2, ups=0.87, wpb=110.4, bsz=40, num_updates=600, lr=6.48649e-06, gnorm=1.747, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=690
2022-10-13 10:42:36 - progress_bar.py[line:274] - INFO: epoch 001:    610 / 28910 loss=0.602, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.7, ups=0.89, wpb=109.4, bsz=40, num_updates=610, lr=6.59459e-06, gnorm=1.63, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=701
2022-10-13 10:42:47 - progress_bar.py[line:274] - INFO: epoch 001:    620 / 28910 loss=0.58, loss_v1=0, loss_v2=0, nll_loss=0.495, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.2, ups=0.9, wpb=109.6, bsz=40, num_updates=620, lr=6.7027e-06, gnorm=1.592, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=712
2022-10-13 10:42:58 - progress_bar.py[line:274] - INFO: epoch 001:    630 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.49, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=101, ups=0.9, wpb=111.7, bsz=40, num_updates=630, lr=6.81081e-06, gnorm=1.655, clip=100, loss_scale=256, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=723
2022-10-13 10:43:10 - progress_bar.py[line:274] - INFO: epoch 001:    640 / 28910 loss=0.629, loss_v1=0, loss_v2=0, nll_loss=0.541, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.45, wps=95.3, ups=0.87, wpb=109.8, bsz=40, num_updates=640, lr=6.91892e-06, gnorm=1.897, clip=100, loss_scale=256, train_wall=11, gb_free=11, ema_decay=0.9999, wall=735
2022-10-13 10:43:21 - progress_bar.py[line:274] - INFO: epoch 001:    650 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.524, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=96.8, ups=0.88, wpb=110.1, bsz=40, num_updates=650, lr=7.02703e-06, gnorm=1.727, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=746
2022-10-13 10:43:32 - progress_bar.py[line:274] - INFO: epoch 001:    660 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.479, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.6, ups=0.88, wpb=110.6, bsz=40, num_updates=660, lr=7.13514e-06, gnorm=1.649, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=757
2022-10-13 10:43:43 - progress_bar.py[line:274] - INFO: epoch 001:    670 / 28910 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.502, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=99.3, ups=0.9, wpb=109.8, bsz=40, num_updates=670, lr=7.24324e-06, gnorm=1.588, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=768
2022-10-13 10:43:55 - progress_bar.py[line:274] - INFO: epoch 001:    680 / 28910 loss=0.656, loss_v1=0, loss_v2=0, nll_loss=0.572, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.49, wps=98.1, ups=0.9, wpb=109.6, bsz=40, num_updates=680, lr=7.35135e-06, gnorm=1.797, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=780
2022-10-13 10:44:06 - progress_bar.py[line:274] - INFO: epoch 001:    690 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.8, ups=0.92, wpb=109.9, bsz=40, num_updates=690, lr=7.45946e-06, gnorm=1.654, clip=100, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=790
2022-10-13 10:44:16 - progress_bar.py[line:274] - INFO: epoch 001:    700 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=106.2, ups=0.94, wpb=112.4, bsz=40, num_updates=700, lr=7.56757e-06, gnorm=1.605, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=801
2022-10-13 10:44:27 - progress_bar.py[line:274] - INFO: epoch 001:    710 / 28910 loss=0.594, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=96.7, ups=0.88, wpb=110, bsz=40, num_updates=710, lr=7.67568e-06, gnorm=1.865, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=812
2022-10-13 10:44:39 - progress_bar.py[line:274] - INFO: epoch 001:    720 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.6, ups=0.88, wpb=110.5, bsz=40, num_updates=720, lr=7.78378e-06, gnorm=1.758, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=824
2022-10-13 10:44:50 - progress_bar.py[line:274] - INFO: epoch 001:    730 / 28910 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.519, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=730, lr=7.89189e-06, gnorm=1.94, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=835
2022-10-13 10:45:01 - progress_bar.py[line:274] - INFO: epoch 001:    740 / 28910 loss=0.624, loss_v1=0, loss_v2=0, nll_loss=0.543, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=96, ups=0.87, wpb=109.9, bsz=40, num_updates=740, lr=8e-06, gnorm=1.724, clip=100, loss_scale=256, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=846
2022-10-13 10:45:13 - progress_bar.py[line:274] - INFO: epoch 001:    750 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=94.1, ups=0.84, wpb=111.6, bsz=40, num_updates=750, lr=8.10811e-06, gnorm=1.499, clip=100, loss_scale=256, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=858
2022-10-13 10:45:24 - progress_bar.py[line:274] - INFO: epoch 001:    760 / 28910 loss=0.607, loss_v1=0, loss_v2=0, nll_loss=0.516, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=100.1, ups=0.91, wpb=109.4, bsz=40, num_updates=760, lr=8.21622e-06, gnorm=1.788, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=869
2022-10-13 10:45:35 - progress_bar.py[line:274] - INFO: epoch 001:    770 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.1, ups=0.9, wpb=111.8, bsz=40, num_updates=770, lr=8.32432e-06, gnorm=1.73, clip=100, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=880
2022-10-13 10:45:47 - progress_bar.py[line:274] - INFO: epoch 001:    780 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=780, lr=8.43243e-06, gnorm=1.756, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=892
2022-10-13 10:45:58 - progress_bar.py[line:274] - INFO: epoch 001:    790 / 28910 loss=0.608, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=790, lr=8.54054e-06, gnorm=1.833, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=903
2022-10-13 10:46:09 - progress_bar.py[line:274] - INFO: epoch 001:    800 / 28910 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.1, ups=0.9, wpb=108.7, bsz=40, num_updates=800, lr=8.64865e-06, gnorm=1.719, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=914
2022-10-13 10:46:20 - progress_bar.py[line:274] - INFO: epoch 001:    810 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.8, ups=0.92, wpb=110.1, bsz=40, num_updates=810, lr=8.75676e-06, gnorm=1.585, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=925
2022-10-13 10:46:30 - progress_bar.py[line:274] - INFO: epoch 001:    820 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=106.7, ups=0.97, wpb=110.3, bsz=40, num_updates=820, lr=8.86486e-06, gnorm=1.488, clip=100, loss_scale=256, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=935
2022-10-13 10:46:41 - progress_bar.py[line:274] - INFO: epoch 001:    830 / 28910 loss=0.609, loss_v1=0, loss_v2=0, nll_loss=0.526, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=100.8, ups=0.9, wpb=111.5, bsz=40, num_updates=830, lr=8.97297e-06, gnorm=1.87, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=946
2022-10-13 10:46:53 - progress_bar.py[line:274] - INFO: epoch 001:    840 / 28910 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.465, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.7, ups=0.89, wpb=110.4, bsz=40, num_updates=840, lr=9.08108e-06, gnorm=1.788, clip=100, loss_scale=256, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=957
2022-10-13 10:47:04 - progress_bar.py[line:274] - INFO: epoch 001:    850 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=94.9, ups=0.86, wpb=109.9, bsz=40, num_updates=850, lr=9.18919e-06, gnorm=1.688, clip=100, loss_scale=256, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=969
2022-10-13 10:47:15 - progress_bar.py[line:274] - INFO: epoch 001:    860 / 28910 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.1, ups=0.89, wpb=111, bsz=40, num_updates=860, lr=9.2973e-06, gnorm=1.613, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=980
2022-10-13 10:47:27 - progress_bar.py[line:274] - INFO: epoch 001:    870 / 28910 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.497, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=870, lr=9.40541e-06, gnorm=1.674, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=992
2022-10-13 10:47:38 - progress_bar.py[line:274] - INFO: epoch 001:    880 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.481, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98, ups=0.89, wpb=109.8, bsz=40, num_updates=880, lr=9.51351e-06, gnorm=1.544, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1003
2022-10-13 10:47:49 - progress_bar.py[line:274] - INFO: epoch 001:    890 / 28910 loss=0.563, loss_v1=0, loss_v2=0, nll_loss=0.468, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.4, ups=0.9, wpb=112.1, bsz=40, num_updates=890, lr=9.62162e-06, gnorm=1.486, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1014
2022-10-13 10:48:00 - progress_bar.py[line:274] - INFO: epoch 001:    900 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=900, lr=9.72973e-06, gnorm=1.615, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1025
2022-10-13 10:48:11 - progress_bar.py[line:274] - INFO: epoch 001:    910 / 28910 loss=0.6, loss_v1=0, loss_v2=0, nll_loss=0.508, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=910, lr=9.83784e-06, gnorm=1.677, clip=100, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=1036
2022-10-13 10:48:23 - progress_bar.py[line:274] - INFO: epoch 001:    920 / 28910 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.489, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.7, ups=0.89, wpb=111.7, bsz=40, num_updates=920, lr=9.94595e-06, gnorm=1.44, clip=100, loss_scale=256, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=1048
2022-10-13 10:48:34 - progress_bar.py[line:274] - INFO: epoch 001:    930 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.6, ups=0.88, wpb=111.3, bsz=40, num_updates=930, lr=1.00541e-05, gnorm=1.389, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1059
2022-10-13 10:48:45 - progress_bar.py[line:274] - INFO: epoch 001:    940 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.46, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=940, lr=1.01622e-05, gnorm=1.533, clip=100, loss_scale=256, train_wall=11, gb_free=10, ema_decay=0.9999, wall=1070
2022-10-13 10:48:56 - progress_bar.py[line:274] - INFO: epoch 001:    950 / 28910 loss=0.611, loss_v1=0, loss_v2=0, nll_loss=0.525, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=99.3, ups=0.9, wpb=109.8, bsz=40, num_updates=950, lr=1.02703e-05, gnorm=1.684, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1081
2022-10-13 10:49:07 - progress_bar.py[line:274] - INFO: epoch 001:    960 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.9, ups=0.89, wpb=109, bsz=40, num_updates=960, lr=1.03784e-05, gnorm=1.539, clip=100, loss_scale=256, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=1092
2022-10-13 10:49:19 - progress_bar.py[line:274] - INFO: epoch 001:    970 / 28910 loss=0.588, loss_v1=0, loss_v2=0, nll_loss=0.5, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=970, lr=1.04865e-05, gnorm=1.654, clip=100, loss_scale=256, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=1104
2022-10-13 10:49:30 - progress_bar.py[line:274] - INFO: epoch 001:    980 / 28910 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.5, ups=0.88, wpb=109.6, bsz=40, num_updates=980, lr=1.05946e-05, gnorm=1.501, clip=100, loss_scale=256, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=1115
2022-10-13 10:49:41 - progress_bar.py[line:274] - INFO: epoch 001:    990 / 28910 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=102.2, ups=0.92, wpb=111.3, bsz=40, num_updates=990, lr=1.07027e-05, gnorm=1.595, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1126
2022-10-13 10:49:52 - progress_bar.py[line:274] - INFO: epoch 001:   1000 / 28910 loss=0.554, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.3, ups=0.9, wpb=112.1, bsz=40, num_updates=1000, lr=1.08108e-05, gnorm=1.451, clip=100, loss_scale=256, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=1137
2022-10-13 10:49:52 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 10:49:52 - tsv_file.py[line:93] - INFO: loading lineidx: /data/private/yutianyu/OFA/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2022-10-13 10:49:53 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 10:49:53 - train.py[line:551] - INFO: load:0.81 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 10:52:28 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 10:52:28 - train.py[line:551] - INFO: load:0.84 valid_run:154.63 task_valid:150.89 collect_output:2.68
2022-10-13 10:54:57 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 10:54:57 - train.py[line:551] - INFO: load:0.86 valid_run:303.33 task_valid:294.25 collect_output:6.96
2022-10-13 10:57:30 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 10:57:30 - train.py[line:551] - INFO: load:0.88 valid_run:456.06 task_valid:437.28 collect_output:15.67
2022-10-13 10:59:59 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 10:59:59 - train.py[line:551] - INFO: load:0.91 valid_run:604.99 task_valid:582.28 collect_output:18.55
2022-10-13 11:02:31 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 11:02:31 - train.py[line:551] - INFO: load:0.93 valid_run:757.10 task_valid:729.72 collect_output:22.19
2022-10-13 11:05:03 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 11:05:03 - train.py[line:551] - INFO: load:0.96 valid_run:908.83 task_valid:875.29 collect_output:27.34
2022-10-13 11:07:36 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 11:07:36 - train.py[line:551] - INFO: load:0.98 valid_run:1061.95 task_valid:1021.20 collect_output:33.54
2022-10-13 11:10:07 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 11:10:07 - train.py[line:551] - INFO: load:1.01 valid_run:1212.97 task_valid:1162.26 collect_output:42.48
2022-10-13 11:12:37 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 11:12:37 - train.py[line:551] - INFO: load:1.05 valid_run:1362.78 task_valid:1307.52 collect_output:45.98
2022-10-13 11:15:06 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 11:15:06 - train.py[line:551] - INFO: load:1.08 valid_run:1511.96 task_valid:1451.45 collect_output:50.03
2022-10-13 11:17:36 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 11:17:36 - train.py[line:551] - INFO: load:1.10 valid_run:1662.21 task_valid:1597.05 collect_output:53.53
2022-10-13 11:20:07 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 11:20:07 - train.py[line:551] - INFO: load:1.13 valid_run:1812.79 task_valid:1742.80 collect_output:57.17
2022-10-13 11:22:37 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 11:22:37 - train.py[line:551] - INFO: load:1.16 valid_run:1962.98 task_valid:1885.31 collect_output:63.69
2022-10-13 11:25:09 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 11:25:09 - train.py[line:551] - INFO: load:1.18 valid_run:2114.21 task_valid:2031.64 collect_output:67.36
2022-10-13 11:27:39 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 11:27:39 - train.py[line:551] - INFO: load:1.21 valid_run:2265.03 task_valid:2178.89 collect_output:69.74
2022-10-13 11:30:10 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 11:30:10 - train.py[line:551] - INFO: load:1.24 valid_run:2415.53 task_valid:2323.77 collect_output:74.26
2022-10-13 11:32:42 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 11:32:42 - train.py[line:551] - INFO: load:1.26 valid_run:2567.60 task_valid:2470.10 collect_output:78.80
2022-10-13 11:35:13 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 11:35:13 - train.py[line:551] - INFO: load:1.29 valid_run:2718.78 task_valid:2617.90 collect_output:81.02
2022-10-13 11:37:43 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 11:37:43 - train.py[line:551] - INFO: load:1.33 valid_run:2868.13 task_valid:2760.97 collect_output:86.12
2022-10-13 11:40:14 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 11:40:14 - train.py[line:551] - INFO: load:1.36 valid_run:3019.04 task_valid:2907.13 collect_output:89.69
2022-10-13 11:42:46 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 11:42:46 - train.py[line:551] - INFO: load:1.39 valid_run:3170.95 task_valid:3051.94 collect_output:95.72
2022-10-13 11:45:15 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 11:45:15 - train.py[line:551] - INFO: load:1.41 valid_run:3320.38 task_valid:3196.71 collect_output:99.35
2022-10-13 11:47:47 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 11:47:47 - train.py[line:551] - INFO: load:1.44 valid_run:3471.63 task_valid:3343.10 collect_output:103.18
2022-10-13 11:50:18 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 11:50:18 - train.py[line:551] - INFO: load:1.46 valid_run:3622.92 task_valid:3489.65 collect_output:106.87

====================================================================================================
SGG eval:     R @ 50: 0.1540;     R @ 100: 0.2420;     R @ 500: 0.3305;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0710;    mR @ 100: 0.1251;    mR @ 500: 0.1752;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0171) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.2069) (says:0.0000) (sitting on:0.2840) (standing on:0.4700) (using:0.1500) (walking in:0.0000) (walking on:0.0270) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1540;     R @ 100: 0.2420;     R @ 500: 0.3305;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0710;    mR @ 100: 0.1251;    mR @ 500: 0.1752;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0171) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.2069) (says:0.0000) (sitting on:0.2840) (standing on:0.4700) (using:0.1500) (walking in:0.0000) (walking on:0.0270) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2022-10-13 11:52:48 - train.py[line:487] - INFO: 0.242
2022-10-13 11:52:48 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 11:52:48 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.346 | loss_v1 0 | loss_v2 0 | nll_loss 0.21 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.242 | ppl 1.16 | vqa_score 0.1633 | wps 118.9 | wpb 89.9 | bsz 30 | num_updates 1000
2022-10-13 11:52:48 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1000 updates
2022-10-13 11:52:48 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-13 11:52:54 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt
2022-10-13 11:52:59 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 0.242) (writing took 10.76417200313881 seconds)
2022-10-13 11:53:10 - progress_bar.py[line:274] - INFO: epoch 001:   1010 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.488, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=0.3, ups=0, wpb=109.3, bsz=40, num_updates=1010, lr=1.09189e-05, gnorm=1.625, clip=100, loss_scale=256, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4935
2022-10-13 11:53:21 - progress_bar.py[line:274] - INFO: epoch 001:   1020 / 28910 loss=0.606, loss_v1=0, loss_v2=0, nll_loss=0.518, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.43, wps=97.4, ups=0.88, wpb=110.6, bsz=40, num_updates=1020, lr=1.1027e-05, gnorm=1.446, clip=100, loss_scale=256, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=4946
2022-10-13 11:53:33 - progress_bar.py[line:274] - INFO: epoch 001:   1030 / 28910 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.1, ups=0.89, wpb=111.2, bsz=40, num_updates=1030, lr=1.11351e-05, gnorm=1.539, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4958
2022-10-13 11:53:44 - progress_bar.py[line:274] - INFO: epoch 001:   1040 / 28910 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=1040, lr=1.12432e-05, gnorm=1.505, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=4969
2022-10-13 11:53:55 - progress_bar.py[line:274] - INFO: epoch 001:   1050 / 28910 loss=0.576, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.9, ups=0.88, wpb=111.2, bsz=40, num_updates=1050, lr=1.13514e-05, gnorm=1.522, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=4980
2022-10-13 11:54:06 - progress_bar.py[line:274] - INFO: epoch 001:   1060 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.487, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.4, ups=0.91, wpb=108.6, bsz=40, num_updates=1060, lr=1.14595e-05, gnorm=1.563, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=4991
2022-10-13 11:54:18 - progress_bar.py[line:274] - INFO: epoch 001:   1070 / 28910 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=96.7, ups=0.87, wpb=111, bsz=40, num_updates=1070, lr=1.15676e-05, gnorm=1.61, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5003
2022-10-13 11:54:29 - progress_bar.py[line:274] - INFO: epoch 001:   1080 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.3, ups=0.87, wpb=110.8, bsz=40, num_updates=1080, lr=1.16757e-05, gnorm=1.558, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5014
2022-10-13 11:54:40 - progress_bar.py[line:274] - INFO: epoch 001:   1090 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.6, ups=0.92, wpb=109.7, bsz=40, num_updates=1090, lr=1.17838e-05, gnorm=1.597, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5025
2022-10-13 11:54:51 - progress_bar.py[line:274] - INFO: epoch 001:   1100 / 28910 loss=0.579, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=100.9, ups=0.91, wpb=110.4, bsz=40, num_updates=1100, lr=1.18919e-05, gnorm=1.551, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5036
2022-10-13 11:55:03 - progress_bar.py[line:274] - INFO: epoch 001:   1110 / 28910 loss=0.613, loss_v1=0, loss_v2=0, nll_loss=0.522, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.44, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=1110, lr=1.2e-05, gnorm=1.737, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5048
2022-10-13 11:55:14 - progress_bar.py[line:274] - INFO: epoch 001:   1120 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=97.3, ups=0.88, wpb=110, bsz=40, num_updates=1120, lr=1.21081e-05, gnorm=1.725, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5059
2022-10-13 11:55:25 - progress_bar.py[line:274] - INFO: epoch 001:   1130 / 28910 loss=0.567, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=102.3, ups=0.92, wpb=110.7, bsz=40, num_updates=1130, lr=1.22162e-05, gnorm=1.46, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5070
2022-10-13 11:55:36 - progress_bar.py[line:274] - INFO: epoch 001:   1140 / 28910 loss=0.591, loss_v1=0, loss_v2=0, nll_loss=0.503, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=100.6, ups=0.91, wpb=110.6, bsz=40, num_updates=1140, lr=1.23243e-05, gnorm=1.437, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5081
2022-10-13 11:55:47 - progress_bar.py[line:274] - INFO: epoch 001:   1150 / 28910 loss=0.589, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=1150, lr=1.24324e-05, gnorm=1.538, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5092
2022-10-13 11:55:58 - progress_bar.py[line:274] - INFO: epoch 001:   1160 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.4, ups=0.93, wpb=110, bsz=40, num_updates=1160, lr=1.25405e-05, gnorm=1.452, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5103
2022-10-13 11:56:09 - progress_bar.py[line:274] - INFO: epoch 001:   1170 / 28910 loss=0.562, loss_v1=0, loss_v2=0, nll_loss=0.461, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.7, ups=0.9, wpb=110.3, bsz=40, num_updates=1170, lr=1.26486e-05, gnorm=1.533, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5114
2022-10-13 11:56:20 - progress_bar.py[line:274] - INFO: epoch 001:   1180 / 28910 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98.7, ups=0.89, wpb=110.3, bsz=40, num_updates=1180, lr=1.27568e-05, gnorm=1.754, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5125
2022-10-13 11:56:32 - progress_bar.py[line:274] - INFO: epoch 001:   1190 / 28910 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.4, ups=0.88, wpb=108.9, bsz=40, num_updates=1190, lr=1.28649e-05, gnorm=1.762, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5137
2022-10-13 11:56:43 - progress_bar.py[line:274] - INFO: epoch 001:   1200 / 28910 loss=0.586, loss_v1=0, loss_v2=0, nll_loss=0.494, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=99.4, ups=0.91, wpb=109.8, bsz=40, num_updates=1200, lr=1.2973e-05, gnorm=1.742, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5148
2022-10-13 11:56:54 - progress_bar.py[line:274] - INFO: epoch 001:   1210 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.475, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.5, ups=0.89, wpb=109.1, bsz=40, num_updates=1210, lr=1.30811e-05, gnorm=1.506, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5159
2022-10-13 11:57:05 - progress_bar.py[line:274] - INFO: epoch 001:   1220 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.9, wpb=110.1, bsz=40, num_updates=1220, lr=1.31892e-05, gnorm=1.591, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5170
2022-10-13 11:57:16 - progress_bar.py[line:274] - INFO: epoch 001:   1230 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.5, ups=0.88, wpb=111.3, bsz=40, num_updates=1230, lr=1.32973e-05, gnorm=1.456, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5181
2022-10-13 11:57:27 - progress_bar.py[line:274] - INFO: epoch 001:   1240 / 28910 loss=0.592, loss_v1=0, loss_v2=0, nll_loss=0.492, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=98.2, ups=0.9, wpb=108.6, bsz=40, num_updates=1240, lr=1.34054e-05, gnorm=1.513, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5192
2022-10-13 11:57:39 - progress_bar.py[line:274] - INFO: epoch 001:   1250 / 28910 loss=0.577, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=95.9, ups=0.88, wpb=108.5, bsz=40, num_updates=1250, lr=1.35135e-05, gnorm=1.51, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5204
2022-10-13 11:57:50 - progress_bar.py[line:274] - INFO: epoch 001:   1260 / 28910 loss=0.59, loss_v1=0, loss_v2=0, nll_loss=0.496, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.41, wps=96.8, ups=0.88, wpb=109.5, bsz=40, num_updates=1260, lr=1.36216e-05, gnorm=1.869, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5215
2022-10-13 11:58:01 - progress_bar.py[line:274] - INFO: epoch 001:   1270 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.462, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=101.2, ups=0.92, wpb=110.2, bsz=40, num_updates=1270, lr=1.37297e-05, gnorm=1.501, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5226
2022-10-13 11:58:12 - progress_bar.py[line:274] - INFO: epoch 001:   1280 / 28910 loss=0.601, loss_v1=0, loss_v2=0, nll_loss=0.509, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.42, wps=98.3, ups=0.89, wpb=110, bsz=40, num_updates=1280, lr=1.38378e-05, gnorm=1.653, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5237
2022-10-13 11:58:23 - progress_bar.py[line:274] - INFO: epoch 001:   1290 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.9, ups=0.9, wpb=109.4, bsz=40, num_updates=1290, lr=1.39459e-05, gnorm=1.603, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5248
2022-10-13 11:58:35 - progress_bar.py[line:274] - INFO: epoch 001:   1300 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.5, ups=0.87, wpb=111.9, bsz=40, num_updates=1300, lr=1.40541e-05, gnorm=1.623, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5260
2022-10-13 11:58:46 - progress_bar.py[line:274] - INFO: epoch 001:   1310 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=1310, lr=1.41622e-05, gnorm=1.316, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5271
2022-10-13 11:58:58 - progress_bar.py[line:274] - INFO: epoch 001:   1320 / 28910 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=1320, lr=1.42703e-05, gnorm=1.524, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5282
2022-10-13 11:59:09 - progress_bar.py[line:274] - INFO: epoch 001:   1330 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100, ups=0.9, wpb=110.8, bsz=40, num_updates=1330, lr=1.43784e-05, gnorm=1.389, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5294
2022-10-13 11:59:20 - progress_bar.py[line:274] - INFO: epoch 001:   1340 / 28910 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.7, ups=0.91, wpb=112.1, bsz=40, num_updates=1340, lr=1.44865e-05, gnorm=1.398, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5305
2022-10-13 11:59:31 - progress_bar.py[line:274] - INFO: epoch 001:   1350 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.1, ups=0.87, wpb=110.5, bsz=40, num_updates=1350, lr=1.45946e-05, gnorm=1.606, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5316
2022-10-13 11:59:42 - progress_bar.py[line:274] - INFO: epoch 001:   1360 / 28910 loss=0.574, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=102, ups=0.92, wpb=111, bsz=40, num_updates=1360, lr=1.47027e-05, gnorm=1.463, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5327
2022-10-13 11:59:54 - progress_bar.py[line:274] - INFO: epoch 001:   1370 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.457, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.3, ups=0.9, wpb=109.7, bsz=40, num_updates=1370, lr=1.48108e-05, gnorm=1.51, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5339
2022-10-13 12:00:04 - progress_bar.py[line:274] - INFO: epoch 001:   1380 / 28910 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=105.3, ups=0.96, wpb=110.2, bsz=40, num_updates=1380, lr=1.49189e-05, gnorm=1.448, clip=100, loss_scale=512, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=5349
2022-10-13 12:00:15 - progress_bar.py[line:274] - INFO: epoch 001:   1390 / 28910 loss=0.566, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99.3, ups=0.91, wpb=109.7, bsz=40, num_updates=1390, lr=1.5027e-05, gnorm=1.427, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5360
2022-10-13 12:00:26 - progress_bar.py[line:274] - INFO: epoch 001:   1400 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.484, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.9, ups=0.9, wpb=109.3, bsz=40, num_updates=1400, lr=1.51351e-05, gnorm=1.498, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5371
2022-10-13 12:00:37 - progress_bar.py[line:274] - INFO: epoch 001:   1410 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.6, ups=0.91, wpb=110.9, bsz=40, num_updates=1410, lr=1.52432e-05, gnorm=1.355, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5382
2022-10-13 12:00:48 - progress_bar.py[line:274] - INFO: epoch 001:   1420 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.478, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.9, ups=0.92, wpb=110.2, bsz=40, num_updates=1420, lr=1.53514e-05, gnorm=1.337, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5393
2022-10-13 12:00:59 - progress_bar.py[line:274] - INFO: epoch 001:   1430 / 28910 loss=0.548, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.6, ups=0.91, wpb=109.8, bsz=40, num_updates=1430, lr=1.54595e-05, gnorm=1.413, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5404
2022-10-13 12:01:10 - progress_bar.py[line:274] - INFO: epoch 001:   1440 / 28910 loss=0.572, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=98.4, ups=0.91, wpb=108.6, bsz=40, num_updates=1440, lr=1.55676e-05, gnorm=1.336, clip=100, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=5415
2022-10-13 12:01:22 - progress_bar.py[line:274] - INFO: epoch 001:   1450 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=1450, lr=1.56757e-05, gnorm=1.358, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5426
2022-10-13 12:01:33 - progress_bar.py[line:274] - INFO: epoch 001:   1460 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.477, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=96.4, ups=0.88, wpb=109.1, bsz=40, num_updates=1460, lr=1.57838e-05, gnorm=1.409, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5438
2022-10-13 12:01:44 - progress_bar.py[line:274] - INFO: epoch 001:   1470 / 28910 loss=0.57, loss_v1=0, loss_v2=0, nll_loss=0.473, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=97.2, ups=0.88, wpb=110.7, bsz=40, num_updates=1470, lr=1.58919e-05, gnorm=1.381, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5449
2022-10-13 12:01:55 - progress_bar.py[line:274] - INFO: epoch 001:   1480 / 28910 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.2, ups=0.91, wpb=110.5, bsz=40, num_updates=1480, lr=1.6e-05, gnorm=1.336, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5460
2022-10-13 12:02:06 - progress_bar.py[line:274] - INFO: epoch 001:   1490 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=102.9, ups=0.93, wpb=110.8, bsz=40, num_updates=1490, lr=1.61081e-05, gnorm=1.365, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5471
2022-10-13 12:02:17 - progress_bar.py[line:274] - INFO: epoch 001:   1500 / 28910 loss=0.489, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.9, ups=0.89, wpb=111.8, bsz=40, num_updates=1500, lr=1.62162e-05, gnorm=1.25, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5482
2022-10-13 12:02:29 - progress_bar.py[line:274] - INFO: epoch 001:   1510 / 28910 loss=0.556, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.7, ups=0.88, wpb=110.6, bsz=40, num_updates=1510, lr=1.63243e-05, gnorm=1.545, clip=100, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=5494
2022-10-13 12:02:40 - progress_bar.py[line:274] - INFO: epoch 001:   1520 / 28910 loss=0.56, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98, ups=0.89, wpb=110.1, bsz=40, num_updates=1520, lr=1.64324e-05, gnorm=1.469, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5505
2022-10-13 12:02:51 - progress_bar.py[line:274] - INFO: epoch 001:   1530 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=102.3, ups=0.92, wpb=111.6, bsz=40, num_updates=1530, lr=1.65405e-05, gnorm=1.319, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5516
2022-10-13 12:03:00 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 12:03:03 - progress_bar.py[line:274] - INFO: epoch 001:   1541 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=88.3, ups=0.8, wpb=110.5, bsz=40, num_updates=1540, lr=1.66486e-05, gnorm=1.372, clip=100, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=5528
2022-10-13 12:03:14 - progress_bar.py[line:274] - INFO: epoch 001:   1551 / 28910 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.8, ups=0.92, wpb=110.9, bsz=40, num_updates=1550, lr=1.67568e-05, gnorm=1.262, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5539
2022-10-13 12:03:25 - progress_bar.py[line:274] - INFO: epoch 001:   1561 / 28910 loss=0.573, loss_v1=0, loss_v2=0, nll_loss=0.482, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.3, ups=0.91, wpb=109.5, bsz=40, num_updates=1560, lr=1.68649e-05, gnorm=1.411, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5550
2022-10-13 12:03:36 - progress_bar.py[line:274] - INFO: epoch 001:   1571 / 28910 loss=0.582, loss_v1=0, loss_v2=0, nll_loss=0.483, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=99.6, ups=0.91, wpb=109.6, bsz=40, num_updates=1570, lr=1.6973e-05, gnorm=1.277, clip=90, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=5561
2022-10-13 12:03:48 - progress_bar.py[line:274] - INFO: epoch 001:   1581 / 28910 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.458, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=1580, lr=1.70811e-05, gnorm=1.311, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5572
2022-10-13 12:03:59 - progress_bar.py[line:274] - INFO: epoch 001:   1591 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.7, ups=0.9, wpb=111.4, bsz=40, num_updates=1590, lr=1.71892e-05, gnorm=1.216, clip=100, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5584
2022-10-13 12:04:10 - progress_bar.py[line:274] - INFO: epoch 001:   1601 / 28910 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.431, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.9, ups=0.88, wpb=111, bsz=40, num_updates=1600, lr=1.72973e-05, gnorm=1.197, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5595
2022-10-13 12:04:21 - progress_bar.py[line:274] - INFO: epoch 001:   1611 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.7, ups=0.88, wpb=109.4, bsz=40, num_updates=1610, lr=1.74054e-05, gnorm=1.302, clip=90, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5606
2022-10-13 12:04:32 - progress_bar.py[line:274] - INFO: epoch 001:   1621 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.45, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=1620, lr=1.75135e-05, gnorm=1.383, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5617
2022-10-13 12:04:44 - progress_bar.py[line:274] - INFO: epoch 001:   1631 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=1630, lr=1.76216e-05, gnorm=1.318, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5629
2022-10-13 12:04:55 - progress_bar.py[line:274] - INFO: epoch 001:   1641 / 28910 loss=0.571, loss_v1=0, loss_v2=0, nll_loss=0.471, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=100.1, ups=0.91, wpb=110.6, bsz=40, num_updates=1640, lr=1.77297e-05, gnorm=1.301, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5640
2022-10-13 12:05:06 - progress_bar.py[line:274] - INFO: epoch 001:   1651 / 28910 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.8, ups=0.9, wpb=110.5, bsz=40, num_updates=1650, lr=1.78378e-05, gnorm=1.351, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5651
2022-10-13 12:05:17 - progress_bar.py[line:274] - INFO: epoch 001:   1661 / 28910 loss=0.581, loss_v1=0, loss_v2=0, nll_loss=0.486, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=97.6, ups=0.88, wpb=110.8, bsz=40, num_updates=1660, lr=1.79459e-05, gnorm=1.312, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5662
2022-10-13 12:05:28 - progress_bar.py[line:274] - INFO: epoch 001:   1671 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.47, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=101.6, ups=0.92, wpb=110.6, bsz=40, num_updates=1670, lr=1.80541e-05, gnorm=1.257, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5673
2022-10-13 12:05:39 - progress_bar.py[line:274] - INFO: epoch 001:   1681 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.446, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.8, ups=0.89, wpb=109.6, bsz=40, num_updates=1680, lr=1.81622e-05, gnorm=1.337, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5684
2022-10-13 12:05:51 - progress_bar.py[line:274] - INFO: epoch 001:   1691 / 28910 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=1690, lr=1.82703e-05, gnorm=1.294, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5695
2022-10-13 12:06:02 - progress_bar.py[line:274] - INFO: epoch 001:   1701 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.5, ups=0.91, wpb=109.2, bsz=40, num_updates=1700, lr=1.83784e-05, gnorm=1.382, clip=100, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5706
2022-10-13 12:06:13 - progress_bar.py[line:274] - INFO: epoch 001:   1711 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=1710, lr=1.84865e-05, gnorm=1.505, clip=100, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=5718
2022-10-13 12:06:23 - progress_bar.py[line:274] - INFO: epoch 001:   1721 / 28910 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.7, ups=0.93, wpb=110.6, bsz=40, num_updates=1720, lr=1.85946e-05, gnorm=1.152, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5728
2022-10-13 12:06:35 - progress_bar.py[line:274] - INFO: epoch 001:   1731 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99, ups=0.9, wpb=110.6, bsz=40, num_updates=1730, lr=1.87027e-05, gnorm=1.189, clip=90, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5740
2022-10-13 12:06:46 - progress_bar.py[line:274] - INFO: epoch 001:   1741 / 28910 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=1740, lr=1.88108e-05, gnorm=1.208, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5751
2022-10-13 12:06:57 - progress_bar.py[line:274] - INFO: epoch 001:   1751 / 28910 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.429, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=1750, lr=1.89189e-05, gnorm=1.232, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5762
2022-10-13 12:07:08 - progress_bar.py[line:274] - INFO: epoch 001:   1761 / 28910 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.4, ups=0.89, wpb=111.2, bsz=40, num_updates=1760, lr=1.9027e-05, gnorm=1.18, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5773
2022-10-13 12:07:19 - progress_bar.py[line:274] - INFO: epoch 001:   1771 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.9, ups=0.91, wpb=110.3, bsz=40, num_updates=1770, lr=1.91351e-05, gnorm=1.102, clip=80, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=5784
2022-10-13 12:07:31 - progress_bar.py[line:274] - INFO: epoch 001:   1781 / 28910 loss=0.565, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96.2, ups=0.87, wpb=110.6, bsz=40, num_updates=1780, lr=1.92432e-05, gnorm=1.331, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5796
2022-10-13 12:07:42 - progress_bar.py[line:274] - INFO: epoch 001:   1791 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=1790, lr=1.93514e-05, gnorm=1.128, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5807
2022-10-13 12:07:53 - progress_bar.py[line:274] - INFO: epoch 001:   1801 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=1800, lr=1.94595e-05, gnorm=1.131, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5818
2022-10-13 12:08:04 - progress_bar.py[line:274] - INFO: epoch 001:   1811 / 28910 loss=0.578, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=98, ups=0.9, wpb=108.4, bsz=40, num_updates=1810, lr=1.95676e-05, gnorm=1.317, clip=100, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5829
2022-10-13 12:08:16 - progress_bar.py[line:274] - INFO: epoch 001:   1821 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.453, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=1820, lr=1.96757e-05, gnorm=1.212, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5840
2022-10-13 12:08:27 - progress_bar.py[line:274] - INFO: epoch 001:   1831 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.1, ups=0.91, wpb=108.3, bsz=40, num_updates=1830, lr=1.97838e-05, gnorm=1.344, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5852
2022-10-13 12:08:38 - progress_bar.py[line:274] - INFO: epoch 001:   1841 / 28910 loss=0.569, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96, ups=0.87, wpb=110.4, bsz=40, num_updates=1840, lr=1.98919e-05, gnorm=1.291, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5863
2022-10-13 12:08:49 - progress_bar.py[line:274] - INFO: epoch 001:   1851 / 28910 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=104.2, ups=0.93, wpb=111.9, bsz=40, num_updates=1850, lr=2e-05, gnorm=1.061, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5874
2022-10-13 12:09:00 - progress_bar.py[line:274] - INFO: epoch 001:   1861 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=99.1, ups=0.91, wpb=109, bsz=40, num_updates=1860, lr=2.01081e-05, gnorm=1.271, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5885
2022-10-13 12:09:11 - progress_bar.py[line:274] - INFO: epoch 001:   1871 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.3, ups=0.9, wpb=111.8, bsz=40, num_updates=1870, lr=2.02162e-05, gnorm=1.269, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5896
2022-10-13 12:09:22 - progress_bar.py[line:274] - INFO: epoch 001:   1881 / 28910 loss=0.528, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.3, ups=0.92, wpb=110.4, bsz=40, num_updates=1880, lr=2.03243e-05, gnorm=1.122, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=5907
2022-10-13 12:09:33 - progress_bar.py[line:274] - INFO: epoch 001:   1891 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=1890, lr=2.04324e-05, gnorm=1.235, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5918
2022-10-13 12:09:44 - progress_bar.py[line:274] - INFO: epoch 001:   1901 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.442, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.6, ups=0.89, wpb=109.2, bsz=40, num_updates=1900, lr=2.05405e-05, gnorm=1.218, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5929
2022-10-13 12:09:56 - progress_bar.py[line:274] - INFO: epoch 001:   1911 / 28910 loss=0.531, loss_v1=0, loss_v2=0, nll_loss=0.421, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.4, ups=0.89, wpb=109.2, bsz=40, num_updates=1910, lr=2.06486e-05, gnorm=1.332, clip=90, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=5941
2022-10-13 12:10:07 - progress_bar.py[line:274] - INFO: epoch 001:   1921 / 28910 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101.7, ups=0.92, wpb=110.9, bsz=40, num_updates=1920, lr=2.07568e-05, gnorm=1.424, clip=100, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=5951
2022-10-13 12:10:18 - progress_bar.py[line:274] - INFO: epoch 001:   1931 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.8, ups=0.88, wpb=110, bsz=40, num_updates=1930, lr=2.08649e-05, gnorm=1.315, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=5963
2022-10-13 12:10:29 - progress_bar.py[line:274] - INFO: epoch 001:   1941 / 28910 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.8, ups=0.88, wpb=110.4, bsz=40, num_updates=1940, lr=2.0973e-05, gnorm=1.135, clip=80, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=5974
2022-10-13 12:10:41 - progress_bar.py[line:274] - INFO: epoch 001:   1951 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.464, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=1950, lr=2.10811e-05, gnorm=1.191, clip=100, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=5985
2022-10-13 12:10:51 - progress_bar.py[line:274] - INFO: epoch 001:   1961 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.9, ups=0.92, wpb=108.9, bsz=40, num_updates=1960, lr=2.11892e-05, gnorm=1.179, clip=70, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=5996
2022-10-13 12:11:03 - progress_bar.py[line:274] - INFO: epoch 001:   1971 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.409, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.3, ups=0.88, wpb=110.3, bsz=40, num_updates=1970, lr=2.12973e-05, gnorm=1.137, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=6008
2022-10-13 12:11:14 - progress_bar.py[line:274] - INFO: epoch 001:   1981 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.2, ups=0.91, wpb=111.8, bsz=40, num_updates=1980, lr=2.14054e-05, gnorm=1.062, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6019
2022-10-13 12:11:25 - progress_bar.py[line:274] - INFO: epoch 001:   1991 / 28910 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.7, ups=0.91, wpb=111.2, bsz=40, num_updates=1990, lr=2.15135e-05, gnorm=1.219, clip=90, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=6030
2022-10-13 12:11:36 - progress_bar.py[line:274] - INFO: epoch 001:   2001 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.1, ups=0.9, wpb=109.5, bsz=40, num_updates=2000, lr=2.16216e-05, gnorm=1.185, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=6041
2022-10-13 12:11:36 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 12:11:37 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 12:11:37 - train.py[line:551] - INFO: load:0.82 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 12:14:09 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 12:14:09 - train.py[line:551] - INFO: load:0.85 valid_run:152.02 task_valid:147.88 collect_output:3.08
2022-10-13 12:16:38 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 12:16:38 - train.py[line:551] - INFO: load:0.87 valid_run:300.87 task_valid:291.15 collect_output:7.63
2022-10-13 12:19:11 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 12:19:11 - train.py[line:551] - INFO: load:0.90 valid_run:453.54 task_valid:434.03 collect_output:16.38
2022-10-13 12:21:40 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 12:21:40 - train.py[line:551] - INFO: load:0.92 valid_run:602.49 task_valid:578.94 collect_output:19.38
2022-10-13 12:24:12 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 12:24:12 - train.py[line:551] - INFO: load:0.95 valid_run:754.85 task_valid:726.40 collect_output:23.26
2022-10-13 12:26:44 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 12:26:44 - train.py[line:551] - INFO: load:0.97 valid_run:906.64 task_valid:872.13 collect_output:28.20
2022-10-13 12:29:18 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 12:29:18 - train.py[line:551] - INFO: load:1.01 valid_run:1060.04 task_valid:1018.74 collect_output:33.83
2022-10-13 12:31:49 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 12:31:49 - train.py[line:551] - INFO: load:1.03 valid_run:1211.75 task_valid:1160.49 collect_output:42.58
2022-10-13 12:34:19 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 12:34:19 - train.py[line:551] - INFO: load:1.06 valid_run:1361.56 task_valid:1305.66 collect_output:46.11
2022-10-13 12:36:48 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 12:36:48 - train.py[line:551] - INFO: load:1.08 valid_run:1510.53 task_valid:1449.34 collect_output:50.18
2022-10-13 12:39:19 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 12:39:19 - train.py[line:551] - INFO: load:1.11 valid_run:1660.86 task_valid:1594.89 collect_output:53.73
2022-10-13 12:41:49 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 12:41:49 - train.py[line:551] - INFO: load:1.13 valid_run:1811.45 task_valid:1740.47 collect_output:57.59
2022-10-13 12:44:20 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 12:44:20 - train.py[line:551] - INFO: load:1.16 valid_run:1961.64 task_valid:1882.74 collect_output:64.43
2022-10-13 12:46:50 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 12:46:50 - train.py[line:551] - INFO: load:1.18 valid_run:2112.41 task_valid:2028.76 collect_output:68.08
2022-10-13 12:49:21 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 12:49:21 - train.py[line:551] - INFO: load:1.21 valid_run:2263.02 task_valid:2175.78 collect_output:70.53
2022-10-13 12:51:51 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 12:51:51 - train.py[line:551] - INFO: load:1.24 valid_run:2413.29 task_valid:2320.46 collect_output:75.00
2022-10-13 12:54:24 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 12:54:24 - train.py[line:551] - INFO: load:1.26 valid_run:2565.42 task_valid:2466.63 collect_output:79.79
2022-10-13 12:56:54 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 12:56:54 - train.py[line:551] - INFO: load:1.29 valid_run:2716.20 task_valid:2614.04 collect_output:82.11
2022-10-13 12:59:23 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 12:59:23 - train.py[line:551] - INFO: load:1.31 valid_run:2864.45 task_valid:2755.79 collect_output:87.57
2022-10-13 13:01:53 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 13:01:53 - train.py[line:551] - INFO: load:1.34 valid_run:3014.69 task_valid:2900.98 collect_output:91.57
2022-10-13 13:04:25 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 13:04:25 - train.py[line:551] - INFO: load:1.37 valid_run:3166.46 task_valid:3045.75 collect_output:97.50
2022-10-13 13:06:54 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 13:06:54 - train.py[line:551] - INFO: load:1.39 valid_run:3315.92 task_valid:3190.30 collect_output:101.37
2022-10-13 13:09:26 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 13:09:26 - train.py[line:551] - INFO: load:1.42 valid_run:3467.06 task_valid:3336.56 collect_output:105.23
2022-10-13 13:11:57 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 13:11:57 - train.py[line:551] - INFO: load:1.44 valid_run:3618.44 task_valid:3483.18 collect_output:108.93

====================================================================================================
SGG eval:     R @ 50: 0.2890;     R @ 100: 0.3475;     R @ 500: 0.4275;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1343;    mR @ 100: 0.1859;    mR @ 500: 0.2271;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0634) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.4402) (says:0.0000) (sitting on:0.4376) (standing on:0.4150) (using:0.1500) (walking in:0.0000) (walking on:0.1982) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2890;     R @ 100: 0.3475;     R @ 500: 0.4275;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1343;    mR @ 100: 0.1859;    mR @ 500: 0.2271;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0634) (covered in:0.0000) (covering:0.1429) (eating:0.4706) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4839) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.4402) (says:0.0000) (sitting on:0.4376) (standing on:0.4150) (using:0.1500) (walking in:0.0000) (walking on:0.1982) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2022-10-13 13:14:27 - train.py[line:487] - INFO: 0.3475333333333333
2022-10-13 13:14:28 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 13:14:28 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.364 | loss_v1 0 | loss_v2 0 | nll_loss 0.219 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.347533 | ppl 1.16 | vqa_score 0.2027 | wps 119 | wpb 89.9 | bsz 30 | num_updates 2000 | best_R@100 0.347533
2022-10-13 13:14:28 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2022-10-13 13:14:28 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-13 13:14:33 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt
2022-10-13 13:14:38 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 0.3475333333333333) (writing took 10.477158833760768 seconds)
2022-10-13 13:14:49 - progress_bar.py[line:274] - INFO: epoch 001:   2011 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=2010, lr=2.17297e-05, gnorm=1.192, clip=90, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=9834
2022-10-13 13:15:00 - progress_bar.py[line:274] - INFO: epoch 001:   2021 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.9, ups=0.9, wpb=109.3, bsz=40, num_updates=2020, lr=2.18378e-05, gnorm=1.109, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=9845
2022-10-13 13:15:12 - progress_bar.py[line:274] - INFO: epoch 001:   2031 / 28910 loss=0.547, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.1, ups=0.88, wpb=110.3, bsz=40, num_updates=2030, lr=2.19459e-05, gnorm=1.247, clip=100, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9857
2022-10-13 13:15:23 - progress_bar.py[line:274] - INFO: epoch 001:   2041 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.6, ups=0.92, wpb=109.7, bsz=40, num_updates=2040, lr=2.20541e-05, gnorm=1.142, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=9868
2022-10-13 13:15:34 - progress_bar.py[line:274] - INFO: epoch 001:   2051 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.455, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.8, ups=0.9, wpb=109.7, bsz=40, num_updates=2050, lr=2.21622e-05, gnorm=1.165, clip=100, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=9879
2022-10-13 13:15:45 - progress_bar.py[line:274] - INFO: epoch 001:   2061 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=2060, lr=2.22703e-05, gnorm=1.113, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9890
2022-10-13 13:15:56 - progress_bar.py[line:274] - INFO: epoch 001:   2071 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.3, ups=0.9, wpb=108.5, bsz=40, num_updates=2070, lr=2.23784e-05, gnorm=1.168, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9901
2022-10-13 13:16:07 - progress_bar.py[line:274] - INFO: epoch 001:   2081 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=2080, lr=2.24865e-05, gnorm=1.113, clip=80, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9912
2022-10-13 13:16:18 - progress_bar.py[line:274] - INFO: epoch 001:   2091 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.4, ups=0.9, wpb=109.8, bsz=40, num_updates=2090, lr=2.25946e-05, gnorm=1.173, clip=80, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=9923
2022-10-13 13:16:30 - progress_bar.py[line:274] - INFO: epoch 001:   2101 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.4, ups=0.89, wpb=111.1, bsz=40, num_updates=2100, lr=2.27027e-05, gnorm=1.04, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=9935
2022-10-13 13:16:41 - progress_bar.py[line:274] - INFO: epoch 001:   2111 / 28910 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.441, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98, ups=0.89, wpb=109.7, bsz=40, num_updates=2110, lr=2.28108e-05, gnorm=1.084, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=9946
2022-10-13 13:16:52 - progress_bar.py[line:274] - INFO: epoch 001:   2121 / 28910 loss=0.568, loss_v1=0, loss_v2=0, nll_loss=0.469, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=96, ups=0.88, wpb=108.7, bsz=40, num_updates=2120, lr=2.29189e-05, gnorm=1.213, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=9957
2022-10-13 13:17:03 - progress_bar.py[line:274] - INFO: epoch 001:   2131 / 28910 loss=0.575, loss_v1=0, loss_v2=0, nll_loss=0.474, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.39, wps=99, ups=0.91, wpb=108.8, bsz=40, num_updates=2130, lr=2.3027e-05, gnorm=1.168, clip=90, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=9968
2022-10-13 13:17:04 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 13:17:16 - progress_bar.py[line:274] - INFO: epoch 001:   2142 / 28910 loss=0.555, loss_v1=0, loss_v2=0, nll_loss=0.463, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=87, ups=0.8, wpb=108.3, bsz=40, num_updates=2140, lr=2.31351e-05, gnorm=1.267, clip=90, loss_scale=512, train_wall=12, gb_free=11, ema_decay=0.9999, wall=9981
2022-10-13 13:17:27 - progress_bar.py[line:274] - INFO: epoch 001:   2152 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.8, ups=0.92, wpb=110.1, bsz=40, num_updates=2150, lr=2.32432e-05, gnorm=1.081, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=9992
2022-10-13 13:17:38 - progress_bar.py[line:274] - INFO: epoch 001:   2162 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=2160, lr=2.33514e-05, gnorm=1.263, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10003
2022-10-13 13:17:48 - progress_bar.py[line:274] - INFO: epoch 001:   2172 / 28910 loss=0.558, loss_v1=0, loss_v2=0, nll_loss=0.454, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=101.4, ups=0.93, wpb=109.2, bsz=40, num_updates=2170, lr=2.34595e-05, gnorm=1.169, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10013
2022-10-13 13:18:00 - progress_bar.py[line:274] - INFO: epoch 001:   2182 / 28910 loss=0.552, loss_v1=0, loss_v2=0, nll_loss=0.452, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=97.2, ups=0.87, wpb=111.4, bsz=40, num_updates=2180, lr=2.35676e-05, gnorm=1.131, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10025
2022-10-13 13:18:11 - progress_bar.py[line:274] - INFO: epoch 001:   2192 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.9, ups=0.9, wpb=110.4, bsz=40, num_updates=2190, lr=2.36757e-05, gnorm=1.163, clip=100, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10036
2022-10-13 13:18:22 - progress_bar.py[line:274] - INFO: epoch 001:   2202 / 28910 loss=0.524, loss_v1=0, loss_v2=0, nll_loss=0.422, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.3, ups=0.92, wpb=109.4, bsz=40, num_updates=2200, lr=2.37838e-05, gnorm=1.152, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10047
2022-10-13 13:18:33 - progress_bar.py[line:274] - INFO: epoch 001:   2212 / 28910 loss=0.535, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.2, ups=0.88, wpb=111.2, bsz=40, num_updates=2210, lr=2.38919e-05, gnorm=1.321, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10058
2022-10-13 13:18:44 - progress_bar.py[line:274] - INFO: epoch 001:   2222 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.4, ups=0.91, wpb=109.7, bsz=40, num_updates=2220, lr=2.4e-05, gnorm=1.183, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10069
2022-10-13 13:18:56 - progress_bar.py[line:274] - INFO: epoch 001:   2232 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.5, ups=0.88, wpb=110.5, bsz=40, num_updates=2230, lr=2.41081e-05, gnorm=1.203, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10081
2022-10-13 13:19:07 - progress_bar.py[line:274] - INFO: epoch 001:   2242 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=95.1, ups=0.87, wpb=109.2, bsz=40, num_updates=2240, lr=2.42162e-05, gnorm=1.093, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10092
2022-10-13 13:19:18 - progress_bar.py[line:274] - INFO: epoch 001:   2252 / 28910 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.444, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=2250, lr=2.43243e-05, gnorm=1.067, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10103
2022-10-13 13:19:30 - progress_bar.py[line:274] - INFO: epoch 001:   2262 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.4, ups=0.89, wpb=112, bsz=40, num_updates=2260, lr=2.44324e-05, gnorm=1.068, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10115
2022-10-13 13:19:41 - progress_bar.py[line:274] - INFO: epoch 001:   2272 / 28910 loss=0.509, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.6, ups=0.9, wpb=111.1, bsz=40, num_updates=2270, lr=2.45405e-05, gnorm=1.033, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10126
2022-10-13 13:19:52 - progress_bar.py[line:274] - INFO: epoch 001:   2282 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=2280, lr=2.46486e-05, gnorm=1.025, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10137
2022-10-13 13:20:03 - progress_bar.py[line:274] - INFO: epoch 001:   2292 / 28910 loss=0.543, loss_v1=0, loss_v2=0, nll_loss=0.437, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.8, ups=0.92, wpb=110.8, bsz=40, num_updates=2290, lr=2.47568e-05, gnorm=1.021, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10148
2022-10-13 13:20:14 - progress_bar.py[line:274] - INFO: epoch 001:   2302 / 28910 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.2, ups=0.9, wpb=109.4, bsz=40, num_updates=2300, lr=2.48649e-05, gnorm=1.082, clip=70, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10159
2022-10-13 13:20:25 - progress_bar.py[line:274] - INFO: epoch 001:   2312 / 28910 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=101, ups=0.92, wpb=110.3, bsz=40, num_updates=2310, lr=2.4973e-05, gnorm=1.063, clip=70, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10170
2022-10-13 13:20:36 - progress_bar.py[line:274] - INFO: epoch 001:   2322 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.7, ups=0.9, wpb=108.9, bsz=40, num_updates=2320, lr=2.50811e-05, gnorm=1.088, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10181
2022-10-13 13:20:48 - progress_bar.py[line:274] - INFO: epoch 001:   2332 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.6, ups=0.88, wpb=109.3, bsz=40, num_updates=2330, lr=2.51892e-05, gnorm=1.128, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10192
2022-10-13 13:20:58 - progress_bar.py[line:274] - INFO: epoch 001:   2342 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=103, ups=0.93, wpb=110.4, bsz=40, num_updates=2340, lr=2.52973e-05, gnorm=1.022, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10203
2022-10-13 13:21:10 - progress_bar.py[line:274] - INFO: epoch 001:   2352 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.1, ups=0.87, wpb=110.2, bsz=40, num_updates=2350, lr=2.54054e-05, gnorm=1.061, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10215
2022-10-13 13:21:21 - progress_bar.py[line:274] - INFO: epoch 001:   2362 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.1, ups=0.89, wpb=109.6, bsz=40, num_updates=2360, lr=2.55135e-05, gnorm=1.143, clip=90, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10226
2022-10-13 13:21:32 - progress_bar.py[line:274] - INFO: epoch 001:   2372 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.7, ups=0.9, wpb=111.2, bsz=40, num_updates=2370, lr=2.56216e-05, gnorm=0.974, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10237
2022-10-13 13:21:43 - progress_bar.py[line:274] - INFO: epoch 001:   2382 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100, ups=0.9, wpb=111.1, bsz=40, num_updates=2380, lr=2.57297e-05, gnorm=1.061, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10248
2022-10-13 13:21:55 - progress_bar.py[line:274] - INFO: epoch 001:   2392 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.2, ups=0.88, wpb=110.1, bsz=40, num_updates=2390, lr=2.58378e-05, gnorm=1.186, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10259
2022-10-13 13:22:06 - progress_bar.py[line:274] - INFO: epoch 001:   2402 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.8, ups=0.89, wpb=109.5, bsz=40, num_updates=2400, lr=2.59459e-05, gnorm=1.181, clip=90, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10271
2022-10-13 13:22:17 - progress_bar.py[line:274] - INFO: epoch 001:   2412 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=2410, lr=2.60541e-05, gnorm=1.1, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10282
2022-10-13 13:22:28 - progress_bar.py[line:274] - INFO: epoch 001:   2422 / 28910 loss=0.561, loss_v1=0, loss_v2=0, nll_loss=0.466, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=2420, lr=2.61622e-05, gnorm=1.195, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10293
2022-10-13 13:22:39 - progress_bar.py[line:274] - INFO: epoch 001:   2432 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.397, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.7, ups=0.92, wpb=110.9, bsz=40, num_updates=2430, lr=2.62703e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10304
2022-10-13 13:22:50 - progress_bar.py[line:274] - INFO: epoch 001:   2442 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.3, ups=0.91, wpb=111.9, bsz=40, num_updates=2440, lr=2.63784e-05, gnorm=0.968, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10315
2022-10-13 13:23:01 - progress_bar.py[line:274] - INFO: epoch 001:   2452 / 28910 loss=0.546, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.2, ups=0.91, wpb=109.5, bsz=40, num_updates=2450, lr=2.64865e-05, gnorm=1.125, clip=90, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10326
2022-10-13 13:23:12 - progress_bar.py[line:274] - INFO: epoch 001:   2462 / 28910 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.415, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=103.1, ups=0.93, wpb=110.9, bsz=40, num_updates=2460, lr=2.65946e-05, gnorm=1.196, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=10337
2022-10-13 13:23:23 - progress_bar.py[line:274] - INFO: epoch 001:   2472 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.6, ups=0.88, wpb=111.8, bsz=40, num_updates=2470, lr=2.67027e-05, gnorm=1.09, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10348
2022-10-13 13:23:34 - progress_bar.py[line:274] - INFO: epoch 001:   2482 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.1, ups=0.9, wpb=109.5, bsz=40, num_updates=2480, lr=2.68108e-05, gnorm=1.056, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10359
2022-10-13 13:23:46 - progress_bar.py[line:274] - INFO: epoch 001:   2492 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.411, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.6, ups=0.88, wpb=111.5, bsz=40, num_updates=2490, lr=2.69189e-05, gnorm=1.144, clip=80, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10371
2022-10-13 13:23:57 - progress_bar.py[line:274] - INFO: epoch 001:   2502 / 28910 loss=0.538, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.2, ups=0.89, wpb=110.8, bsz=40, num_updates=2500, lr=2.7027e-05, gnorm=1.247, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10382
2022-10-13 13:24:08 - progress_bar.py[line:274] - INFO: epoch 001:   2512 / 28910 loss=0.559, loss_v1=0, loss_v2=0, nll_loss=0.448, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=99.8, ups=0.9, wpb=110.3, bsz=40, num_updates=2510, lr=2.71351e-05, gnorm=1.106, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10393
2022-10-13 13:24:19 - progress_bar.py[line:274] - INFO: epoch 001:   2522 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.7, ups=0.88, wpb=109.9, bsz=40, num_updates=2520, lr=2.72432e-05, gnorm=0.993, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10404
2022-10-13 13:24:31 - progress_bar.py[line:274] - INFO: epoch 001:   2532 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.3, ups=0.87, wpb=110.4, bsz=40, num_updates=2530, lr=2.73514e-05, gnorm=0.997, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10416
2022-10-13 13:24:42 - progress_bar.py[line:274] - INFO: epoch 001:   2542 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=102.2, ups=0.92, wpb=111, bsz=40, num_updates=2540, lr=2.74595e-05, gnorm=0.948, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10427
2022-10-13 13:24:53 - progress_bar.py[line:274] - INFO: epoch 001:   2552 / 28910 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.439, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.1, ups=0.92, wpb=108.7, bsz=40, num_updates=2550, lr=2.75676e-05, gnorm=1.085, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10437
2022-10-13 13:25:04 - progress_bar.py[line:274] - INFO: epoch 001:   2562 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.7, ups=0.89, wpb=111.7, bsz=40, num_updates=2560, lr=2.76757e-05, gnorm=0.956, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10449
2022-10-13 13:25:15 - progress_bar.py[line:274] - INFO: epoch 001:   2572 / 28910 loss=0.545, loss_v1=0, loss_v2=0, nll_loss=0.436, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=100.8, ups=0.91, wpb=111.3, bsz=40, num_updates=2570, lr=2.77838e-05, gnorm=1.022, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10460
2022-10-13 13:25:26 - progress_bar.py[line:274] - INFO: epoch 001:   2582 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.9, ups=0.87, wpb=110, bsz=40, num_updates=2580, lr=2.78919e-05, gnorm=1.007, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10471
2022-10-13 13:25:37 - progress_bar.py[line:274] - INFO: epoch 001:   2592 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.3, ups=0.9, wpb=109.8, bsz=40, num_updates=2590, lr=2.8e-05, gnorm=0.977, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10482
2022-10-13 13:25:49 - progress_bar.py[line:274] - INFO: epoch 001:   2602 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=98.4, ups=0.88, wpb=111.2, bsz=40, num_updates=2600, lr=2.81081e-05, gnorm=1.063, clip=50, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=10494
2022-10-13 13:26:00 - progress_bar.py[line:274] - INFO: epoch 001:   2612 / 28910 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.3, ups=0.87, wpb=111.2, bsz=40, num_updates=2610, lr=2.82162e-05, gnorm=1.056, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10505
2022-10-13 13:26:12 - progress_bar.py[line:274] - INFO: epoch 001:   2622 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.8, ups=0.88, wpb=111.9, bsz=40, num_updates=2620, lr=2.83243e-05, gnorm=1.061, clip=70, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10516
2022-10-13 13:26:23 - progress_bar.py[line:274] - INFO: epoch 001:   2632 / 28910 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=2630, lr=2.84324e-05, gnorm=0.952, clip=40, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=10528
2022-10-13 13:26:34 - progress_bar.py[line:274] - INFO: epoch 001:   2642 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=2640, lr=2.85405e-05, gnorm=1.038, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10539
2022-10-13 13:26:45 - progress_bar.py[line:274] - INFO: epoch 001:   2652 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=2650, lr=2.86486e-05, gnorm=1.064, clip=70, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10550
2022-10-13 13:26:56 - progress_bar.py[line:274] - INFO: epoch 001:   2662 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=2660, lr=2.87568e-05, gnorm=1.012, clip=50, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10561
2022-10-13 13:27:07 - progress_bar.py[line:274] - INFO: epoch 001:   2672 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.449, ntokens=107.3, nsentences=40, sample_size=107.3, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=98.8, ups=0.92, wpb=107.3, bsz=40, num_updates=2670, lr=2.88649e-05, gnorm=1.093, clip=70, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10572
2022-10-13 13:27:18 - progress_bar.py[line:274] - INFO: epoch 001:   2682 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.6, ups=0.88, wpb=110.4, bsz=40, num_updates=2680, lr=2.8973e-05, gnorm=0.978, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10583
2022-10-13 13:27:30 - progress_bar.py[line:274] - INFO: epoch 001:   2692 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.6, ups=0.88, wpb=110.4, bsz=40, num_updates=2690, lr=2.90811e-05, gnorm=1.197, clip=80, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10595
2022-10-13 13:27:41 - progress_bar.py[line:274] - INFO: epoch 001:   2702 / 28910 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.402, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100.3, ups=0.91, wpb=110.7, bsz=40, num_updates=2700, lr=2.91892e-05, gnorm=1.013, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10606
2022-10-13 13:27:52 - progress_bar.py[line:274] - INFO: epoch 001:   2712 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=2710, lr=2.92973e-05, gnorm=0.94, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10617
2022-10-13 13:27:54 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 13:28:04 - progress_bar.py[line:274] - INFO: epoch 001:   2723 / 28910 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=92.9, ups=0.84, wpb=110.8, bsz=40, num_updates=2720, lr=2.94054e-05, gnorm=1.019, clip=60, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=10629
2022-10-13 13:28:16 - progress_bar.py[line:274] - INFO: epoch 001:   2733 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=108.2, nsentences=40, sample_size=108.2, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=94.2, ups=0.87, wpb=108.2, bsz=40, num_updates=2730, lr=2.95135e-05, gnorm=1.009, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10640
2022-10-13 13:28:27 - progress_bar.py[line:274] - INFO: epoch 001:   2743 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.403, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.2, ups=0.9, wpb=110.5, bsz=40, num_updates=2740, lr=2.96216e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10652
2022-10-13 13:28:38 - progress_bar.py[line:274] - INFO: epoch 001:   2753 / 28910 loss=0.54, loss_v1=0, loss_v2=0, nll_loss=0.435, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=101.1, ups=0.92, wpb=110.1, bsz=40, num_updates=2750, lr=2.97297e-05, gnorm=0.929, clip=50, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10663
2022-10-13 13:28:49 - progress_bar.py[line:274] - INFO: epoch 001:   2763 / 28910 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.3, ups=0.9, wpb=109.6, bsz=40, num_updates=2760, lr=2.98378e-05, gnorm=1.012, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10674
2022-10-13 13:29:00 - progress_bar.py[line:274] - INFO: epoch 001:   2773 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.91, wpb=110.2, bsz=40, num_updates=2770, lr=2.99459e-05, gnorm=0.956, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10685
2022-10-13 13:29:11 - progress_bar.py[line:274] - INFO: epoch 001:   2783 / 28910 loss=0.549, loss_v1=0, loss_v2=0, nll_loss=0.445, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=2780, lr=3.00541e-05, gnorm=1.139, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10696
2022-10-13 13:29:22 - progress_bar.py[line:274] - INFO: epoch 001:   2793 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.9, ups=0.89, wpb=111.8, bsz=40, num_updates=2790, lr=3.01622e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10707
2022-10-13 13:29:33 - progress_bar.py[line:274] - INFO: epoch 001:   2803 / 28910 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.9, ups=0.9, wpb=111.5, bsz=40, num_updates=2800, lr=3.02703e-05, gnorm=0.917, clip=30, loss_scale=512, train_wall=11, gb_free=11.5, ema_decay=0.9999, wall=10718
2022-10-13 13:29:44 - progress_bar.py[line:274] - INFO: epoch 001:   2813 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.7, ups=0.88, wpb=111.7, bsz=40, num_updates=2810, lr=3.03784e-05, gnorm=0.938, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=10729
2022-10-13 13:29:55 - progress_bar.py[line:274] - INFO: epoch 001:   2823 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=101.7, ups=0.92, wpb=111.1, bsz=40, num_updates=2820, lr=3.04865e-05, gnorm=1.003, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=10740
2022-10-13 13:30:07 - progress_bar.py[line:274] - INFO: epoch 001:   2833 / 28910 loss=0.512, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.4, ups=0.89, wpb=110.1, bsz=40, num_updates=2830, lr=3.05946e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10752
2022-10-13 13:30:17 - progress_bar.py[line:274] - INFO: epoch 001:   2843 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.412, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=103, ups=0.92, wpb=111.7, bsz=40, num_updates=2840, lr=3.07027e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10762
2022-10-13 13:30:28 - progress_bar.py[line:274] - INFO: epoch 001:   2853 / 28910 loss=0.539, loss_v1=0, loss_v2=0, nll_loss=0.432, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=102.2, ups=0.93, wpb=110.4, bsz=40, num_updates=2850, lr=3.08108e-05, gnorm=1.044, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10773
2022-10-13 13:30:39 - progress_bar.py[line:274] - INFO: epoch 001:   2863 / 28910 loss=0.544, loss_v1=0, loss_v2=0, nll_loss=0.443, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.5, ups=0.89, wpb=109, bsz=40, num_updates=2860, lr=3.09189e-05, gnorm=1.02, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10784
2022-10-13 13:30:51 - progress_bar.py[line:274] - INFO: epoch 001:   2873 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.4, ups=0.9, wpb=109.7, bsz=40, num_updates=2870, lr=3.1027e-05, gnorm=0.965, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10796
2022-10-13 13:31:02 - progress_bar.py[line:274] - INFO: epoch 001:   2883 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.3, ups=0.87, wpb=110.6, bsz=40, num_updates=2880, lr=3.11351e-05, gnorm=0.932, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10807
2022-10-13 13:31:13 - progress_bar.py[line:274] - INFO: epoch 001:   2893 / 28910 loss=0.529, loss_v1=0, loss_v2=0, nll_loss=0.419, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=2890, lr=3.12432e-05, gnorm=0.974, clip=40, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=10818
2022-10-13 13:31:24 - progress_bar.py[line:274] - INFO: epoch 001:   2903 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=2900, lr=3.13514e-05, gnorm=0.942, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10829
2022-10-13 13:31:36 - progress_bar.py[line:274] - INFO: epoch 001:   2913 / 28910 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.7, ups=0.87, wpb=110.9, bsz=40, num_updates=2910, lr=3.14595e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10841
2022-10-13 13:31:47 - progress_bar.py[line:274] - INFO: epoch 001:   2923 / 28910 loss=0.49, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102, ups=0.92, wpb=110.6, bsz=40, num_updates=2920, lr=3.15676e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10852
2022-10-13 13:31:58 - progress_bar.py[line:274] - INFO: epoch 001:   2933 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.386, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.2, ups=0.91, wpb=110.5, bsz=40, num_updates=2930, lr=3.16757e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10863
2022-10-13 13:32:09 - progress_bar.py[line:274] - INFO: epoch 001:   2943 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.91, wpb=110.5, bsz=40, num_updates=2940, lr=3.17838e-05, gnorm=0.946, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=10874
2022-10-13 13:32:20 - progress_bar.py[line:274] - INFO: epoch 001:   2953 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.396, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=99.7, ups=0.9, wpb=111.3, bsz=40, num_updates=2950, lr=3.18919e-05, gnorm=1.012, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10885
2022-10-13 13:32:31 - progress_bar.py[line:274] - INFO: epoch 001:   2963 / 28910 loss=0.542, loss_v1=0, loss_v2=0, nll_loss=0.44, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.36, wps=97.1, ups=0.88, wpb=110.2, bsz=40, num_updates=2960, lr=3.2e-05, gnorm=0.894, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10896
2022-10-13 13:32:42 - progress_bar.py[line:274] - INFO: epoch 001:   2973 / 28910 loss=0.553, loss_v1=0, loss_v2=0, nll_loss=0.456, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=98.9, ups=0.9, wpb=109.3, bsz=40, num_updates=2970, lr=3.21081e-05, gnorm=0.909, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=10907
2022-10-13 13:32:53 - progress_bar.py[line:274] - INFO: epoch 001:   2983 / 28910 loss=0.557, loss_v1=0, loss_v2=0, nll_loss=0.459, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.37, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=2980, lr=3.22162e-05, gnorm=0.972, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10918
2022-10-13 13:33:05 - progress_bar.py[line:274] - INFO: epoch 001:   2993 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.3, ups=0.9, wpb=110.9, bsz=40, num_updates=2990, lr=3.23243e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=10929
2022-10-13 13:33:16 - progress_bar.py[line:274] - INFO: epoch 001:   3003 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=3000, lr=3.24324e-05, gnorm=0.89, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=10941
2022-10-13 13:33:16 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 13:33:17 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 13:33:17 - train.py[line:551] - INFO: load:0.93 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 13:35:48 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 13:35:48 - train.py[line:551] - INFO: load:0.95 valid_run:151.49 task_valid:147.87 collect_output:2.59
2022-10-13 13:38:17 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 13:38:17 - train.py[line:551] - INFO: load:0.98 valid_run:300.04 task_valid:291.29 collect_output:6.72
2022-10-13 13:40:49 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 13:40:49 - train.py[line:551] - INFO: load:1.00 valid_run:452.46 task_valid:434.97 collect_output:14.24
2022-10-13 13:43:19 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 13:43:19 - train.py[line:551] - INFO: load:1.02 valid_run:602.10 task_valid:580.59 collect_output:17.10
2022-10-13 13:45:52 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 13:45:52 - train.py[line:551] - INFO: load:1.05 valid_run:754.94 task_valid:728.80 collect_output:20.59
2022-10-13 13:48:24 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 13:48:24 - train.py[line:551] - INFO: load:1.08 valid_run:907.07 task_valid:875.09 collect_output:25.25
2022-10-13 13:50:58 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 13:50:58 - train.py[line:551] - INFO: load:1.10 valid_run:1060.47 task_valid:1021.79 collect_output:30.85
2022-10-13 13:53:29 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 13:53:29 - train.py[line:551] - INFO: load:1.13 valid_run:1211.78 task_valid:1163.50 collect_output:39.33
2022-10-13 13:55:59 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 13:55:59 - train.py[line:551] - INFO: load:1.15 valid_run:1362.07 task_valid:1308.86 collect_output:43.15
2022-10-13 13:58:29 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 13:58:29 - train.py[line:551] - INFO: load:1.18 valid_run:1511.23 task_valid:1452.76 collect_output:47.19
2022-10-13 14:00:59 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 14:00:59 - train.py[line:551] - INFO: load:1.20 valid_run:1661.68 task_valid:1598.53 collect_output:50.73
2022-10-13 14:03:30 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 14:03:30 - train.py[line:551] - INFO: load:1.23 valid_run:1812.18 task_valid:1744.28 collect_output:54.34
2022-10-13 14:06:00 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 14:06:00 - train.py[line:551] - INFO: load:1.26 valid_run:1962.52 task_valid:1886.86 collect_output:60.87
2022-10-13 14:08:31 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 14:08:31 - train.py[line:551] - INFO: load:1.29 valid_run:2113.50 task_valid:2032.98 collect_output:64.64
2022-10-13 14:11:01 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 14:11:01 - train.py[line:551] - INFO: load:1.31 valid_run:2263.43 task_valid:2179.44 collect_output:67.11
2022-10-13 14:13:31 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 14:13:31 - train.py[line:551] - INFO: load:1.34 valid_run:2413.50 task_valid:2323.62 collect_output:71.95
2022-10-13 14:16:03 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 14:16:03 - train.py[line:551] - INFO: load:1.36 valid_run:2564.95 task_valid:2469.27 collect_output:76.70
2022-10-13 14:18:33 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 14:18:33 - train.py[line:551] - INFO: load:1.39 valid_run:2715.43 task_valid:2616.20 collect_output:79.22
2022-10-13 14:21:02 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 14:21:02 - train.py[line:551] - INFO: load:1.41 valid_run:2863.98 task_valid:2758.04 collect_output:84.85
2022-10-13 14:23:32 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 14:23:32 - train.py[line:551] - INFO: load:1.43 valid_run:3014.26 task_valid:2903.41 collect_output:88.72
2022-10-13 14:26:04 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 14:26:04 - train.py[line:551] - INFO: load:1.46 valid_run:3166.04 task_valid:3048.16 collect_output:94.68
2022-10-13 14:28:34 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 14:28:34 - train.py[line:551] - INFO: load:1.48 valid_run:3315.44 task_valid:3192.81 collect_output:98.39
2022-10-13 14:31:05 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 14:31:05 - train.py[line:551] - INFO: load:1.51 valid_run:3466.65 task_valid:3339.11 collect_output:102.28
2022-10-13 14:33:36 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 14:33:36 - train.py[line:551] - INFO: load:1.53 valid_run:3617.93 task_valid:3485.66 collect_output:105.94

====================================================================================================
SGG eval:     R @ 50: 0.3980;     R @ 100: 0.4613;     R @ 500: 0.5378;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1963;    mR @ 100: 0.2701;    mR @ 500: 0.3398;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2537) (covered in:0.1250) (covering:0.3714) (eating:0.4853) (flying in:0.5909) (growing on:0.1250) (hanging from:0.4194) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.4167) (playing:0.0000) (riding:0.6775) (says:0.0000) (sitting on:0.5697) (standing on:0.4100) (using:0.3000) (walking in:0.0000) (walking on:0.4054) (watching:0.0694) 
--------------------------------------------------------
====================================================================================================

2022-10-13 14:36:07 - train.py[line:487] - INFO: 0.4612731601731601

====================================================================================================
SGG eval:     R @ 50: 0.3980;     R @ 100: 0.4613;     R @ 500: 0.5378;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1963;    mR @ 100: 0.2701;    mR @ 500: 0.3398;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2537) (covered in:0.1250) (covering:0.3714) (eating:0.4853) (flying in:0.5909) (growing on:0.1250) (hanging from:0.4194) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.4167) (playing:0.0000) (riding:0.6775) (says:0.0000) (sitting on:0.5697) (standing on:0.4100) (using:0.3000) (walking in:0.0000) (walking on:0.4054) (watching:0.0694) 
--------------------------------------------------------
====================================================================================================

2022-10-13 14:36:07 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 14:36:07 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.372 | loss_v1 0 | loss_v2 0 | nll_loss 0.226 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.461273 | ppl 1.17 | vqa_score 0.259 | wps 119 | wpb 89.9 | bsz 30 | num_updates 3000 | best_R@100 0.461273
2022-10-13 14:36:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3000 updates
2022-10-13 14:36:07 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-13 14:36:12 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt
2022-10-13 14:36:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 0.4612731601731601) (writing took 11.038537597749382 seconds)
2022-10-13 14:36:29 - progress_bar.py[line:274] - INFO: epoch 001:   3013 / 28910 loss=0.52, loss_v1=0, loss_v2=0, nll_loss=0.418, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=0.3, ups=0, wpb=109.9, bsz=40, num_updates=3010, lr=3.25405e-05, gnorm=1.144, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14733
2022-10-13 14:36:40 - progress_bar.py[line:274] - INFO: epoch 001:   3023 / 28910 loss=0.534, loss_v1=0, loss_v2=0, nll_loss=0.427, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=3020, lr=3.26486e-05, gnorm=0.949, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14745
2022-10-13 14:36:51 - progress_bar.py[line:274] - INFO: epoch 001:   3033 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.9, ups=0.91, wpb=111.5, bsz=40, num_updates=3030, lr=3.27568e-05, gnorm=0.943, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14756
2022-10-13 14:37:02 - progress_bar.py[line:274] - INFO: epoch 001:   3043 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.404, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.6, ups=0.9, wpb=109, bsz=40, num_updates=3040, lr=3.28649e-05, gnorm=0.976, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14767
2022-10-13 14:37:13 - progress_bar.py[line:274] - INFO: epoch 001:   3053 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.4, ups=0.92, wpb=110.5, bsz=40, num_updates=3050, lr=3.2973e-05, gnorm=0.954, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14778
2022-10-13 14:37:24 - progress_bar.py[line:274] - INFO: epoch 001:   3063 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.369, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.5, ups=0.89, wpb=111.4, bsz=40, num_updates=3060, lr=3.30811e-05, gnorm=0.84, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14789
2022-10-13 14:37:35 - progress_bar.py[line:274] - INFO: epoch 001:   3073 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.3, ups=0.92, wpb=109.5, bsz=40, num_updates=3070, lr=3.31892e-05, gnorm=0.974, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14800
2022-10-13 14:37:46 - progress_bar.py[line:274] - INFO: epoch 001:   3083 / 28910 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.428, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=3080, lr=3.32973e-05, gnorm=0.975, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14811
2022-10-13 14:37:57 - progress_bar.py[line:274] - INFO: epoch 001:   3093 / 28910 loss=0.482, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=3090, lr=3.34054e-05, gnorm=0.817, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14822
2022-10-13 14:38:08 - progress_bar.py[line:274] - INFO: epoch 001:   3103 / 28910 loss=0.536, loss_v1=0, loss_v2=0, nll_loss=0.43, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=99.3, ups=0.91, wpb=109.7, bsz=40, num_updates=3100, lr=3.35135e-05, gnorm=0.931, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14833
2022-10-13 14:38:20 - progress_bar.py[line:274] - INFO: epoch 001:   3113 / 28910 loss=0.537, loss_v1=0, loss_v2=0, nll_loss=0.434, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=97.4, ups=0.89, wpb=109, bsz=40, num_updates=3110, lr=3.36216e-05, gnorm=0.918, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=14845
2022-10-13 14:38:31 - progress_bar.py[line:274] - INFO: epoch 001:   3123 / 28910 loss=0.519, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.6, ups=0.87, wpb=111.1, bsz=40, num_updates=3120, lr=3.37297e-05, gnorm=0.927, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14856
2022-10-13 14:38:42 - progress_bar.py[line:274] - INFO: epoch 001:   3133 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.373, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=102.8, ups=0.92, wpb=111.2, bsz=40, num_updates=3130, lr=3.38378e-05, gnorm=0.818, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14867
2022-10-13 14:38:53 - progress_bar.py[line:274] - INFO: epoch 001:   3143 / 28910 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97, ups=0.88, wpb=109.8, bsz=40, num_updates=3140, lr=3.39459e-05, gnorm=0.858, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14878
2022-10-13 14:39:04 - progress_bar.py[line:274] - INFO: epoch 001:   3153 / 28910 loss=0.514, loss_v1=0, loss_v2=0, nll_loss=0.406, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=100.6, ups=0.92, wpb=109.9, bsz=40, num_updates=3150, lr=3.40541e-05, gnorm=0.849, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14889
2022-10-13 14:39:16 - progress_bar.py[line:274] - INFO: epoch 001:   3163 / 28910 loss=0.51, loss_v1=0, loss_v2=0, nll_loss=0.4, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=95.3, ups=0.87, wpb=109.5, bsz=40, num_updates=3160, lr=3.41622e-05, gnorm=1.033, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=14901
2022-10-13 14:39:27 - progress_bar.py[line:274] - INFO: epoch 001:   3173 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.6, ups=0.9, wpb=110.2, bsz=40, num_updates=3170, lr=3.42703e-05, gnorm=0.933, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14912
2022-10-13 14:39:38 - progress_bar.py[line:274] - INFO: epoch 001:   3183 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.383, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=3180, lr=3.43784e-05, gnorm=0.957, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=14923
2022-10-13 14:39:49 - progress_bar.py[line:274] - INFO: epoch 001:   3193 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.8, ups=0.89, wpb=109.4, bsz=40, num_updates=3190, lr=3.44865e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=14934
2022-10-13 14:40:00 - progress_bar.py[line:274] - INFO: epoch 001:   3203 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.425, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=99.5, ups=0.91, wpb=109.6, bsz=40, num_updates=3200, lr=3.45946e-05, gnorm=1.055, clip=60, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=14945
2022-10-13 14:40:12 - progress_bar.py[line:274] - INFO: epoch 001:   3213 / 28910 loss=0.541, loss_v1=0, loss_v2=0, nll_loss=0.438, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.35, wps=96.4, ups=0.88, wpb=109.4, bsz=40, num_updates=3210, lr=3.47027e-05, gnorm=0.927, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=14957
2022-10-13 14:40:23 - progress_bar.py[line:274] - INFO: epoch 001:   3223 / 28910 loss=0.53, loss_v1=0, loss_v2=0, nll_loss=0.426, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=96.8, ups=0.89, wpb=108.4, bsz=40, num_updates=3220, lr=3.48108e-05, gnorm=0.976, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=14968
2022-10-13 14:40:34 - progress_bar.py[line:274] - INFO: epoch 001:   3233 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.381, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=101.3, ups=0.91, wpb=111.7, bsz=40, num_updates=3230, lr=3.49189e-05, gnorm=0.921, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=14979
2022-10-13 14:40:45 - progress_bar.py[line:274] - INFO: epoch 001:   3243 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.7, ups=0.89, wpb=109.3, bsz=40, num_updates=3240, lr=3.5027e-05, gnorm=0.903, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=14990
2022-10-13 14:40:56 - progress_bar.py[line:274] - INFO: epoch 001:   3253 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=3250, lr=3.51351e-05, gnorm=0.906, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15001
2022-10-13 14:41:08 - progress_bar.py[line:274] - INFO: epoch 001:   3263 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.7, ups=0.88, wpb=109.3, bsz=40, num_updates=3260, lr=3.52432e-05, gnorm=0.947, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15013
2022-10-13 14:41:19 - progress_bar.py[line:274] - INFO: epoch 001:   3273 / 28910 loss=0.533, loss_v1=0, loss_v2=0, nll_loss=0.423, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=100.8, ups=0.92, wpb=109.8, bsz=40, num_updates=3270, lr=3.53514e-05, gnorm=0.986, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15024
2022-10-13 14:41:30 - progress_bar.py[line:274] - INFO: epoch 001:   3283 / 28910 loss=0.502, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98, ups=0.89, wpb=109.9, bsz=40, num_updates=3280, lr=3.54595e-05, gnorm=0.876, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15035
2022-10-13 14:41:40 - progress_bar.py[line:274] - INFO: epoch 001:   3293 / 28910 loss=0.501, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=104.6, ups=0.96, wpb=109.5, bsz=40, num_updates=3290, lr=3.55676e-05, gnorm=0.859, clip=20, loss_scale=1024, train_wall=10, gb_free=10.6, ema_decay=0.9999, wall=15045
2022-10-13 14:41:51 - progress_bar.py[line:274] - INFO: epoch 001:   3303 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=3300, lr=3.56757e-05, gnorm=1.003, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15056
2022-10-13 14:42:03 - progress_bar.py[line:274] - INFO: epoch 001:   3313 / 28910 loss=0.508, loss_v1=0, loss_v2=0, nll_loss=0.398, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=100, ups=0.91, wpb=110.4, bsz=40, num_updates=3310, lr=3.57838e-05, gnorm=1.062, clip=60, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15067
2022-10-13 14:42:14 - progress_bar.py[line:274] - INFO: epoch 001:   3323 / 28910 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.8, ups=0.88, wpb=110.7, bsz=40, num_updates=3320, lr=3.58919e-05, gnorm=0.936, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15079
2022-10-13 14:42:25 - progress_bar.py[line:274] - INFO: epoch 001:   3333 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.7, ups=0.91, wpb=111.1, bsz=40, num_updates=3330, lr=3.6e-05, gnorm=1.029, clip=50, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=15090
2022-10-13 14:42:36 - progress_bar.py[line:274] - INFO: epoch 001:   3343 / 28910 loss=0.516, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=95.2, ups=0.87, wpb=109.4, bsz=40, num_updates=3340, lr=3.61081e-05, gnorm=1.157, clip=90, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15101
2022-10-13 14:42:48 - progress_bar.py[line:274] - INFO: epoch 001:   3353 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=97, ups=0.87, wpb=111.3, bsz=40, num_updates=3350, lr=3.62162e-05, gnorm=0.894, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15113
2022-10-13 14:42:59 - progress_bar.py[line:274] - INFO: epoch 001:   3363 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.364, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101, ups=0.91, wpb=111.5, bsz=40, num_updates=3360, lr=3.63243e-05, gnorm=0.859, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15124
2022-10-13 14:43:10 - progress_bar.py[line:274] - INFO: epoch 001:   3373 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.8, ups=0.9, wpb=110.2, bsz=40, num_updates=3370, lr=3.64324e-05, gnorm=0.944, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15135
2022-10-13 14:43:21 - progress_bar.py[line:274] - INFO: epoch 001:   3383 / 28910 loss=0.532, loss_v1=0, loss_v2=0, nll_loss=0.424, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=98.3, ups=0.91, wpb=108.6, bsz=40, num_updates=3380, lr=3.65405e-05, gnorm=1.169, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15146
2022-10-13 14:43:32 - progress_bar.py[line:274] - INFO: epoch 001:   3393 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.9, ups=0.9, wpb=111.4, bsz=40, num_updates=3390, lr=3.66486e-05, gnorm=0.794, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15157
2022-10-13 14:43:44 - progress_bar.py[line:274] - INFO: epoch 001:   3403 / 28910 loss=0.525, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=98.3, ups=0.9, wpb=109.6, bsz=40, num_updates=3400, lr=3.67568e-05, gnorm=0.909, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15168
2022-10-13 14:43:55 - progress_bar.py[line:274] - INFO: epoch 001:   3413 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=100.1, ups=0.89, wpb=111.9, bsz=40, num_updates=3410, lr=3.68649e-05, gnorm=0.989, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15180
2022-10-13 14:44:06 - progress_bar.py[line:274] - INFO: epoch 001:   3423 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.385, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.9, ups=0.89, wpb=109.5, bsz=40, num_updates=3420, lr=3.6973e-05, gnorm=0.93, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15191
2022-10-13 14:44:17 - progress_bar.py[line:274] - INFO: epoch 001:   3433 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.8, ups=0.89, wpb=110.4, bsz=40, num_updates=3430, lr=3.70811e-05, gnorm=0.944, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15202
2022-10-13 14:44:28 - progress_bar.py[line:274] - INFO: epoch 001:   3443 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.5, ups=0.9, wpb=111, bsz=40, num_updates=3440, lr=3.71892e-05, gnorm=1.018, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15213
2022-10-13 14:44:33 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 14:44:40 - progress_bar.py[line:274] - INFO: epoch 001:   3454 / 28910 loss=0.521, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=89.5, ups=0.82, wpb=109.5, bsz=40, num_updates=3450, lr=3.72973e-05, gnorm=1.131, clip=70, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=15225
2022-10-13 14:44:51 - progress_bar.py[line:274] - INFO: epoch 001:   3464 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.7, ups=0.92, wpb=109.8, bsz=40, num_updates=3460, lr=3.74054e-05, gnorm=1.029, clip=60, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=15236
2022-10-13 14:45:03 - progress_bar.py[line:274] - INFO: epoch 001:   3474 / 28910 loss=0.503, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=3470, lr=3.75135e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15247
2022-10-13 14:45:14 - progress_bar.py[line:274] - INFO: epoch 001:   3484 / 28910 loss=0.487, loss_v1=0, loss_v2=0, nll_loss=0.376, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=99.5, ups=0.89, wpb=111.9, bsz=40, num_updates=3480, lr=3.76216e-05, gnorm=0.848, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15259
2022-10-13 14:45:25 - progress_bar.py[line:274] - INFO: epoch 001:   3494 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.7, ups=0.87, wpb=111.2, bsz=40, num_updates=3490, lr=3.77297e-05, gnorm=0.908, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15270
2022-10-13 14:45:36 - progress_bar.py[line:274] - INFO: epoch 001:   3504 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.6, ups=0.93, wpb=109.2, bsz=40, num_updates=3500, lr=3.78378e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15281
2022-10-13 14:45:47 - progress_bar.py[line:274] - INFO: epoch 001:   3514 / 28910 loss=0.515, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.6, ups=0.88, wpb=109.4, bsz=40, num_updates=3510, lr=3.79459e-05, gnorm=0.996, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15292
2022-10-13 14:45:59 - progress_bar.py[line:274] - INFO: epoch 001:   3524 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97, ups=0.89, wpb=108.7, bsz=40, num_updates=3520, lr=3.80541e-05, gnorm=0.978, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15304
2022-10-13 14:46:09 - progress_bar.py[line:274] - INFO: epoch 001:   3534 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.2, ups=0.92, wpb=110.1, bsz=40, num_updates=3530, lr=3.81622e-05, gnorm=1.042, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15314
2022-10-13 14:46:21 - progress_bar.py[line:274] - INFO: epoch 001:   3544 / 28910 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.372, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.6, ups=0.88, wpb=109.3, bsz=40, num_updates=3540, lr=3.82703e-05, gnorm=1.12, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15326
2022-10-13 14:46:32 - progress_bar.py[line:274] - INFO: epoch 001:   3554 / 28910 loss=0.522, loss_v1=0, loss_v2=0, nll_loss=0.41, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.9, ups=0.87, wpb=110.8, bsz=40, num_updates=3550, lr=3.83784e-05, gnorm=0.985, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15337
2022-10-13 14:46:43 - progress_bar.py[line:274] - INFO: epoch 001:   3564 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.392, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.1, ups=0.91, wpb=110.5, bsz=40, num_updates=3560, lr=3.84865e-05, gnorm=0.906, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15348
2022-10-13 14:46:55 - progress_bar.py[line:274] - INFO: epoch 001:   3574 / 28910 loss=0.483, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=98.1, ups=0.88, wpb=111.2, bsz=40, num_updates=3570, lr=3.85946e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15359
2022-10-13 14:47:06 - progress_bar.py[line:274] - INFO: epoch 001:   3584 / 28910 loss=0.505, loss_v1=0, loss_v2=0, nll_loss=0.394, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.8, ups=0.89, wpb=110, bsz=40, num_updates=3580, lr=3.87027e-05, gnorm=0.93, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15371
2022-10-13 14:47:17 - progress_bar.py[line:274] - INFO: epoch 001:   3594 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.37, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.6, ups=0.89, wpb=111.4, bsz=40, num_updates=3590, lr=3.88108e-05, gnorm=0.951, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15382
2022-10-13 14:47:28 - progress_bar.py[line:274] - INFO: epoch 001:   3604 / 28910 loss=0.517, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.6, ups=0.88, wpb=109.9, bsz=40, num_updates=3600, lr=3.89189e-05, gnorm=1.01, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15393
2022-10-13 14:47:39 - progress_bar.py[line:274] - INFO: epoch 001:   3614 / 28910 loss=0.518, loss_v1=0, loss_v2=0, nll_loss=0.408, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=99.9, ups=0.91, wpb=110.1, bsz=40, num_updates=3610, lr=3.9027e-05, gnorm=1.006, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15404
2022-10-13 14:47:51 - progress_bar.py[line:274] - INFO: epoch 001:   3624 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.3, ups=0.88, wpb=109, bsz=40, num_updates=3620, lr=3.91351e-05, gnorm=0.958, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15416
2022-10-13 14:48:02 - progress_bar.py[line:274] - INFO: epoch 001:   3634 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100.6, ups=0.91, wpb=111, bsz=40, num_updates=3630, lr=3.92432e-05, gnorm=0.979, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15427
2022-10-13 14:48:13 - progress_bar.py[line:274] - INFO: epoch 001:   3644 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.8, ups=0.87, wpb=112.2, bsz=40, num_updates=3640, lr=3.93514e-05, gnorm=0.904, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=15438
2022-10-13 14:48:24 - progress_bar.py[line:274] - INFO: epoch 001:   3654 / 28910 loss=0.497, loss_v1=0, loss_v2=0, nll_loss=0.379, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.1, ups=0.9, wpb=111.7, bsz=40, num_updates=3650, lr=3.94595e-05, gnorm=0.941, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15449
2022-10-13 14:48:35 - progress_bar.py[line:274] - INFO: epoch 001:   3664 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.9, ups=0.91, wpb=111.4, bsz=40, num_updates=3660, lr=3.95676e-05, gnorm=1.003, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15460
2022-10-13 14:48:47 - progress_bar.py[line:274] - INFO: epoch 001:   3674 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=96.6, ups=0.87, wpb=110.5, bsz=40, num_updates=3670, lr=3.96757e-05, gnorm=0.889, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15472
2022-10-13 14:48:58 - progress_bar.py[line:274] - INFO: epoch 001:   3684 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.414, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=3680, lr=3.97838e-05, gnorm=0.918, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15483
2022-10-13 14:49:09 - progress_bar.py[line:274] - INFO: epoch 001:   3694 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.361, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=100, ups=0.9, wpb=111.2, bsz=40, num_updates=3690, lr=3.98919e-05, gnorm=0.888, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15494
2022-10-13 14:49:20 - progress_bar.py[line:274] - INFO: epoch 001:   3704 / 28910 loss=0.507, loss_v1=0, loss_v2=0, nll_loss=0.395, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.4, ups=0.92, wpb=110.6, bsz=40, num_updates=3700, lr=4e-05, gnorm=0.978, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15505
2022-10-13 14:49:32 - progress_bar.py[line:274] - INFO: epoch 001:   3714 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.3, ups=0.88, wpb=110.6, bsz=40, num_updates=3710, lr=4.01081e-05, gnorm=0.928, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15517
2022-10-13 14:49:43 - progress_bar.py[line:274] - INFO: epoch 001:   3724 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.389, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.8, ups=0.88, wpb=110.8, bsz=40, num_updates=3720, lr=4.02162e-05, gnorm=0.885, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15528
2022-10-13 14:49:54 - progress_bar.py[line:274] - INFO: epoch 001:   3734 / 28910 loss=0.499, loss_v1=0, loss_v2=0, nll_loss=0.393, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=97.4, ups=0.88, wpb=110.3, bsz=40, num_updates=3730, lr=4.03243e-05, gnorm=1.023, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15539
2022-10-13 14:50:05 - progress_bar.py[line:274] - INFO: epoch 001:   3744 / 28910 loss=0.485, loss_v1=0, loss_v2=0, nll_loss=0.377, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=102, ups=0.92, wpb=111.1, bsz=40, num_updates=3740, lr=4.04324e-05, gnorm=0.941, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15550
2022-10-13 14:50:16 - progress_bar.py[line:274] - INFO: epoch 001:   3754 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=98.7, ups=0.89, wpb=110.7, bsz=40, num_updates=3750, lr=4.05405e-05, gnorm=0.806, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15561
2022-10-13 14:50:28 - progress_bar.py[line:274] - INFO: epoch 001:   3764 / 28910 loss=0.523, loss_v1=0, loss_v2=0, nll_loss=0.416, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=96.9, ups=0.88, wpb=109.6, bsz=40, num_updates=3760, lr=4.06486e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15573
2022-10-13 14:50:39 - progress_bar.py[line:274] - INFO: epoch 001:   3774 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.2, ups=0.89, wpb=111, bsz=40, num_updates=3770, lr=4.07568e-05, gnorm=0.967, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=15584
2022-10-13 14:50:50 - progress_bar.py[line:274] - INFO: epoch 001:   3784 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.9, ups=0.89, wpb=110.5, bsz=40, num_updates=3780, lr=4.08649e-05, gnorm=0.912, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15595
2022-10-13 14:51:02 - progress_bar.py[line:274] - INFO: epoch 001:   3794 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.352, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.1, ups=0.87, wpb=109.8, bsz=40, num_updates=3790, lr=4.0973e-05, gnorm=0.957, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15606
2022-10-13 14:51:12 - progress_bar.py[line:274] - INFO: epoch 001:   3804 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=102.2, ups=0.92, wpb=111.2, bsz=40, num_updates=3800, lr=4.10811e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15617
2022-10-13 14:51:24 - progress_bar.py[line:274] - INFO: epoch 001:   3814 / 28910 loss=0.504, loss_v1=0, loss_v2=0, nll_loss=0.391, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.2, ups=0.88, wpb=109, bsz=40, num_updates=3810, lr=4.11892e-05, gnorm=1.048, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15629
2022-10-13 14:51:35 - progress_bar.py[line:274] - INFO: epoch 001:   3824 / 28910 loss=0.506, loss_v1=0, loss_v2=0, nll_loss=0.39, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=102.9, ups=0.93, wpb=110.8, bsz=40, num_updates=3820, lr=4.12973e-05, gnorm=1.101, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15639
2022-10-13 14:51:46 - progress_bar.py[line:274] - INFO: epoch 001:   3834 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.375, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.7, ups=0.91, wpb=111.3, bsz=40, num_updates=3830, lr=4.14054e-05, gnorm=1.016, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=15651
2022-10-13 14:51:57 - progress_bar.py[line:274] - INFO: epoch 001:   3844 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=95.2, ups=0.86, wpb=110.2, bsz=40, num_updates=3840, lr=4.15135e-05, gnorm=0.933, clip=30, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=15662
2022-10-13 14:52:09 - progress_bar.py[line:274] - INFO: epoch 001:   3854 / 28910 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.384, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=96.4, ups=0.88, wpb=109.7, bsz=40, num_updates=3850, lr=4.16216e-05, gnorm=1.033, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15674
2022-10-13 14:52:20 - progress_bar.py[line:274] - INFO: epoch 001:   3864 / 28910 loss=0.527, loss_v1=0, loss_v2=0, nll_loss=0.413, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=97.5, ups=0.89, wpb=109.3, bsz=40, num_updates=3860, lr=4.17297e-05, gnorm=1.075, clip=80, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15685
2022-10-13 14:52:31 - progress_bar.py[line:274] - INFO: epoch 001:   3874 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.365, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=3870, lr=4.18378e-05, gnorm=0.937, clip=40, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=15696
2022-10-13 14:52:42 - progress_bar.py[line:274] - INFO: epoch 001:   3884 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.1, ups=0.89, wpb=109.8, bsz=40, num_updates=3880, lr=4.19459e-05, gnorm=0.945, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15707
2022-10-13 14:52:54 - progress_bar.py[line:274] - INFO: epoch 001:   3894 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=112.7, nsentences=40, sample_size=112.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.7, ups=0.89, wpb=112.7, bsz=40, num_updates=3890, lr=4.20541e-05, gnorm=0.915, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15719
2022-10-13 14:53:05 - progress_bar.py[line:274] - INFO: epoch 001:   3904 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.345, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=3900, lr=4.21622e-05, gnorm=1.04, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15730
2022-10-13 14:53:16 - progress_bar.py[line:274] - INFO: epoch 001:   3914 / 28910 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=99.1, ups=0.9, wpb=109.5, bsz=40, num_updates=3910, lr=4.22703e-05, gnorm=1.08, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15741
2022-10-13 14:53:27 - progress_bar.py[line:274] - INFO: epoch 001:   3924 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=102.9, ups=0.93, wpb=110.9, bsz=40, num_updates=3920, lr=4.23784e-05, gnorm=0.936, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15752
2022-10-13 14:53:38 - progress_bar.py[line:274] - INFO: epoch 001:   3934 / 28910 loss=0.513, loss_v1=0, loss_v2=0, nll_loss=0.399, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=97.9, ups=0.89, wpb=110, bsz=40, num_updates=3930, lr=4.24865e-05, gnorm=1.017, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=15763
2022-10-13 14:53:49 - progress_bar.py[line:274] - INFO: epoch 001:   3944 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.371, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=101.7, ups=0.91, wpb=112.1, bsz=40, num_updates=3940, lr=4.25946e-05, gnorm=0.931, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15774
2022-10-13 14:54:00 - progress_bar.py[line:274] - INFO: epoch 001:   3954 / 28910 loss=0.526, loss_v1=0, loss_v2=0, nll_loss=0.42, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.34, wps=102, ups=0.92, wpb=110.9, bsz=40, num_updates=3950, lr=4.27027e-05, gnorm=1.04, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=15785
2022-10-13 14:54:11 - progress_bar.py[line:274] - INFO: epoch 001:   3964 / 28910 loss=0.498, loss_v1=0, loss_v2=0, nll_loss=0.387, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=102.7, ups=0.94, wpb=109.2, bsz=40, num_updates=3960, lr=4.28108e-05, gnorm=0.935, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15795
2022-10-13 14:54:22 - progress_bar.py[line:274] - INFO: epoch 001:   3974 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=3970, lr=4.29189e-05, gnorm=1.041, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15807
2022-10-13 14:54:33 - progress_bar.py[line:274] - INFO: epoch 001:   3984 / 28910 loss=0.492, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=96.9, ups=0.89, wpb=108.7, bsz=40, num_updates=3980, lr=4.3027e-05, gnorm=1.071, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=15818
2022-10-13 14:54:44 - progress_bar.py[line:274] - INFO: epoch 001:   3994 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.353, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.9, ups=0.89, wpb=110.5, bsz=40, num_updates=3990, lr=4.31351e-05, gnorm=1.006, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=15829
2022-10-13 14:54:55 - progress_bar.py[line:274] - INFO: epoch 001:   4004 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=102.1, ups=0.93, wpb=109.8, bsz=40, num_updates=4000, lr=4.32432e-05, gnorm=0.847, clip=20, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=15840
2022-10-13 14:54:55 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 14:54:57 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 14:54:57 - train.py[line:551] - INFO: load:1.08 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 14:57:28 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 14:57:28 - train.py[line:551] - INFO: load:1.10 valid_run:151.80 task_valid:148.44 collect_output:2.13
2022-10-13 14:59:57 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 14:59:57 - train.py[line:551] - INFO: load:1.13 valid_run:300.65 task_valid:292.10 collect_output:6.16
2022-10-13 15:02:30 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 15:02:30 - train.py[line:551] - INFO: load:1.15 valid_run:453.31 task_valid:436.06 collect_output:13.70
2022-10-13 15:05:00 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 15:05:00 - train.py[line:551] - INFO: load:1.21 valid_run:603.12 task_valid:581.94 collect_output:16.47
2022-10-13 15:07:33 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 15:07:33 - train.py[line:551] - INFO: load:1.24 valid_run:756.04 task_valid:730.27 collect_output:19.93
2022-10-13 15:10:05 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 15:10:05 - train.py[line:551] - INFO: load:1.27 valid_run:908.33 task_valid:876.48 collect_output:24.85
2022-10-13 15:12:39 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 15:12:39 - train.py[line:551] - INFO: load:1.29 valid_run:1062.06 task_valid:1023.48 collect_output:30.43
2022-10-13 15:15:11 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 15:15:11 - train.py[line:551] - INFO: load:1.32 valid_run:1213.50 task_valid:1165.21 collect_output:38.98
2022-10-13 15:17:41 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 15:17:41 - train.py[line:551] - INFO: load:1.34 valid_run:1363.58 task_valid:1310.54 collect_output:42.56
2022-10-13 15:20:10 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 15:20:10 - train.py[line:551] - INFO: load:1.37 valid_run:1512.47 task_valid:1454.23 collect_output:46.62
2022-10-13 15:22:40 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 15:22:40 - train.py[line:551] - INFO: load:1.39 valid_run:1662.38 task_valid:1599.36 collect_output:50.30
2022-10-13 15:25:10 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 15:25:10 - train.py[line:551] - INFO: load:1.41 valid_run:1812.33 task_valid:1744.30 collect_output:54.30
2022-10-13 15:27:40 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 15:27:40 - train.py[line:551] - INFO: load:1.44 valid_run:1962.21 task_valid:1886.06 collect_output:61.40
2022-10-13 15:30:10 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 15:30:10 - train.py[line:551] - INFO: load:1.47 valid_run:2112.94 task_valid:2031.81 collect_output:65.35
2022-10-13 15:32:40 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 15:32:40 - train.py[line:551] - INFO: load:1.49 valid_run:2263.01 task_valid:2178.28 collect_output:67.90
2022-10-13 15:35:11 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 15:35:11 - train.py[line:551] - INFO: load:1.52 valid_run:2413.16 task_valid:2322.71 collect_output:72.51
2022-10-13 15:37:43 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 15:37:43 - train.py[line:551] - INFO: load:1.54 valid_run:2565.03 task_valid:2468.63 collect_output:77.44
2022-10-13 15:40:14 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 15:40:14 - train.py[line:551] - INFO: load:1.57 valid_run:2715.95 task_valid:2615.72 collect_output:80.21
2022-10-13 15:42:42 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 15:42:42 - train.py[line:551] - INFO: load:1.59 valid_run:2864.44 task_valid:2757.48 collect_output:85.91
2022-10-13 15:45:13 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 15:45:13 - train.py[line:551] - INFO: load:1.62 valid_run:3014.88 task_valid:2902.98 collect_output:89.79
2022-10-13 15:47:45 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 15:47:45 - train.py[line:551] - INFO: load:1.64 valid_run:3166.80 task_valid:3047.94 collect_output:95.71
2022-10-13 15:50:14 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 15:50:14 - train.py[line:551] - INFO: load:1.67 valid_run:3316.44 task_valid:3192.62 collect_output:99.61
2022-10-13 15:52:46 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 15:52:46 - train.py[line:551] - INFO: load:1.69 valid_run:3467.66 task_valid:3339.01 collect_output:103.41
2022-10-13 15:55:17 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 15:55:17 - train.py[line:551] - INFO: load:1.72 valid_run:3619.13 task_valid:3485.73 collect_output:107.12

====================================================================================================
SGG eval:     R @ 50: 0.4760;     R @ 100: 0.5279;     R @ 500: 0.5887;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2825;    mR @ 100: 0.3497;    mR @ 500: 0.4106;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4659) (covered in:0.3958) (covering:0.5714) (eating:0.6471) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4677) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.4833) (playing:0.0000) (riding:0.7745) (says:0.0000) (sitting on:0.6471) (standing on:0.2750) (using:0.4000) (walking in:0.0000) (walking on:0.5946) (watching:0.1111) 
--------------------------------------------------------
====================================================================================================

2022-10-13 15:57:48 - train.py[line:487] - INFO: 0.5279233766233766
2022-10-13 15:57:48 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 15:57:48 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.35 | loss_v1 0 | loss_v2 0 | nll_loss 0.195 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.527923 | ppl 1.14 | vqa_score 0.3311 | wps 118.9 | wpb 89.9 | bsz 30 | num_updates 4000 | best_R@100 0.527923
2022-10-13 15:57:48 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2022-10-13 15:57:48 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt

====================================================================================================
SGG eval:     R @ 50: 0.4760;     R @ 100: 0.5279;     R @ 500: 0.5887;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2825;    mR @ 100: 0.3497;    mR @ 500: 0.4106;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4659) (covered in:0.3958) (covering:0.5714) (eating:0.6471) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4677) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.4833) (playing:0.0000) (riding:0.7745) (says:0.0000) (sitting on:0.6471) (standing on:0.2750) (using:0.4000) (walking in:0.0000) (walking on:0.5946) (watching:0.1111) 
--------------------------------------------------------
====================================================================================================

2022-10-13 15:57:54 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt
2022-10-13 15:57:59 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 0.5279233766233766) (writing took 11.35240692133084 seconds)
2022-10-13 15:58:11 - progress_bar.py[line:274] - INFO: epoch 001:   4014 / 28910 loss=0.475, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=0.3, ups=0, wpb=109, bsz=40, num_updates=4010, lr=4.33514e-05, gnorm=0.973, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19636
2022-10-13 15:58:22 - progress_bar.py[line:274] - INFO: epoch 001:   4024 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.2, ups=0.9, wpb=110.7, bsz=40, num_updates=4020, lr=4.34595e-05, gnorm=0.965, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19647
2022-10-13 15:58:33 - progress_bar.py[line:274] - INFO: epoch 001:   4034 / 28910 loss=0.5, loss_v1=0, loss_v2=0, nll_loss=0.388, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.31, wps=101.4, ups=0.91, wpb=111.4, bsz=40, num_updates=4030, lr=4.35676e-05, gnorm=1.12, clip=80, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19658
2022-10-13 15:58:41 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 15:58:45 - progress_bar.py[line:274] - INFO: epoch 001:   4045 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=89.6, ups=0.81, wpb=111.2, bsz=40, num_updates=4040, lr=4.36757e-05, gnorm=0.989, clip=40, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=19670
2022-10-13 15:58:56 - progress_bar.py[line:274] - INFO: epoch 001:   4055 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=104.1, ups=0.94, wpb=110.7, bsz=40, num_updates=4050, lr=4.37838e-05, gnorm=0.93, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19681
2022-10-13 15:59:07 - progress_bar.py[line:274] - INFO: epoch 001:   4065 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=4060, lr=4.38919e-05, gnorm=0.925, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19692
2022-10-13 15:59:18 - progress_bar.py[line:274] - INFO: epoch 001:   4075 / 28910 loss=0.511, loss_v1=0, loss_v2=0, nll_loss=0.401, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.32, wps=104, ups=0.94, wpb=110.6, bsz=40, num_updates=4070, lr=4.4e-05, gnorm=1.119, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19703
2022-10-13 15:59:29 - progress_bar.py[line:274] - INFO: epoch 001:   4085 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.6, ups=0.9, wpb=110.1, bsz=40, num_updates=4080, lr=4.41081e-05, gnorm=0.929, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19714
2022-10-13 15:59:40 - progress_bar.py[line:274] - INFO: epoch 001:   4095 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.367, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=95.5, ups=0.87, wpb=109.3, bsz=40, num_updates=4090, lr=4.42162e-05, gnorm=1.043, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19725
2022-10-13 15:59:51 - progress_bar.py[line:274] - INFO: epoch 001:   4105 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.1, ups=0.91, wpb=110.2, bsz=40, num_updates=4100, lr=4.43243e-05, gnorm=0.992, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19736
2022-10-13 16:00:02 - progress_bar.py[line:274] - INFO: epoch 001:   4115 / 28910 loss=0.484, loss_v1=0, loss_v2=0, nll_loss=0.366, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=100, ups=0.91, wpb=110.1, bsz=40, num_updates=4110, lr=4.44324e-05, gnorm=1.242, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19747
2022-10-13 16:00:14 - progress_bar.py[line:274] - INFO: epoch 001:   4125 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.339, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97, ups=0.88, wpb=109.8, bsz=40, num_updates=4120, lr=4.45405e-05, gnorm=0.995, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19759
2022-10-13 16:00:25 - progress_bar.py[line:274] - INFO: epoch 001:   4135 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.8, ups=0.89, wpb=110.5, bsz=40, num_updates=4130, lr=4.46486e-05, gnorm=1.013, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19770
2022-10-13 16:00:36 - progress_bar.py[line:274] - INFO: epoch 001:   4145 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=102.1, ups=0.93, wpb=110, bsz=40, num_updates=4140, lr=4.47568e-05, gnorm=0.966, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19781
2022-10-13 16:00:47 - progress_bar.py[line:274] - INFO: epoch 001:   4155 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.7, ups=0.91, wpb=111, bsz=40, num_updates=4150, lr=4.48649e-05, gnorm=0.915, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19792
2022-10-13 16:00:58 - progress_bar.py[line:274] - INFO: epoch 001:   4165 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.6, ups=0.92, wpb=109.7, bsz=40, num_updates=4160, lr=4.4973e-05, gnorm=1.094, clip=60, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=19803
2022-10-13 16:01:09 - progress_bar.py[line:274] - INFO: epoch 001:   4175 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.8, ups=0.9, wpb=109, bsz=40, num_updates=4170, lr=4.50811e-05, gnorm=1.178, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19814
2022-10-13 16:01:20 - progress_bar.py[line:274] - INFO: epoch 001:   4185 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99, ups=0.89, wpb=111, bsz=40, num_updates=4180, lr=4.51892e-05, gnorm=0.978, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19825
2022-10-13 16:01:31 - progress_bar.py[line:274] - INFO: epoch 001:   4195 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=4190, lr=4.52973e-05, gnorm=1.006, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19836
2022-10-13 16:01:42 - progress_bar.py[line:274] - INFO: epoch 001:   4205 / 28910 loss=0.458, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.5, ups=0.89, wpb=111.3, bsz=40, num_updates=4200, lr=4.54054e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19847
2022-10-13 16:01:54 - progress_bar.py[line:274] - INFO: epoch 001:   4215 / 28910 loss=0.494, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.1, ups=0.89, wpb=109.6, bsz=40, num_updates=4210, lr=4.55135e-05, gnorm=1.23, clip=90, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19859
2022-10-13 16:02:05 - progress_bar.py[line:274] - INFO: epoch 001:   4225 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=4220, lr=4.56216e-05, gnorm=1.069, clip=60, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=19870
2022-10-13 16:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   4235 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.5, ups=0.89, wpb=110.3, bsz=40, num_updates=4230, lr=4.57297e-05, gnorm=0.893, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=19881
2022-10-13 16:02:27 - progress_bar.py[line:274] - INFO: epoch 001:   4245 / 28910 loss=0.493, loss_v1=0, loss_v2=0, nll_loss=0.374, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=100.6, ups=0.9, wpb=111.3, bsz=40, num_updates=4240, lr=4.58378e-05, gnorm=0.932, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=19892
2022-10-13 16:02:38 - progress_bar.py[line:274] - INFO: epoch 001:   4255 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.346, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.1, ups=0.9, wpb=110.7, bsz=40, num_updates=4250, lr=4.59459e-05, gnorm=0.923, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19903
2022-10-13 16:02:49 - progress_bar.py[line:274] - INFO: epoch 001:   4265 / 28910 loss=0.465, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.1, ups=0.89, wpb=112, bsz=40, num_updates=4260, lr=4.60541e-05, gnorm=1.091, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19914
2022-10-13 16:03:00 - progress_bar.py[line:274] - INFO: epoch 001:   4275 / 28910 loss=0.469, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.1, ups=0.9, wpb=109.3, bsz=40, num_updates=4270, lr=4.61622e-05, gnorm=1.264, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19925
2022-10-13 16:03:11 - progress_bar.py[line:274] - INFO: epoch 001:   4285 / 28910 loss=0.468, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.4, ups=0.91, wpb=108.4, bsz=40, num_updates=4280, lr=4.62703e-05, gnorm=1.049, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19936
2022-10-13 16:03:22 - progress_bar.py[line:274] - INFO: epoch 001:   4295 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=104.4, ups=0.94, wpb=110.9, bsz=40, num_updates=4290, lr=4.63784e-05, gnorm=1.142, clip=50, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=19947
2022-10-13 16:03:33 - progress_bar.py[line:274] - INFO: epoch 001:   4305 / 28910 loss=0.463, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.7, ups=0.89, wpb=110.5, bsz=40, num_updates=4300, lr=4.64865e-05, gnorm=1.076, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19958
2022-10-13 16:03:44 - progress_bar.py[line:274] - INFO: epoch 001:   4315 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.4, ups=0.89, wpb=111.3, bsz=40, num_updates=4310, lr=4.65946e-05, gnorm=1.093, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=19969
2022-10-13 16:03:56 - progress_bar.py[line:274] - INFO: epoch 001:   4325 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.35, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.5, ups=0.89, wpb=110.2, bsz=40, num_updates=4320, lr=4.67027e-05, gnorm=1.198, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=19981
2022-10-13 16:04:07 - progress_bar.py[line:274] - INFO: epoch 001:   4335 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=95.4, ups=0.88, wpb=109, bsz=40, num_updates=4330, lr=4.68108e-05, gnorm=0.969, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=19992
2022-10-13 16:04:18 - progress_bar.py[line:274] - INFO: epoch 001:   4345 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.6, ups=0.88, wpb=110.9, bsz=40, num_updates=4340, lr=4.69189e-05, gnorm=1.157, clip=80, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20003
2022-10-13 16:04:30 - progress_bar.py[line:274] - INFO: epoch 001:   4355 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.5, ups=0.9, wpb=111.5, bsz=40, num_updates=4350, lr=4.7027e-05, gnorm=0.964, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20014
2022-10-13 16:04:40 - progress_bar.py[line:274] - INFO: epoch 001:   4365 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=103.2, ups=0.93, wpb=110.6, bsz=40, num_updates=4360, lr=4.71351e-05, gnorm=1.092, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20025
2022-10-13 16:04:51 - progress_bar.py[line:274] - INFO: epoch 001:   4375 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.6, ups=0.89, wpb=110.3, bsz=40, num_updates=4370, lr=4.72432e-05, gnorm=0.968, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20036
2022-10-13 16:05:03 - progress_bar.py[line:274] - INFO: epoch 001:   4385 / 28910 loss=0.495, loss_v1=0, loss_v2=0, nll_loss=0.38, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.3, wps=97.9, ups=0.88, wpb=110.7, bsz=40, num_updates=4380, lr=4.73514e-05, gnorm=1.039, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20048
2022-10-13 16:05:14 - progress_bar.py[line:274] - INFO: epoch 001:   4395 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.1, ups=0.89, wpb=110.9, bsz=40, num_updates=4390, lr=4.74595e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=11, gb_free=10, ema_decay=0.9999, wall=20059
2022-10-13 16:05:24 - progress_bar.py[line:274] - INFO: epoch 001:   4405 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=106.7, ups=0.96, wpb=110.9, bsz=40, num_updates=4400, lr=4.75676e-05, gnorm=1.085, clip=70, loss_scale=512, train_wall=10, gb_free=10.8, ema_decay=0.9999, wall=20069
2022-10-13 16:05:36 - progress_bar.py[line:274] - INFO: epoch 001:   4415 / 28910 loss=0.48, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=4410, lr=4.76757e-05, gnorm=1.082, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20081
2022-10-13 16:05:47 - progress_bar.py[line:274] - INFO: epoch 001:   4425 / 28910 loss=0.467, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.8, ups=0.88, wpb=112, bsz=40, num_updates=4420, lr=4.77838e-05, gnorm=1.154, clip=80, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=20092
2022-10-13 16:05:58 - progress_bar.py[line:274] - INFO: epoch 001:   4435 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=4430, lr=4.78919e-05, gnorm=0.963, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20103
2022-10-13 16:06:09 - progress_bar.py[line:274] - INFO: epoch 001:   4445 / 28910 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=4440, lr=4.8e-05, gnorm=0.895, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20114
2022-10-13 16:06:20 - progress_bar.py[line:274] - INFO: epoch 001:   4455 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=102.8, ups=0.93, wpb=110.9, bsz=40, num_updates=4450, lr=4.81081e-05, gnorm=1.109, clip=60, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=20125
2022-10-13 16:06:32 - progress_bar.py[line:274] - INFO: epoch 001:   4465 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.327, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97, ups=0.88, wpb=110, bsz=40, num_updates=4460, lr=4.82162e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20137
2022-10-13 16:06:42 - progress_bar.py[line:274] - INFO: epoch 001:   4475 / 28910 loss=0.476, loss_v1=0, loss_v2=0, nll_loss=0.359, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=101.7, ups=0.93, wpb=109.6, bsz=40, num_updates=4470, lr=4.83243e-05, gnorm=1.019, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20147
2022-10-13 16:06:54 - progress_bar.py[line:274] - INFO: epoch 001:   4485 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.321, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.3, ups=0.88, wpb=110.1, bsz=40, num_updates=4480, lr=4.84324e-05, gnorm=1.209, clip=60, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=20159
2022-10-13 16:07:05 - progress_bar.py[line:274] - INFO: epoch 001:   4495 / 28910 loss=0.466, loss_v1=0, loss_v2=0, nll_loss=0.357, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=97.9, ups=0.89, wpb=109.6, bsz=40, num_updates=4490, lr=4.85405e-05, gnorm=1.175, clip=70, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20170
2022-10-13 16:07:16 - progress_bar.py[line:274] - INFO: epoch 001:   4505 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.2, ups=0.9, wpb=109.5, bsz=40, num_updates=4500, lr=4.86486e-05, gnorm=0.914, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20181
2022-10-13 16:07:27 - progress_bar.py[line:274] - INFO: epoch 001:   4515 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.6, ups=0.9, wpb=110.2, bsz=40, num_updates=4510, lr=4.87568e-05, gnorm=1.203, clip=80, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20192
2022-10-13 16:07:38 - progress_bar.py[line:274] - INFO: epoch 001:   4525 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98, ups=0.89, wpb=109.5, bsz=40, num_updates=4520, lr=4.88649e-05, gnorm=0.993, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20203
2022-10-13 16:07:49 - progress_bar.py[line:274] - INFO: epoch 001:   4535 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.5, ups=0.92, wpb=108.4, bsz=40, num_updates=4530, lr=4.8973e-05, gnorm=1.056, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20214
2022-10-13 16:08:01 - progress_bar.py[line:274] - INFO: epoch 001:   4545 / 28910 loss=0.47, loss_v1=0, loss_v2=0, nll_loss=0.349, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.1, ups=0.89, wpb=109.9, bsz=40, num_updates=4540, lr=4.90811e-05, gnorm=1.143, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20225
2022-10-13 16:08:12 - progress_bar.py[line:274] - INFO: epoch 001:   4555 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.4, ups=0.89, wpb=110.2, bsz=40, num_updates=4550, lr=4.91892e-05, gnorm=0.899, clip=30, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20237
2022-10-13 16:08:23 - progress_bar.py[line:274] - INFO: epoch 001:   4565 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.3, ups=0.87, wpb=110.8, bsz=40, num_updates=4560, lr=4.92973e-05, gnorm=1.016, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20248
2022-10-13 16:08:35 - progress_bar.py[line:274] - INFO: epoch 001:   4575 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.1, ups=0.88, wpb=110.1, bsz=40, num_updates=4570, lr=4.94054e-05, gnorm=0.938, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20260
2022-10-13 16:08:46 - progress_bar.py[line:274] - INFO: epoch 001:   4585 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=99.1, ups=0.9, wpb=110.7, bsz=40, num_updates=4580, lr=4.95135e-05, gnorm=1.149, clip=80, loss_scale=1024, train_wall=11, gb_free=10, ema_decay=0.9999, wall=20271
2022-10-13 16:08:57 - progress_bar.py[line:274] - INFO: epoch 001:   4595 / 28910 loss=0.464, loss_v1=0, loss_v2=0, nll_loss=0.343, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=98.2, ups=0.9, wpb=109.7, bsz=40, num_updates=4590, lr=4.96216e-05, gnorm=0.924, clip=20, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20282
2022-10-13 16:09:08 - progress_bar.py[line:274] - INFO: epoch 001:   4605 / 28910 loss=0.486, loss_v1=0, loss_v2=0, nll_loss=0.362, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.29, wps=98.6, ups=0.91, wpb=108.6, bsz=40, num_updates=4600, lr=4.97297e-05, gnorm=1.107, clip=80, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20293
2022-10-13 16:09:19 - progress_bar.py[line:274] - INFO: epoch 001:   4615 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=4610, lr=4.98378e-05, gnorm=1.001, clip=50, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=20304
2022-10-13 16:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   4625 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=108.6, nsentences=40, sample_size=108.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=96.1, ups=0.89, wpb=108.6, bsz=40, num_updates=4620, lr=4.99459e-05, gnorm=1.203, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20315
2022-10-13 16:09:42 - progress_bar.py[line:274] - INFO: epoch 001:   4635 / 28910 loss=0.477, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99, ups=0.91, wpb=109.3, bsz=40, num_updates=4630, lr=4.99977e-05, gnorm=1.158, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20326
2022-10-13 16:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   4645 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.347, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.8, ups=0.92, wpb=109.4, bsz=40, num_updates=4640, lr=4.99932e-05, gnorm=1.011, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20337
2022-10-13 16:10:04 - progress_bar.py[line:274] - INFO: epoch 001:   4655 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.2, ups=0.89, wpb=109.8, bsz=40, num_updates=4650, lr=4.99887e-05, gnorm=0.953, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20349
2022-10-13 16:10:15 - progress_bar.py[line:274] - INFO: epoch 001:   4665 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.6, ups=0.87, wpb=112.1, bsz=40, num_updates=4660, lr=4.99842e-05, gnorm=0.953, clip=40, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20360
2022-10-13 16:10:26 - progress_bar.py[line:274] - INFO: epoch 001:   4675 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.1, ups=0.9, wpb=111.6, bsz=40, num_updates=4670, lr=4.99797e-05, gnorm=1.087, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20371
2022-10-13 16:10:37 - progress_bar.py[line:274] - INFO: epoch 001:   4685 / 28910 loss=0.471, loss_v1=0, loss_v2=0, nll_loss=0.348, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=4680, lr=4.99752e-05, gnorm=1.279, clip=90, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20382
2022-10-13 16:10:49 - progress_bar.py[line:274] - INFO: epoch 001:   4695 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=4690, lr=4.99707e-05, gnorm=1.022, clip=60, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20394
2022-10-13 16:11:00 - progress_bar.py[line:274] - INFO: epoch 001:   4705 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.2, ups=0.91, wpb=110.6, bsz=40, num_updates=4700, lr=4.99662e-05, gnorm=0.922, clip=30, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=20405
2022-10-13 16:11:11 - progress_bar.py[line:274] - INFO: epoch 001:   4715 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.8, ups=0.88, wpb=111, bsz=40, num_updates=4710, lr=4.99617e-05, gnorm=1.078, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20416
2022-10-13 16:11:23 - progress_bar.py[line:274] - INFO: epoch 001:   4725 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=96.4, ups=0.87, wpb=110.5, bsz=40, num_updates=4720, lr=4.99572e-05, gnorm=1.083, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20427
2022-10-13 16:11:34 - progress_bar.py[line:274] - INFO: epoch 001:   4735 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=4730, lr=4.99527e-05, gnorm=0.961, clip=30, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=20439
2022-10-13 16:11:45 - progress_bar.py[line:274] - INFO: epoch 001:   4745 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.5, ups=0.89, wpb=111.1, bsz=40, num_updates=4740, lr=4.99482e-05, gnorm=0.992, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20450
2022-10-13 16:11:56 - progress_bar.py[line:274] - INFO: epoch 001:   4755 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.7, ups=0.91, wpb=110.7, bsz=40, num_updates=4750, lr=4.99437e-05, gnorm=0.921, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20461
2022-10-13 16:12:07 - progress_bar.py[line:274] - INFO: epoch 001:   4765 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.5, ups=0.91, wpb=111, bsz=40, num_updates=4760, lr=4.99392e-05, gnorm=1.052, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20472
2022-10-13 16:12:18 - progress_bar.py[line:274] - INFO: epoch 001:   4775 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=4770, lr=4.99347e-05, gnorm=0.967, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20483
2022-10-13 16:12:29 - progress_bar.py[line:274] - INFO: epoch 001:   4785 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.2, ups=0.89, wpb=108.7, bsz=40, num_updates=4780, lr=4.99302e-05, gnorm=0.974, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20494
2022-10-13 16:12:40 - progress_bar.py[line:274] - INFO: epoch 001:   4795 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.9, ups=0.9, wpb=112, bsz=40, num_updates=4790, lr=4.99257e-05, gnorm=1.12, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20505
2022-10-13 16:12:51 - progress_bar.py[line:274] - INFO: epoch 001:   4805 / 28910 loss=0.457, loss_v1=0, loss_v2=0, nll_loss=0.331, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.2, ups=0.89, wpb=111.3, bsz=40, num_updates=4800, lr=4.99212e-05, gnorm=1.017, clip=60, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20516
2022-10-13 16:13:02 - progress_bar.py[line:274] - INFO: epoch 001:   4815 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.5, ups=0.91, wpb=109.9, bsz=40, num_updates=4810, lr=4.99167e-05, gnorm=1.036, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20527
2022-10-13 16:13:13 - progress_bar.py[line:274] - INFO: epoch 001:   4825 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.335, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.2, ups=0.91, wpb=109.4, bsz=40, num_updates=4820, lr=4.99122e-05, gnorm=1.065, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20538
2022-10-13 16:13:24 - progress_bar.py[line:274] - INFO: epoch 001:   4835 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.1, ups=0.91, wpb=109.5, bsz=40, num_updates=4830, lr=4.99077e-05, gnorm=0.938, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20549
2022-10-13 16:13:36 - progress_bar.py[line:274] - INFO: epoch 001:   4845 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=112.9, nsentences=40, sample_size=112.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101.5, ups=0.9, wpb=112.9, bsz=40, num_updates=4840, lr=4.99032e-05, gnorm=0.926, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20560
2022-10-13 16:13:47 - progress_bar.py[line:274] - INFO: epoch 001:   4855 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.7, ups=0.9, wpb=110.3, bsz=40, num_updates=4850, lr=4.98987e-05, gnorm=0.929, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20572
2022-10-13 16:13:58 - progress_bar.py[line:274] - INFO: epoch 001:   4865 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.7, ups=0.9, wpb=109.6, bsz=40, num_updates=4860, lr=4.98942e-05, gnorm=1.034, clip=70, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=20583
2022-10-13 16:14:09 - progress_bar.py[line:274] - INFO: epoch 001:   4875 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=4870, lr=4.98897e-05, gnorm=0.919, clip=10, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20594
2022-10-13 16:14:12 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 16:14:21 - progress_bar.py[line:274] - INFO: epoch 001:   4886 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=92.8, ups=0.84, wpb=110.5, bsz=40, num_updates=4880, lr=4.98852e-05, gnorm=1.08, clip=80, loss_scale=512, train_wall=12, gb_free=10.6, ema_decay=0.9999, wall=20606
2022-10-13 16:14:32 - progress_bar.py[line:274] - INFO: epoch 001:   4896 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.1, ups=0.9, wpb=111, bsz=40, num_updates=4890, lr=4.98806e-05, gnorm=0.867, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20617
2022-10-13 16:14:43 - progress_bar.py[line:274] - INFO: epoch 001:   4906 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=102.8, ups=0.93, wpb=110.4, bsz=40, num_updates=4900, lr=4.98761e-05, gnorm=0.957, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20628
2022-10-13 16:14:54 - progress_bar.py[line:274] - INFO: epoch 001:   4916 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=4910, lr=4.98716e-05, gnorm=0.924, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20639
2022-10-13 16:15:05 - progress_bar.py[line:274] - INFO: epoch 001:   4926 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=102, ups=0.91, wpb=112.2, bsz=40, num_updates=4920, lr=4.98671e-05, gnorm=0.908, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=20650
2022-10-13 16:15:16 - progress_bar.py[line:274] - INFO: epoch 001:   4936 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99, ups=0.9, wpb=110.2, bsz=40, num_updates=4930, lr=4.98626e-05, gnorm=1.021, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20661
2022-10-13 16:15:27 - progress_bar.py[line:274] - INFO: epoch 001:   4946 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.7, ups=0.89, wpb=109.8, bsz=40, num_updates=4940, lr=4.98581e-05, gnorm=0.89, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20672
2022-10-13 16:15:38 - progress_bar.py[line:274] - INFO: epoch 001:   4956 / 28910 loss=0.445, loss_v1=0, loss_v2=0, nll_loss=0.32, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.1, ups=0.9, wpb=111.1, bsz=40, num_updates=4950, lr=4.98536e-05, gnorm=1.026, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20683
2022-10-13 16:15:50 - progress_bar.py[line:274] - INFO: epoch 001:   4966 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.2, ups=0.89, wpb=109.5, bsz=40, num_updates=4960, lr=4.98491e-05, gnorm=0.97, clip=40, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=20695
2022-10-13 16:16:01 - progress_bar.py[line:274] - INFO: epoch 001:   4976 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.6, ups=0.88, wpb=108.7, bsz=40, num_updates=4970, lr=4.98446e-05, gnorm=1.017, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=20706
2022-10-13 16:16:12 - progress_bar.py[line:274] - INFO: epoch 001:   4986 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.1, ups=0.9, wpb=111.1, bsz=40, num_updates=4980, lr=4.98401e-05, gnorm=0.886, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=20717
2022-10-13 16:16:23 - progress_bar.py[line:274] - INFO: epoch 001:   4996 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=100.4, ups=0.92, wpb=109.3, bsz=40, num_updates=4990, lr=4.98356e-05, gnorm=0.986, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=20728
2022-10-13 16:16:34 - progress_bar.py[line:274] - INFO: epoch 001:   5006 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.312, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.6, ups=0.89, wpb=112.3, bsz=40, num_updates=5000, lr=4.98311e-05, gnorm=0.972, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=20739
2022-10-13 16:16:34 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 16:16:36 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 16:16:36 - train.py[line:551] - INFO: load:1.01 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 16:19:08 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 16:19:08 - train.py[line:551] - INFO: load:1.03 valid_run:152.50 task_valid:149.01 collect_output:2.33
2022-10-13 16:21:37 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 16:21:37 - train.py[line:551] - INFO: load:1.06 valid_run:301.48 task_valid:293.08 collect_output:6.08
2022-10-13 16:24:10 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 16:24:10 - train.py[line:551] - INFO: load:1.08 valid_run:454.14 task_valid:437.29 collect_output:13.41
2022-10-13 16:26:40 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 16:26:40 - train.py[line:551] - INFO: load:1.11 valid_run:603.96 task_valid:583.11 collect_output:16.19
2022-10-13 16:29:13 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 16:29:13 - train.py[line:551] - INFO: load:1.14 valid_run:756.65 task_valid:731.32 collect_output:19.54
2022-10-13 16:31:45 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 16:31:45 - train.py[line:551] - INFO: load:1.17 valid_run:908.93 task_valid:877.66 collect_output:24.34
2022-10-13 16:34:18 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 16:34:18 - train.py[line:551] - INFO: load:1.20 valid_run:1062.33 task_valid:1024.55 collect_output:29.74
2022-10-13 16:36:50 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 16:36:50 - train.py[line:551] - INFO: load:1.22 valid_run:1213.75 task_valid:1166.09 collect_output:38.45
2022-10-13 16:39:20 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 16:39:20 - train.py[line:551] - INFO: load:1.25 valid_run:1363.92 task_valid:1311.68 collect_output:41.90
2022-10-13 16:41:49 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 16:41:49 - train.py[line:551] - INFO: load:1.27 valid_run:1512.74 task_valid:1455.44 collect_output:45.79
2022-10-13 16:44:19 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 16:44:19 - train.py[line:551] - INFO: load:1.30 valid_run:1663.08 task_valid:1601.13 collect_output:49.34
2022-10-13 16:46:49 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 16:46:49 - train.py[line:551] - INFO: load:1.33 valid_run:1813.02 task_valid:1746.28 collect_output:53.06
2022-10-13 16:49:19 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 16:49:19 - train.py[line:551] - INFO: load:1.35 valid_run:1962.93 task_valid:1888.19 collect_output:60.04
2022-10-13 16:51:50 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 16:51:50 - train.py[line:551] - INFO: load:1.38 valid_run:2113.33 task_valid:2033.50 collect_output:64.08
2022-10-13 16:54:20 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 16:54:20 - train.py[line:551] - INFO: load:1.40 valid_run:2263.20 task_valid:2179.89 collect_output:66.58
2022-10-13 16:56:50 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 16:56:50 - train.py[line:551] - INFO: load:1.43 valid_run:2413.23 task_valid:2324.10 collect_output:71.34
2022-10-13 16:59:21 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 16:59:21 - train.py[line:551] - INFO: load:1.45 valid_run:2564.70 task_valid:2469.59 collect_output:76.31
2022-10-13 17:01:52 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 17:01:52 - train.py[line:551] - INFO: load:1.48 valid_run:2715.23 task_valid:2616.57 collect_output:78.83
2022-10-13 17:04:20 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 17:04:20 - train.py[line:551] - INFO: load:1.50 valid_run:2863.55 task_valid:2758.35 collect_output:84.30
2022-10-13 17:06:51 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 17:06:51 - train.py[line:551] - INFO: load:1.53 valid_run:3013.89 task_valid:2903.53 collect_output:88.42
2022-10-13 17:09:23 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 17:09:23 - train.py[line:551] - INFO: load:1.55 valid_run:3165.71 task_valid:3048.13 collect_output:94.63
2022-10-13 17:11:52 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 17:11:52 - train.py[line:551] - INFO: load:1.58 valid_run:3314.89 task_valid:3192.63 collect_output:98.28
2022-10-13 17:14:23 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 17:14:23 - train.py[line:551] - INFO: load:1.60 valid_run:3466.08 task_valid:3339.02 collect_output:102.03
2022-10-13 17:16:54 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 17:16:54 - train.py[line:551] - INFO: load:1.63 valid_run:3617.37 task_valid:3485.53 collect_output:105.76

====================================================================================================
SGG eval:     R @ 50: 0.5344;     R @ 100: 0.5865;     R @ 500: 0.6256;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3468;    mR @ 100: 0.4038;    mR @ 500: 0.4525;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6610) (covered in:0.6875) (covering:0.5143) (eating:0.7647) (flying in:0.7727) (growing on:0.2500) (hanging from:0.4839) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7917) (playing:0.0000) (riding:0.9134) (says:0.0000) (sitting on:0.7007) (standing on:0.2117) (using:0.4500) (walking in:0.0000) (walking on:0.5946) (watching:0.0972) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5344;     R @ 100: 0.5865;     R @ 500: 0.6256;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3468;    mR @ 100: 0.4038;    mR @ 500: 0.4525;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6610) (covered in:0.6875) (covering:0.5143) (eating:0.7647) (flying in:0.7727) (growing on:0.2500) (hanging from:0.4839) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.7917) (playing:0.0000) (riding:0.9134) (says:0.0000) (sitting on:0.7007) (standing on:0.2117) (using:0.4500) (walking in:0.0000) (walking on:0.5946) (watching:0.0972) 
--------------------------------------------------------
====================================================================================================

2022-10-13 17:19:25 - train.py[line:487] - INFO: 0.5865337662337662
2022-10-13 17:19:25 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 17:19:25 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.399 | loss_v1 0 | loss_v2 0 | nll_loss 0.257 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.586534 | ppl 1.2 | vqa_score 0.4088 | wps 119 | wpb 89.9 | bsz 30 | num_updates 5000 | best_R@100 0.586534
2022-10-13 17:19:25 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 5000 updates
2022-10-13 17:19:25 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-13 17:19:31 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt
2022-10-13 17:19:36 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 0.5865337662337662) (writing took 10.501832991372794 seconds)
2022-10-13 17:19:47 - progress_bar.py[line:274] - INFO: epoch 001:   5016 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=0.3, ups=0, wpb=109.8, bsz=40, num_updates=5010, lr=4.98266e-05, gnorm=0.984, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24532
2022-10-13 17:19:58 - progress_bar.py[line:274] - INFO: epoch 001:   5026 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.316, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=5020, lr=4.98221e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24543
2022-10-13 17:20:10 - progress_bar.py[line:274] - INFO: epoch 001:   5036 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.9, ups=0.88, wpb=112.1, bsz=40, num_updates=5030, lr=4.98176e-05, gnorm=0.775, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24555
2022-10-13 17:20:20 - progress_bar.py[line:274] - INFO: epoch 001:   5046 / 28910 loss=0.456, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=102, ups=0.93, wpb=109.9, bsz=40, num_updates=5040, lr=4.98131e-05, gnorm=0.917, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24565
2022-10-13 17:20:31 - progress_bar.py[line:274] - INFO: epoch 001:   5056 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.1, ups=0.9, wpb=110.8, bsz=40, num_updates=5050, lr=4.98086e-05, gnorm=1.009, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24576
2022-10-13 17:20:42 - progress_bar.py[line:274] - INFO: epoch 001:   5066 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101.9, ups=0.92, wpb=111.3, bsz=40, num_updates=5060, lr=4.98041e-05, gnorm=1.044, clip=60, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=24587
2022-10-13 17:20:54 - progress_bar.py[line:274] - INFO: epoch 001:   5076 / 28910 loss=0.451, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.2, ups=0.88, wpb=111.3, bsz=40, num_updates=5070, lr=4.97996e-05, gnorm=1.031, clip=50, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24599
2022-10-13 17:21:05 - progress_bar.py[line:274] - INFO: epoch 001:   5086 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.7, ups=0.89, wpb=109.5, bsz=40, num_updates=5080, lr=4.97951e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24610
2022-10-13 17:21:16 - progress_bar.py[line:274] - INFO: epoch 001:   5096 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=104, ups=0.94, wpb=110.2, bsz=40, num_updates=5090, lr=4.97906e-05, gnorm=1.05, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24621
2022-10-13 17:21:27 - progress_bar.py[line:274] - INFO: epoch 001:   5106 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=102.1, ups=0.92, wpb=111, bsz=40, num_updates=5100, lr=4.97861e-05, gnorm=1.029, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24632
2022-10-13 17:21:38 - progress_bar.py[line:274] - INFO: epoch 001:   5116 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.5, ups=0.9, wpb=110, bsz=40, num_updates=5110, lr=4.97816e-05, gnorm=0.978, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=24643
2022-10-13 17:21:49 - progress_bar.py[line:274] - INFO: epoch 001:   5126 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.2, ups=0.88, wpb=110.2, bsz=40, num_updates=5120, lr=4.97771e-05, gnorm=1.024, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24654
2022-10-13 17:22:00 - progress_bar.py[line:274] - INFO: epoch 001:   5136 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.3, ups=0.9, wpb=110.9, bsz=40, num_updates=5130, lr=4.97726e-05, gnorm=0.987, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24665
2022-10-13 17:22:11 - progress_bar.py[line:274] - INFO: epoch 001:   5146 / 28910 loss=0.473, loss_v1=0, loss_v2=0, nll_loss=0.356, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=99.8, ups=0.91, wpb=109.1, bsz=40, num_updates=5140, lr=4.9768e-05, gnorm=1.095, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24676
2022-10-13 17:22:22 - progress_bar.py[line:274] - INFO: epoch 001:   5156 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=5150, lr=4.97635e-05, gnorm=0.959, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24687
2022-10-13 17:22:33 - progress_bar.py[line:274] - INFO: epoch 001:   5166 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.338, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.8, ups=0.91, wpb=110.1, bsz=40, num_updates=5160, lr=4.9759e-05, gnorm=1.043, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24698
2022-10-13 17:22:45 - progress_bar.py[line:274] - INFO: epoch 001:   5176 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=5170, lr=4.97545e-05, gnorm=0.902, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24709
2022-10-13 17:22:56 - progress_bar.py[line:274] - INFO: epoch 001:   5186 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97.9, ups=0.88, wpb=110.8, bsz=40, num_updates=5180, lr=4.975e-05, gnorm=1.058, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24721
2022-10-13 17:23:07 - progress_bar.py[line:274] - INFO: epoch 001:   5196 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97, ups=0.88, wpb=109.7, bsz=40, num_updates=5190, lr=4.97455e-05, gnorm=0.977, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=24732
2022-10-13 17:23:18 - progress_bar.py[line:274] - INFO: epoch 001:   5206 / 28910 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.6, ups=0.91, wpb=110, bsz=40, num_updates=5200, lr=4.9741e-05, gnorm=1.007, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24743
2022-10-13 17:23:29 - progress_bar.py[line:274] - INFO: epoch 001:   5216 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101.2, ups=0.9, wpb=112, bsz=40, num_updates=5210, lr=4.97365e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24754
2022-10-13 17:23:40 - progress_bar.py[line:274] - INFO: epoch 001:   5226 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.328, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.2, ups=0.9, wpb=110, bsz=40, num_updates=5220, lr=4.9732e-05, gnorm=0.939, clip=20, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=24765
2022-10-13 17:23:52 - progress_bar.py[line:274] - INFO: epoch 001:   5236 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.8, ups=0.87, wpb=110.5, bsz=40, num_updates=5230, lr=4.97275e-05, gnorm=1.549, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24777
2022-10-13 17:24:03 - progress_bar.py[line:274] - INFO: epoch 001:   5246 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.3, ups=0.9, wpb=109, bsz=40, num_updates=5240, lr=4.9723e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=24788
2022-10-13 17:24:14 - progress_bar.py[line:274] - INFO: epoch 001:   5256 / 28910 loss=0.452, loss_v1=0, loss_v2=0, nll_loss=0.33, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.8, ups=0.92, wpb=109, bsz=40, num_updates=5250, lr=4.97185e-05, gnorm=1.116, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24799
2022-10-13 17:24:25 - progress_bar.py[line:274] - INFO: epoch 001:   5266 / 28910 loss=0.442, loss_v1=0, loss_v2=0, nll_loss=0.317, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101, ups=0.91, wpb=111, bsz=40, num_updates=5260, lr=4.9714e-05, gnorm=1.002, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24810
2022-10-13 17:24:36 - progress_bar.py[line:274] - INFO: epoch 001:   5276 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.2, ups=0.88, wpb=109.6, bsz=40, num_updates=5270, lr=4.97095e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24821
2022-10-13 17:24:48 - progress_bar.py[line:274] - INFO: epoch 001:   5286 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.6, ups=0.87, wpb=108.5, bsz=40, num_updates=5280, lr=4.9705e-05, gnorm=0.936, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24833
2022-10-13 17:24:59 - progress_bar.py[line:274] - INFO: epoch 001:   5296 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.1, ups=0.91, wpb=110.6, bsz=40, num_updates=5290, lr=4.97005e-05, gnorm=1.061, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=24844
2022-10-13 17:25:10 - progress_bar.py[line:274] - INFO: epoch 001:   5306 / 28910 loss=0.45, loss_v1=0, loss_v2=0, nll_loss=0.322, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.2, ups=0.9, wpb=109.7, bsz=40, num_updates=5300, lr=4.9696e-05, gnorm=0.984, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24855
2022-10-13 17:25:21 - progress_bar.py[line:274] - INFO: epoch 001:   5316 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.5, ups=0.9, wpb=108.9, bsz=40, num_updates=5310, lr=4.96915e-05, gnorm=1.032, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24866
2022-10-13 17:25:32 - progress_bar.py[line:274] - INFO: epoch 001:   5326 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.319, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=99.2, ups=0.9, wpb=110, bsz=40, num_updates=5320, lr=4.9687e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24877
2022-10-13 17:25:43 - progress_bar.py[line:274] - INFO: epoch 001:   5336 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.6, ups=0.9, wpb=110.3, bsz=40, num_updates=5330, lr=4.96825e-05, gnorm=1.011, clip=50, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=24888
2022-10-13 17:25:54 - progress_bar.py[line:274] - INFO: epoch 001:   5346 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.2, ups=0.9, wpb=109.5, bsz=40, num_updates=5340, lr=4.9678e-05, gnorm=1.022, clip=70, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24899
2022-10-13 17:26:06 - progress_bar.py[line:274] - INFO: epoch 001:   5356 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.307, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.6, ups=0.89, wpb=112.1, bsz=40, num_updates=5350, lr=4.96735e-05, gnorm=0.953, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24911
2022-10-13 17:26:17 - progress_bar.py[line:274] - INFO: epoch 001:   5366 / 28910 loss=0.455, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.9, ups=0.89, wpb=111.5, bsz=40, num_updates=5360, lr=4.9669e-05, gnorm=1.005, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24922
2022-10-13 17:26:28 - progress_bar.py[line:274] - INFO: epoch 001:   5376 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99, ups=0.9, wpb=109.8, bsz=40, num_updates=5370, lr=4.96645e-05, gnorm=0.883, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=24933
2022-10-13 17:26:39 - progress_bar.py[line:274] - INFO: epoch 001:   5386 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.1, ups=0.88, wpb=111.5, bsz=40, num_updates=5380, lr=4.966e-05, gnorm=0.981, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24944
2022-10-13 17:26:51 - progress_bar.py[line:274] - INFO: epoch 001:   5396 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.9, ups=0.87, wpb=110.2, bsz=40, num_updates=5390, lr=4.96555e-05, gnorm=0.85, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24956
2022-10-13 17:27:02 - progress_bar.py[line:274] - INFO: epoch 001:   5406 / 28910 loss=0.472, loss_v1=0, loss_v2=0, nll_loss=0.351, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.28, wps=96.9, ups=0.88, wpb=110, bsz=40, num_updates=5400, lr=4.96509e-05, gnorm=0.952, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=24967
2022-10-13 17:27:13 - progress_bar.py[line:274] - INFO: epoch 001:   5416 / 28910 loss=0.448, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=97.6, ups=0.89, wpb=109.1, bsz=40, num_updates=5410, lr=4.96464e-05, gnorm=1.048, clip=60, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=24978
2022-10-13 17:27:25 - progress_bar.py[line:274] - INFO: epoch 001:   5426 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.6, ups=0.9, wpb=111.4, bsz=40, num_updates=5420, lr=4.96419e-05, gnorm=0.902, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=24989
2022-10-13 17:27:36 - progress_bar.py[line:274] - INFO: epoch 001:   5436 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.1, ups=0.88, wpb=109.5, bsz=40, num_updates=5430, lr=4.96374e-05, gnorm=0.998, clip=50, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25001
2022-10-13 17:27:47 - progress_bar.py[line:274] - INFO: epoch 001:   5446 / 28910 loss=0.432, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.6, ups=0.89, wpb=110.8, bsz=40, num_updates=5440, lr=4.96329e-05, gnorm=0.974, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25012
2022-10-13 17:27:58 - progress_bar.py[line:274] - INFO: epoch 001:   5456 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.326, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=101.6, ups=0.93, wpb=109.5, bsz=40, num_updates=5450, lr=4.96284e-05, gnorm=0.94, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25023
2022-10-13 17:28:09 - progress_bar.py[line:274] - INFO: epoch 001:   5466 / 28910 loss=0.444, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.4, ups=0.88, wpb=109.8, bsz=40, num_updates=5460, lr=4.96239e-05, gnorm=1.083, clip=60, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25034
2022-10-13 17:28:21 - progress_bar.py[line:274] - INFO: epoch 001:   5476 / 28910 loss=0.449, loss_v1=0, loss_v2=0, nll_loss=0.325, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=5470, lr=4.96194e-05, gnorm=0.817, clip=30, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=25045
2022-10-13 17:28:31 - progress_bar.py[line:274] - INFO: epoch 001:   5486 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.5, ups=0.92, wpb=109.4, bsz=40, num_updates=5480, lr=4.96149e-05, gnorm=1.035, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25056
2022-10-13 17:28:43 - progress_bar.py[line:274] - INFO: epoch 001:   5496 / 28910 loss=0.453, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=98.6, ups=0.89, wpb=111, bsz=40, num_updates=5490, lr=4.96104e-05, gnorm=1.015, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25068
2022-10-13 17:28:54 - progress_bar.py[line:274] - INFO: epoch 001:   5506 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.1, ups=0.89, wpb=111.1, bsz=40, num_updates=5500, lr=4.96059e-05, gnorm=0.808, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=25079
2022-10-13 17:29:05 - progress_bar.py[line:274] - INFO: epoch 001:   5516 / 28910 loss=0.454, loss_v1=0, loss_v2=0, nll_loss=0.333, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=97.4, ups=0.89, wpb=109.2, bsz=40, num_updates=5510, lr=4.96014e-05, gnorm=0.941, clip=40, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25090
2022-10-13 17:29:16 - progress_bar.py[line:274] - INFO: epoch 001:   5526 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99, ups=0.89, wpb=110.7, bsz=40, num_updates=5520, lr=4.95969e-05, gnorm=0.994, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25101
2022-10-13 17:29:28 - progress_bar.py[line:274] - INFO: epoch 001:   5536 / 28910 loss=0.439, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.9, ups=0.87, wpb=111, bsz=40, num_updates=5530, lr=4.95924e-05, gnorm=0.846, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25113
2022-10-13 17:29:39 - progress_bar.py[line:274] - INFO: epoch 001:   5546 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=5540, lr=4.95879e-05, gnorm=0.928, clip=30, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25124
2022-10-13 17:29:50 - progress_bar.py[line:274] - INFO: epoch 001:   5556 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.1, ups=0.89, wpb=110.3, bsz=40, num_updates=5550, lr=4.95834e-05, gnorm=1.095, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25135
2022-10-13 17:30:02 - progress_bar.py[line:274] - INFO: epoch 001:   5566 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.9, ups=0.89, wpb=110.9, bsz=40, num_updates=5560, lr=4.95789e-05, gnorm=0.923, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25147
2022-10-13 17:30:13 - progress_bar.py[line:274] - INFO: epoch 001:   5576 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101, ups=0.92, wpb=110.4, bsz=40, num_updates=5570, lr=4.95744e-05, gnorm=0.879, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25158
2022-10-13 17:30:24 - progress_bar.py[line:274] - INFO: epoch 001:   5586 / 28910 loss=0.44, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.7, ups=0.86, wpb=110.6, bsz=40, num_updates=5580, lr=4.95699e-05, gnorm=0.956, clip=40, loss_scale=1024, train_wall=12, gb_free=11, ema_decay=0.9999, wall=25169
2022-10-13 17:30:35 - progress_bar.py[line:274] - INFO: epoch 001:   5596 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101.7, ups=0.92, wpb=111.1, bsz=40, num_updates=5590, lr=4.95654e-05, gnorm=0.928, clip=40, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25180
2022-10-13 17:30:46 - progress_bar.py[line:274] - INFO: epoch 001:   5606 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=5600, lr=4.95609e-05, gnorm=0.86, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=25191
2022-10-13 17:30:56 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 17:30:58 - progress_bar.py[line:274] - INFO: epoch 001:   5617 / 28910 loss=0.459, loss_v1=0, loss_v2=0, nll_loss=0.337, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=92.6, ups=0.84, wpb=110.7, bsz=40, num_updates=5610, lr=4.95564e-05, gnorm=1.088, clip=50, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=25203
2022-10-13 17:31:10 - progress_bar.py[line:274] - INFO: epoch 001:   5627 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.3, ups=0.88, wpb=110.4, bsz=40, num_updates=5620, lr=4.95519e-05, gnorm=0.932, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25215
2022-10-13 17:31:20 - progress_bar.py[line:274] - INFO: epoch 001:   5637 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=102.1, ups=0.92, wpb=110.5, bsz=40, num_updates=5630, lr=4.95474e-05, gnorm=0.963, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25225
2022-10-13 17:31:32 - progress_bar.py[line:274] - INFO: epoch 001:   5647 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.1, ups=0.88, wpb=111.6, bsz=40, num_updates=5640, lr=4.95429e-05, gnorm=0.963, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25237
2022-10-13 17:31:43 - progress_bar.py[line:274] - INFO: epoch 001:   5657 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.291, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99, ups=0.9, wpb=110.4, bsz=40, num_updates=5650, lr=4.95384e-05, gnorm=0.908, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25248
2022-10-13 17:31:54 - progress_bar.py[line:274] - INFO: epoch 001:   5667 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=5660, lr=4.95338e-05, gnorm=0.813, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25259
2022-10-13 17:32:05 - progress_bar.py[line:274] - INFO: epoch 001:   5677 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=5670, lr=4.95293e-05, gnorm=0.909, clip=30, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=25270
2022-10-13 17:32:17 - progress_bar.py[line:274] - INFO: epoch 001:   5687 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.2, ups=0.89, wpb=110.1, bsz=40, num_updates=5680, lr=4.95248e-05, gnorm=0.82, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25282
2022-10-13 17:32:28 - progress_bar.py[line:274] - INFO: epoch 001:   5697 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.2, ups=0.89, wpb=112.1, bsz=40, num_updates=5690, lr=4.95203e-05, gnorm=0.927, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25293
2022-10-13 17:32:39 - progress_bar.py[line:274] - INFO: epoch 001:   5707 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.4, ups=0.88, wpb=110.1, bsz=40, num_updates=5700, lr=4.95158e-05, gnorm=0.9, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25304
2022-10-13 17:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   5717 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.308, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.9, ups=0.92, wpb=110, bsz=40, num_updates=5710, lr=4.95113e-05, gnorm=1.078, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25315
2022-10-13 17:33:01 - progress_bar.py[line:274] - INFO: epoch 001:   5727 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100, ups=0.9, wpb=110.5, bsz=40, num_updates=5720, lr=4.95068e-05, gnorm=0.794, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25326
2022-10-13 17:33:12 - progress_bar.py[line:274] - INFO: epoch 001:   5737 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.7, ups=0.9, wpb=110.4, bsz=40, num_updates=5730, lr=4.95023e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25337
2022-10-13 17:33:23 - progress_bar.py[line:274] - INFO: epoch 001:   5747 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.9, ups=0.9, wpb=110.4, bsz=40, num_updates=5740, lr=4.94978e-05, gnorm=0.836, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25348
2022-10-13 17:33:35 - progress_bar.py[line:274] - INFO: epoch 001:   5757 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.313, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=95.7, ups=0.87, wpb=109.7, bsz=40, num_updates=5750, lr=4.94933e-05, gnorm=1.014, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25360
2022-10-13 17:33:46 - progress_bar.py[line:274] - INFO: epoch 001:   5767 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.5, ups=0.88, wpb=110.4, bsz=40, num_updates=5760, lr=4.94888e-05, gnorm=0.983, clip=40, loss_scale=512, train_wall=11, gb_free=9.9, ema_decay=0.9999, wall=25371
2022-10-13 17:33:57 - progress_bar.py[line:274] - INFO: epoch 001:   5777 / 28910 loss=0.462, loss_v1=0, loss_v2=0, nll_loss=0.34, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=97.9, ups=0.89, wpb=109.9, bsz=40, num_updates=5770, lr=4.94843e-05, gnorm=1.117, clip=70, loss_scale=512, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=25382
2022-10-13 17:34:09 - progress_bar.py[line:274] - INFO: epoch 001:   5787 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.4, ups=0.88, wpb=109.5, bsz=40, num_updates=5780, lr=4.94798e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25394
2022-10-13 17:34:20 - progress_bar.py[line:274] - INFO: epoch 001:   5797 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99, ups=0.89, wpb=111.3, bsz=40, num_updates=5790, lr=4.94753e-05, gnorm=1, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25405
2022-10-13 17:34:31 - progress_bar.py[line:274] - INFO: epoch 001:   5807 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97, ups=0.89, wpb=108.8, bsz=40, num_updates=5800, lr=4.94708e-05, gnorm=1.006, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25416
2022-10-13 17:34:42 - progress_bar.py[line:274] - INFO: epoch 001:   5817 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.5, ups=0.91, wpb=110.8, bsz=40, num_updates=5810, lr=4.94663e-05, gnorm=0.947, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25427
2022-10-13 17:34:53 - progress_bar.py[line:274] - INFO: epoch 001:   5827 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.6, ups=0.9, wpb=110.8, bsz=40, num_updates=5820, lr=4.94618e-05, gnorm=0.888, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25438
2022-10-13 17:35:05 - progress_bar.py[line:274] - INFO: epoch 001:   5837 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=5830, lr=4.94573e-05, gnorm=0.961, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25450
2022-10-13 17:35:16 - progress_bar.py[line:274] - INFO: epoch 001:   5847 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.9, ups=0.92, wpb=110.5, bsz=40, num_updates=5840, lr=4.94528e-05, gnorm=0.931, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25461
2022-10-13 17:35:27 - progress_bar.py[line:274] - INFO: epoch 001:   5857 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.5, ups=0.88, wpb=109.8, bsz=40, num_updates=5850, lr=4.94483e-05, gnorm=1.066, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25472
2022-10-13 17:35:38 - progress_bar.py[line:274] - INFO: epoch 001:   5867 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.8, ups=0.91, wpb=110.2, bsz=40, num_updates=5860, lr=4.94438e-05, gnorm=0.981, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25483
2022-10-13 17:35:49 - progress_bar.py[line:274] - INFO: epoch 001:   5877 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.5, ups=0.9, wpb=110.3, bsz=40, num_updates=5870, lr=4.94393e-05, gnorm=0.897, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=25494
2022-10-13 17:36:00 - progress_bar.py[line:274] - INFO: epoch 001:   5887 / 28910 loss=0.446, loss_v1=0, loss_v2=0, nll_loss=0.324, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=98.3, ups=0.9, wpb=109.8, bsz=40, num_updates=5880, lr=4.94348e-05, gnorm=0.992, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25505
2022-10-13 17:36:11 - progress_bar.py[line:274] - INFO: epoch 001:   5897 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=102.7, ups=0.92, wpb=111.8, bsz=40, num_updates=5890, lr=4.94303e-05, gnorm=0.913, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25516
2022-10-13 17:36:22 - progress_bar.py[line:274] - INFO: epoch 001:   5907 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.6, ups=0.9, wpb=109.1, bsz=40, num_updates=5900, lr=4.94258e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25527
2022-10-13 17:36:33 - progress_bar.py[line:274] - INFO: epoch 001:   5917 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=112.6, nsentences=40, sample_size=112.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.7, ups=0.9, wpb=112.6, bsz=40, num_updates=5910, lr=4.94212e-05, gnorm=0.735, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25538
2022-10-13 17:36:45 - progress_bar.py[line:274] - INFO: epoch 001:   5927 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99, ups=0.9, wpb=110.1, bsz=40, num_updates=5920, lr=4.94167e-05, gnorm=0.86, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25550
2022-10-13 17:36:56 - progress_bar.py[line:274] - INFO: epoch 001:   5937 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.5, ups=0.89, wpb=110.5, bsz=40, num_updates=5930, lr=4.94122e-05, gnorm=0.958, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25561
2022-10-13 17:37:07 - progress_bar.py[line:274] - INFO: epoch 001:   5947 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.2, ups=0.89, wpb=109.4, bsz=40, num_updates=5940, lr=4.94077e-05, gnorm=0.91, clip=20, loss_scale=512, train_wall=11, gb_free=9.8, ema_decay=0.9999, wall=25572
2022-10-13 17:37:19 - progress_bar.py[line:274] - INFO: epoch 001:   5957 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.301, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96, ups=0.87, wpb=110, bsz=40, num_updates=5950, lr=4.94032e-05, gnorm=0.969, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25583
2022-10-13 17:37:30 - progress_bar.py[line:274] - INFO: epoch 001:   5967 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98, ups=0.9, wpb=108.5, bsz=40, num_updates=5960, lr=4.93987e-05, gnorm=0.835, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=25595
2022-10-13 17:37:41 - progress_bar.py[line:274] - INFO: epoch 001:   5977 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.9, ups=0.89, wpb=110.6, bsz=40, num_updates=5970, lr=4.93942e-05, gnorm=0.955, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=25606
2022-10-13 17:37:52 - progress_bar.py[line:274] - INFO: epoch 001:   5987 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.8, ups=0.88, wpb=109.2, bsz=40, num_updates=5980, lr=4.93897e-05, gnorm=1.035, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25617
2022-10-13 17:38:04 - progress_bar.py[line:274] - INFO: epoch 001:   5997 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.1, ups=0.88, wpb=110.7, bsz=40, num_updates=5990, lr=4.93852e-05, gnorm=0.947, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=25629
2022-10-13 17:38:15 - progress_bar.py[line:274] - INFO: epoch 001:   6007 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98, ups=0.9, wpb=109.3, bsz=40, num_updates=6000, lr=4.93807e-05, gnorm=0.864, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=25640
2022-10-13 17:38:15 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 17:38:16 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 17:38:16 - train.py[line:551] - INFO: load:0.92 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 17:40:49 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 17:40:49 - train.py[line:551] - INFO: load:0.95 valid_run:152.63 task_valid:149.15 collect_output:2.30
2022-10-13 17:43:18 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 17:43:18 - train.py[line:551] - INFO: load:0.97 valid_run:302.11 task_valid:294.08 collect_output:5.71
2022-10-13 17:45:51 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 17:45:51 - train.py[line:551] - INFO: load:1.00 valid_run:455.01 task_valid:438.22 collect_output:13.32
2022-10-13 17:48:21 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 17:48:21 - train.py[line:551] - INFO: load:1.02 valid_run:604.77 task_valid:584.08 collect_output:16.06
2022-10-13 17:50:54 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 17:50:54 - train.py[line:551] - INFO: load:1.05 valid_run:757.79 task_valid:732.40 collect_output:19.54
2022-10-13 17:53:26 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 17:53:26 - train.py[line:551] - INFO: load:1.08 valid_run:909.68 task_valid:878.44 collect_output:24.31
2022-10-13 17:56:00 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 17:56:00 - train.py[line:551] - INFO: load:1.10 valid_run:1063.05 task_valid:1025.05 collect_output:29.99
2022-10-13 17:58:31 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 17:58:31 - train.py[line:551] - INFO: load:1.13 valid_run:1214.46 task_valid:1166.93 collect_output:38.42
2022-10-13 18:01:01 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 18:01:01 - train.py[line:551] - INFO: load:1.15 valid_run:1364.44 task_valid:1312.29 collect_output:41.94
2022-10-13 18:03:30 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 18:03:30 - train.py[line:551] - INFO: load:1.18 valid_run:1513.53 task_valid:1456.24 collect_output:45.91
2022-10-13 18:06:00 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 18:06:00 - train.py[line:551] - INFO: load:1.20 valid_run:1663.53 task_valid:1601.55 collect_output:49.53
2022-10-13 18:08:30 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 18:08:30 - train.py[line:551] - INFO: load:1.23 valid_run:1813.28 task_valid:1746.44 collect_output:53.36
2022-10-13 18:11:00 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 18:11:00 - train.py[line:551] - INFO: load:1.25 valid_run:1963.14 task_valid:1888.28 collect_output:60.33
2022-10-13 18:13:30 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 18:13:30 - train.py[line:551] - INFO: load:1.28 valid_run:2113.59 task_valid:2033.82 collect_output:64.19
2022-10-13 18:16:01 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 18:16:01 - train.py[line:551] - INFO: load:1.31 valid_run:2263.81 task_valid:2180.46 collect_output:66.71
2022-10-13 18:18:31 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 18:18:31 - train.py[line:551] - INFO: load:1.34 valid_run:2414.06 task_valid:2324.85 collect_output:71.51
2022-10-13 18:21:03 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 18:21:03 - train.py[line:551] - INFO: load:1.36 valid_run:2565.91 task_valid:2470.59 collect_output:76.55
2022-10-13 18:23:34 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 18:23:34 - train.py[line:551] - INFO: load:1.39 valid_run:2716.62 task_valid:2617.82 collect_output:78.99
2022-10-13 18:26:02 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 18:26:02 - train.py[line:551] - INFO: load:1.41 valid_run:2864.83 task_valid:2759.53 collect_output:84.45
2022-10-13 18:28:33 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 18:28:33 - train.py[line:551] - INFO: load:1.44 valid_run:3015.24 task_valid:2904.79 collect_output:88.56
2022-10-13 18:31:04 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 18:31:04 - train.py[line:551] - INFO: load:1.46 valid_run:3167.06 task_valid:3049.41 collect_output:94.75
2022-10-13 18:33:34 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 18:33:34 - train.py[line:551] - INFO: load:1.49 valid_run:3316.33 task_valid:3193.94 collect_output:98.45
2022-10-13 18:36:05 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 18:36:05 - train.py[line:551] - INFO: load:1.51 valid_run:3467.41 task_valid:3340.20 collect_output:102.25
2022-10-13 18:38:36 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 18:38:36 - train.py[line:551] - INFO: load:1.54 valid_run:3618.75 task_valid:3486.89 collect_output:105.86

====================================================================================================
SGG eval:     R @ 50: 0.5622;     R @ 100: 0.5909;     R @ 500: 0.6396;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3608;    mR @ 100: 0.3848;    mR @ 500: 0.4671;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.6875) (covering:0.5143) (eating:0.7059) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8333) (playing:0.0000) (riding:0.9477) (says:0.0000) (sitting on:0.7245) (standing on:0.1567) (using:0.5000) (walking in:0.0000) (walking on:0.6486) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5622;     R @ 100: 0.5909;     R @ 500: 0.6396;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3608;    mR @ 100: 0.3848;    mR @ 500: 0.4671;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.6875) (covering:0.5143) (eating:0.7059) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8333) (playing:0.0000) (riding:0.9477) (says:0.0000) (sitting on:0.7245) (standing on:0.1567) (using:0.5000) (walking in:0.0000) (walking on:0.6486) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================

2022-10-13 18:41:07 - train.py[line:487] - INFO: 0.5909095238095238
2022-10-13 18:41:07 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 18:41:07 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.312 | loss_v1 0 | loss_v2 0 | nll_loss 0.153 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.59091 | ppl 1.11 | vqa_score 0.4628 | wps 119 | wpb 89.9 | bsz 30 | num_updates 6000 | best_R@100 0.59091
2022-10-13 18:41:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2022-10-13 18:41:07 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-13 18:41:13 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt
2022-10-13 18:41:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 0.5909095238095238) (writing took 10.777669347357005 seconds)
2022-10-13 18:41:29 - progress_bar.py[line:274] - INFO: epoch 001:   6017 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.315, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=0.3, ups=0, wpb=110.6, bsz=40, num_updates=6010, lr=4.93762e-05, gnorm=0.848, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29434
2022-10-13 18:41:40 - progress_bar.py[line:274] - INFO: epoch 001:   6027 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.8, ups=0.9, wpb=109.9, bsz=40, num_updates=6020, lr=4.93717e-05, gnorm=0.925, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=29445
2022-10-13 18:41:52 - progress_bar.py[line:274] - INFO: epoch 001:   6037 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.1, ups=0.89, wpb=110.4, bsz=40, num_updates=6030, lr=4.93672e-05, gnorm=0.972, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29457
2022-10-13 18:42:03 - progress_bar.py[line:274] - INFO: epoch 001:   6047 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=102.2, ups=0.92, wpb=111.2, bsz=40, num_updates=6040, lr=4.93627e-05, gnorm=0.986, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29468
2022-10-13 18:42:13 - progress_bar.py[line:274] - INFO: epoch 001:   6057 / 28910 loss=0.425, loss_v1=0, loss_v2=0, nll_loss=0.302, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=101.3, ups=0.92, wpb=110.3, bsz=40, num_updates=6050, lr=4.93582e-05, gnorm=1.012, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=29478
2022-10-13 18:42:25 - progress_bar.py[line:274] - INFO: epoch 001:   6067 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.3, ups=0.91, wpb=109.6, bsz=40, num_updates=6060, lr=4.93537e-05, gnorm=0.914, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29489
2022-10-13 18:42:36 - progress_bar.py[line:274] - INFO: epoch 001:   6077 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.2, ups=0.88, wpb=109.3, bsz=40, num_updates=6070, lr=4.93492e-05, gnorm=0.976, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29501
2022-10-13 18:42:47 - progress_bar.py[line:274] - INFO: epoch 001:   6087 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=102.2, ups=0.92, wpb=111.3, bsz=40, num_updates=6080, lr=4.93447e-05, gnorm=0.887, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29512
2022-10-13 18:42:58 - progress_bar.py[line:274] - INFO: epoch 001:   6097 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.3, ups=0.89, wpb=111.2, bsz=40, num_updates=6090, lr=4.93402e-05, gnorm=0.919, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29523
2022-10-13 18:43:09 - progress_bar.py[line:274] - INFO: epoch 001:   6107 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.4, ups=0.91, wpb=110.6, bsz=40, num_updates=6100, lr=4.93357e-05, gnorm=1.167, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29534
2022-10-13 18:43:20 - progress_bar.py[line:274] - INFO: epoch 001:   6117 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.5, ups=0.9, wpb=109.8, bsz=40, num_updates=6110, lr=4.93312e-05, gnorm=0.914, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29545
2022-10-13 18:43:31 - progress_bar.py[line:274] - INFO: epoch 001:   6127 / 28910 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.332, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=100.6, ups=0.92, wpb=109.7, bsz=40, num_updates=6120, lr=4.93267e-05, gnorm=1.005, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29556
2022-10-13 18:43:42 - progress_bar.py[line:274] - INFO: epoch 001:   6137 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.2, ups=0.91, wpb=111.6, bsz=40, num_updates=6130, lr=4.93222e-05, gnorm=0.843, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29567
2022-10-13 18:43:54 - progress_bar.py[line:274] - INFO: epoch 001:   6147 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.3, ups=0.88, wpb=111.4, bsz=40, num_updates=6140, lr=4.93177e-05, gnorm=0.79, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29578
2022-10-13 18:44:05 - progress_bar.py[line:274] - INFO: epoch 001:   6157 / 28910 loss=0.421, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99, ups=0.9, wpb=110.5, bsz=40, num_updates=6150, lr=4.93132e-05, gnorm=0.911, clip=20, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=29590
2022-10-13 18:44:15 - progress_bar.py[line:274] - INFO: epoch 001:   6167 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.288, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=102.7, ups=0.93, wpb=110.4, bsz=40, num_updates=6160, lr=4.93087e-05, gnorm=0.915, clip=30, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=29600
2022-10-13 18:44:27 - progress_bar.py[line:274] - INFO: epoch 001:   6177 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97, ups=0.88, wpb=110.2, bsz=40, num_updates=6170, lr=4.93041e-05, gnorm=1.022, clip=60, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29612
2022-10-13 18:44:38 - progress_bar.py[line:274] - INFO: epoch 001:   6187 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.297, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.5, ups=0.9, wpb=110.8, bsz=40, num_updates=6180, lr=4.92996e-05, gnorm=0.91, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29623
2022-10-13 18:44:49 - progress_bar.py[line:274] - INFO: epoch 001:   6197 / 28910 loss=0.428, loss_v1=0, loss_v2=0, nll_loss=0.296, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.9, ups=0.88, wpb=109.6, bsz=40, num_updates=6190, lr=4.92951e-05, gnorm=0.928, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29634
2022-10-13 18:45:01 - progress_bar.py[line:274] - INFO: epoch 001:   6207 / 28910 loss=0.441, loss_v1=0, loss_v2=0, nll_loss=0.318, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=96.8, ups=0.88, wpb=109.8, bsz=40, num_updates=6200, lr=4.92906e-05, gnorm=0.842, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29646
2022-10-13 18:45:12 - progress_bar.py[line:274] - INFO: epoch 001:   6217 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.2, ups=0.88, wpb=111, bsz=40, num_updates=6210, lr=4.92861e-05, gnorm=0.735, clip=10, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=29657
2022-10-13 18:45:23 - progress_bar.py[line:274] - INFO: epoch 001:   6227 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101.1, ups=0.92, wpb=109.8, bsz=40, num_updates=6220, lr=4.92816e-05, gnorm=0.905, clip=50, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29668
2022-10-13 18:45:34 - progress_bar.py[line:274] - INFO: epoch 001:   6237 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.8, ups=0.88, wpb=109.6, bsz=40, num_updates=6230, lr=4.92771e-05, gnorm=0.961, clip=50, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29679
2022-10-13 18:45:46 - progress_bar.py[line:274] - INFO: epoch 001:   6247 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.287, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.8, ups=0.87, wpb=109.1, bsz=40, num_updates=6240, lr=4.92726e-05, gnorm=0.986, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=29691
2022-10-13 18:45:57 - progress_bar.py[line:274] - INFO: epoch 001:   6257 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.9, ups=0.91, wpb=110.3, bsz=40, num_updates=6250, lr=4.92681e-05, gnorm=1.015, clip=50, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29702
2022-10-13 18:46:08 - progress_bar.py[line:274] - INFO: epoch 001:   6267 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=94.2, ups=0.86, wpb=109.1, bsz=40, num_updates=6260, lr=4.92636e-05, gnorm=0.884, clip=10, loss_scale=1024, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=29713
2022-10-13 18:46:19 - progress_bar.py[line:274] - INFO: epoch 001:   6277 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.6, ups=0.9, wpb=111, bsz=40, num_updates=6270, lr=4.92591e-05, gnorm=0.804, clip=0, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=29724
2022-10-13 18:46:20 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 18:46:32 - progress_bar.py[line:274] - INFO: epoch 001:   6288 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=88.3, ups=0.8, wpb=110.4, bsz=40, num_updates=6280, lr=4.92546e-05, gnorm=0.781, clip=0, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=29737
2022-10-13 18:46:43 - progress_bar.py[line:274] - INFO: epoch 001:   6298 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.7, ups=0.87, wpb=109.5, bsz=40, num_updates=6290, lr=4.92501e-05, gnorm=0.883, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29748
2022-10-13 18:46:55 - progress_bar.py[line:274] - INFO: epoch 001:   6308 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.5, ups=0.87, wpb=109.4, bsz=40, num_updates=6300, lr=4.92456e-05, gnorm=0.783, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29760
2022-10-13 18:47:06 - progress_bar.py[line:274] - INFO: epoch 001:   6318 / 28910 loss=0.435, loss_v1=0, loss_v2=0, nll_loss=0.305, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.4, ups=0.92, wpb=109.7, bsz=40, num_updates=6310, lr=4.92411e-05, gnorm=1, clip=40, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=29771
2022-10-13 18:47:17 - progress_bar.py[line:274] - INFO: epoch 001:   6328 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.8, ups=0.9, wpb=110.3, bsz=40, num_updates=6320, lr=4.92366e-05, gnorm=1.025, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29782
2022-10-13 18:47:28 - progress_bar.py[line:274] - INFO: epoch 001:   6338 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.2, ups=0.88, wpb=110.4, bsz=40, num_updates=6330, lr=4.92321e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29793
2022-10-13 18:47:39 - progress_bar.py[line:274] - INFO: epoch 001:   6348 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.6, ups=0.89, wpb=110.5, bsz=40, num_updates=6340, lr=4.92276e-05, gnorm=0.932, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29804
2022-10-13 18:47:50 - progress_bar.py[line:274] - INFO: epoch 001:   6358 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.2, ups=0.92, wpb=109.1, bsz=40, num_updates=6350, lr=4.92231e-05, gnorm=0.945, clip=40, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=29815
2022-10-13 18:48:02 - progress_bar.py[line:274] - INFO: epoch 001:   6368 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98, ups=0.9, wpb=109.3, bsz=40, num_updates=6360, lr=4.92186e-05, gnorm=0.919, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29826
2022-10-13 18:48:13 - progress_bar.py[line:274] - INFO: epoch 001:   6378 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.8, ups=0.87, wpb=110.7, bsz=40, num_updates=6370, lr=4.92141e-05, gnorm=0.825, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29838
2022-10-13 18:48:24 - progress_bar.py[line:274] - INFO: epoch 001:   6388 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.7, ups=0.88, wpb=109.6, bsz=40, num_updates=6380, lr=4.92096e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29849
2022-10-13 18:48:35 - progress_bar.py[line:274] - INFO: epoch 001:   6398 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101.1, ups=0.92, wpb=110.4, bsz=40, num_updates=6390, lr=4.92051e-05, gnorm=0.779, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29860
2022-10-13 18:48:47 - progress_bar.py[line:274] - INFO: epoch 001:   6408 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.9, ups=0.88, wpb=111.1, bsz=40, num_updates=6400, lr=4.92006e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29872
2022-10-13 18:48:57 - progress_bar.py[line:274] - INFO: epoch 001:   6418 / 28910 loss=0.42, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.8, ups=0.92, wpb=110, bsz=40, num_updates=6410, lr=4.91961e-05, gnorm=0.924, clip=20, loss_scale=512, train_wall=11, gb_free=11.3, ema_decay=0.9999, wall=29882
2022-10-13 18:49:09 - progress_bar.py[line:274] - INFO: epoch 001:   6428 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.9, ups=0.89, wpb=111.1, bsz=40, num_updates=6420, lr=4.91916e-05, gnorm=1.056, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29894
2022-10-13 18:49:20 - progress_bar.py[line:274] - INFO: epoch 001:   6438 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.3, ups=0.9, wpb=109.7, bsz=40, num_updates=6430, lr=4.9187e-05, gnorm=0.896, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=29905
2022-10-13 18:49:31 - progress_bar.py[line:274] - INFO: epoch 001:   6448 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.5, ups=0.92, wpb=110.9, bsz=40, num_updates=6440, lr=4.91825e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29916
2022-10-13 18:49:42 - progress_bar.py[line:274] - INFO: epoch 001:   6458 / 28910 loss=0.429, loss_v1=0, loss_v2=0, nll_loss=0.303, ntokens=108.5, nsentences=40, sample_size=108.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=94.6, ups=0.87, wpb=108.5, bsz=40, num_updates=6450, lr=4.9178e-05, gnorm=0.862, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29927
2022-10-13 18:49:53 - progress_bar.py[line:274] - INFO: epoch 001:   6468 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=102.6, ups=0.92, wpb=111.8, bsz=40, num_updates=6460, lr=4.91735e-05, gnorm=0.837, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29938
2022-10-13 18:50:05 - progress_bar.py[line:274] - INFO: epoch 001:   6478 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.1, ups=0.87, wpb=110, bsz=40, num_updates=6470, lr=4.9169e-05, gnorm=0.929, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=29950
2022-10-13 18:50:16 - progress_bar.py[line:274] - INFO: epoch 001:   6488 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.4, ups=0.9, wpb=111.4, bsz=40, num_updates=6480, lr=4.91645e-05, gnorm=0.888, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29961
2022-10-13 18:50:27 - progress_bar.py[line:274] - INFO: epoch 001:   6498 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.9, ups=0.9, wpb=109.8, bsz=40, num_updates=6490, lr=4.916e-05, gnorm=0.859, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29972
2022-10-13 18:50:38 - progress_bar.py[line:274] - INFO: epoch 001:   6508 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=102.2, ups=0.93, wpb=110.2, bsz=40, num_updates=6500, lr=4.91555e-05, gnorm=0.796, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=29983
2022-10-13 18:50:49 - progress_bar.py[line:274] - INFO: epoch 001:   6518 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.7, ups=0.89, wpb=110.9, bsz=40, num_updates=6510, lr=4.9151e-05, gnorm=0.741, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=29994
2022-10-13 18:51:00 - progress_bar.py[line:274] - INFO: epoch 001:   6528 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.3, ups=0.9, wpb=110.4, bsz=40, num_updates=6520, lr=4.91465e-05, gnorm=0.993, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30005
2022-10-13 18:51:11 - progress_bar.py[line:274] - INFO: epoch 001:   6538 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.4, ups=0.89, wpb=109.4, bsz=40, num_updates=6530, lr=4.9142e-05, gnorm=0.938, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30016
2022-10-13 18:51:23 - progress_bar.py[line:274] - INFO: epoch 001:   6548 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.289, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.7, ups=0.88, wpb=109.7, bsz=40, num_updates=6540, lr=4.91375e-05, gnorm=0.896, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30027
2022-10-13 18:51:34 - progress_bar.py[line:274] - INFO: epoch 001:   6558 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.1, ups=0.88, wpb=110.8, bsz=40, num_updates=6550, lr=4.9133e-05, gnorm=0.814, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30039
2022-10-13 18:51:45 - progress_bar.py[line:274] - INFO: epoch 001:   6568 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.7, ups=0.9, wpb=109.2, bsz=40, num_updates=6560, lr=4.91285e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30050
2022-10-13 18:51:56 - progress_bar.py[line:274] - INFO: epoch 001:   6578 / 28910 loss=0.433, loss_v1=0, loss_v2=0, nll_loss=0.306, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=97, ups=0.88, wpb=110.3, bsz=40, num_updates=6570, lr=4.9124e-05, gnorm=0.849, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30061
2022-10-13 18:52:07 - progress_bar.py[line:274] - INFO: epoch 001:   6588 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.4, ups=0.91, wpb=110.1, bsz=40, num_updates=6580, lr=4.91195e-05, gnorm=0.814, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30072
2022-10-13 18:52:18 - progress_bar.py[line:274] - INFO: epoch 001:   6598 / 28910 loss=0.426, loss_v1=0, loss_v2=0, nll_loss=0.298, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.1, ups=0.91, wpb=109.4, bsz=40, num_updates=6590, lr=4.9115e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30083
2022-10-13 18:52:29 - progress_bar.py[line:274] - INFO: epoch 001:   6608 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.1, ups=0.91, wpb=110.4, bsz=40, num_updates=6600, lr=4.91105e-05, gnorm=0.872, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30094
2022-10-13 18:52:41 - progress_bar.py[line:274] - INFO: epoch 001:   6618 / 28910 loss=0.414, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.7, ups=0.88, wpb=110.5, bsz=40, num_updates=6610, lr=4.9106e-05, gnorm=0.892, clip=30, loss_scale=512, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=30106
2022-10-13 18:52:52 - progress_bar.py[line:274] - INFO: epoch 001:   6628 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.9, ups=0.9, wpb=110.6, bsz=40, num_updates=6620, lr=4.91015e-05, gnorm=0.852, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30117
2022-10-13 18:53:03 - progress_bar.py[line:274] - INFO: epoch 001:   6638 / 28910 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=97.8, ups=0.89, wpb=109.4, bsz=40, num_updates=6630, lr=4.9097e-05, gnorm=1.007, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30128
2022-10-13 18:53:14 - progress_bar.py[line:274] - INFO: epoch 001:   6648 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.7, ups=0.87, wpb=110.1, bsz=40, num_updates=6640, lr=4.90925e-05, gnorm=0.88, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30139
2022-10-13 18:53:26 - progress_bar.py[line:274] - INFO: epoch 001:   6658 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.8, ups=0.9, wpb=109.9, bsz=40, num_updates=6650, lr=4.9088e-05, gnorm=0.872, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30150
2022-10-13 18:53:36 - progress_bar.py[line:274] - INFO: epoch 001:   6668 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.7, ups=0.92, wpb=109.7, bsz=40, num_updates=6660, lr=4.90835e-05, gnorm=0.765, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30161
2022-10-13 18:53:48 - progress_bar.py[line:274] - INFO: epoch 001:   6678 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.5, ups=0.9, wpb=110.1, bsz=40, num_updates=6670, lr=4.9079e-05, gnorm=0.837, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30172
2022-10-13 18:53:59 - progress_bar.py[line:274] - INFO: epoch 001:   6688 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=100.2, ups=0.9, wpb=111, bsz=40, num_updates=6680, lr=4.90744e-05, gnorm=0.946, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30184
2022-10-13 18:54:10 - progress_bar.py[line:274] - INFO: epoch 001:   6698 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.7, ups=0.89, wpb=109.1, bsz=40, num_updates=6690, lr=4.90699e-05, gnorm=0.926, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30195
2022-10-13 18:54:21 - progress_bar.py[line:274] - INFO: epoch 001:   6708 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=6700, lr=4.90654e-05, gnorm=0.968, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30206
2022-10-13 18:54:33 - progress_bar.py[line:274] - INFO: epoch 001:   6718 / 28910 loss=0.438, loss_v1=0, loss_v2=0, nll_loss=0.31, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=98.3, ups=0.89, wpb=110.3, bsz=40, num_updates=6710, lr=4.90609e-05, gnorm=1.015, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30217
2022-10-13 18:54:43 - progress_bar.py[line:274] - INFO: epoch 001:   6728 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.3, ups=0.91, wpb=111.2, bsz=40, num_updates=6720, lr=4.90564e-05, gnorm=0.923, clip=20, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30228
2022-10-13 18:54:55 - progress_bar.py[line:274] - INFO: epoch 001:   6738 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.3, ups=0.88, wpb=109.4, bsz=40, num_updates=6730, lr=4.90519e-05, gnorm=0.765, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30240
2022-10-13 18:55:06 - progress_bar.py[line:274] - INFO: epoch 001:   6748 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.1, ups=0.88, wpb=110.4, bsz=40, num_updates=6740, lr=4.90474e-05, gnorm=0.837, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30251
2022-10-13 18:55:17 - progress_bar.py[line:274] - INFO: epoch 001:   6758 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=103.6, ups=0.94, wpb=109.9, bsz=40, num_updates=6750, lr=4.90429e-05, gnorm=0.899, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30262
2022-10-13 18:55:28 - progress_bar.py[line:274] - INFO: epoch 001:   6768 / 28910 loss=0.411, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=6760, lr=4.90384e-05, gnorm=0.964, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30273
2022-10-13 18:55:39 - progress_bar.py[line:274] - INFO: epoch 001:   6778 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.8, ups=0.9, wpb=110.4, bsz=40, num_updates=6770, lr=4.90339e-05, gnorm=0.858, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30284
2022-10-13 18:55:50 - progress_bar.py[line:274] - INFO: epoch 001:   6788 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.3, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.7, ups=0.9, wpb=109.2, bsz=40, num_updates=6780, lr=4.90294e-05, gnorm=0.904, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30295
2022-10-13 18:56:01 - progress_bar.py[line:274] - INFO: epoch 001:   6798 / 28910 loss=0.461, loss_v1=0, loss_v2=0, nll_loss=0.334, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=99.2, ups=0.91, wpb=109.5, bsz=40, num_updates=6790, lr=4.90249e-05, gnorm=0.964, clip=40, loss_scale=1024, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=30306
2022-10-13 18:56:06 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 18:56:14 - progress_bar.py[line:274] - INFO: epoch 001:   6809 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=88.1, ups=0.8, wpb=110.3, bsz=40, num_updates=6800, lr=4.90204e-05, gnorm=0.829, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=30319
2022-10-13 18:56:25 - progress_bar.py[line:274] - INFO: epoch 001:   6819 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.5, ups=0.9, wpb=110.2, bsz=40, num_updates=6810, lr=4.90159e-05, gnorm=0.854, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30330
2022-10-13 18:56:36 - progress_bar.py[line:274] - INFO: epoch 001:   6829 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=108.9, nsentences=40, sample_size=108.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.1, ups=0.89, wpb=108.9, bsz=40, num_updates=6820, lr=4.90114e-05, gnorm=0.85, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30341
2022-10-13 18:56:47 - progress_bar.py[line:274] - INFO: epoch 001:   6839 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.2, ups=0.9, wpb=109.8, bsz=40, num_updates=6830, lr=4.90069e-05, gnorm=0.838, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30352
2022-10-13 18:56:58 - progress_bar.py[line:274] - INFO: epoch 001:   6849 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98, ups=0.89, wpb=110, bsz=40, num_updates=6840, lr=4.90024e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30363
2022-10-13 18:57:09 - progress_bar.py[line:274] - INFO: epoch 001:   6859 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.9, ups=0.91, wpb=110.3, bsz=40, num_updates=6850, lr=4.89979e-05, gnorm=0.831, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30374
2022-10-13 18:57:20 - progress_bar.py[line:274] - INFO: epoch 001:   6869 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.3, ups=0.91, wpb=110.8, bsz=40, num_updates=6860, lr=4.89934e-05, gnorm=0.816, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30385
2022-10-13 18:57:31 - progress_bar.py[line:274] - INFO: epoch 001:   6879 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.1, ups=0.91, wpb=110.1, bsz=40, num_updates=6870, lr=4.89889e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30396
2022-10-13 18:57:43 - progress_bar.py[line:274] - INFO: epoch 001:   6889 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.4, ups=0.88, wpb=111.3, bsz=40, num_updates=6880, lr=4.89844e-05, gnorm=0.75, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30408
2022-10-13 18:57:54 - progress_bar.py[line:274] - INFO: epoch 001:   6899 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.7, ups=0.89, wpb=110.8, bsz=40, num_updates=6890, lr=4.89799e-05, gnorm=0.846, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30419
2022-10-13 18:58:05 - progress_bar.py[line:274] - INFO: epoch 001:   6909 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.2, ups=0.89, wpb=109.9, bsz=40, num_updates=6900, lr=4.89754e-05, gnorm=0.764, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=30430
2022-10-13 18:58:16 - progress_bar.py[line:274] - INFO: epoch 001:   6919 / 28910 loss=0.437, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.4, ups=0.91, wpb=110.4, bsz=40, num_updates=6910, lr=4.89709e-05, gnorm=1.292, clip=80, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=30441
2022-10-13 18:58:27 - progress_bar.py[line:274] - INFO: epoch 001:   6929 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.311, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=100.8, ups=0.91, wpb=110.4, bsz=40, num_updates=6920, lr=4.89664e-05, gnorm=0.98, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30452
2022-10-13 18:58:38 - progress_bar.py[line:274] - INFO: epoch 001:   6939 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.29, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.8, ups=0.9, wpb=110.8, bsz=40, num_updates=6930, lr=4.89619e-05, gnorm=0.795, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30463
2022-10-13 18:58:49 - progress_bar.py[line:274] - INFO: epoch 001:   6949 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101.6, ups=0.92, wpb=110.6, bsz=40, num_updates=6940, lr=4.89573e-05, gnorm=0.872, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30474
2022-10-13 18:59:01 - progress_bar.py[line:274] - INFO: epoch 001:   6959 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96, ups=0.87, wpb=110.4, bsz=40, num_updates=6950, lr=4.89528e-05, gnorm=0.976, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30486
2022-10-13 18:59:12 - progress_bar.py[line:274] - INFO: epoch 001:   6969 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.1, ups=0.89, wpb=111.9, bsz=40, num_updates=6960, lr=4.89483e-05, gnorm=0.845, clip=40, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=30497
2022-10-13 18:59:23 - progress_bar.py[line:274] - INFO: epoch 001:   6979 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=102.1, ups=0.92, wpb=110.8, bsz=40, num_updates=6970, lr=4.89438e-05, gnorm=0.838, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=30508
2022-10-13 18:59:34 - progress_bar.py[line:274] - INFO: epoch 001:   6989 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.285, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99, ups=0.89, wpb=111.1, bsz=40, num_updates=6980, lr=4.89393e-05, gnorm=0.947, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=30519
2022-10-13 18:59:45 - progress_bar.py[line:274] - INFO: epoch 001:   6999 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.2, ups=0.91, wpb=109.9, bsz=40, num_updates=6990, lr=4.89348e-05, gnorm=0.848, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=30530
2022-10-13 18:59:56 - progress_bar.py[line:274] - INFO: epoch 001:   7009 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.7, ups=0.92, wpb=111, bsz=40, num_updates=7000, lr=4.89303e-05, gnorm=0.929, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=30541
2022-10-13 18:59:56 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 18:59:57 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 18:59:57 - train.py[line:551] - INFO: load:0.93 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 19:02:30 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 19:02:30 - train.py[line:551] - INFO: load:0.96 valid_run:152.34 task_valid:148.82 collect_output:2.39
2022-10-13 19:04:59 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 19:04:59 - train.py[line:551] - INFO: load:0.98 valid_run:301.20 task_valid:292.52 collect_output:6.45
2022-10-13 19:07:31 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 19:07:31 - train.py[line:551] - INFO: load:1.01 valid_run:453.84 task_valid:436.15 collect_output:14.29
2022-10-13 19:10:01 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 19:10:01 - train.py[line:551] - INFO: load:1.03 valid_run:603.43 task_valid:581.84 collect_output:17.06
2022-10-13 19:12:34 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 19:12:34 - train.py[line:551] - INFO: load:1.06 valid_run:756.09 task_valid:729.77 collect_output:20.68
2022-10-13 19:15:06 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 19:15:06 - train.py[line:551] - INFO: load:1.10 valid_run:908.16 task_valid:876.00 collect_output:25.35
2022-10-13 19:17:39 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 19:17:39 - train.py[line:551] - INFO: load:1.12 valid_run:1061.68 task_valid:1022.78 collect_output:30.88
2022-10-13 19:20:11 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 19:20:11 - train.py[line:551] - INFO: load:1.15 valid_run:1212.90 task_valid:1164.26 collect_output:39.54
2022-10-13 19:22:40 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 19:22:40 - train.py[line:551] - INFO: load:1.17 valid_run:1362.68 task_valid:1309.15 collect_output:43.37
2022-10-13 19:25:09 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 19:25:09 - train.py[line:551] - INFO: load:1.20 valid_run:1511.30 task_valid:1452.39 collect_output:47.70
2022-10-13 19:27:39 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 19:27:39 - train.py[line:551] - INFO: load:1.23 valid_run:1661.08 task_valid:1597.54 collect_output:51.26
2022-10-13 19:30:09 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 19:30:09 - train.py[line:551] - INFO: load:1.25 valid_run:1811.01 task_valid:1742.48 collect_output:55.23
2022-10-13 19:32:39 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 19:32:39 - train.py[line:551] - INFO: load:1.28 valid_run:1960.67 task_valid:1884.19 collect_output:62.17
2022-10-13 19:35:09 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 19:35:09 - train.py[line:551] - INFO: load:1.30 valid_run:2111.22 task_valid:2029.73 collect_output:66.16
2022-10-13 19:37:39 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 19:37:39 - train.py[line:551] - INFO: load:1.33 valid_run:2261.31 task_valid:2176.19 collect_output:68.74
2022-10-13 19:40:10 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 19:40:10 - train.py[line:551] - INFO: load:1.35 valid_run:2411.33 task_valid:2320.47 collect_output:73.45
2022-10-13 19:42:41 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 19:42:41 - train.py[line:551] - INFO: load:1.38 valid_run:2562.79 task_valid:2466.07 collect_output:78.26
2022-10-13 19:45:12 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 19:45:12 - train.py[line:551] - INFO: load:1.40 valid_run:2713.29 task_valid:2613.09 collect_output:80.72
2022-10-13 19:47:40 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 19:47:40 - train.py[line:551] - INFO: load:1.43 valid_run:2861.60 task_valid:2754.74 collect_output:86.34
2022-10-13 19:50:10 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 19:50:10 - train.py[line:551] - INFO: load:1.46 valid_run:3011.94 task_valid:2900.18 collect_output:90.18
2022-10-13 19:52:42 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 19:52:42 - train.py[line:551] - INFO: load:1.48 valid_run:3163.94 task_valid:3045.06 collect_output:96.26
2022-10-13 19:55:12 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 19:55:12 - train.py[line:551] - INFO: load:1.51 valid_run:3313.21 task_valid:3189.46 collect_output:100.12
2022-10-13 19:57:43 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 19:57:43 - train.py[line:551] - INFO: load:1.54 valid_run:3464.30 task_valid:3335.66 collect_output:103.97
2022-10-13 20:00:15 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 20:00:15 - train.py[line:551] - INFO: load:1.56 valid_run:3615.89 task_valid:3482.63 collect_output:107.54

====================================================================================================
SGG eval:     R @ 50: 0.5687;     R @ 100: 0.6105;     R @ 500: 0.6523;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3574;    mR @ 100: 0.3869;    mR @ 500: 0.4365;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.8125) (covering:0.5143) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.5419) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8750) (playing:0.0000) (riding:0.9477) (says:0.0000) (sitting on:0.7358) (standing on:0.1817) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2500) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5687;     R @ 100: 0.6105;     R @ 500: 0.6523;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3574;    mR @ 100: 0.3869;    mR @ 500: 0.4365;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.8125) (covering:0.5143) (eating:0.7059) (flying in:0.0000) (growing on:0.1250) (hanging from:0.5419) (lying on:0.1000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.8750) (playing:0.0000) (riding:0.9477) (says:0.0000) (sitting on:0.7358) (standing on:0.1817) (using:0.5500) (walking in:0.0000) (walking on:0.7027) (watching:0.2500) 
--------------------------------------------------------
====================================================================================================

2022-10-13 20:02:46 - train.py[line:487] - INFO: 0.6105095238095238
2022-10-13 20:02:46 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 20:02:46 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.353 | loss_v1 0 | loss_v2 0 | nll_loss 0.195 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.61051 | ppl 1.14 | vqa_score 0.518 | wps 119 | wpb 89.9 | bsz 30 | num_updates 7000 | best_R@100 0.61051
2022-10-13 20:02:46 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 7000 updates
2022-10-13 20:02:46 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-13 20:02:52 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt
2022-10-13 20:02:57 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 0.6105095238095238) (writing took 10.738108308054507 seconds)
2022-10-13 20:03:08 - progress_bar.py[line:274] - INFO: epoch 001:   7019 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=0.3, ups=0, wpb=112, bsz=40, num_updates=7010, lr=4.89258e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34333
2022-10-13 20:03:19 - progress_bar.py[line:274] - INFO: epoch 001:   7029 / 28910 loss=0.417, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=7020, lr=4.89213e-05, gnorm=1.072, clip=70, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34344
2022-10-13 20:03:31 - progress_bar.py[line:274] - INFO: epoch 001:   7039 / 28910 loss=0.431, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=107.9, nsentences=40, sample_size=107.9, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96, ups=0.89, wpb=107.9, bsz=40, num_updates=7030, lr=4.89168e-05, gnorm=0.989, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34356
2022-10-13 20:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   7049 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.1, ups=0.88, wpb=110.7, bsz=40, num_updates=7040, lr=4.89123e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=34367
2022-10-13 20:03:53 - progress_bar.py[line:274] - INFO: epoch 001:   7059 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.6, ups=0.89, wpb=111.3, bsz=40, num_updates=7050, lr=4.89078e-05, gnorm=0.913, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34378
2022-10-13 20:04:05 - progress_bar.py[line:274] - INFO: epoch 001:   7069 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.284, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=95.6, ups=0.87, wpb=109.9, bsz=40, num_updates=7060, lr=4.89033e-05, gnorm=0.947, clip=30, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34390
2022-10-13 20:04:16 - progress_bar.py[line:274] - INFO: epoch 001:   7079 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.1, ups=0.87, wpb=112, bsz=40, num_updates=7070, lr=4.88988e-05, gnorm=0.752, clip=0, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34401
2022-10-13 20:04:27 - progress_bar.py[line:274] - INFO: epoch 001:   7089 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.5, ups=0.91, wpb=111.3, bsz=40, num_updates=7080, lr=4.88943e-05, gnorm=0.894, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34412
2022-10-13 20:04:39 - progress_bar.py[line:274] - INFO: epoch 001:   7099 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.5, ups=0.88, wpb=110.9, bsz=40, num_updates=7090, lr=4.88898e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34424
2022-10-13 20:04:50 - progress_bar.py[line:274] - INFO: epoch 001:   7109 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.279, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.9, ups=0.89, wpb=109.1, bsz=40, num_updates=7100, lr=4.88853e-05, gnorm=0.944, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34435
2022-10-13 20:05:01 - progress_bar.py[line:274] - INFO: epoch 001:   7119 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.5, ups=0.91, wpb=109.2, bsz=40, num_updates=7110, lr=4.88808e-05, gnorm=0.96, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34446
2022-10-13 20:05:12 - progress_bar.py[line:274] - INFO: epoch 001:   7129 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.2, ups=0.88, wpb=110.8, bsz=40, num_updates=7120, lr=4.88763e-05, gnorm=0.896, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34457
2022-10-13 20:05:24 - progress_bar.py[line:274] - INFO: epoch 001:   7139 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.292, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.8, ups=0.89, wpb=109.8, bsz=40, num_updates=7130, lr=4.88718e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34469
2022-10-13 20:05:35 - progress_bar.py[line:274] - INFO: epoch 001:   7149 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.2, ups=0.9, wpb=109.2, bsz=40, num_updates=7140, lr=4.88673e-05, gnorm=0.739, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34480
2022-10-13 20:05:46 - progress_bar.py[line:274] - INFO: epoch 001:   7159 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.6, ups=0.93, wpb=110.9, bsz=40, num_updates=7150, lr=4.88628e-05, gnorm=0.893, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34490
2022-10-13 20:05:57 - progress_bar.py[line:274] - INFO: epoch 001:   7169 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=95.6, ups=0.87, wpb=110.3, bsz=40, num_updates=7160, lr=4.88583e-05, gnorm=0.899, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34502
2022-10-13 20:06:08 - progress_bar.py[line:274] - INFO: epoch 001:   7179 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.8, ups=0.88, wpb=111, bsz=40, num_updates=7170, lr=4.88538e-05, gnorm=0.856, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34513
2022-10-13 20:06:20 - progress_bar.py[line:274] - INFO: epoch 001:   7189 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100, ups=0.9, wpb=111.5, bsz=40, num_updates=7180, lr=4.88493e-05, gnorm=1.003, clip=30, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=34525
2022-10-13 20:06:31 - progress_bar.py[line:274] - INFO: epoch 001:   7199 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.1, ups=0.87, wpb=111.1, bsz=40, num_updates=7190, lr=4.88448e-05, gnorm=0.88, clip=0, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=34536
2022-10-13 20:06:42 - progress_bar.py[line:274] - INFO: epoch 001:   7209 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.6, ups=0.91, wpb=109.5, bsz=40, num_updates=7200, lr=4.88402e-05, gnorm=0.884, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34547
2022-10-13 20:06:53 - progress_bar.py[line:274] - INFO: epoch 001:   7219 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.8, ups=0.92, wpb=111.1, bsz=40, num_updates=7210, lr=4.88357e-05, gnorm=1.096, clip=40, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=34558
2022-10-13 20:07:04 - progress_bar.py[line:274] - INFO: epoch 001:   7229 / 28910 loss=0.436, loss_v1=0, loss_v2=0, nll_loss=0.309, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.24, wps=99.9, ups=0.9, wpb=110.7, bsz=40, num_updates=7220, lr=4.88312e-05, gnorm=0.897, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34569
2022-10-13 20:07:15 - progress_bar.py[line:274] - INFO: epoch 001:   7239 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.3, ups=0.9, wpb=109.8, bsz=40, num_updates=7230, lr=4.88267e-05, gnorm=0.842, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34580
2022-10-13 20:07:26 - progress_bar.py[line:274] - INFO: epoch 001:   7249 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.1, ups=0.91, wpb=111.1, bsz=40, num_updates=7240, lr=4.88222e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34591
2022-10-13 20:07:38 - progress_bar.py[line:274] - INFO: epoch 001:   7259 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.2, ups=0.87, wpb=111.1, bsz=40, num_updates=7250, lr=4.88177e-05, gnorm=1.018, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=34603
2022-10-13 20:07:49 - progress_bar.py[line:274] - INFO: epoch 001:   7269 / 28910 loss=0.424, loss_v1=0, loss_v2=0, nll_loss=0.293, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=99.7, ups=0.9, wpb=110.3, bsz=40, num_updates=7260, lr=4.88132e-05, gnorm=0.912, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34614
2022-10-13 20:08:00 - progress_bar.py[line:274] - INFO: epoch 001:   7279 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.277, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.2, ups=0.9, wpb=109.9, bsz=40, num_updates=7270, lr=4.88087e-05, gnorm=0.831, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34625
2022-10-13 20:08:11 - progress_bar.py[line:274] - INFO: epoch 001:   7289 / 28910 loss=0.43, loss_v1=0, loss_v2=0, nll_loss=0.304, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.5, ups=0.9, wpb=109.2, bsz=40, num_updates=7280, lr=4.88042e-05, gnorm=0.881, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34636
2022-10-13 20:08:22 - progress_bar.py[line:274] - INFO: epoch 001:   7299 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=7290, lr=4.87997e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34647
2022-10-13 20:08:34 - progress_bar.py[line:274] - INFO: epoch 001:   7309 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.5, ups=0.89, wpb=110.9, bsz=40, num_updates=7300, lr=4.87952e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34659
2022-10-13 20:08:45 - progress_bar.py[line:274] - INFO: epoch 001:   7319 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.9, ups=0.89, wpb=109.7, bsz=40, num_updates=7310, lr=4.87907e-05, gnorm=0.903, clip=20, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34670
2022-10-13 20:08:56 - progress_bar.py[line:274] - INFO: epoch 001:   7329 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.8, ups=0.89, wpb=111.8, bsz=40, num_updates=7320, lr=4.87862e-05, gnorm=0.84, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34681
2022-10-13 20:09:07 - progress_bar.py[line:274] - INFO: epoch 001:   7339 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.2, ups=0.89, wpb=111.5, bsz=40, num_updates=7330, lr=4.87817e-05, gnorm=0.807, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34692
2022-10-13 20:09:19 - progress_bar.py[line:274] - INFO: epoch 001:   7349 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.5, ups=0.89, wpb=110.9, bsz=40, num_updates=7340, lr=4.87772e-05, gnorm=1.007, clip=40, loss_scale=1024, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34703
2022-10-13 20:09:30 - progress_bar.py[line:274] - INFO: epoch 001:   7359 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.2, ups=0.89, wpb=110.9, bsz=40, num_updates=7350, lr=4.87727e-05, gnorm=0.979, clip=40, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34715
2022-10-13 20:09:41 - progress_bar.py[line:274] - INFO: epoch 001:   7369 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=112.5, nsentences=40, sample_size=112.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.4, ups=0.89, wpb=112.5, bsz=40, num_updates=7360, lr=4.87682e-05, gnorm=0.86, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34726
2022-10-13 20:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   7379 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.263, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.2, ups=0.88, wpb=111.7, bsz=40, num_updates=7370, lr=4.87637e-05, gnorm=0.862, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34737
2022-10-13 20:10:04 - progress_bar.py[line:274] - INFO: epoch 001:   7389 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.5, ups=0.89, wpb=109.8, bsz=40, num_updates=7380, lr=4.87592e-05, gnorm=0.838, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34749
2022-10-13 20:10:11 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 20:10:16 - progress_bar.py[line:274] - INFO: epoch 001:   7400 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=88.4, ups=0.8, wpb=110.7, bsz=40, num_updates=7390, lr=4.87547e-05, gnorm=0.869, clip=40, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=34761
2022-10-13 20:10:27 - progress_bar.py[line:274] - INFO: epoch 001:   7410 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=7400, lr=4.87502e-05, gnorm=0.896, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34772
2022-10-13 20:10:38 - progress_bar.py[line:274] - INFO: epoch 001:   7420 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.233, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.2, ups=0.9, wpb=110.7, bsz=40, num_updates=7410, lr=4.87457e-05, gnorm=0.781, clip=20, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34783
2022-10-13 20:10:50 - progress_bar.py[line:274] - INFO: epoch 001:   7430 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97, ups=0.88, wpb=109.9, bsz=40, num_updates=7420, lr=4.87412e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34795
2022-10-13 20:11:01 - progress_bar.py[line:274] - INFO: epoch 001:   7440 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.5, ups=0.87, wpb=110.6, bsz=40, num_updates=7430, lr=4.87367e-05, gnorm=0.861, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34806
2022-10-13 20:11:12 - progress_bar.py[line:274] - INFO: epoch 001:   7450 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.7, ups=0.9, wpb=109.3, bsz=40, num_updates=7440, lr=4.87322e-05, gnorm=0.914, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34817
2022-10-13 20:11:23 - progress_bar.py[line:274] - INFO: epoch 001:   7460 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.281, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.9, ups=0.91, wpb=110.3, bsz=40, num_updates=7450, lr=4.87276e-05, gnorm=0.995, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34828
2022-10-13 20:11:35 - progress_bar.py[line:274] - INFO: epoch 001:   7470 / 28910 loss=0.416, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=97.8, ups=0.89, wpb=110.5, bsz=40, num_updates=7460, lr=4.87231e-05, gnorm=0.854, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34839
2022-10-13 20:11:46 - progress_bar.py[line:274] - INFO: epoch 001:   7480 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99, ups=0.89, wpb=110.9, bsz=40, num_updates=7470, lr=4.87186e-05, gnorm=0.784, clip=0, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34851
2022-10-13 20:11:57 - progress_bar.py[line:274] - INFO: epoch 001:   7490 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.9, ups=0.9, wpb=110.9, bsz=40, num_updates=7480, lr=4.87141e-05, gnorm=0.87, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34862
2022-10-13 20:12:08 - progress_bar.py[line:274] - INFO: epoch 001:   7500 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.9, ups=0.93, wpb=110.9, bsz=40, num_updates=7490, lr=4.87096e-05, gnorm=0.716, clip=0, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=34873
2022-10-13 20:12:19 - progress_bar.py[line:274] - INFO: epoch 001:   7510 / 28910 loss=0.403, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.5, ups=0.88, wpb=110, bsz=40, num_updates=7500, lr=4.87051e-05, gnorm=0.843, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34884
2022-10-13 20:12:30 - progress_bar.py[line:274] - INFO: epoch 001:   7520 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.294, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=96.6, ups=0.88, wpb=109.8, bsz=40, num_updates=7510, lr=4.87006e-05, gnorm=0.905, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34895
2022-10-13 20:12:41 - progress_bar.py[line:274] - INFO: epoch 001:   7530 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=7520, lr=4.86961e-05, gnorm=0.799, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34906
2022-10-13 20:12:53 - progress_bar.py[line:274] - INFO: epoch 001:   7540 / 28910 loss=0.356, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=97.9, ups=0.87, wpb=111.9, bsz=40, num_updates=7530, lr=4.86916e-05, gnorm=0.849, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=34918
2022-10-13 20:13:04 - progress_bar.py[line:274] - INFO: epoch 001:   7550 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=102.5, ups=0.94, wpb=109.5, bsz=40, num_updates=7540, lr=4.86871e-05, gnorm=0.91, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34928
2022-10-13 20:13:15 - progress_bar.py[line:274] - INFO: epoch 001:   7560 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.9, ups=0.89, wpb=108.7, bsz=40, num_updates=7550, lr=4.86826e-05, gnorm=0.951, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=34940
2022-10-13 20:13:26 - progress_bar.py[line:274] - INFO: epoch 001:   7570 / 28910 loss=0.41, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=100.7, ups=0.91, wpb=110.8, bsz=40, num_updates=7560, lr=4.86781e-05, gnorm=0.897, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34951
2022-10-13 20:13:37 - progress_bar.py[line:274] - INFO: epoch 001:   7580 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97, ups=0.88, wpb=109.7, bsz=40, num_updates=7570, lr=4.86736e-05, gnorm=0.83, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=34962
2022-10-13 20:13:48 - progress_bar.py[line:274] - INFO: epoch 001:   7590 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.3, ups=0.91, wpb=109.7, bsz=40, num_updates=7580, lr=4.86691e-05, gnorm=0.837, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=34973
2022-10-13 20:14:00 - progress_bar.py[line:274] - INFO: epoch 001:   7600 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.9, ups=0.87, wpb=109.9, bsz=40, num_updates=7590, lr=4.86646e-05, gnorm=0.94, clip=10, loss_scale=512, train_wall=11, gb_free=11.4, ema_decay=0.9999, wall=34984
2022-10-13 20:14:11 - progress_bar.py[line:274] - INFO: epoch 001:   7610 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.2, ups=0.89, wpb=110.2, bsz=40, num_updates=7600, lr=4.86601e-05, gnorm=0.82, clip=10, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=34996
2022-10-13 20:14:22 - progress_bar.py[line:274] - INFO: epoch 001:   7620 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.3, ups=0.89, wpb=110.2, bsz=40, num_updates=7610, lr=4.86556e-05, gnorm=0.945, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35007
2022-10-13 20:14:33 - progress_bar.py[line:274] - INFO: epoch 001:   7630 / 28910 loss=0.367, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.3, ups=0.9, wpb=109.9, bsz=40, num_updates=7620, lr=4.86511e-05, gnorm=0.795, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35018
2022-10-13 20:14:44 - progress_bar.py[line:274] - INFO: epoch 001:   7640 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=111.5, nsentences=40, sample_size=111.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.4, ups=0.89, wpb=111.5, bsz=40, num_updates=7630, lr=4.86466e-05, gnorm=0.943, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35029
2022-10-13 20:14:55 - progress_bar.py[line:274] - INFO: epoch 001:   7650 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.27, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101, ups=0.9, wpb=111.9, bsz=40, num_updates=7640, lr=4.86421e-05, gnorm=0.86, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35040
2022-10-13 20:15:07 - progress_bar.py[line:274] - INFO: epoch 001:   7660 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.9, ups=0.87, wpb=109.3, bsz=40, num_updates=7650, lr=4.86376e-05, gnorm=0.8, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35052
2022-10-13 20:15:18 - progress_bar.py[line:274] - INFO: epoch 001:   7670 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.1, ups=0.88, wpb=111.6, bsz=40, num_updates=7660, lr=4.86331e-05, gnorm=0.829, clip=10, loss_scale=512, train_wall=11, gb_free=9.7, ema_decay=0.9999, wall=35063
2022-10-13 20:15:29 - progress_bar.py[line:274] - INFO: epoch 001:   7680 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99.2, ups=0.9, wpb=110.5, bsz=40, num_updates=7670, lr=4.86286e-05, gnorm=0.825, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35074
2022-10-13 20:15:41 - progress_bar.py[line:274] - INFO: epoch 001:   7690 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.256, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96, ups=0.88, wpb=109.7, bsz=40, num_updates=7680, lr=4.86241e-05, gnorm=0.942, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35086
2022-10-13 20:15:52 - progress_bar.py[line:274] - INFO: epoch 001:   7700 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99.7, ups=0.91, wpb=110.1, bsz=40, num_updates=7690, lr=4.86196e-05, gnorm=1.02, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35097
2022-10-13 20:16:03 - progress_bar.py[line:274] - INFO: epoch 001:   7710 / 28910 loss=0.389, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.6, ups=0.89, wpb=109.7, bsz=40, num_updates=7700, lr=4.86151e-05, gnorm=0.881, clip=20, loss_scale=512, train_wall=11, gb_free=10.2, ema_decay=0.9999, wall=35108
2022-10-13 20:16:14 - progress_bar.py[line:274] - INFO: epoch 001:   7720 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=99, ups=0.9, wpb=109.5, bsz=40, num_updates=7710, lr=4.86105e-05, gnorm=1.031, clip=50, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35119
2022-10-13 20:16:26 - progress_bar.py[line:274] - INFO: epoch 001:   7730 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.9, ups=0.87, wpb=110.5, bsz=40, num_updates=7720, lr=4.8606e-05, gnorm=0.887, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35131
2022-10-13 20:16:37 - progress_bar.py[line:274] - INFO: epoch 001:   7740 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99, ups=0.89, wpb=111.1, bsz=40, num_updates=7730, lr=4.86015e-05, gnorm=0.769, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35142
2022-10-13 20:16:48 - progress_bar.py[line:274] - INFO: epoch 001:   7750 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.239, ntokens=109.6, nsentences=40, sample_size=109.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.5, ups=0.9, wpb=109.6, bsz=40, num_updates=7740, lr=4.8597e-05, gnorm=0.776, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=35153
2022-10-13 20:16:59 - progress_bar.py[line:274] - INFO: epoch 001:   7760 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=104.1, ups=0.93, wpb=112.1, bsz=40, num_updates=7750, lr=4.85925e-05, gnorm=0.812, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35164
2022-10-13 20:17:10 - progress_bar.py[line:274] - INFO: epoch 001:   7770 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.1, ups=0.9, wpb=111.9, bsz=40, num_updates=7760, lr=4.8588e-05, gnorm=0.937, clip=40, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=35175
2022-10-13 20:17:21 - progress_bar.py[line:274] - INFO: epoch 001:   7780 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.278, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.6, ups=0.88, wpb=108.7, bsz=40, num_updates=7770, lr=4.85835e-05, gnorm=0.865, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35186
2022-10-13 20:17:33 - progress_bar.py[line:274] - INFO: epoch 001:   7790 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.5, ups=0.88, wpb=109.9, bsz=40, num_updates=7780, lr=4.8579e-05, gnorm=0.884, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35198
2022-10-13 20:17:44 - progress_bar.py[line:274] - INFO: epoch 001:   7800 / 28910 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.232, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100, ups=0.9, wpb=110.9, bsz=40, num_updates=7790, lr=4.85745e-05, gnorm=0.745, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35209
2022-10-13 20:17:55 - progress_bar.py[line:274] - INFO: epoch 001:   7810 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=7800, lr=4.857e-05, gnorm=0.983, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35220
2022-10-13 20:18:06 - progress_bar.py[line:274] - INFO: epoch 001:   7820 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100, ups=0.9, wpb=110.7, bsz=40, num_updates=7810, lr=4.85655e-05, gnorm=0.735, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35231
2022-10-13 20:18:18 - progress_bar.py[line:274] - INFO: epoch 001:   7830 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.2, ups=0.87, wpb=111.9, bsz=40, num_updates=7820, lr=4.8561e-05, gnorm=0.886, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=35243
2022-10-13 20:18:29 - progress_bar.py[line:274] - INFO: epoch 001:   7840 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.3, ups=0.89, wpb=110.1, bsz=40, num_updates=7830, lr=4.85565e-05, gnorm=0.807, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35254
2022-10-13 20:18:40 - progress_bar.py[line:274] - INFO: epoch 001:   7850 / 28910 loss=0.404, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.7, ups=0.88, wpb=110.2, bsz=40, num_updates=7840, lr=4.8552e-05, gnorm=0.935, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35265
2022-10-13 20:18:51 - progress_bar.py[line:274] - INFO: epoch 001:   7860 / 28910 loss=0.434, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.5, ups=0.9, wpb=109.5, bsz=40, num_updates=7850, lr=4.85475e-05, gnorm=0.864, clip=20, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=35276
2022-10-13 20:19:03 - progress_bar.py[line:274] - INFO: epoch 001:   7870 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.273, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.4, ups=0.88, wpb=109.5, bsz=40, num_updates=7860, lr=4.8543e-05, gnorm=0.848, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35288
2022-10-13 20:19:14 - progress_bar.py[line:274] - INFO: epoch 001:   7880 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.5, ups=0.89, wpb=108.4, bsz=40, num_updates=7870, lr=4.85385e-05, gnorm=1, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35299
2022-10-13 20:19:26 - progress_bar.py[line:274] - INFO: epoch 001:   7890 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=103.5, ups=0.93, wpb=110.7, bsz=40, num_updates=7880, lr=4.8534e-05, gnorm=0.963, clip=50, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=35310
2022-10-13 20:19:37 - progress_bar.py[line:274] - INFO: epoch 001:   7900 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.231, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.2, ups=0.88, wpb=111, bsz=40, num_updates=7890, lr=4.85295e-05, gnorm=0.761, clip=10, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35322
2022-10-13 20:19:49 - progress_bar.py[line:274] - INFO: epoch 001:   7910 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.5, ups=0.89, wpb=109.8, bsz=40, num_updates=7900, lr=4.8525e-05, gnorm=0.896, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35334
2022-10-13 20:20:00 - progress_bar.py[line:274] - INFO: epoch 001:   7920 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=102.3, ups=0.91, wpb=111.8, bsz=40, num_updates=7910, lr=4.85205e-05, gnorm=0.791, clip=10, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=35344
2022-10-13 20:20:11 - progress_bar.py[line:274] - INFO: epoch 001:   7930 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.2, ups=0.88, wpb=110.3, bsz=40, num_updates=7920, lr=4.8516e-05, gnorm=0.778, clip=0, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35356
2022-10-13 20:20:22 - progress_bar.py[line:274] - INFO: epoch 001:   7940 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.5, ups=0.88, wpb=110.3, bsz=40, num_updates=7930, lr=4.85115e-05, gnorm=0.899, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35367
2022-10-13 20:20:34 - progress_bar.py[line:274] - INFO: epoch 001:   7950 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.25, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.7, ups=0.89, wpb=110.6, bsz=40, num_updates=7940, lr=4.8507e-05, gnorm=0.827, clip=0, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35379
2022-10-13 20:20:45 - progress_bar.py[line:274] - INFO: epoch 001:   7960 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=108.7, nsentences=40, sample_size=108.7, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.9, ups=0.9, wpb=108.7, bsz=40, num_updates=7950, lr=4.85025e-05, gnorm=0.788, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35390
2022-10-13 20:20:56 - progress_bar.py[line:274] - INFO: epoch 001:   7970 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.1, ups=0.89, wpb=110.3, bsz=40, num_updates=7960, lr=4.8498e-05, gnorm=0.816, clip=10, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=35401
2022-10-13 20:21:07 - progress_bar.py[line:274] - INFO: epoch 001:   7980 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=112.2, nsentences=40, sample_size=112.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=100.3, ups=0.89, wpb=112.2, bsz=40, num_updates=7970, lr=4.84934e-05, gnorm=0.867, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=35412
2022-10-13 20:21:18 - progress_bar.py[line:274] - INFO: epoch 001:   7990 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=102.1, ups=0.92, wpb=110.7, bsz=40, num_updates=7980, lr=4.84889e-05, gnorm=0.839, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35423
2022-10-13 20:21:29 - progress_bar.py[line:274] - INFO: epoch 001:   8000 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99, ups=0.89, wpb=111.1, bsz=40, num_updates=7990, lr=4.84844e-05, gnorm=0.789, clip=0, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=35434
2022-10-13 20:21:40 - progress_bar.py[line:274] - INFO: epoch 001:   8010 / 28910 loss=0.406, loss_v1=0, loss_v2=0, nll_loss=0.274, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.3, ups=0.89, wpb=109.9, bsz=40, num_updates=8000, lr=4.84799e-05, gnorm=0.88, clip=20, loss_scale=1024, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=35445
2022-10-13 20:21:40 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 20:21:42 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 20:21:42 - train.py[line:551] - INFO: load:0.93 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 20:24:14 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 20:24:14 - train.py[line:551] - INFO: load:0.95 valid_run:152.47 task_valid:148.86 collect_output:2.48
2022-10-13 20:26:43 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 20:26:43 - train.py[line:551] - INFO: load:0.98 valid_run:301.17 task_valid:292.52 collect_output:6.41
2022-10-13 20:29:15 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 20:29:15 - train.py[line:551] - INFO: load:1.00 valid_run:453.65 task_valid:435.97 collect_output:14.34
2022-10-13 20:31:45 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 20:31:45 - train.py[line:551] - INFO: load:1.03 valid_run:603.31 task_valid:581.53 collect_output:17.26
2022-10-13 20:34:17 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 20:34:17 - train.py[line:551] - INFO: load:1.05 valid_run:755.55 task_valid:728.97 collect_output:21.03
2022-10-13 20:36:49 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 20:36:49 - train.py[line:551] - INFO: load:1.07 valid_run:906.91 task_valid:874.28 collect_output:26.09
2022-10-13 20:39:22 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 20:39:22 - train.py[line:551] - INFO: load:1.10 valid_run:1060.12 task_valid:1020.37 collect_output:32.20
2022-10-13 20:41:53 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 20:41:53 - train.py[line:551] - INFO: load:1.12 valid_run:1211.19 task_valid:1161.44 collect_output:41.18
2022-10-13 20:44:23 - train.py[line:549] - INFO: 1800 / 4988
2022-10-13 20:44:23 - train.py[line:551] - INFO: load:1.15 valid_run:1360.50 task_valid:1305.99 collect_output:44.94
2022-10-13 20:46:51 - train.py[line:549] - INFO: 2000 / 4988
2022-10-13 20:46:51 - train.py[line:551] - INFO: load:1.17 valid_run:1508.87 task_valid:1449.16 collect_output:49.15
2022-10-13 20:49:21 - train.py[line:549] - INFO: 2200 / 4988
2022-10-13 20:49:21 - train.py[line:551] - INFO: load:1.19 valid_run:1658.34 task_valid:1593.80 collect_output:52.99
2022-10-13 20:51:50 - train.py[line:549] - INFO: 2400 / 4988
2022-10-13 20:51:50 - train.py[line:551] - INFO: load:1.22 valid_run:1808.04 task_valid:1738.61 collect_output:56.88
2022-10-13 20:54:20 - train.py[line:549] - INFO: 2600 / 4988
2022-10-13 20:54:20 - train.py[line:551] - INFO: load:1.24 valid_run:1957.69 task_valid:1880.17 collect_output:63.95
2022-10-13 20:56:51 - train.py[line:549] - INFO: 2800 / 4988
2022-10-13 20:56:51 - train.py[line:551] - INFO: load:1.27 valid_run:2108.16 task_valid:2025.57 collect_output:68.00
2022-10-13 20:59:21 - train.py[line:549] - INFO: 3000 / 4988
2022-10-13 20:59:21 - train.py[line:551] - INFO: load:1.29 valid_run:2258.05 task_valid:2171.94 collect_output:70.51
2022-10-13 21:01:51 - train.py[line:549] - INFO: 3200 / 4988
2022-10-13 21:01:51 - train.py[line:551] - INFO: load:1.31 valid_run:2408.05 task_valid:2316.08 collect_output:75.31
2022-10-13 21:04:22 - train.py[line:549] - INFO: 3400 / 4988
2022-10-13 21:04:22 - train.py[line:551] - INFO: load:1.34 valid_run:2559.62 task_valid:2461.67 collect_output:80.26
2022-10-13 21:06:53 - train.py[line:549] - INFO: 3600 / 4988
2022-10-13 21:06:53 - train.py[line:551] - INFO: load:1.37 valid_run:2710.00 task_valid:2608.48 collect_output:82.80
2022-10-13 21:09:21 - train.py[line:549] - INFO: 3800 / 4988
2022-10-13 21:09:21 - train.py[line:551] - INFO: load:1.39 valid_run:2858.24 task_valid:2750.09 collect_output:88.39
2022-10-13 21:11:51 - train.py[line:549] - INFO: 4000 / 4988
2022-10-13 21:11:51 - train.py[line:551] - INFO: load:1.41 valid_run:3008.46 task_valid:2895.21 collect_output:92.45
2022-10-13 21:14:23 - train.py[line:549] - INFO: 4200 / 4988
2022-10-13 21:14:23 - train.py[line:551] - INFO: load:1.44 valid_run:3160.14 task_valid:3039.64 collect_output:98.69
2022-10-13 21:16:52 - train.py[line:549] - INFO: 4400 / 4988
2022-10-13 21:16:52 - train.py[line:551] - INFO: load:1.46 valid_run:3309.44 task_valid:3184.02 collect_output:102.58
2022-10-13 21:19:24 - train.py[line:549] - INFO: 4600 / 4988
2022-10-13 21:19:24 - train.py[line:551] - INFO: load:1.49 valid_run:3460.91 task_valid:3330.85 collect_output:106.08
2022-10-13 21:21:56 - train.py[line:549] - INFO: 4800 / 4988
2022-10-13 21:21:56 - train.py[line:551] - INFO: load:1.51 valid_run:3612.83 task_valid:3478.43 collect_output:109.30

====================================================================================================
SGG eval:     R @ 50: 0.5870;     R @ 100: 0.6379;     R @ 500: 0.6646;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3812;    mR @ 100: 0.4203;    mR @ 500: 0.4537;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.9375) (covering:0.5143) (eating:0.7647) (flying in:0.0000) (growing on:0.1250) (hanging from:0.6097) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9722) (says:0.0000) (sitting on:0.7324) (standing on:0.1900) (using:0.6000) (walking in:0.0000) (walking on:0.7297) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5870;     R @ 100: 0.6379;     R @ 500: 0.6646;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3812;    mR @ 100: 0.4203;    mR @ 500: 0.4537;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7805) (covered in:0.9375) (covering:0.5143) (eating:0.7647) (flying in:0.0000) (growing on:0.1250) (hanging from:0.6097) (lying on:0.2000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.9583) (playing:0.0000) (riding:0.9722) (says:0.0000) (sitting on:0.7324) (standing on:0.1900) (using:0.6000) (walking in:0.0000) (walking on:0.7297) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================

2022-10-13 21:24:27 - train.py[line:487] - INFO: 0.6378761904761905
2022-10-13 21:24:28 - train.py[line:575] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2022-10-13 21:24:28 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.355 | loss_v1 0 | loss_v2 0 | nll_loss 0.198 | ntokens 89.926 | nsentences 29.995 | sample_size 89.926 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.637876 | ppl 1.15 | vqa_score 0.5608 | wps 119.1 | wpb 89.9 | bsz 30 | num_updates 8000 | best_R@100 0.637876
2022-10-13 21:24:28 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 8000 updates
2022-10-13 21:24:28 - trainer.py[line:431] - INFO: Saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-13 21:24:33 - trainer.py[line:441] - INFO: Finished saving checkpoint to ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt
2022-10-13 21:24:40 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint ./vqa_checkpoints/test_EDS(with_cap_pretrain)_MDS-k0.25-a1.0-maskName0.8/1_B20_A1_E4_0.04_5e-5_480/checkpoint_1_8000.pt (epoch 1 @ 8000 updates, score 0.6378761904761905) (writing took 12.080922198016196 seconds)
2022-10-13 21:24:51 - progress_bar.py[line:274] - INFO: epoch 001:   8020 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=0.3, ups=0, wpb=111.6, bsz=40, num_updates=8010, lr=4.84754e-05, gnorm=0.98, clip=40, loss_scale=1024, train_wall=11, gb_free=10.1, ema_decay=0.9999, wall=39236
2022-10-13 21:25:02 - progress_bar.py[line:274] - INFO: epoch 001:   8030 / 28910 loss=0.408, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=108, nsentences=40, sample_size=108, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96.1, ups=0.89, wpb=108, bsz=40, num_updates=8020, lr=4.84709e-05, gnorm=0.895, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39247
2022-10-13 21:25:13 - progress_bar.py[line:274] - INFO: epoch 001:   8040 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.2, ups=0.9, wpb=110.4, bsz=40, num_updates=8030, lr=4.84664e-05, gnorm=0.804, clip=0, loss_scale=1024, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39258
2022-10-13 21:25:25 - progress_bar.py[line:274] - INFO: epoch 001:   8050 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=111.8, nsentences=40, sample_size=111.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.2, ups=0.89, wpb=111.8, bsz=40, num_updates=8040, lr=4.84619e-05, gnorm=0.823, clip=30, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39270
2022-10-13 21:25:36 - progress_bar.py[line:274] - INFO: epoch 001:   8060 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.266, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.1, ups=0.87, wpb=110.7, bsz=40, num_updates=8050, lr=4.84574e-05, gnorm=0.91, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39281
2022-10-13 21:25:48 - progress_bar.py[line:274] - INFO: epoch 001:   8070 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.6, ups=0.88, wpb=109.8, bsz=40, num_updates=8060, lr=4.84529e-05, gnorm=0.898, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39293
2022-10-13 21:25:59 - progress_bar.py[line:274] - INFO: epoch 001:   8080 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.6, ups=0.9, wpb=110.1, bsz=40, num_updates=8070, lr=4.84484e-05, gnorm=0.802, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39304
2022-10-13 21:26:10 - progress_bar.py[line:274] - INFO: epoch 001:   8090 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=110.3, nsentences=40, sample_size=110.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=101.2, ups=0.92, wpb=110.3, bsz=40, num_updates=8080, lr=4.84439e-05, gnorm=0.939, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39314
2022-10-13 21:26:12 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 21:26:22 - progress_bar.py[line:274] - INFO: epoch 001:   8101 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=89.3, ups=0.8, wpb=111.3, bsz=40, num_updates=8090, lr=4.84394e-05, gnorm=0.843, clip=20, loss_scale=512, train_wall=12, gb_free=10.8, ema_decay=0.9999, wall=39327
2022-10-13 21:26:33 - progress_bar.py[line:274] - INFO: epoch 001:   8111 / 28910 loss=0.401, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=104.4, ups=0.94, wpb=110.9, bsz=40, num_updates=8100, lr=4.84349e-05, gnorm=1.142, clip=80, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39338
2022-10-13 21:26:43 - progress_bar.py[line:274] - INFO: epoch 001:   8121 / 28910 loss=0.387, loss_v1=0, loss_v2=0, nll_loss=0.249, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101.4, ups=0.93, wpb=109.2, bsz=40, num_updates=8110, lr=4.84304e-05, gnorm=0.792, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39348
2022-10-13 21:26:54 - progress_bar.py[line:274] - INFO: epoch 001:   8131 / 28910 loss=0.388, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101.1, ups=0.91, wpb=110.8, bsz=40, num_updates=8120, lr=4.84259e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39359
2022-10-13 21:27:06 - progress_bar.py[line:274] - INFO: epoch 001:   8141 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95.8, ups=0.87, wpb=110.6, bsz=40, num_updates=8130, lr=4.84214e-05, gnorm=0.985, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39371
2022-10-13 21:27:17 - progress_bar.py[line:274] - INFO: epoch 001:   8151 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.1, ups=0.89, wpb=110.1, bsz=40, num_updates=8140, lr=4.84169e-05, gnorm=0.93, clip=50, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39382
2022-10-13 21:27:28 - progress_bar.py[line:274] - INFO: epoch 001:   8161 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98, ups=0.9, wpb=109.3, bsz=40, num_updates=8150, lr=4.84124e-05, gnorm=0.947, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39393
2022-10-13 21:27:40 - progress_bar.py[line:274] - INFO: epoch 001:   8171 / 28910 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.9, ups=0.89, wpb=108.8, bsz=40, num_updates=8160, lr=4.84079e-05, gnorm=0.911, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39404
2022-10-13 21:27:51 - progress_bar.py[line:274] - INFO: epoch 001:   8181 / 28910 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.228, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=99.3, ups=0.91, wpb=109.7, bsz=40, num_updates=8170, lr=4.84034e-05, gnorm=0.81, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39416
2022-10-13 21:28:02 - progress_bar.py[line:274] - INFO: epoch 001:   8191 / 28910 loss=0.373, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.3, ups=0.92, wpb=110.6, bsz=40, num_updates=8180, lr=4.83989e-05, gnorm=0.978, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39426
2022-10-13 21:28:13 - progress_bar.py[line:274] - INFO: epoch 001:   8201 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.242, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.9, ups=0.9, wpb=109.5, bsz=40, num_updates=8190, lr=4.83944e-05, gnorm=0.889, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39438
2022-10-13 21:28:24 - progress_bar.py[line:274] - INFO: epoch 001:   8211 / 28910 loss=0.359, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=95.6, ups=0.87, wpb=110, bsz=40, num_updates=8200, lr=4.83899e-05, gnorm=0.766, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=39449
2022-10-13 21:28:35 - progress_bar.py[line:274] - INFO: epoch 001:   8221 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.223, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100, ups=0.9, wpb=111.7, bsz=40, num_updates=8210, lr=4.83854e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39460
2022-10-13 21:28:47 - progress_bar.py[line:274] - INFO: epoch 001:   8231 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.6, ups=0.87, wpb=111.4, bsz=40, num_updates=8220, lr=4.83808e-05, gnorm=0.925, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39472
2022-10-13 21:28:58 - progress_bar.py[line:274] - INFO: epoch 001:   8241 / 28910 loss=0.366, loss_v1=0, loss_v2=0, nll_loss=0.234, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98, ups=0.89, wpb=110.5, bsz=40, num_updates=8230, lr=4.83763e-05, gnorm=0.85, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39483
2022-10-13 21:29:09 - progress_bar.py[line:274] - INFO: epoch 001:   8251 / 28910 loss=0.355, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.9, ups=0.89, wpb=111.2, bsz=40, num_updates=8240, lr=4.83718e-05, gnorm=0.822, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39494
2022-10-13 21:29:21 - progress_bar.py[line:274] - INFO: epoch 001:   8261 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.8, ups=0.89, wpb=110.7, bsz=40, num_updates=8250, lr=4.83673e-05, gnorm=1.22, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39505
2022-10-13 21:29:32 - progress_bar.py[line:274] - INFO: epoch 001:   8271 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.5, ups=0.89, wpb=110.4, bsz=40, num_updates=8260, lr=4.83628e-05, gnorm=1.014, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39517
2022-10-13 21:29:43 - progress_bar.py[line:274] - INFO: epoch 001:   8281 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.1, ups=0.9, wpb=109.7, bsz=40, num_updates=8270, lr=4.83583e-05, gnorm=0.958, clip=60, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39528
2022-10-13 21:29:54 - progress_bar.py[line:274] - INFO: epoch 001:   8291 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.264, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.1, ups=0.88, wpb=109.3, bsz=40, num_updates=8280, lr=4.83538e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39539
2022-10-13 21:30:06 - progress_bar.py[line:274] - INFO: epoch 001:   8301 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.235, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.2, ups=0.88, wpb=109.9, bsz=40, num_updates=8290, lr=4.83493e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39550
2022-10-13 21:30:16 - progress_bar.py[line:274] - INFO: epoch 001:   8311 / 28910 loss=0.398, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=103.5, ups=0.93, wpb=111.3, bsz=40, num_updates=8300, lr=4.83448e-05, gnorm=0.826, clip=10, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39561
2022-10-13 21:30:28 - progress_bar.py[line:274] - INFO: epoch 001:   8321 / 28910 loss=0.395, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.8, ups=0.89, wpb=109.1, bsz=40, num_updates=8310, lr=4.83403e-05, gnorm=0.951, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39572
2022-10-13 21:30:39 - progress_bar.py[line:274] - INFO: epoch 001:   8331 / 28910 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=95.9, ups=0.87, wpb=110.2, bsz=40, num_updates=8320, lr=4.83358e-05, gnorm=0.866, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39584
2022-10-13 21:30:50 - progress_bar.py[line:274] - INFO: epoch 001:   8341 / 28910 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=97.8, ups=0.88, wpb=111.2, bsz=40, num_updates=8330, lr=4.83313e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39595
2022-10-13 21:31:01 - progress_bar.py[line:274] - INFO: epoch 001:   8351 / 28910 loss=0.362, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.8, ups=0.91, wpb=111.4, bsz=40, num_updates=8340, lr=4.83268e-05, gnorm=0.784, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39606
2022-10-13 21:31:13 - progress_bar.py[line:274] - INFO: epoch 001:   8361 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.251, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.4, ups=0.89, wpb=111.6, bsz=40, num_updates=8350, lr=4.83223e-05, gnorm=0.873, clip=30, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=39618
2022-10-13 21:31:24 - progress_bar.py[line:274] - INFO: epoch 001:   8371 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.7, ups=0.89, wpb=109.3, bsz=40, num_updates=8360, lr=4.83178e-05, gnorm=0.849, clip=10, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39629
2022-10-13 21:31:35 - progress_bar.py[line:274] - INFO: epoch 001:   8381 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.269, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=98.1, ups=0.89, wpb=110.4, bsz=40, num_updates=8370, lr=4.83133e-05, gnorm=0.961, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39640
2022-10-13 21:31:47 - progress_bar.py[line:274] - INFO: epoch 001:   8391 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.5, ups=0.88, wpb=109.7, bsz=40, num_updates=8380, lr=4.83088e-05, gnorm=0.969, clip=40, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39651
2022-10-13 21:31:57 - progress_bar.py[line:274] - INFO: epoch 001:   8401 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.4, ups=0.92, wpb=108.3, bsz=40, num_updates=8390, lr=4.83043e-05, gnorm=0.925, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39662
2022-10-13 21:32:08 - progress_bar.py[line:274] - INFO: epoch 001:   8411 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.4, ups=0.92, wpb=109.7, bsz=40, num_updates=8400, lr=4.82998e-05, gnorm=0.927, clip=20, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=39673
2022-10-13 21:32:20 - progress_bar.py[line:274] - INFO: epoch 001:   8421 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.259, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.9, ups=0.88, wpb=110.2, bsz=40, num_updates=8410, lr=4.82953e-05, gnorm=1.06, clip=50, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39685
2022-10-13 21:32:31 - progress_bar.py[line:274] - INFO: epoch 001:   8431 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.227, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.5, ups=0.91, wpb=110.1, bsz=40, num_updates=8420, lr=4.82908e-05, gnorm=0.939, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39696
2022-10-13 21:32:42 - progress_bar.py[line:274] - INFO: epoch 001:   8441 / 28910 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.299, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=98.6, ups=0.9, wpb=109.1, bsz=40, num_updates=8430, lr=4.82863e-05, gnorm=1.011, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39707
2022-10-13 21:32:53 - progress_bar.py[line:274] - INFO: epoch 001:   8451 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100, ups=0.89, wpb=111.9, bsz=40, num_updates=8440, lr=4.82818e-05, gnorm=0.884, clip=30, loss_scale=512, train_wall=11, gb_free=10.3, ema_decay=0.9999, wall=39718
2022-10-13 21:33:04 - progress_bar.py[line:274] - INFO: epoch 001:   8461 / 28910 loss=0.413, loss_v1=0, loss_v2=0, nll_loss=0.272, ntokens=108.4, nsentences=40, sample_size=108.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97, ups=0.89, wpb=108.4, bsz=40, num_updates=8450, lr=4.82773e-05, gnorm=0.953, clip=50, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39729
2022-10-13 21:33:16 - progress_bar.py[line:274] - INFO: epoch 001:   8471 / 28910 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.217, ntokens=110.1, nsentences=40, sample_size=110.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=95.9, ups=0.87, wpb=110.1, bsz=40, num_updates=8460, lr=4.82728e-05, gnorm=0.806, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39741
2022-10-13 21:33:27 - progress_bar.py[line:274] - INFO: epoch 001:   8481 / 28910 loss=0.39, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=112.4, nsentences=40, sample_size=112.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=102.8, ups=0.91, wpb=112.4, bsz=40, num_updates=8470, lr=4.82683e-05, gnorm=0.904, clip=30, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39752
2022-10-13 21:33:38 - progress_bar.py[line:274] - INFO: epoch 001:   8491 / 28910 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.7, ups=0.89, wpb=109.2, bsz=40, num_updates=8480, lr=4.82637e-05, gnorm=0.758, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39763
2022-10-13 21:33:49 - progress_bar.py[line:274] - INFO: epoch 001:   8501 / 28910 loss=0.397, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=112.3, nsentences=40, sample_size=112.3, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99, ups=0.88, wpb=112.3, bsz=40, num_updates=8490, lr=4.82592e-05, gnorm=0.798, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39774
2022-10-13 21:34:01 - progress_bar.py[line:274] - INFO: epoch 001:   8511 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.262, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=95.3, ups=0.86, wpb=110.8, bsz=40, num_updates=8500, lr=4.82547e-05, gnorm=0.987, clip=40, loss_scale=512, train_wall=12, gb_free=10.7, ema_decay=0.9999, wall=39786
2022-10-13 21:34:12 - progress_bar.py[line:274] - INFO: epoch 001:   8521 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.247, ntokens=111.6, nsentences=40, sample_size=111.6, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=103.2, ups=0.92, wpb=111.6, bsz=40, num_updates=8510, lr=4.82502e-05, gnorm=0.884, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39797
2022-10-13 21:34:23 - progress_bar.py[line:274] - INFO: epoch 001:   8531 / 28910 loss=0.4, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=109.4, nsentences=40, sample_size=109.4, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.6, ups=0.9, wpb=109.4, bsz=40, num_updates=8520, lr=4.82457e-05, gnorm=1.062, clip=60, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39808
2022-10-13 21:34:34 - progress_bar.py[line:274] - INFO: epoch 001:   8541 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.258, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=102.1, ups=0.92, wpb=111.2, bsz=40, num_updates=8530, lr=4.82412e-05, gnorm=0.851, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39819
2022-10-13 21:34:45 - progress_bar.py[line:274] - INFO: epoch 001:   8551 / 28910 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=112, nsentences=40, sample_size=112, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=98.3, ups=0.88, wpb=112, bsz=40, num_updates=8540, lr=4.82367e-05, gnorm=0.707, clip=0, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=39830
2022-10-13 21:34:56 - progress_bar.py[line:274] - INFO: epoch 001:   8561 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.224, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.3, ups=0.9, wpb=111.2, bsz=40, num_updates=8550, lr=4.82322e-05, gnorm=0.749, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39841
2022-10-13 21:35:08 - progress_bar.py[line:274] - INFO: epoch 001:   8571 / 28910 loss=0.422, loss_v1=0, loss_v2=0, nll_loss=0.286, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=94.1, ups=0.86, wpb=109.8, bsz=40, num_updates=8560, lr=4.82277e-05, gnorm=0.911, clip=20, loss_scale=512, train_wall=12, gb_free=11.1, ema_decay=0.9999, wall=39853
2022-10-13 21:35:19 - progress_bar.py[line:274] - INFO: epoch 001:   8581 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=109.7, nsentences=40, sample_size=109.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96.5, ups=0.88, wpb=109.7, bsz=40, num_updates=8570, lr=4.82232e-05, gnorm=1.037, clip=30, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39864
2022-10-13 21:35:30 - progress_bar.py[line:274] - INFO: epoch 001:   8591 / 28910 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.221, ntokens=111.9, nsentences=40, sample_size=111.9, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=102.1, ups=0.91, wpb=111.9, bsz=40, num_updates=8580, lr=4.82187e-05, gnorm=0.921, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39875
2022-10-13 21:35:41 - progress_bar.py[line:274] - INFO: epoch 001:   8601 / 28910 loss=0.415, loss_v1=0, loss_v2=0, nll_loss=0.28, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=97.4, ups=0.88, wpb=110.4, bsz=40, num_updates=8590, lr=4.82142e-05, gnorm=0.894, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39886
2022-10-13 21:35:52 - progress_bar.py[line:274] - INFO: epoch 001:   8611 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=100.5, ups=0.92, wpb=109.5, bsz=40, num_updates=8600, lr=4.82097e-05, gnorm=0.978, clip=40, loss_scale=1024, train_wall=11, gb_free=11, ema_decay=0.9999, wall=39897
2022-10-13 21:36:04 - progress_bar.py[line:274] - INFO: epoch 001:   8621 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.5, ups=0.88, wpb=110.6, bsz=40, num_updates=8610, lr=4.82052e-05, gnorm=0.856, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39909
2022-10-13 21:36:15 - progress_bar.py[line:274] - INFO: epoch 001:   8631 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.7, ups=0.88, wpb=110.8, bsz=40, num_updates=8620, lr=4.82007e-05, gnorm=0.832, clip=10, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39920
2022-10-13 21:36:26 - progress_bar.py[line:274] - INFO: epoch 001:   8641 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.3, ups=0.91, wpb=110, bsz=40, num_updates=8630, lr=4.81962e-05, gnorm=0.85, clip=20, loss_scale=1024, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=39931
2022-10-13 21:36:37 - progress_bar.py[line:274] - INFO: epoch 001:   8651 / 28910 loss=0.381, loss_v1=0, loss_v2=0, nll_loss=0.246, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=99.9, ups=0.89, wpb=111.7, bsz=40, num_updates=8640, lr=4.81917e-05, gnorm=0.801, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39942
2022-10-13 21:36:48 - progress_bar.py[line:274] - INFO: epoch 001:   8661 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.3, ups=0.89, wpb=110.4, bsz=40, num_updates=8650, lr=4.81872e-05, gnorm=0.827, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=39953
2022-10-13 21:36:59 - progress_bar.py[line:274] - INFO: epoch 001:   8671 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=99.7, ups=0.91, wpb=109.8, bsz=40, num_updates=8660, lr=4.81827e-05, gnorm=0.87, clip=30, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39964
2022-10-13 21:37:11 - progress_bar.py[line:274] - INFO: epoch 001:   8681 / 28910 loss=0.37, loss_v1=0, loss_v2=0, nll_loss=0.238, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.6, ups=0.89, wpb=110.4, bsz=40, num_updates=8670, lr=4.81782e-05, gnorm=0.825, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39976
2022-10-13 21:37:22 - progress_bar.py[line:274] - INFO: epoch 001:   8691 / 28910 loss=0.384, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=110.8, nsentences=40, sample_size=110.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101.6, ups=0.92, wpb=110.8, bsz=40, num_updates=8680, lr=4.81737e-05, gnorm=0.908, clip=40, loss_scale=1024, train_wall=11, gb_free=11.2, ema_decay=0.9999, wall=39986
2022-10-13 21:37:33 - progress_bar.py[line:274] - INFO: epoch 001:   8701 / 28910 loss=0.402, loss_v1=0, loss_v2=0, nll_loss=0.271, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=96.7, ups=0.89, wpb=109.3, bsz=40, num_updates=8690, lr=4.81692e-05, gnorm=0.882, clip=20, loss_scale=1024, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=39998
2022-10-13 21:37:44 - progress_bar.py[line:274] - INFO: epoch 001:   8711 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.252, ntokens=108.8, nsentences=40, sample_size=108.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=96, ups=0.88, wpb=108.8, bsz=40, num_updates=8700, lr=4.81647e-05, gnorm=0.825, clip=20, loss_scale=1024, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40009
2022-10-13 21:37:52 - trainer.py[line:932] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2022-10-13 21:37:56 - progress_bar.py[line:274] - INFO: epoch 001:   8722 / 28910 loss=0.38, loss_v1=0, loss_v2=0, nll_loss=0.248, ntokens=110.4, nsentences=40, sample_size=110.4, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=90, ups=0.82, wpb=110.4, bsz=40, num_updates=8710, lr=4.81602e-05, gnorm=0.805, clip=0, loss_scale=512, train_wall=12, gb_free=10.5, ema_decay=0.9999, wall=40021
2022-10-13 21:38:07 - progress_bar.py[line:274] - INFO: epoch 001:   8732 / 28910 loss=0.394, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=104.2, ups=0.95, wpb=109.3, bsz=40, num_updates=8720, lr=4.81557e-05, gnorm=0.839, clip=0, loss_scale=512, train_wall=10, gb_free=10.4, ema_decay=0.9999, wall=40032
2022-10-13 21:38:18 - progress_bar.py[line:274] - INFO: epoch 001:   8742 / 28910 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=111.7, nsentences=40, sample_size=111.7, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=99.5, ups=0.89, wpb=111.7, bsz=40, num_updates=8730, lr=4.81512e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40043
2022-10-13 21:38:29 - progress_bar.py[line:274] - INFO: epoch 001:   8752 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=109.3, nsentences=40, sample_size=109.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=98.5, ups=0.9, wpb=109.3, bsz=40, num_updates=8740, lr=4.81466e-05, gnorm=0.855, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40054
2022-10-13 21:38:41 - progress_bar.py[line:274] - INFO: epoch 001:   8762 / 28910 loss=0.391, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=111.3, nsentences=40, sample_size=111.3, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=97.8, ups=0.88, wpb=111.3, bsz=40, num_updates=8750, lr=4.81421e-05, gnorm=0.969, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40066
2022-10-13 21:38:52 - progress_bar.py[line:274] - INFO: epoch 001:   8772 / 28910 loss=0.385, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=95.5, ups=0.87, wpb=109.8, bsz=40, num_updates=8760, lr=4.81376e-05, gnorm=0.869, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40077
2022-10-13 21:39:04 - progress_bar.py[line:274] - INFO: epoch 001:   8782 / 28910 loss=0.412, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=96, ups=0.88, wpb=109, bsz=40, num_updates=8770, lr=4.81331e-05, gnorm=0.944, clip=40, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40088
2022-10-13 21:39:15 - progress_bar.py[line:274] - INFO: epoch 001:   8792 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.257, ntokens=110.5, nsentences=40, sample_size=110.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=98.3, ups=0.89, wpb=110.5, bsz=40, num_updates=8780, lr=4.81286e-05, gnorm=0.848, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40100
2022-10-13 21:39:26 - progress_bar.py[line:274] - INFO: epoch 001:   8802 / 28910 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.243, ntokens=108.3, nsentences=40, sample_size=108.3, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.5, ups=0.9, wpb=108.3, bsz=40, num_updates=8790, lr=4.81241e-05, gnorm=0.841, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40111
2022-10-13 21:39:37 - progress_bar.py[line:274] - INFO: epoch 001:   8812 / 28910 loss=0.378, loss_v1=0, loss_v2=0, nll_loss=0.245, ntokens=111, nsentences=40, sample_size=111, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.3, ups=0.87, wpb=111, bsz=40, num_updates=8800, lr=4.81196e-05, gnorm=1.032, clip=30, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=40122
2022-10-13 21:39:49 - progress_bar.py[line:274] - INFO: epoch 001:   8822 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.7, ups=0.9, wpb=109.5, bsz=40, num_updates=8810, lr=4.81151e-05, gnorm=0.922, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40133
2022-10-13 21:40:00 - progress_bar.py[line:274] - INFO: epoch 001:   8832 / 28910 loss=0.353, loss_v1=0, loss_v2=0, nll_loss=0.212, ntokens=111.2, nsentences=40, sample_size=111.2, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=101.5, ups=0.91, wpb=111.2, bsz=40, num_updates=8820, lr=4.81106e-05, gnorm=0.802, clip=10, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=40144
2022-10-13 21:40:11 - progress_bar.py[line:274] - INFO: epoch 001:   8842 / 28910 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.237, ntokens=110, nsentences=40, sample_size=110, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=97.1, ups=0.88, wpb=110, bsz=40, num_updates=8830, lr=4.81061e-05, gnorm=0.823, clip=10, loss_scale=512, train_wall=11, gb_free=11, ema_decay=0.9999, wall=40156
2022-10-13 21:40:22 - progress_bar.py[line:274] - INFO: epoch 001:   8852 / 28910 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.236, ntokens=109.1, nsentences=40, sample_size=109.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=96.4, ups=0.88, wpb=109.1, bsz=40, num_updates=8840, lr=4.81016e-05, gnorm=0.933, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40167
2022-10-13 21:40:33 - progress_bar.py[line:274] - INFO: epoch 001:   8862 / 28910 loss=0.407, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=97.3, ups=0.88, wpb=110.2, bsz=40, num_updates=8850, lr=4.80971e-05, gnorm=1.049, clip=40, loss_scale=512, train_wall=11, gb_free=10.5, ema_decay=0.9999, wall=40178
2022-10-13 21:40:45 - progress_bar.py[line:274] - INFO: epoch 001:   8872 / 28910 loss=0.369, loss_v1=0, loss_v2=0, nll_loss=0.24, ntokens=110.2, nsentences=40, sample_size=110.2, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=99, ups=0.9, wpb=110.2, bsz=40, num_updates=8860, lr=4.80926e-05, gnorm=0.835, clip=20, loss_scale=512, train_wall=11, gb_free=10.9, ema_decay=0.9999, wall=40190
2022-10-13 21:40:56 - progress_bar.py[line:274] - INFO: epoch 001:   8882 / 28910 loss=0.405, loss_v1=0, loss_v2=0, nll_loss=0.276, ntokens=109, nsentences=40, sample_size=109, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=95, ups=0.87, wpb=109, bsz=40, num_updates=8870, lr=4.80881e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40201
2022-10-13 21:41:07 - progress_bar.py[line:274] - INFO: epoch 001:   8892 / 28910 loss=0.409, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=99.1, ups=0.89, wpb=111.4, bsz=40, num_updates=8880, lr=4.80836e-05, gnorm=0.792, clip=0, loss_scale=512, train_wall=11, gb_free=11.1, ema_decay=0.9999, wall=40212
2022-10-13 21:41:18 - progress_bar.py[line:274] - INFO: epoch 001:   8902 / 28910 loss=0.383, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=112.1, nsentences=40, sample_size=112.1, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=101.1, ups=0.9, wpb=112.1, bsz=40, num_updates=8890, lr=4.80791e-05, gnorm=0.746, clip=0, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40223
2022-10-13 21:41:30 - progress_bar.py[line:274] - INFO: epoch 001:   8912 / 28910 loss=0.399, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=109.9, nsentences=40, sample_size=109.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=96.8, ups=0.88, wpb=109.9, bsz=40, num_updates=8900, lr=4.80746e-05, gnorm=0.891, clip=40, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40235
2022-10-13 21:41:41 - progress_bar.py[line:274] - INFO: epoch 001:   8922 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.265, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.5, ups=0.93, wpb=109.5, bsz=40, num_updates=8910, lr=4.80701e-05, gnorm=0.858, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40246
2022-10-13 21:41:52 - progress_bar.py[line:274] - INFO: epoch 001:   8932 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.244, ntokens=111.1, nsentences=40, sample_size=111.1, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=100.2, ups=0.9, wpb=111.1, bsz=40, num_updates=8920, lr=4.80656e-05, gnorm=0.99, clip=60, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40257
2022-10-13 21:42:03 - progress_bar.py[line:274] - INFO: epoch 001:   8942 / 28910 loss=0.393, loss_v1=0, loss_v2=0, nll_loss=0.261, ntokens=110.9, nsentences=40, sample_size=110.9, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=101.6, ups=0.92, wpb=110.9, bsz=40, num_updates=8930, lr=4.80611e-05, gnorm=0.834, clip=20, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40268
2022-10-13 21:42:14 - progress_bar.py[line:274] - INFO: epoch 001:   8952 / 28910 loss=0.392, loss_v1=0, loss_v2=0, nll_loss=0.254, ntokens=110.7, nsentences=40, sample_size=110.7, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=98.6, ups=0.89, wpb=110.7, bsz=40, num_updates=8940, lr=4.80566e-05, gnorm=0.951, clip=40, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40279
2022-10-13 21:42:25 - progress_bar.py[line:274] - INFO: epoch 001:   8962 / 28910 loss=0.376, loss_v1=0, loss_v2=0, nll_loss=0.241, ntokens=111.4, nsentences=40, sample_size=111.4, sample_size_v1=0, sample_size_v2=0, ppl=1.18, wps=101.9, ups=0.91, wpb=111.4, bsz=40, num_updates=8950, lr=4.80521e-05, gnorm=0.831, clip=20, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40290
2022-10-13 21:42:36 - progress_bar.py[line:274] - INFO: epoch 001:   8972 / 28910 loss=0.364, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100, ups=0.9, wpb=110.6, bsz=40, num_updates=8960, lr=4.80476e-05, gnorm=0.786, clip=0, loss_scale=512, train_wall=11, gb_free=10.7, ema_decay=0.9999, wall=40301
2022-10-13 21:42:47 - progress_bar.py[line:274] - INFO: epoch 001:   8982 / 28910 loss=0.396, loss_v1=0, loss_v2=0, nll_loss=0.268, ntokens=109.5, nsentences=40, sample_size=109.5, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=100.7, ups=0.92, wpb=109.5, bsz=40, num_updates=8970, lr=4.80431e-05, gnorm=0.907, clip=30, loss_scale=512, train_wall=11, gb_free=10.8, ema_decay=0.9999, wall=40312
2022-10-13 21:42:58 - progress_bar.py[line:274] - INFO: epoch 001:   8992 / 28910 loss=0.363, loss_v1=0, loss_v2=0, nll_loss=0.23, ntokens=109.8, nsentences=40, sample_size=109.8, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=100.4, ups=0.91, wpb=109.8, bsz=40, num_updates=8980, lr=4.80386e-05, gnorm=0.824, clip=10, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40323
2022-10-13 21:43:08 - progress_bar.py[line:274] - INFO: epoch 001:   9002 / 28910 loss=0.423, loss_v1=0, loss_v2=0, nll_loss=0.283, ntokens=109.2, nsentences=40, sample_size=109.2, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=101.1, ups=0.93, wpb=109.2, bsz=40, num_updates=8990, lr=4.8034e-05, gnorm=0.967, clip=40, loss_scale=512, train_wall=11, gb_free=10.4, ema_decay=0.9999, wall=40333
2022-10-13 21:43:20 - progress_bar.py[line:274] - INFO: epoch 001:   9012 / 28910 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.229, ntokens=110.6, nsentences=40, sample_size=110.6, sample_size_v1=0, sample_size_v2=0, ppl=1.17, wps=98.8, ups=0.89, wpb=110.6, bsz=40, num_updates=9000, lr=4.80295e-05, gnorm=0.878, clip=20, loss_scale=512, train_wall=11, gb_free=10.6, ema_decay=0.9999, wall=40345
2022-10-13 21:43:20 - train.py[line:506] - INFO: begin validation on "valid" subset
2022-10-13 21:43:21 - train.py[line:549] - INFO: 0 / 4988
2022-10-13 21:43:21 - train.py[line:551] - INFO: load:0.88 valid_run:0.00 task_valid:0.00 collect_output:0.00
2022-10-13 21:45:53 - train.py[line:549] - INFO: 200 / 4988
2022-10-13 21:45:53 - train.py[line:551] - INFO: load:0.91 valid_run:152.14 task_valid:148.54 collect_output:2.43
2022-10-13 21:48:22 - train.py[line:549] - INFO: 400 / 4988
2022-10-13 21:48:22 - train.py[line:551] - INFO: load:0.93 valid_run:301.16 task_valid:292.40 collect_output:6.48
2022-10-13 21:50:54 - train.py[line:549] - INFO: 600 / 4988
2022-10-13 21:50:54 - train.py[line:551] - INFO: load:0.96 valid_run:453.43 task_valid:435.92 collect_output:14.15
2022-10-13 21:53:24 - train.py[line:549] - INFO: 800 / 4988
2022-10-13 21:53:24 - train.py[line:551] - INFO: load:0.99 valid_run:602.75 task_valid:581.15 collect_output:17.19
2022-10-13 21:55:56 - train.py[line:549] - INFO: 1000 / 4988
2022-10-13 21:55:56 - train.py[line:551] - INFO: load:1.01 valid_run:755.18 task_valid:729.08 collect_output:20.63
2022-10-13 21:58:28 - train.py[line:549] - INFO: 1200 / 4988
2022-10-13 21:58:28 - train.py[line:551] - INFO: load:1.04 valid_run:906.93 task_valid:875.06 collect_output:25.36
2022-10-13 22:01:01 - train.py[line:549] - INFO: 1400 / 4988
2022-10-13 22:01:01 - train.py[line:551] - INFO: load:1.06 valid_run:1060.21 task_valid:1021.78 collect_output:30.87
2022-10-13 22:03:33 - train.py[line:549] - INFO: 1600 / 4988
2022-10-13 22:03:33 - train.py[line:551] - INFO: load:1.09 valid_run:1211.49 task_valid:1163.16 collect_output:39.71
