/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-10-04 17:36:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpksyouivi
2023-10-04 17:36:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmprr6swsas
2023-10-04 17:36:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmpksyouivi/_remote_module_non_scriptable.py
2023-10-04 17:36:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp_87yo5gk
2023-10-04 17:36:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpnzug1062
2023-10-04 17:36:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpv24tkpex
2023-10-04 17:36:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmp_87yo5gk/_remote_module_non_scriptable.py
2023-10-04 17:36:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmpnzug1062/_remote_module_non_scriptable.py
2023-10-04 17:36:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmprr6swsas/_remote_module_non_scriptable.py
2023-10-04 17:36:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmpv24tkpex/_remote_module_non_scriptable.py
2023-10-04 17:36:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp3ama5fnd
2023-10-04 17:36:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmp3ama5fnd/_remote_module_non_scriptable.py
2023-10-04 17:36:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmprh3zoq7i
2023-10-04 17:36:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmprh3zoq7i/_remote_module_non_scriptable.py
2023-10-04 17:36:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp4pr6b68_
2023-10-04 17:36:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmp4pr6b68_/_remote_module_non_scriptable.py
1
qwqwqwqw 1
6
qwqwqwqw 6
0
5
qwqwqwqw 0
qwqwqwqw 5
2
qwqwqwqw 2
4
qwqwqwqw 4
7
qwqwqwqw 7
3
qwqwqwqw 3
2023-10-04 17:36:47 - utils.py[line:256] - INFO: distributed init (rank 1): env://
2023-10-04 17:36:47 - utils.py[line:262] - INFO: Start init
2023-10-04 17:36:47 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-10-04 17:36:47 - utils.py[line:256] - INFO: distributed init (rank 6): env://
2023-10-04 17:36:47 - utils.py[line:262] - INFO: Start init
2023-10-04 17:36:48 - utils.py[line:256] - INFO: distributed init (rank 0): env://
2023-10-04 17:36:48 - utils.py[line:262] - INFO: Start init
2023-10-04 17:36:48 - utils.py[line:256] - INFO: distributed init (rank 5): env://
2023-10-04 17:36:48 - utils.py[line:262] - INFO: Start init
2023-10-04 17:36:48 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2023-10-04 17:36:48 - utils.py[line:256] - INFO: distributed init (rank 2): env://
2023-10-04 17:36:48 - utils.py[line:262] - INFO: Start init
2023-10-04 17:36:48 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-10-04 17:36:48 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
2023-10-04 17:36:48 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2023-10-04 17:36:48 - utils.py[line:256] - INFO: distributed init (rank 4): env://
2023-10-04 17:36:48 - utils.py[line:262] - INFO: Start init
2023-10-04 17:36:48 - utils.py[line:256] - INFO: distributed init (rank 7): env://
2023-10-04 17:36:48 - utils.py[line:262] - INFO: Start init
2023-10-04 17:36:48 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
2023-10-04 17:36:48 - utils.py[line:256] - INFO: distributed init (rank 3): env://
2023-10-04 17:36:48 - utils.py[line:262] - INFO: Start init
2023-10-04 17:36:48 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
2023-10-04 17:36:48 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2023-10-04 17:36:48 - distributed_c10d.py[line:476] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 17:36:48 - utils.py[line:272] - INFO: initialized host root as rank 3
single-machine distributed training is initialized.
2023-10-04 17:36:48 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 17:36:48 - utils.py[line:272] - INFO: initialized host root as rank 0
single-machine distributed training is initialized.
2023-10-04 17:36:48 - distributed_c10d.py[line:476] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 17:36:48 - utils.py[line:272] - INFO: initialized host root as rank 5
single-machine distributed training is initialized.
2023-10-04 17:36:48 - distributed_c10d.py[line:476] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 17:36:48 - utils.py[line:272] - INFO: initialized host root as rank 2
single-machine distributed training is initialized.
2023-10-04 17:36:48 - distributed_c10d.py[line:476] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 17:36:48 - utils.py[line:272] - INFO: initialized host root as rank 4
single-machine distributed training is initialized.
2023-10-04 17:36:48 - distributed_c10d.py[line:476] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 17:36:48 - utils.py[line:272] - INFO: initialized host root as rank 7
single-machine distributed training is initialized.
2023-10-04 17:36:48 - distributed_c10d.py[line:476] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 17:36:48 - utils.py[line:272] - INFO: initialized host root as rank 6
single-machine distributed training is initialized.
2023-10-04 17:36:48 - distributed_c10d.py[line:476] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 17:36:48 - utils.py[line:272] - INFO: initialized host root as rank 1
single-machine distributed training is initialized.
2023-10-04 17:36:50 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './../../vqa_tensorboard/20_way_caption_five_filtered', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 12, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 200, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 9, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_0e-5_480', 'restore_file': '../../SGG_0909_OFA_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=12, batch_size_valid='8', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id='0', disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[0.0], lr_scheduler='polynomial_decay', max_epoch=9, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../SGG_0909_OFA_base.pt', sample_patch_num=196, save_dir='./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_0e-5_480', save_interval=10, save_interval_updates=200, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./../../vqa_tensorboard/20_way_caption_five_filtered', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=200, wandb_project=None, warmup_ratio=0.05, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.05, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [0.0]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-10-04 17:36:51 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-10-04 17:36:51 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-10-04 17:36:54 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-10-04 17:36:54 - train.py[line:118] - INFO: task: VqaGenTask
2023-10-04 17:36:54 - train.py[line:119] - INFO: model: OFAModel
2023-10-04 17:36:54 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-10-04 17:36:54 - train.py[line:121] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-10-04 17:36:54 - train.py[line:128] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 3 row count 52613 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 2 row count 52613 total row count 420900file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 5 row count 52612 total row count 420900file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 1 row count 52613 total row count 420900file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 4 row count 52612 total row count 420900



file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 7 row count 52612 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 6 row count 52612 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 0 row count 52613 total row count 420900
2023-10-04 17:36:55 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-10-04 17:36:55 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-10-04 17:36:55 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-10-04 17:36:55 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2023-10-04 17:36:55 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 17:36:55 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 17:36:55 - utils.py[line:761] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 17:36:55 - utils.py[line:761] - INFO: rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 17:36:55 - utils.py[line:761] - INFO: rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 17:36:55 - utils.py[line:761] - INFO: rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 17:36:55 - utils.py[line:761] - INFO: rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 17:36:55 - utils.py[line:761] - INFO: rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 17:36:55 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-10-04 17:36:56 - train.py[line:159] - INFO: training on 8 devices (GPUs/TPUs)
2023-10-04 17:36:56 - train.py[line:164] - INFO: max tokens per device = None and max sentences per device = 12
Done 0.95 cuda cpu, cpu
2023-10-04 17:36:56 - trainer.py[line:499] - INFO: Preparing to load checkpoint ../../SGG_0909_OFA_base.pt
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-10-04 17:37:04 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-10-04 17:37:05 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 17:37:05 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 17:37:05 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 17:37:05 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 17:37:05 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 17:37:05 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 17:37:05 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 17:37:05 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 17:37:05 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-10-04 17:37:05 - trainer.py[line:313] - INFO: Exponential Moving Average Shadow Model is initialized.
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 3 row count 10874 total row count 86994
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 65, in seek
    self._ensure_tsv_opened()
  File "/data/cminus/ofa/data/tsv_file.py", line 99, in _ensure_tsv_opened
    self._fp = open(self.tsv_file, 'r')
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.tsv'
2023-10-04 17:37:06 - trainer.py[line:672] - INFO: Loaded checkpoint ../../SGG_0909_OFA_base.pt (epoch 48 @ 0 updates)
2023-10-04 17:37:06 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 0 row count 10875 total row count 86994
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 65, in seek
    self._ensure_tsv_opened()
  File "/data/cminus/ofa/data/tsv_file.py", line 99, in _ensure_tsv_opened
    self._fp = open(self.tsv_file, 'r')
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.tsv'
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 7 row count 10874 total row count 86994
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 65, in seek
    self._ensure_tsv_opened()
  File "/data/cminus/ofa/data/tsv_file.py", line 99, in _ensure_tsv_opened
    self._fp = open(self.tsv_file, 'r')
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.tsv'
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 1 row count 10875 total row count 86994
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 65, in seek
    self._ensure_tsv_opened()
  File "/data/cminus/ofa/data/tsv_file.py", line 99, in _ensure_tsv_opened
    self._fp = open(self.tsv_file, 'r')
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.tsv'
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 5 row count 10874 total row count 86994
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 65, in seek
    self._ensure_tsv_opened()
  File "/data/cminus/ofa/data/tsv_file.py", line 99, in _ensure_tsv_opened
    self._fp = open(self.tsv_file, 'r')
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.tsv'
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 2 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 6 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 4 row count 10874 total row count 86994
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
Traceback (most recent call last):
      File "../../train.py", line 636, in <module>
cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
        distributed_utils.call_main(cfg, main)main(cfg, **kwargs)

  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 65, in seek
    self._ensure_tsv_opened()
  File "/data/cminus/ofa/data/tsv_file.py", line 99, in _ensure_tsv_opened
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    self._fp = open(self.tsv_file, 'r')
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.tsv'
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 65, in seek
    self._ensure_tsv_opened()
  File "/data/cminus/ofa/data/tsv_file.py", line 99, in _ensure_tsv_opened
    self._fp = open(self.tsv_file, 'r')
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.tsv'
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 65, in seek
    self._ensure_tsv_opened()
  File "/data/cminus/ofa/data/tsv_file.py", line 99, in _ensure_tsv_opened
    self._fp = open(self.tsv_file, 'r')
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.tsv'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 8623) of binary: /data/cminus/anaconda3/envs/OFA/bin/python3
Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 192, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../../train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-04_17:37:11
  host      : root
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 8624)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-04_17:37:11
  host      : root
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 8625)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-04_17:37:11
  host      : root
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 8626)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-04_17:37:11
  host      : root
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 8627)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-04_17:37:11
  host      : root
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 8628)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-04_17:37:11
  host      : root
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 8630)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-04_17:37:11
  host      : root
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 8632)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-04_17:37:11
  host      : root
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 8623)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-10-04 18:18:11 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp395kibx4
2023-10-04 18:18:11 - instantiator.py[line:76] - INFO: Writing /tmp/tmp395kibx4/_remote_module_non_scriptable.py
2023-10-04 18:18:11 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmphzwazeo3
2023-10-04 18:18:11 - instantiator.py[line:76] - INFO: Writing /tmp/tmphzwazeo3/_remote_module_non_scriptable.py
2023-10-04 18:18:11 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpgwc0oo6f
2023-10-04 18:18:11 - instantiator.py[line:76] - INFO: Writing /tmp/tmpgwc0oo6f/_remote_module_non_scriptable.py
2023-10-04 18:18:11 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpphdnpxcr
2023-10-04 18:18:11 - instantiator.py[line:76] - INFO: Writing /tmp/tmpphdnpxcr/_remote_module_non_scriptable.py
2023-10-04 18:18:11 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmppqanyz4n
2023-10-04 18:18:11 - instantiator.py[line:76] - INFO: Writing /tmp/tmppqanyz4n/_remote_module_non_scriptable.py
2023-10-04 18:18:11 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpu33p179a
2023-10-04 18:18:11 - instantiator.py[line:76] - INFO: Writing /tmp/tmpu33p179a/_remote_module_non_scriptable.py
2023-10-04 18:18:11 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp1_2ztxeb
2023-10-04 18:18:11 - instantiator.py[line:76] - INFO: Writing /tmp/tmp1_2ztxeb/_remote_module_non_scriptable.py
2023-10-04 18:18:11 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpskdxtsmi
2023-10-04 18:18:11 - instantiator.py[line:76] - INFO: Writing /tmp/tmpskdxtsmi/_remote_module_non_scriptable.py
0
qwqwqwqw 0
2023-10-04 18:18:13 - utils.py[line:256] - INFO: distributed init (rank 0): env://
2023-10-04 18:18:13 - utils.py[line:262] - INFO: Start init
2023-10-04 18:18:13 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
7
qwqwqwqw 7
2023-10-04 18:18:13 - utils.py[line:256] - INFO: distributed init (rank 7): env://
2023-10-04 18:18:13 - utils.py[line:262] - INFO: Start init
2023-10-04 18:18:13 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
6
qwqwqwqw 6
2023-10-04 18:18:13 - utils.py[line:256] - INFO: distributed init (rank 6): env://
2023-10-04 18:18:13 - utils.py[line:262] - INFO: Start init
2023-10-04 18:18:13 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2
qwqwqwqw 2
2023-10-04 18:18:13 - utils.py[line:256] - INFO: distributed init (rank 2): env://
2023-10-04 18:18:13 - utils.py[line:262] - INFO: Start init
2023-10-04 18:18:13 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
4
qwqwqwqw 4
2023-10-04 18:18:13 - utils.py[line:256] - INFO: distributed init (rank 4): env://
2023-10-04 18:18:13 - utils.py[line:262] - INFO: Start init
2023-10-04 18:18:13 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
1
qwqwqwqw 1
2023-10-04 18:18:13 - utils.py[line:256] - INFO: distributed init (rank 1): env://
2023-10-04 18:18:13 - utils.py[line:262] - INFO: Start init
2023-10-04 18:18:13 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
3
qwqwqwqw 3
2023-10-04 18:18:13 - utils.py[line:256] - INFO: distributed init (rank 3): env://
2023-10-04 18:18:13 - utils.py[line:262] - INFO: Start init
2023-10-04 18:18:13 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
5
qwqwqwqw 5
2023-10-04 18:18:13 - utils.py[line:256] - INFO: distributed init (rank 5): env://
2023-10-04 18:18:13 - utils.py[line:262] - INFO: Start init
2023-10-04 18:18:13 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
2023-10-04 18:18:13 - distributed_c10d.py[line:476] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:18:13 - distributed_c10d.py[line:476] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:18:13 - utils.py[line:272] - INFO: initialized host root as rank 5
single-machine distributed training is initialized.
2023-10-04 18:18:13 - distributed_c10d.py[line:476] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:18:13 - utils.py[line:272] - INFO: initialized host root as rank 1
single-machine distributed training is initialized.
2023-10-04 18:18:13 - distributed_c10d.py[line:476] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:18:13 - utils.py[line:272] - INFO: initialized host root as rank 3
single-machine distributed training is initialized.
2023-10-04 18:18:13 - utils.py[line:272] - INFO: initialized host root as rank 2
single-machine distributed training is initialized.
2023-10-04 18:18:13 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:18:13 - utils.py[line:272] - INFO: initialized host root as rank 0
single-machine distributed training is initialized.
2023-10-04 18:18:13 - distributed_c10d.py[line:476] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:18:13 - utils.py[line:272] - INFO: initialized host root as rank 6
single-machine distributed training is initialized.
2023-10-04 18:18:13 - distributed_c10d.py[line:476] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:18:13 - utils.py[line:272] - INFO: initialized host root as rank 7
single-machine distributed training is initialized.
2023-10-04 18:18:13 - distributed_c10d.py[line:476] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:18:13 - utils.py[line:272] - INFO: initialized host root as rank 4
single-machine distributed training is initialized.
2023-10-04 18:18:16 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './../../vqa_tensorboard/20_way_caption_five_filtered', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 12, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 200, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 9, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_0e-5_480', 'restore_file': '../../SGG_0909_OFA_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=12, batch_size_valid='8', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id='0', disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[0.0], lr_scheduler='polynomial_decay', max_epoch=9, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../SGG_0909_OFA_base.pt', sample_patch_num=196, save_dir='./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_0e-5_480', save_interval=10, save_interval_updates=200, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./../../vqa_tensorboard/20_way_caption_five_filtered', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=200, wandb_project=None, warmup_ratio=0.05, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.05, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [0.0]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-10-04 18:18:16 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-10-04 18:18:16 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-10-04 18:18:19 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-10-04 18:18:19 - train.py[line:118] - INFO: task: VqaGenTask
2023-10-04 18:18:19 - train.py[line:119] - INFO: model: OFAModel
2023-10-04 18:18:19 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-10-04 18:18:19 - train.py[line:121] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-10-04 18:18:20 - train.py[line:128] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 6 row count 52612 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 7 row count 52612 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 2 row count 52613 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 0 row count 52613 total row count 420900file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 1 row count 52613 total row count 420900

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 5 row count 52612 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 3 row count 52613 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 4 row count 52612 total row count 420900
2023-10-04 18:18:20 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-10-04 18:18:20 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-10-04 18:18:20 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-10-04 18:18:20 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2023-10-04 18:18:20 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:18:20 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:18:20 - utils.py[line:761] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:18:20 - utils.py[line:761] - INFO: rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:18:20 - utils.py[line:761] - INFO: rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:18:20 - utils.py[line:761] - INFO: rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:18:20 - utils.py[line:761] - INFO: rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:18:20 - utils.py[line:761] - INFO: rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:18:20 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-10-04 18:18:22 - train.py[line:159] - INFO: training on 8 devices (GPUs/TPUs)
2023-10-04 18:18:22 - train.py[line:164] - INFO: max tokens per device = None and max sentences per device = 12
2023-10-04 18:18:22 - trainer.py[line:499] - INFO: Preparing to load checkpoint ../../SGG_0909_OFA_base.pt
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-10-04 18:18:26 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-10-04 18:18:26 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:18:26 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:18:26 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:18:26 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:18:26 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:18:26 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:18:26 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:18:26 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:18:26 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-10-04 18:18:26 - trainer.py[line:313] - INFO: Exponential Moving Average Shadow Model is initialized.
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 3 row count 10874 total row count 86994
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 66, in seek
    self._ensure_lineidx_loaded()
  File "/data/cminus/ofa/data/tsv_file.py", line 94, in _ensure_lineidx_loaded
    with open(self.lineidx, 'r') as fp:
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx'
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 5 row count 10874 total row count 86994
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 66, in seek
    self._ensure_lineidx_loaded()
  File "/data/cminus/ofa/data/tsv_file.py", line 94, in _ensure_lineidx_loaded
    with open(self.lineidx, 'r') as fp:
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx'
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 6 row count 10874 total row count 86994
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 66, in seek
    self._ensure_lineidx_loaded()
  File "/data/cminus/ofa/data/tsv_file.py", line 94, in _ensure_lineidx_loaded
    with open(self.lineidx, 'r') as fp:
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx'
2023-10-04 18:18:27 - trainer.py[line:672] - INFO: Loaded checkpoint ../../SGG_0909_OFA_base.pt (epoch 48 @ 0 updates)
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 7 row count 10874 total row count 86994
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 66, in seek
    self._ensure_lineidx_loaded()
  File "/data/cminus/ofa/data/tsv_file.py", line 94, in _ensure_lineidx_loaded
    with open(self.lineidx, 'r') as fp:
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx'
2023-10-04 18:18:27 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 4 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 1 row count 10875 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 2 row count 10874 total row count 86994

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 0 row count 10875 total row count 86994
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    cli_main()
  File "../../train.py", line 629, in cli_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    self.reset_dummy_batch(batch_iterator.first_batch)
    return self.seek(index)  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch

  File "/data/cminus/ofa/data/tsv_file.py", line 66, in seek
    self._ensure_lineidx_loaded()
  File "/data/cminus/ofa/data/tsv_file.py", line 94, in _ensure_lineidx_loaded
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])    
with open(self.lineidx, 'r') as fp:  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>

FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx'
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 66, in seek
    self._ensure_lineidx_loaded()
  File "/data/cminus/ofa/data/tsv_file.py", line 94, in _ensure_lineidx_loaded
    with open(self.lineidx, 'r') as fp:
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx'
2023-10-04 18:18:27 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 66, in seek
    self._ensure_lineidx_loaded()
  File "/data/cminus/ofa/data/tsv_file.py", line 94, in _ensure_lineidx_loaded
    with open(self.lineidx, 'r') as fp:
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx'
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 721, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/fairseq/fairseq/data/iterators.py", line 322, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/data/cminus/ofa/data/mm_data/vqa_gen_dataset.py", line 244, in __getitem__
    image = Image.open(BytesIO(base64.urlsafe_b64decode(self.coco_2017_img_feat_file[int(image)][0])))
  File "/data/cminus/ofa/data/tsv_file.py", line 86, in __getitem__
    return self.seek(index)
  File "/data/cminus/ofa/data/tsv_file.py", line 66, in seek
    self._ensure_lineidx_loaded()
  File "/data/cminus/ofa/data/tsv_file.py", line 94, in _ensure_lineidx_loaded
    with open(self.lineidx, 'r') as fp:
FileNotFoundError: [Errno 2] No such file or directory: '/data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx'
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15219 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15220 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15222 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 15218) of binary: /data/cminus/anaconda3/envs/OFA/bin/python3
Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 192, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../../train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-04_18:18:28
  host      : root
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 15221)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-04_18:18:28
  host      : root
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 15223)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-04_18:18:28
  host      : root
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 15224)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-04_18:18:28
  host      : root
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 15227)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-04_18:18:28
  host      : root
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 15218)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-10-04 18:21:03 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpr_bm6r8n
2023-10-04 18:21:03 - instantiator.py[line:76] - INFO: Writing /tmp/tmpr_bm6r8n/_remote_module_non_scriptable.py
2023-10-04 18:21:04 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpoa1jjvox
2023-10-04 18:21:04 - instantiator.py[line:76] - INFO: Writing /tmp/tmpoa1jjvox/_remote_module_non_scriptable.py
2023-10-04 18:21:04 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp5mq5dpd3
2023-10-04 18:21:04 - instantiator.py[line:76] - INFO: Writing /tmp/tmp5mq5dpd3/_remote_module_non_scriptable.py
2023-10-04 18:21:04 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpg_9qy6he
2023-10-04 18:21:04 - instantiator.py[line:76] - INFO: Writing /tmp/tmpg_9qy6he/_remote_module_non_scriptable.py
2023-10-04 18:21:04 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpq6v5k4b5
2023-10-04 18:21:04 - instantiator.py[line:76] - INFO: Writing /tmp/tmpq6v5k4b5/_remote_module_non_scriptable.py
2023-10-04 18:21:04 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp2mm8uldg
2023-10-04 18:21:04 - instantiator.py[line:76] - INFO: Writing /tmp/tmp2mm8uldg/_remote_module_non_scriptable.py
2023-10-04 18:21:04 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpdjxj63ib
2023-10-04 18:21:04 - instantiator.py[line:76] - INFO: Writing /tmp/tmpdjxj63ib/_remote_module_non_scriptable.py
2023-10-04 18:21:04 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp11i0zwoy
2023-10-04 18:21:04 - instantiator.py[line:76] - INFO: Writing /tmp/tmp11i0zwoy/_remote_module_non_scriptable.py
1
qwqwqwqw 1
2023-10-04 18:21:05 - utils.py[line:256] - INFO: distributed init (rank 1): env://
2023-10-04 18:21:05 - utils.py[line:262] - INFO: Start init
2023-10-04 18:21:05 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
5
qwqwqwqw 5
2023-10-04 18:21:05 - utils.py[line:256] - INFO: distributed init (rank 5): env://
2023-10-04 18:21:05 - utils.py[line:262] - INFO: Start init
2023-10-04 18:21:05 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
2
qwqwqwqw 2
2023-10-04 18:21:05 - utils.py[line:256] - INFO: distributed init (rank 2): env://
2023-10-04 18:21:05 - utils.py[line:262] - INFO: Start init
2023-10-04 18:21:05 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
3
qwqwqwqw 3
2023-10-04 18:21:05 - utils.py[line:256] - INFO: distributed init (rank 3): env://
2023-10-04 18:21:05 - utils.py[line:262] - INFO: Start init
2023-10-04 18:21:05 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
6
qwqwqwqw 6
7
qwqwqwqw 7
4
0
qwqwqwqw 4
qwqwqwqw 0
2023-10-04 18:21:05 - utils.py[line:256] - INFO: distributed init (rank 6): env://
2023-10-04 18:21:05 - utils.py[line:262] - INFO: Start init
2023-10-04 18:21:05 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2023-10-04 18:21:05 - utils.py[line:256] - INFO: distributed init (rank 7): env://
2023-10-04 18:21:05 - utils.py[line:262] - INFO: Start init
2023-10-04 18:21:05 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
2023-10-04 18:21:05 - utils.py[line:256] - INFO: distributed init (rank 0): env://
2023-10-04 18:21:05 - utils.py[line:262] - INFO: Start init
2023-10-04 18:21:05 - utils.py[line:256] - INFO: distributed init (rank 4): env://
2023-10-04 18:21:05 - utils.py[line:262] - INFO: Start init
2023-10-04 18:21:05 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-10-04 18:21:05 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
2023-10-04 18:21:05 - distributed_c10d.py[line:476] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:21:05 - utils.py[line:272] - INFO: initialized host root as rank 4
single-machine distributed training is initialized.
2023-10-04 18:21:05 - distributed_c10d.py[line:476] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:21:05 - distributed_c10d.py[line:476] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:21:05 - distributed_c10d.py[line:476] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:21:05 - utils.py[line:272] - INFO: initialized host root as rank 6
single-machine distributed training is initialized.
2023-10-04 18:21:05 - utils.py[line:272] - INFO: initialized host root as rank 7
single-machine distributed training is initialized.
2023-10-04 18:21:05 - utils.py[line:272] - INFO: initialized host root as rank 3
single-machine distributed training is initialized.
2023-10-04 18:21:05 - distributed_c10d.py[line:476] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:21:05 - utils.py[line:272] - INFO: initialized host root as rank 1
single-machine distributed training is initialized.
2023-10-04 18:21:05 - distributed_c10d.py[line:476] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:21:05 - distributed_c10d.py[line:476] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:21:05 - utils.py[line:272] - INFO: initialized host root as rank 5
single-machine distributed training is initialized.
2023-10-04 18:21:05 - utils.py[line:272] - INFO: initialized host root as rank 2
single-machine distributed training is initialized.
2023-10-04 18:21:05 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 18:21:05 - utils.py[line:272] - INFO: initialized host root as rank 0
single-machine distributed training is initialized.
2023-10-04 18:21:08 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './../../vqa_tensorboard/20_way_caption_five_filtered', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 12, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 200, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 9, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_0e-5_480', 'restore_file': '../../SGG_0909_OFA_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=12, batch_size_valid='8', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id='0', disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[0.0], lr_scheduler='polynomial_decay', max_epoch=9, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../SGG_0909_OFA_base.pt', sample_patch_num=196, save_dir='./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_0e-5_480', save_interval=10, save_interval_updates=200, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./../../vqa_tensorboard/20_way_caption_five_filtered', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=200, wandb_project=None, warmup_ratio=0.05, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.05, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [0.0]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-10-04 18:21:08 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-10-04 18:21:08 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-10-04 18:21:11 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-10-04 18:21:12 - train.py[line:118] - INFO: task: VqaGenTask
2023-10-04 18:21:12 - train.py[line:119] - INFO: model: OFAModel
2023-10-04 18:21:12 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-10-04 18:21:12 - train.py[line:121] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-10-04 18:21:12 - train.py[line:128] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 3 row count 52613 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 0 row count 52613 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 7 row count 52612 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 2 row count 52613 total row count 420900file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 4 row count 52612 total row count 420900file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 1 row count 52613 total row count 420900


2023-10-04 18:21:12 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 5 row count 52612 total row count 420900
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_1566.tsv slice_id 6 row count 52612 total row count 420900
2023-10-04 18:21:12 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-10-04 18:21:12 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-10-04 18:21:13 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2023-10-04 18:21:13 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:21:13 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:21:13 - utils.py[line:761] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:21:13 - utils.py[line:761] - INFO: rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:21:13 - utils.py[line:761] - INFO: rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:21:13 - utils.py[line:761] - INFO: rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:21:13 - utils.py[line:761] - INFO: rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:21:13 - utils.py[line:761] - INFO: rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 18:21:13 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
Done 0.95 cuda cpu, cpu
2023-10-04 18:21:14 - train.py[line:159] - INFO: training on 8 devices (GPUs/TPUs)
2023-10-04 18:21:14 - train.py[line:164] - INFO: max tokens per device = None and max sentences per device = 12
2023-10-04 18:21:14 - trainer.py[line:499] - INFO: Preparing to load checkpoint ../../SGG_0909_OFA_base.pt
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-10-04 18:21:18 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-10-04 18:21:18 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:21:18 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:21:18 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:21:18 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:21:19 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:21:19 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:21:19 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:21:19 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 18:21:19 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-10-04 18:21:19 - trainer.py[line:313] - INFO: Exponential Moving Average Shadow Model is initialized.
2023-10-04 18:21:19 - trainer.py[line:672] - INFO: Loaded checkpoint ../../SGG_0909_OFA_base.pt (epoch 48 @ 0 updates)
2023-10-04 18:21:19 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 2 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 0 row count 10875 total row count 86994
2023-10-04 18:21:19 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
2023-10-04 18:21:19 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 3 row count 10874 total row count 86994
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
2023-10-04 18:21:20 - trainer.py[line:758] - INFO: begin training epoch 1
2023-10-04 18:21:20 - train.py[line:312] - INFO: Start iterating over samples
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 6 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 1 row count 10875 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 5 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 4 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 7 row count 10874 total row count 86994
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
2023-10-04 18:21:39 - progress_bar.py[line:272] - INFO: epoch 001:     10 / 907 loss=1.044, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=348.6, ups=1.29, wpb=270, bsz=96, num_updates=10, lr=0, gnorm=10.597, clip=100, loss_scale=128, train_wall=17, gb_free=6.5, ema_decay=0.9999, wall=26
2023-10-04 18:21:46 - progress_bar.py[line:272] - INFO: epoch 001:     20 / 907 loss=1.037, loss_v1=0, loss_v2=0, nll_loss=0.878, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=382.3, ups=1.42, wpb=269.9, bsz=96, num_updates=20, lr=0, gnorm=10.851, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=33
2023-10-04 18:21:53 - progress_bar.py[line:272] - INFO: epoch 001:     30 / 907 loss=1.077, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=371.3, ups=1.38, wpb=269.9, bsz=96, num_updates=30, lr=0, gnorm=11.326, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=41
2023-10-04 18:22:00 - progress_bar.py[line:272] - INFO: epoch 001:     40 / 907 loss=1.063, loss_v1=0, loss_v2=0, nll_loss=0.913, ntokens=271.4, nsentences=96, sample_size=271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=382.9, ups=1.41, wpb=271.4, bsz=96, num_updates=40, lr=0, gnorm=10.369, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=48
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 18:22:07 - progress_bar.py[line:272] - INFO: epoch 001:     50 / 907 loss=1.115, loss_v1=0, loss_v2=0, nll_loss=0.962, ntokens=267.6, nsentences=96, sample_size=267.6, sample_size_v1=0, sample_size_v2=0, ppl=1.95, wps=382.5, ups=1.43, wpb=267.6, bsz=96, num_updates=50, lr=0, gnorm=11.8, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=55
2023-10-04 18:22:15 - progress_bar.py[line:272] - INFO: epoch 001:     60 / 907 loss=1.056, loss_v1=0, loss_v2=0, nll_loss=0.903, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.87, wps=380.9, ups=1.4, wpb=271.3, bsz=96, num_updates=60, lr=0, gnorm=10.48, clip=100, loss_scale=128, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=62
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 18:22:22 - progress_bar.py[line:272] - INFO: epoch 001:     70 / 907 loss=1.038, loss_v1=0, loss_v2=0, nll_loss=0.881, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=385.6, ups=1.42, wpb=271.2, bsz=96, num_updates=70, lr=0, gnorm=10.601, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=69
2023-10-04 18:22:28 - progress_bar.py[line:272] - INFO: epoch 001:     80 / 907 loss=1.075, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=396.2, ups=1.47, wpb=269.6, bsz=96, num_updates=80, lr=0, gnorm=11.208, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=76
2023-10-04 18:22:35 - progress_bar.py[line:272] - INFO: epoch 001:     90 / 907 loss=1.047, loss_v1=0, loss_v2=0, nll_loss=0.89, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=396.3, ups=1.46, wpb=271.2, bsz=96, num_updates=90, lr=0, gnorm=10.768, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=82
2023-10-04 18:22:42 - progress_bar.py[line:272] - INFO: epoch 001:    100 / 907 loss=1.041, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.84, wps=394.1, ups=1.46, wpb=269.9, bsz=96, num_updates=100, lr=0, gnorm=10.572, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=89
2023-10-04 18:22:49 - progress_bar.py[line:272] - INFO: epoch 001:    110 / 907 loss=1.105, loss_v1=0, loss_v2=0, nll_loss=0.953, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.94, wps=389.5, ups=1.45, wpb=268.5, bsz=96, num_updates=110, lr=0, gnorm=11.178, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=96
2023-10-04 18:22:56 - progress_bar.py[line:272] - INFO: epoch 001:    120 / 907 loss=1.069, loss_v1=0, loss_v2=0, nll_loss=0.915, ntokens=268.8, nsentences=96, sample_size=268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=395, ups=1.47, wpb=268.8, bsz=96, num_updates=120, lr=0, gnorm=10.708, clip=100, loss_scale=128, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=103
2023-10-04 18:23:03 - progress_bar.py[line:272] - INFO: epoch 001:    130 / 907 loss=1.072, loss_v1=0, loss_v2=0, nll_loss=0.92, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=400.7, ups=1.48, wpb=270.2, bsz=96, num_updates=130, lr=0, gnorm=11.421, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=110
2023-10-04 18:23:09 - progress_bar.py[line:272] - INFO: epoch 001:    140 / 907 loss=1.07, loss_v1=0, loss_v2=0, nll_loss=0.91, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=393.2, ups=1.46, wpb=268.4, bsz=96, num_updates=140, lr=0, gnorm=10.774, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=117
2023-10-04 18:23:16 - progress_bar.py[line:272] - INFO: epoch 001:    150 / 907 loss=1.044, loss_v1=0, loss_v2=0, nll_loss=0.886, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=403.1, ups=1.49, wpb=270, bsz=96, num_updates=150, lr=0, gnorm=11.165, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=123
2023-10-04 18:23:23 - progress_bar.py[line:272] - INFO: epoch 001:    160 / 907 loss=1.073, loss_v1=0, loss_v2=0, nll_loss=0.921, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.89, wps=401.5, ups=1.49, wpb=269.3, bsz=96, num_updates=160, lr=0, gnorm=10.898, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=130
2023-10-04 18:23:30 - progress_bar.py[line:272] - INFO: epoch 001:    170 / 907 loss=1.031, loss_v1=0, loss_v2=0, nll_loss=0.872, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.83, wps=384.4, ups=1.42, wpb=270, bsz=96, num_updates=170, lr=0, gnorm=10.357, clip=100, loss_scale=128, train_wall=7, gb_free=5.9, ema_decay=0.9999, wall=137
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 18:23:37 - progress_bar.py[line:272] - INFO: epoch 001:    180 / 907 loss=1.067, loss_v1=0, loss_v2=0, nll_loss=0.914, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.88, wps=383.5, ups=1.42, wpb=269.3, bsz=96, num_updates=180, lr=0, gnorm=10.836, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=144
2023-10-04 18:23:44 - progress_bar.py[line:272] - INFO: epoch 001:    190 / 907 loss=1.02, loss_v1=0, loss_v2=0, nll_loss=0.863, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.82, wps=398.8, ups=1.48, wpb=269.1, bsz=96, num_updates=190, lr=0, gnorm=10.263, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=151
2023-10-04 18:23:50 - progress_bar.py[line:272] - INFO: epoch 001:    200 / 907 loss=1.123, loss_v1=0, loss_v2=0, nll_loss=0.972, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.96, wps=398.6, ups=1.48, wpb=269.2, bsz=96, num_updates=200, lr=0, gnorm=11.469, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=158
2023-10-04 18:23:50 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 18:23:50 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-04 18:23:53 - train.py[line:549] - INFO: 0 / 6577
2023-10-04 18:23:53 - train.py[line:550] - INFO: load:2.20 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 18:25:37 - train.py[line:549] - INFO: 200 / 6577
2023-10-04 18:25:37 - train.py[line:550] - INFO: load:2.28 valid_run:104.30 task_valid:95.03 collect_output:8.31
2023-10-04 18:27:17 - train.py[line:549] - INFO: 400 / 6577
2023-10-04 18:27:17 - train.py[line:550] - INFO: load:2.36 valid_run:203.73 task_valid:186.95 collect_output:14.88
2023-10-04 18:28:56 - train.py[line:549] - INFO: 600 / 6577
2023-10-04 18:28:56 - train.py[line:550] - INFO: load:2.45 valid_run:302.88 task_valid:275.90 collect_output:24.11
2023-10-04 18:30:35 - train.py[line:549] - INFO: 800 / 6577
2023-10-04 18:30:35 - train.py[line:550] - INFO: load:2.53 valid_run:401.96 task_valid:365.93 collect_output:32.25
2023-10-04 18:32:17 - train.py[line:549] - INFO: 1000 / 6577
2023-10-04 18:32:17 - train.py[line:550] - INFO: load:2.61 valid_run:503.10 task_valid:456.31 collect_output:42.11
2023-10-04 18:33:55 - train.py[line:549] - INFO: 1200 / 6577
2023-10-04 18:33:55 - train.py[line:550] - INFO: load:2.70 valid_run:601.71 task_valid:545.85 collect_output:50.25
2023-10-04 18:35:34 - train.py[line:549] - INFO: 1400 / 6577
2023-10-04 18:35:34 - train.py[line:550] - INFO: load:2.78 valid_run:699.87 task_valid:636.14 collect_output:57.18
2023-10-04 18:37:14 - train.py[line:549] - INFO: 1600 / 6577
2023-10-04 18:37:14 - train.py[line:550] - INFO: load:2.87 valid_run:800.09 task_valid:728.17 collect_output:64.44
2023-10-04 18:38:52 - train.py[line:549] - INFO: 1800 / 6577
2023-10-04 18:38:52 - train.py[line:550] - INFO: load:2.95 valid_run:897.90 task_valid:819.03 collect_output:70.42
2023-10-04 18:40:31 - train.py[line:549] - INFO: 2000 / 6577
2023-10-04 18:40:31 - train.py[line:550] - INFO: load:3.04 valid_run:997.44 task_valid:910.48 collect_output:77.55
2023-10-04 18:42:10 - train.py[line:549] - INFO: 2200 / 6577
2023-10-04 18:42:10 - train.py[line:550] - INFO: load:3.12 valid_run:1095.43 task_valid:1002.06 collect_output:83.01
2023-10-04 18:43:49 - train.py[line:549] - INFO: 2400 / 6577
2023-10-04 18:43:49 - train.py[line:550] - INFO: load:3.21 valid_run:1194.98 task_valid:1092.39 collect_output:91.29
2023-10-04 18:45:31 - train.py[line:549] - INFO: 2600 / 6577
2023-10-04 18:45:31 - train.py[line:550] - INFO: load:3.29 valid_run:1296.90 task_valid:1183.37 collect_output:101.32
2023-10-04 18:47:09 - train.py[line:549] - INFO: 2800 / 6577
2023-10-04 18:47:09 - train.py[line:550] - INFO: load:3.37 valid_run:1394.76 task_valid:1273.60 collect_output:108.03
2023-10-04 18:48:48 - train.py[line:549] - INFO: 3000 / 6577
2023-10-04 18:48:48 - train.py[line:550] - INFO: load:3.46 valid_run:1493.52 task_valid:1362.28 collect_output:117.15
2023-10-04 18:50:26 - train.py[line:549] - INFO: 3200 / 6577
2023-10-04 18:50:26 - train.py[line:550] - INFO: load:3.54 valid_run:1591.69 task_valid:1451.50 collect_output:125.15
2023-10-04 18:52:05 - train.py[line:549] - INFO: 3400 / 6577
2023-10-04 18:52:05 - train.py[line:550] - INFO: load:3.63 valid_run:1690.05 task_valid:1541.41 collect_output:132.61
2023-10-04 18:53:44 - train.py[line:549] - INFO: 3600 / 6577
2023-10-04 18:53:44 - train.py[line:550] - INFO: load:3.71 valid_run:1789.22 task_valid:1633.22 collect_output:138.99
2023-10-04 18:55:28 - train.py[line:549] - INFO: 3800 / 6577
2023-10-04 18:55:28 - train.py[line:550] - INFO: load:3.80 valid_run:1892.37 task_valid:1723.21 collect_output:151.19
2023-10-04 18:57:09 - train.py[line:549] - INFO: 4000 / 6577
2023-10-04 18:57:09 - train.py[line:550] - INFO: load:3.88 valid_run:1993.59 task_valid:1813.32 collect_output:161.39
2023-10-04 18:58:47 - train.py[line:549] - INFO: 4200 / 6577
2023-10-04 18:58:47 - train.py[line:550] - INFO: load:3.97 valid_run:2091.63 task_valid:1905.61 collect_output:166.20
2023-10-04 19:00:25 - train.py[line:549] - INFO: 4400 / 6577
2023-10-04 19:00:25 - train.py[line:550] - INFO: load:4.05 valid_run:2189.38 task_valid:1995.95 collect_output:172.65
2023-10-04 19:02:03 - train.py[line:549] - INFO: 4600 / 6577
2023-10-04 19:02:03 - train.py[line:550] - INFO: load:4.14 valid_run:2287.09 task_valid:2085.03 collect_output:180.32
2023-10-04 19:03:43 - train.py[line:549] - INFO: 4800 / 6577
2023-10-04 19:03:43 - train.py[line:550] - INFO: load:4.23 valid_run:2387.72 task_valid:2173.87 collect_output:191.18
2023-10-04 19:05:23 - train.py[line:549] - INFO: 5000 / 6577
2023-10-04 19:05:23 - train.py[line:550] - INFO: load:4.31 valid_run:2487.32 task_valid:2265.05 collect_output:198.65
2023-10-04 19:07:02 - train.py[line:549] - INFO: 5200 / 6577
2023-10-04 19:07:02 - train.py[line:550] - INFO: load:4.40 valid_run:2585.97 task_valid:2355.93 collect_output:205.47
2023-10-04 19:08:39 - train.py[line:549] - INFO: 5400 / 6577
2023-10-04 19:08:39 - train.py[line:550] - INFO: load:4.49 valid_run:2682.94 task_valid:2446.47 collect_output:210.96
2023-10-04 19:10:18 - train.py[line:549] - INFO: 5600 / 6577
2023-10-04 19:10:18 - train.py[line:550] - INFO: load:4.57 valid_run:2781.85 task_valid:2538.53 collect_output:216.87
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
    cli_main()
  File "../../train.py", line 629, in cli_main
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
Traceback (most recent call last):
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "../../train.py", line 636, in <module>
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15870 closing signal SIGINT
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
        cli_main()valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)

  File "../../train.py", line 629, in cli_main
  File "../../train.py", line 556, in validate
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15871 closing signal SIGINT
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
    distributed_utils.call_main(cfg, main)
      File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15872 closing signal SIGINT
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main

WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15873 closing signal SIGINT
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
  File "../../train.py", line 206, in main
    _loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
      File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 222, in valid_step
_loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 222, in valid_step
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15874 closing signal SIGINT
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    encoder_out = eval_model.encoder(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
  File "../../train.py", line 629, in cli_main
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15875 closing signal SIGINT
    encoder_out = eval_model.encoder(    
valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
Traceback (most recent call last):
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15877 closing signal SIGINT
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 222, in valid_step
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15879 closing signal SIGINT
    return forward_call(*args, **kwargs)
      File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 797, in forward
distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 935, in forward_scriptable
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    return func(*args, **kwds)
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
      File "../../train.py", line 331, in train
x = layer(x, encoder_padding_mask=encoder_padding_mask if has_pads else None, \
    KeyboardInterruptencoder_out = eval_model.encoder(

    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    _loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 222, in valid_step
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    encoder_out = eval_model.encoder(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 797, in forward
        return self.forward_scriptable(src_tokens,_loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(

  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 935, in forward_scriptable
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 222, in valid_step
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 797, in forward
    encoder_out = eval_model.encoder(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    x = layer(x, encoder_padding_mask=encoder_padding_mask if has_pads else None, \
KeyboardInterrupt    return self.forward_scriptable(src_tokens,


During handling of the above exception, another exception occurred:

  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 935, in forward_scriptable
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
        return forward_call(*args, **kwargs)cli_main()

  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 797, in forward
  File "../../train.py", line 629, in cli_main
    x = layer(x, encoder_padding_mask=encoder_padding_mask if has_pads else None, \
KeyboardInterrupt
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    return self.forward_scriptable(src_tokens,
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 935, in forward_scriptable
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    x = layer(x, encoder_padding_mask=encoder_padding_mask if has_pads else None, \
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
KeyboardInterrupt
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    cli_main()
    return func(*args, **kwds)  File "../../train.py", line 629, in cli_main

  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
      File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
_loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 222, in valid_step
    encoder_out = eval_model.encoder(    
main(cfg, **kwargs)KeyboardInterrupt

  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    _loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 222, in valid_step
    encoder_out = eval_model.encoder(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 797, in forward
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
        return self.forward_scriptable(src_tokens,main(cfg, **kwargs)

  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 935, in forward_scriptable
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    x = layer(x, encoder_padding_mask=encoder_padding_mask if has_pads else None, \
    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
KeyboardInterrupt
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
    _loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 222, in valid_step
    encoder_out = eval_model.encoder(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 797, in forward
    return self.forward_scriptable(src_tokens,
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 935, in forward_scriptable
    x = layer(x, encoder_padding_mask=encoder_padding_mask if has_pads else None, \
KeyboardInterrupt

WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15870 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15871 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15872 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15873 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15874 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15875 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15877 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 15879 closing signal SIGTERM
Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 723, in run
    result = self._invoke_run(role)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    time.sleep(monitor_interval)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 15793 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 730, in run
    self._shutdown(e.sigval)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 289, in _shutdown
    self._pcontext.close(death_sig)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 331, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 708, in _close
    handler.proc.wait(time_to_wait)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/subprocess.py", line 1079, in wait
    return self._wait(timeout=timeout)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/subprocess.py", line 1798, in _wait
    time.sleep(delay)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 15793 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 192, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 241, in launch_agent
    result = agent.run()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 735, in run
    self._shutdown()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 289, in _shutdown
    self._pcontext.close(death_sig)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 331, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 708, in _close
    handler.proc.wait(time_to_wait)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/subprocess.py", line 1079, in wait
    return self._wait(timeout=timeout)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/subprocess.py", line 1798, in _wait
    time.sleep(delay)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 15793 got signal: 2
