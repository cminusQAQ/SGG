/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-10-04 19:12:05 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp4efa43rx
2023-10-04 19:12:05 - instantiator.py[line:76] - INFO: Writing /tmp/tmp4efa43rx/_remote_module_non_scriptable.py
2023-10-04 19:12:06 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpacqeuh0q
2023-10-04 19:12:06 - instantiator.py[line:76] - INFO: Writing /tmp/tmpacqeuh0q/_remote_module_non_scriptable.py
2023-10-04 19:12:06 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp13rxg_w4
2023-10-04 19:12:06 - instantiator.py[line:76] - INFO: Writing /tmp/tmp13rxg_w4/_remote_module_non_scriptable.py
2023-10-04 19:12:06 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpz17p3ntv
2023-10-04 19:12:06 - instantiator.py[line:76] - INFO: Writing /tmp/tmpz17p3ntv/_remote_module_non_scriptable.py
2023-10-04 19:12:06 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpttnmzd5i
2023-10-04 19:12:06 - instantiator.py[line:76] - INFO: Writing /tmp/tmpttnmzd5i/_remote_module_non_scriptable.py
2023-10-04 19:12:06 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpyb276khe
2023-10-04 19:12:06 - instantiator.py[line:76] - INFO: Writing /tmp/tmpyb276khe/_remote_module_non_scriptable.py
2023-10-04 19:12:06 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpgnphiue6
2023-10-04 19:12:06 - instantiator.py[line:76] - INFO: Writing /tmp/tmpgnphiue6/_remote_module_non_scriptable.py
2023-10-04 19:12:06 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpn1nz8ujb
2023-10-04 19:12:06 - instantiator.py[line:76] - INFO: Writing /tmp/tmpn1nz8ujb/_remote_module_non_scriptable.py
3
qwqwqwqw 3
2023-10-04 19:12:07 - utils.py[line:256] - INFO: distributed init (rank 3): env://
2023-10-04 19:12:07 - utils.py[line:262] - INFO: Start init
7
qwqwqwqw 7
2023-10-04 19:12:07 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2023-10-04 19:12:07 - utils.py[line:256] - INFO: distributed init (rank 7): env://
2023-10-04 19:12:07 - utils.py[line:262] - INFO: Start init
2023-10-04 19:12:07 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
5
qwqwqwqw 5
2023-10-04 19:12:07 - utils.py[line:256] - INFO: distributed init (rank 5): env://
2023-10-04 19:12:07 - utils.py[line:262] - INFO: Start init
2023-10-04 19:12:07 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
4
qwqwqwqw 4
2023-10-04 19:12:07 - utils.py[line:256] - INFO: distributed init (rank 4): env://
2023-10-04 19:12:07 - utils.py[line:262] - INFO: Start init
2023-10-04 19:12:07 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
6
qwqwqwqw 6
2023-10-04 19:12:07 - utils.py[line:256] - INFO: distributed init (rank 6): env://
2023-10-04 19:12:07 - utils.py[line:262] - INFO: Start init
2023-10-04 19:12:07 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
0
qwqwqwqw 0
2023-10-04 19:12:07 - utils.py[line:256] - INFO: distributed init (rank 0): env://
2023-10-04 19:12:07 - utils.py[line:262] - INFO: Start init
2023-10-04 19:12:07 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2
qwqwqwqw 2
1
qwqwqwqw 1
2023-10-04 19:12:07 - utils.py[line:256] - INFO: distributed init (rank 2): env://
2023-10-04 19:12:07 - utils.py[line:262] - INFO: Start init
2023-10-04 19:12:07 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2023-10-04 19:12:07 - utils.py[line:256] - INFO: distributed init (rank 1): env://
2023-10-04 19:12:07 - utils.py[line:262] - INFO: Start init
2023-10-04 19:12:07 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2023-10-04 19:12:07 - distributed_c10d.py[line:476] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:12:07 - utils.py[line:272] - INFO: initialized host root as rank 1
single-machine distributed training is initialized.
2023-10-04 19:12:07 - distributed_c10d.py[line:476] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:12:07 - utils.py[line:272] - INFO: initialized host root as rank 5
single-machine distributed training is initialized.
2023-10-04 19:12:07 - distributed_c10d.py[line:476] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:12:07 - distributed_c10d.py[line:476] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:12:07 - utils.py[line:272] - INFO: initialized host root as rank 2
single-machine distributed training is initialized.
2023-10-04 19:12:07 - distributed_c10d.py[line:476] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:12:07 - utils.py[line:272] - INFO: initialized host root as rank 7
single-machine distributed training is initialized.
2023-10-04 19:12:07 - utils.py[line:272] - INFO: initialized host root as rank 3
single-machine distributed training is initialized.
2023-10-04 19:12:07 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:12:07 - distributed_c10d.py[line:476] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:12:07 - utils.py[line:272] - INFO: initialized host root as rank 0
single-machine distributed training is initialized.
2023-10-04 19:12:07 - utils.py[line:272] - INFO: initialized host root as rank 4
single-machine distributed training is initialized.
2023-10-04 19:12:07 - distributed_c10d.py[line:476] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:12:07 - utils.py[line:272] - INFO: initialized host root as rank 6
single-machine distributed training is initialized.
2023-10-04 19:12:10 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './../../vqa_tensorboard/20_way_caption_five_filtered', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 12, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 200, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 10, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 9, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480', 'restore_file': '../../SGG_0909_OFA_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=12, batch_size_valid='10', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id='0', disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=9, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../SGG_0909_OFA_base.pt', sample_patch_num=196, save_dir='./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480', save_interval=10, save_interval_updates=200, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./../../vqa_tensorboard/20_way_caption_five_filtered', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=200, wandb_project=None, warmup_ratio=0.05, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.05, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-10-04 19:12:10 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-10-04 19:12:10 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-10-04 19:12:14 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-10-04 19:12:14 - train.py[line:118] - INFO: task: VqaGenTask
2023-10-04 19:12:14 - train.py[line:119] - INFO: model: OFAModel
2023-10-04 19:12:14 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-10-04 19:12:14 - train.py[line:121] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-10-04 19:12:14 - train.py[line:128] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 0 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 1 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 5 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 6 row count 18701 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 2 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 7 row count 18701 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 4 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 3 row count 18702 total row count 149614
2023-10-04 19:12:14 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-10-04 19:12:14 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-10-04 19:12:14 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-10-04 19:12:15 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2023-10-04 19:12:15 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:12:15 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:12:15 - utils.py[line:761] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:12:15 - utils.py[line:761] - INFO: rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:12:15 - utils.py[line:761] - INFO: rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:12:15 - utils.py[line:761] - INFO: rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:12:15 - utils.py[line:761] - INFO: rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:12:15 - utils.py[line:761] - INFO: rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:12:15 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-10-04 19:12:16 - train.py[line:159] - INFO: training on 8 devices (GPUs/TPUs)
2023-10-04 19:12:16 - train.py[line:164] - INFO: max tokens per device = None and max sentences per device = 12
2023-10-04 19:12:16 - trainer.py[line:499] - INFO: Preparing to load checkpoint ../../SGG_0909_OFA_base.pt
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-10-04 19:12:20 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-10-04 19:12:20 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:12:20 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:12:20 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:12:20 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:12:20 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:12:20 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:12:21 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:12:21 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:12:21 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-10-04 19:12:21 - trainer.py[line:313] - INFO: Exponential Moving Average Shadow Model is initialized.
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
2023-10-04 19:12:21 - trainer.py[line:672] - INFO: Loaded checkpoint ../../SGG_0909_OFA_base.pt (epoch 48 @ 0 updates)
Exception ignored in: <function FileDataset.__del__ at 0x7f36fb3ded30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
2023-10-04 19:12:21 - trainer.py[line:694] - INFO: loading train data for epoch 1
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Exception ignored in: <function FileDataset.__del__ at 0x7f275ec1ed30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Exception ignored in: <function FileDataset.__del__ at 0x7f2e5fd85d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Exception ignored in: <function FileDataset.__del__ at 0x7f31aa344d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Exception ignored in: <function FileDataset.__del__ at 0x7f38e9c44d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Exception ignored in: <function FileDataset.__del__ at 0x7f07b7f05d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Exception ignored in: <function FileDataset.__del__ at 0x7f90e9a44d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Exception ignored in: <function FileDataset.__del__ at 0x7f58f5343d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 21706) of binary: /data/cminus/anaconda3/envs/OFA/bin/python3
Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 192, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../../train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-04_19:12:27
  host      : root
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 21707)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-10-04_19:12:27
  host      : root
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 21708)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-10-04_19:12:27
  host      : root
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 21709)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-10-04_19:12:27
  host      : root
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 21710)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-10-04_19:12:27
  host      : root
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 21711)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-10-04_19:12:27
  host      : root
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 21713)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-10-04_19:12:27
  host      : root
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 21715)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-04_19:12:27
  host      : root
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 21706)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-10-04 19:14:30 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp45opoey4
2023-10-04 19:14:30 - instantiator.py[line:76] - INFO: Writing /tmp/tmp45opoey4/_remote_module_non_scriptable.py
2023-10-04 19:14:30 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp1s1egh4g
2023-10-04 19:14:30 - instantiator.py[line:76] - INFO: Writing /tmp/tmp1s1egh4g/_remote_module_non_scriptable.py
2023-10-04 19:14:30 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpewshetb8
2023-10-04 19:14:30 - instantiator.py[line:76] - INFO: Writing /tmp/tmpewshetb8/_remote_module_non_scriptable.py
2023-10-04 19:14:30 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpp5kffqsm
2023-10-04 19:14:30 - instantiator.py[line:76] - INFO: Writing /tmp/tmpp5kffqsm/_remote_module_non_scriptable.py
2023-10-04 19:14:30 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpxzty4hzc
2023-10-04 19:14:30 - instantiator.py[line:76] - INFO: Writing /tmp/tmpxzty4hzc/_remote_module_non_scriptable.py
2023-10-04 19:14:30 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp28hbs_au
2023-10-04 19:14:30 - instantiator.py[line:76] - INFO: Writing /tmp/tmp28hbs_au/_remote_module_non_scriptable.py
2023-10-04 19:14:30 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmphp46ts5m
2023-10-04 19:14:30 - instantiator.py[line:76] - INFO: Writing /tmp/tmphp46ts5m/_remote_module_non_scriptable.py
2023-10-04 19:14:30 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpecstvp0u
2023-10-04 19:14:30 - instantiator.py[line:76] - INFO: Writing /tmp/tmpecstvp0u/_remote_module_non_scriptable.py
0
qwqwqwqw 0
2023-10-04 19:14:32 - utils.py[line:256] - INFO: distributed init (rank 0): env://
2023-10-04 19:14:32 - utils.py[line:262] - INFO: Start init
2023-10-04 19:14:32 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2
4
qwqwqwqw 2
qwqwqwqw 4
2023-10-04 19:14:32 - utils.py[line:256] - INFO: distributed init (rank 2): env://
2023-10-04 19:14:32 - utils.py[line:262] - INFO: Start init
2023-10-04 19:14:32 - utils.py[line:256] - INFO: distributed init (rank 4): env://
2023-10-04 19:14:32 - utils.py[line:262] - INFO: Start init
2023-10-04 19:14:32 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2023-10-04 19:14:32 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
1
qwqwqwqw 1
2023-10-04 19:14:32 - utils.py[line:256] - INFO: distributed init (rank 1): env://
2023-10-04 19:14:32 - utils.py[line:262] - INFO: Start init
2023-10-04 19:14:32 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
7
qwqwqwqw 7
2023-10-04 19:14:32 - utils.py[line:256] - INFO: distributed init (rank 7): env://
2023-10-04 19:14:32 - utils.py[line:262] - INFO: Start init
2023-10-04 19:14:32 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
6
qwqwqwqw 6
5
qwqwqwqw 5
2023-10-04 19:14:32 - utils.py[line:256] - INFO: distributed init (rank 6): env://
2023-10-04 19:14:32 - utils.py[line:262] - INFO: Start init
2023-10-04 19:14:32 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2023-10-04 19:14:32 - utils.py[line:256] - INFO: distributed init (rank 5): env://
2023-10-04 19:14:32 - utils.py[line:262] - INFO: Start init
2023-10-04 19:14:32 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
3
qwqwqwqw 3
2023-10-04 19:14:32 - utils.py[line:256] - INFO: distributed init (rank 3): env://
2023-10-04 19:14:32 - utils.py[line:262] - INFO: Start init
2023-10-04 19:14:32 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2023-10-04 19:14:32 - distributed_c10d.py[line:476] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:14:32 - utils.py[line:272] - INFO: initialized host root as rank 3
single-machine distributed training is initialized.
2023-10-04 19:14:32 - distributed_c10d.py[line:476] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:14:32 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:14:32 - utils.py[line:272] - INFO: initialized host root as rank 0
single-machine distributed training is initialized.
2023-10-04 19:14:32 - distributed_c10d.py[line:476] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:14:32 - utils.py[line:272] - INFO: initialized host root as rank 5
single-machine distributed training is initialized.
2023-10-04 19:14:32 - utils.py[line:272] - INFO: initialized host root as rank 1
single-machine distributed training is initialized.
2023-10-04 19:14:32 - distributed_c10d.py[line:476] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:14:32 - utils.py[line:272] - INFO: initialized host root as rank 2
single-machine distributed training is initialized.2023-10-04 19:14:32 - distributed_c10d.py[line:476] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.

2023-10-04 19:14:32 - distributed_c10d.py[line:476] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:14:32 - utils.py[line:272] - INFO: initialized host root as rank 4
single-machine distributed training is initialized.
2023-10-04 19:14:32 - utils.py[line:272] - INFO: initialized host root as rank 6
single-machine distributed training is initialized.
2023-10-04 19:14:32 - distributed_c10d.py[line:476] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:14:32 - utils.py[line:272] - INFO: initialized host root as rank 7
single-machine distributed training is initialized.
2023-10-04 19:14:35 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './../../vqa_tensorboard/20_way_caption_five_filtered', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 12, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 200, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 10, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 9, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480', 'restore_file': '../../SGG_0909_OFA_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=12, batch_size_valid='10', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id='0', disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=9, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../SGG_0909_OFA_base.pt', sample_patch_num=196, save_dir='./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480', save_interval=10, save_interval_updates=200, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./../../vqa_tensorboard/20_way_caption_five_filtered', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=200, wandb_project=None, warmup_ratio=0.05, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.05, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-10-04 19:14:35 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-10-04 19:14:35 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-10-04 19:14:39 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-10-04 19:14:39 - train.py[line:118] - INFO: task: VqaGenTask
2023-10-04 19:14:39 - train.py[line:119] - INFO: model: OFAModel
2023-10-04 19:14:39 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-10-04 19:14:39 - train.py[line:121] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-10-04 19:14:39 - train.py[line:128] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 6 row count 18701 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 0 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 1 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 4 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 2 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 5 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 3 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 7 row count 18701 total row count 149614
2023-10-04 19:14:39 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-10-04 19:14:39 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-10-04 19:14:39 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-10-04 19:14:40 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2023-10-04 19:14:40 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:14:40 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:14:40 - utils.py[line:761] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:14:40 - utils.py[line:761] - INFO: rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:14:40 - utils.py[line:761] - INFO: rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:14:40 - utils.py[line:761] - INFO: rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:14:40 - utils.py[line:761] - INFO: rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:14:40 - utils.py[line:761] - INFO: rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:14:40 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-10-04 19:14:41 - train.py[line:159] - INFO: training on 8 devices (GPUs/TPUs)
2023-10-04 19:14:41 - train.py[line:164] - INFO: max tokens per device = None and max sentences per device = 12
2023-10-04 19:14:41 - trainer.py[line:499] - INFO: Preparing to load checkpoint ../../SGG_0909_OFA_base.pt
Done 0.95 cuda cpu, cpu
2023-10-04 19:14:45 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-10-04 19:14:45 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:14:45 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:14:45 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:14:45 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:14:45 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:14:45 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:14:45 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:14:45 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:14:45 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-10-04 19:14:45 - trainer.py[line:313] - INFO: Exponential Moving Average Shadow Model is initialized.
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Exception ignored in: <function FileDataset.__del__ at 0x7fe895944d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Exception ignored in: <function FileDataset.__del__ at 0x7f078dfc3d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
2023-10-04 19:14:46 - trainer.py[line:672] - INFO: Loaded checkpoint ../../SGG_0909_OFA_base.pt (epoch 48 @ 0 updates)
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
2023-10-04 19:14:46 - trainer.py[line:694] - INFO: loading train data for epoch 1
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 173, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/data/cminus/ofa/utils/checkpoint_utils.py", line 287, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/data/cminus/ofa/trainer.py", line 695, in get_train_iterator
    self.task.load_dataset(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 130, in load_dataset
    dataset = FileDataset(table_path, self.cfg.selected_cols)
  File "/data/cminus/ofa/data/file_dataset.py", line 14, in __init__
    assert os.path.exists(self.file_path), "Error: The local datafile {} not exists!".format(self.file_path)
AssertionError: Error: The local datafile /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opttrain_NA1_E0.tsv not exists!
Exception ignored in: <function FileDataset.__del__ at 0x7f3d2e504d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Exception ignored in: <function FileDataset.__del__ at 0x7fea67644d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Exception ignored in: <function FileDataset.__del__ at 0x7fc5f2e83d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
Exception ignored in: <function FileDataset.__del__ at 0x7fa328044d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Exception ignored in: <function FileDataset.__del__ at 0x7faf94684d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
Exception ignored in: <function FileDataset.__del__ at 0x7f956c143d30>
Traceback (most recent call last):
  File "/data/cminus/ofa/data/file_dataset.py", line 92, in __del__
    self._reader.close()
AttributeError: 'FileDataset' object has no attribute '_reader'
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22326 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22327 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22328 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22330 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22331 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22335 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 3 (pid: 22329) of binary: /data/cminus/anaconda3/envs/OFA/bin/python3
Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 192, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../../train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-10-04_19:14:47
  host      : root
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 22333)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-10-04_19:14:47
  host      : root
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 22329)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-10-04 19:18:34 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpmqj8zu4c
2023-10-04 19:18:34 - instantiator.py[line:76] - INFO: Writing /tmp/tmpmqj8zu4c/_remote_module_non_scriptable.py
2023-10-04 19:18:34 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpn5mh6kaw
2023-10-04 19:18:34 - instantiator.py[line:76] - INFO: Writing /tmp/tmpn5mh6kaw/_remote_module_non_scriptable.py
2023-10-04 19:18:34 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp4relr9sz
2023-10-04 19:18:34 - instantiator.py[line:76] - INFO: Writing /tmp/tmp4relr9sz/_remote_module_non_scriptable.py
2023-10-04 19:18:34 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp3der8gxs
2023-10-04 19:18:34 - instantiator.py[line:76] - INFO: Writing /tmp/tmp3der8gxs/_remote_module_non_scriptable.py
2023-10-04 19:18:34 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpkq908m7r
2023-10-04 19:18:34 - instantiator.py[line:76] - INFO: Writing /tmp/tmpkq908m7r/_remote_module_non_scriptable.py
2023-10-04 19:18:34 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpr_o5abdx
2023-10-04 19:18:34 - instantiator.py[line:76] - INFO: Writing /tmp/tmpr_o5abdx/_remote_module_non_scriptable.py
2023-10-04 19:18:34 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp3vmtvmbk
2023-10-04 19:18:34 - instantiator.py[line:76] - INFO: Writing /tmp/tmp3vmtvmbk/_remote_module_non_scriptable.py
2023-10-04 19:18:34 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp_n5oi9aw
2023-10-04 19:18:34 - instantiator.py[line:76] - INFO: Writing /tmp/tmp_n5oi9aw/_remote_module_non_scriptable.py
0
qwqwqwqw 0
2023-10-04 19:18:36 - utils.py[line:256] - INFO: distributed init (rank 0): env://
2023-10-04 19:18:36 - utils.py[line:262] - INFO: Start init
2023-10-04 19:18:36 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
3
qwqwqwqw 3
2023-10-04 19:18:36 - utils.py[line:256] - INFO: distributed init (rank 3): env://
2023-10-04 19:18:36 - utils.py[line:262] - INFO: Start init
2023-10-04 19:18:36 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
2
qwqwqwqw 2
2023-10-04 19:18:36 - utils.py[line:256] - INFO: distributed init (rank 2): env://
2023-10-04 19:18:36 - utils.py[line:262] - INFO: Start init
2023-10-04 19:18:36 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
4
qwqwqwqw 4
2023-10-04 19:18:36 - utils.py[line:256] - INFO: distributed init (rank 4): env://
2023-10-04 19:18:36 - utils.py[line:262] - INFO: Start init
2023-10-04 19:18:36 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
5
qwqwqwqw 5
2023-10-04 19:18:36 - utils.py[line:256] - INFO: distributed init (rank 5): env://
2023-10-04 19:18:36 - utils.py[line:262] - INFO: Start init
2023-10-04 19:18:36 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
1
qwqwqwqw 1
2023-10-04 19:18:36 - utils.py[line:256] - INFO: distributed init (rank 1): env://
2023-10-04 19:18:36 - utils.py[line:262] - INFO: Start init
2023-10-04 19:18:36 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
6
qwqwqwqw 6
2023-10-04 19:18:36 - utils.py[line:256] - INFO: distributed init (rank 6): env://
2023-10-04 19:18:36 - utils.py[line:262] - INFO: Start init
2023-10-04 19:18:36 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
7
qwqwqwqw 7
2023-10-04 19:18:36 - utils.py[line:256] - INFO: distributed init (rank 7): env://
2023-10-04 19:18:36 - utils.py[line:262] - INFO: Start init
2023-10-04 19:18:36 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
2023-10-04 19:18:36 - distributed_c10d.py[line:476] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:18:36 - utils.py[line:272] - INFO: initialized host root as rank 7
single-machine distributed training is initialized.
2023-10-04 19:18:36 - distributed_c10d.py[line:476] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:18:36 - distributed_c10d.py[line:476] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:18:36 - distributed_c10d.py[line:476] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:18:36 - utils.py[line:272] - INFO: initialized host root as rank 1
single-machine distributed training is initialized.
2023-10-04 19:18:36 - utils.py[line:272] - INFO: initialized host root as rank 5
single-machine distributed training is initialized.
2023-10-04 19:18:36 - utils.py[line:272] - INFO: initialized host root as rank 4
single-machine distributed training is initialized.
2023-10-04 19:18:36 - distributed_c10d.py[line:476] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:18:36 - distributed_c10d.py[line:476] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:18:36 - utils.py[line:272] - INFO: initialized host root as rank 2
single-machine distributed training is initialized.
2023-10-04 19:18:36 - utils.py[line:272] - INFO: initialized host root as rank 3
single-machine distributed training is initialized.
2023-10-04 19:18:36 - distributed_c10d.py[line:476] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:18:36 - utils.py[line:272] - INFO: initialized host root as rank 6
2023-10-04 19:18:36 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
single-machine distributed training is initialized.
2023-10-04 19:18:36 - utils.py[line:272] - INFO: initialized host root as rank 0
single-machine distributed training is initialized.
2023-10-04 19:18:39 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './../../vqa_tensorboard/20_way_caption_five_filtered', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 12, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 200, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 10, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 9, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480', 'restore_file': '../../SGG_0909_OFA_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=12, batch_size_valid='10', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id='0', disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=9, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../SGG_0909_OFA_base.pt', sample_patch_num=196, save_dir='./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480', save_interval=10, save_interval_updates=200, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./../../vqa_tensorboard/20_way_caption_five_filtered', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=200, wandb_project=None, warmup_ratio=0.05, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.05, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-10-04 19:18:39 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-10-04 19:18:39 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-10-04 19:18:42 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-10-04 19:18:42 - train.py[line:118] - INFO: task: VqaGenTask
2023-10-04 19:18:42 - train.py[line:119] - INFO: model: OFAModel
2023-10-04 19:18:42 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-10-04 19:18:42 - train.py[line:121] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-10-04 19:18:42 - train.py[line:128] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 0 row count 18702 total row count 149614file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 5 row count 18702 total row count 149614

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 2 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 4 row count 18702 total row count 149614file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 6 row count 18701 total row count 149614file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 3 row count 18702 total row count 149614


file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 7 row count 18701 total row count 149614
2023-10-04 19:18:43 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 1 row count 18702 total row count 149614
2023-10-04 19:18:43 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-10-04 19:18:43 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-10-04 19:18:43 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2023-10-04 19:18:43 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:18:43 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:18:43 - utils.py[line:761] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:18:43 - utils.py[line:761] - INFO: rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:18:43 - utils.py[line:761] - INFO: rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:18:43 - utils.py[line:761] - INFO: rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:18:43 - utils.py[line:761] - INFO: rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:18:43 - utils.py[line:761] - INFO: rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:18:43 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-10-04 19:18:45 - train.py[line:159] - INFO: training on 8 devices (GPUs/TPUs)
2023-10-04 19:18:45 - train.py[line:164] - INFO: max tokens per device = None and max sentences per device = 12
2023-10-04 19:18:45 - trainer.py[line:499] - INFO: Preparing to load checkpoint ../../SGG_0909_OFA_base.pt
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-10-04 19:18:48 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-10-04 19:18:49 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:18:49 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:18:49 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:18:49 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:18:49 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:18:49 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:18:49 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:18:49 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:18:49 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-10-04 19:18:49 - trainer.py[line:313] - INFO: Exponential Moving Average Shadow Model is initialized.
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E0.tsv slice_id 7 row count 1170 total row count 9364
Total steps 882, warmup steps 44, warmup_factor 0.022727272727272728
2023-10-04 19:18:50 - trainer.py[line:672] - INFO: Loaded checkpoint ../../SGG_0909_OFA_base.pt (epoch 48 @ 0 updates)
2023-10-04 19:18:50 - trainer.py[line:694] - INFO: loading train data for epoch 1
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E0.tsv slice_id 0 row count 1171 total row count 9364
2023-10-04 19:18:50 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E0.tsv slice_id 2 row count 1171 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E0.tsv slice_id 4 row count 1170 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E0.tsv slice_id 5 row count 1170 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E0.tsv slice_id 3 row count 1171 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E0.tsv slice_id 1 row count 1171 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E0.tsv slice_id 6 row count 1170 total row count 9364
Total steps 882, warmup steps 44, warmup_factor 0.022727272727272728
2023-10-04 19:18:50 - trainer.py[line:758] - INFO: begin training epoch 1
2023-10-04 19:18:50 - train.py[line:312] - INFO: Start iterating over samples
Total steps 882, warmup steps 44, warmup_factor 0.022727272727272728
Total steps 882, warmup steps 44, warmup_factor 0.022727272727272728
Total steps 882, warmup steps 44, warmup_factor 0.022727272727272728
Total steps 882, warmup steps 44, warmup_factor 0.022727272727272728
Total steps 882, warmup steps 44, warmup_factor 0.022727272727272728
Total steps 882, warmup steps 44, warmup_factor 0.022727272727272728
2023-10-04 19:19:05 - progress_bar.py[line:272] - INFO: epoch 001:     10 / 98 loss=0.911, loss_v1=0, loss_v2=0, nll_loss=0.753, ntokens=265.9, nsentences=96, sample_size=265.9, sample_size_v1=0, sample_size_v2=0, ppl=1.69, wps=367.4, ups=1.38, wpb=265.9, bsz=96, num_updates=10, lr=1.13636e-05, gnorm=7.969, clip=100, loss_scale=128, train_wall=13, gb_free=6.6, ema_decay=0.9999, wall=22
2023-10-04 19:19:13 - progress_bar.py[line:272] - INFO: epoch 001:     20 / 98 loss=0.639, loss_v1=0, loss_v2=0, nll_loss=0.485, ntokens=264.7, nsentences=96, sample_size=264.7, sample_size_v1=0, sample_size_v2=0, ppl=1.4, wps=366.6, ups=1.39, wpb=264.7, bsz=96, num_updates=20, lr=2.27273e-05, gnorm=3.704, clip=100, loss_scale=128, train_wall=7, gb_free=6.6, ema_decay=0.9999, wall=29
2023-10-04 19:19:19 - progress_bar.py[line:272] - INFO: epoch 001:     30 / 98 loss=0.491, loss_v1=0, loss_v2=0, nll_loss=0.336, ntokens=265.1, nsentences=96, sample_size=265.1, sample_size_v1=0, sample_size_v2=0, ppl=1.26, wps=384.4, ups=1.45, wpb=265.1, bsz=96, num_updates=30, lr=3.40909e-05, gnorm=2.016, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=36
2023-10-04 19:19:26 - progress_bar.py[line:272] - INFO: epoch 001:     40 / 98 loss=0.447, loss_v1=0, loss_v2=0, nll_loss=0.267, ntokens=264, nsentences=96, sample_size=264, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=389.2, ups=1.47, wpb=264, bsz=96, num_updates=40, lr=4.54545e-05, gnorm=2.143, clip=100, loss_scale=128, train_wall=7, gb_free=6.6, ema_decay=0.9999, wall=43
2023-10-04 19:19:34 - progress_bar.py[line:272] - INFO: epoch 001:     50 / 98 loss=0.427, loss_v1=0, loss_v2=0, nll_loss=0.26, ntokens=265, nsentences=96, sample_size=265, sample_size_v1=0, sample_size_v2=0, ppl=1.2, wps=356.6, ups=1.35, wpb=265, bsz=96, num_updates=50, lr=4.9642e-05, gnorm=1.689, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=50
2023-10-04 19:19:40 - progress_bar.py[line:272] - INFO: epoch 001:     60 / 98 loss=0.371, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=264.4, nsentences=96, sample_size=264.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=389.5, ups=1.47, wpb=264.4, bsz=96, num_updates=60, lr=4.90453e-05, gnorm=1.234, clip=80, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=57
2023-10-04 19:19:47 - progress_bar.py[line:272] - INFO: epoch 001:     70 / 98 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.187, ntokens=264.1, nsentences=96, sample_size=264.1, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=392.9, ups=1.49, wpb=264.1, bsz=96, num_updates=70, lr=4.84487e-05, gnorm=1.153, clip=80, loss_scale=128, train_wall=7, gb_free=6.6, ema_decay=0.9999, wall=64
2023-10-04 19:19:54 - progress_bar.py[line:272] - INFO: epoch 001:     80 / 98 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.177, ntokens=267.5, nsentences=96, sample_size=267.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=402.5, ups=1.5, wpb=267.5, bsz=96, num_updates=80, lr=4.7852e-05, gnorm=1.102, clip=70, loss_scale=128, train_wall=7, gb_free=6.7, ema_decay=0.9999, wall=70
2023-10-04 19:20:01 - progress_bar.py[line:272] - INFO: epoch 001:     90 / 98 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.171, ntokens=263.7, nsentences=96, sample_size=263.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=379.9, ups=1.44, wpb=263.7, bsz=96, num_updates=90, lr=4.72554e-05, gnorm=1.124, clip=80, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=77
2023-10-04 19:20:06 - train.py[line:339] - INFO: end of epoch 1 (average epoch stats below)
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E1.tsv slice_id 4 row count 1170 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E1.tsv slice_id 6 row count 1170 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E1.tsv slice_id 5 row count 1170 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E1.tsv slice_id 2 row count 1171 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E1.tsv slice_id 1 row count 1171 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E1.tsv slice_id 3 row count 1171 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E1.tsv slice_id 7 row count 1170 total row count 9364
2023-10-04 19:20:06 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.473 | loss_v1 0 | loss_v2 0 | nll_loss 0.303 | ntokens 263.52 | nsentences 95.551 | sample_size 263.52 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.23 | wps 380.5 | ups 1.44 | wpb 263.5 | bsz 95.6 | num_updates 98 | lr 4.6778e-05 | gnorm 2.357 | clip 88.8 | loss_scale 128 | train_wall 73 | gb_free 12 | ema_decay 0.9999 | wall 83
2023-10-04 19:20:06 - trainer.py[line:694] - INFO: loading train data for epoch 2
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E1.tsv slice_id 0 row count 1171 total row count 9364
2023-10-04 19:20:06 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-04 19:20:06 - trainer.py[line:758] - INFO: begin training epoch 2
2023-10-04 19:20:06 - train.py[line:312] - INFO: Start iterating over samples
2023-10-04 19:20:11 - progress_bar.py[line:272] - INFO: epoch 002:      2 / 98 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=250.6, nsentences=91.6, sample_size=250.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=243.6, ups=0.97, wpb=250.6, bsz=91.6, num_updates=100, lr=4.66587e-05, gnorm=1.157, clip=70, loss_scale=128, train_wall=8, gb_free=6.8, ema_decay=0.9999, wall=88
2023-10-04 19:20:18 - progress_bar.py[line:272] - INFO: epoch 002:     12 / 98 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=263.6, nsentences=96, sample_size=263.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=397.2, ups=1.51, wpb=263.6, bsz=96, num_updates=110, lr=4.60621e-05, gnorm=0.931, clip=40, loss_scale=128, train_wall=7, gb_free=6.8, ema_decay=0.9999, wall=94
2023-10-04 19:20:24 - progress_bar.py[line:272] - INFO: epoch 002:     22 / 98 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=264.4, nsentences=96, sample_size=264.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=394.2, ups=1.49, wpb=264.4, bsz=96, num_updates=120, lr=4.54654e-05, gnorm=1.063, clip=60, loss_scale=128, train_wall=7, gb_free=6.7, ema_decay=0.9999, wall=101
2023-10-04 19:20:32 - progress_bar.py[line:272] - INFO: epoch 002:     32 / 98 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=265.7, nsentences=96, sample_size=265.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=371, ups=1.4, wpb=265.7, bsz=96, num_updates=130, lr=4.48687e-05, gnorm=1.195, clip=80, loss_scale=128, train_wall=7, gb_free=6.7, ema_decay=0.9999, wall=108
2023-10-04 19:20:39 - progress_bar.py[line:272] - INFO: epoch 002:     42 / 98 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=266.1, nsentences=96, sample_size=266.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=363.8, ups=1.37, wpb=266.1, bsz=96, num_updates=140, lr=4.42721e-05, gnorm=0.925, clip=50, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=115
2023-10-04 19:20:46 - progress_bar.py[line:272] - INFO: epoch 002:     52 / 98 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=264.7, nsentences=96, sample_size=264.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=397.2, ups=1.5, wpb=264.7, bsz=96, num_updates=150, lr=4.36754e-05, gnorm=1.167, clip=80, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=122
2023-10-04 19:20:52 - progress_bar.py[line:272] - INFO: epoch 002:     62 / 98 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.114, ntokens=265.1, nsentences=96, sample_size=265.1, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=390.5, ups=1.47, wpb=265.1, bsz=96, num_updates=160, lr=4.30788e-05, gnorm=0.922, clip=40, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=129
2023-10-04 19:20:59 - progress_bar.py[line:272] - INFO: epoch 002:     72 / 98 loss=0.313, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=264.3, nsentences=96, sample_size=264.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=389, ups=1.47, wpb=264.3, bsz=96, num_updates=170, lr=4.24821e-05, gnorm=0.904, clip=30, loss_scale=128, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=136
2023-10-04 19:21:06 - progress_bar.py[line:272] - INFO: epoch 002:     82 / 98 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=265.4, nsentences=96, sample_size=265.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=402.7, ups=1.52, wpb=265.4, bsz=96, num_updates=180, lr=4.18854e-05, gnorm=1.058, clip=50, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=142
2023-10-04 19:21:12 - progress_bar.py[line:272] - INFO: epoch 002:     92 / 98 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=264.3, nsentences=96, sample_size=264.3, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=396.5, ups=1.5, wpb=264.3, bsz=96, num_updates=190, lr=4.12888e-05, gnorm=1.055, clip=40, loss_scale=128, train_wall=7, gb_free=6.7, ema_decay=0.9999, wall=149
2023-10-04 19:21:16 - train.py[line:339] - INFO: end of epoch 2 (average epoch stats below)
2023-10-04 19:21:16 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.311 | loss_v1 0 | loss_v2 0 | nll_loss 0.129 | ntokens 263.52 | nsentences 95.551 | sample_size 263.52 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.09 | wps 367.8 | ups 1.4 | wpb 263.5 | bsz 95.6 | num_updates 196 | lr 4.09308e-05 | gnorm 1.035 | clip 52 | loss_scale 128 | train_wall 67 | gb_free 11.9 | ema_decay 0.9999 | wall 153
2023-10-04 19:21:16 - trainer.py[line:694] - INFO: loading train data for epoch 3
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E2.tsv slice_id 4 row count 1170 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E2.tsv slice_id 6 row count 1170 total row count 9364file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E2.tsv slice_id 5 row count 1170 total row count 9364

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E2.tsv slice_id 3 row count 1171 total row count 9364file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E2.tsv slice_id 2 row count 1171 total row count 9364

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E2.tsv slice_id 1 row count 1171 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E2.tsv slice_id 7 row count 1170 total row count 9364
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_opt_train_NA1_E2.tsv slice_id 0 row count 1171 total row count 9364
2023-10-04 19:21:16 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-04 19:21:17 - trainer.py[line:758] - INFO: begin training epoch 3
2023-10-04 19:21:17 - train.py[line:312] - INFO: Start iterating over samples
2023-10-04 19:21:22 - progress_bar.py[line:272] - INFO: epoch 003:      4 / 98 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.11, ntokens=252.8, nsentences=91.6, sample_size=252.8, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=251.4, ups=0.99, wpb=252.8, bsz=91.6, num_updates=200, lr=4.06921e-05, gnorm=1.054, clip=40, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=159
2023-10-04 19:21:22 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 19:21:22 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-04 19:21:24 - train.py[line:549] - INFO: 0 / 1871
2023-10-04 19:21:24 - train.py[line:550] - INFO: load:1.50 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 19:21:28 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.68 GiB (GPU 0; 23.70 GiB total capacity; 7.14 GiB already allocated; 3.25 GiB free; 19.06 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-04 19:21:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 6         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7307 MiB |  10920 MiB |  19104 GiB |  19097 GiB |
|       from large pool |   7163 MiB |  10776 MiB |  19058 GiB |  19051 GiB |
|       from small pool |    144 MiB |    145 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7307 MiB |  10920 MiB |  19104 GiB |  19097 GiB |
|       from large pool |   7163 MiB |  10776 MiB |  19058 GiB |  19051 GiB |
|       from small pool |    144 MiB |    145 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7255 MiB |  10868 MiB |  19050 GiB |  19043 GiB |
|       from large pool |   7111 MiB |  10723 MiB |  19003 GiB |  18996 GiB |
|       from small pool |    144 MiB |    145 MiB |     46 GiB |     46 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  19518 MiB |  21548 MiB |  62334 MiB |  42816 MiB |
|       from large pool |  19372 MiB |  21306 MiB |  61904 MiB |  42532 MiB |
|       from small pool |    146 MiB |    242 MiB |    430 MiB |    284 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  12210 MiB |  12210 MiB |  15844 GiB |  15832 GiB |
|       from large pool |  12208 MiB |  12208 MiB |  15795 GiB |  15783 GiB |
|       from small pool |      1 MiB |      2 MiB |     49 GiB |     49 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    3578    |    3593    |    1025 K  |    1021 K  |
|       from large pool |     565    |     577    |     532 K  |     531 K  |
|       from small pool |    3013    |    3023    |     492 K  |     489 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3578    |    3593    |    1025 K  |    1021 K  |
|       from large pool |     565    |     577    |     532 K  |     531 K  |
|       from small pool |    3013    |    3023    |     492 K  |     489 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     171    |     227    |     425    |     254    |
|       from large pool |      98    |     106    |     210    |     112    |
|       from small pool |      73    |     121    |     215    |     142    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     113    |     118    |  531480    |  531367    |
|       from large pool |      86    |      87    |  296692    |  296606    |
|       from small pool |      27    |      36    |  234788    |  234761    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:28 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-04 19:21:33 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.81 GiB (GPU 1; 23.70 GiB total capacity; 7.22 GiB already allocated; 3.80 GiB free; 18.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-04 19:21:33 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:33 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 5         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7389 MiB |  11219 MiB |  19547 GiB |  19539 GiB |
|       from large pool |   7245 MiB |  11074 MiB |  19499 GiB |  19492 GiB |
|       from small pool |    144 MiB |    145 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7389 MiB |  11219 MiB |  19547 GiB |  19539 GiB |
|       from large pool |   7245 MiB |  11074 MiB |  19499 GiB |  19492 GiB |
|       from small pool |    144 MiB |    145 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7338 MiB |  11168 MiB |  19499 GiB |  19492 GiB |
|       from large pool |   7194 MiB |  11024 MiB |  19451 GiB |  19444 GiB |
|       from small pool |    144 MiB |    145 MiB |     47 GiB |     47 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  18962 MiB |  22824 MiB |  46534 MiB |  27572 MiB |
|       from large pool |  18816 MiB |  22676 MiB |  46240 MiB |  27424 MiB |
|       from small pool |    146 MiB |    242 MiB |    294 MiB |    148 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  11572 MiB |  12755 MiB |  17563 GiB |  17551 GiB |
|       from large pool |  11570 MiB |  12754 MiB |  17511 GiB |  17500 GiB |
|       from small pool |      1 MiB |      2 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    3578    |    3593    |    1049 K  |    1045 K  |
|       from large pool |     565    |     577    |     542 K  |     541 K  |
|       from small pool |    3013    |    3023    |     507 K  |     504 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3578    |    3593    |    1049 K  |    1045 K  |
|       from large pool |     565    |     577    |     542 K  |     541 K  |
|       from small pool |    3013    |    3023    |     507 K  |     504 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     176    |     234    |     310    |     134    |
|       from large pool |     103    |     113    |     163    |      60    |
|       from small pool |      73    |     121    |     147    |      74    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     107    |     120    |  530091    |  529984    |
|       from large pool |      83    |      87    |  284815    |  284732    |
|       from small pool |      24    |      39    |  245276    |  245252    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:33 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:33 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:33 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:33 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:33 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:33 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:33 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-04 19:21:44 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 4.23 GiB (GPU 5; 23.70 GiB total capacity; 7.46 GiB already allocated; 3.66 GiB free; 18.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-04 19:21:44 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:44 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:44 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:44 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:44 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:44 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 4         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   7643 MiB |  11903 MiB |  20872 GiB |  20865 GiB |
|       from large pool |   7498 MiB |  11758 MiB |  20821 GiB |  20814 GiB |
|       from small pool |    144 MiB |    145 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   7643 MiB |  11903 MiB |  20872 GiB |  20865 GiB |
|       from large pool |   7498 MiB |  11758 MiB |  20821 GiB |  20814 GiB |
|       from small pool |    144 MiB |    145 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   7586 MiB |  11846 MiB |  20817 GiB |  20810 GiB |
|       from large pool |   7442 MiB |  11701 MiB |  20766 GiB |  20759 GiB |
|       from small pool |    144 MiB |    145 MiB |     51 GiB |     51 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  19106 MiB |  21252 MiB |  44220 MiB |  25114 MiB |
|       from large pool |  18960 MiB |  21104 MiB |  43928 MiB |  24968 MiB |
|       from small pool |    146 MiB |    242 MiB |    292 MiB |    146 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  11462 MiB |  11462 MiB |  18154 GiB |  18143 GiB |
|       from large pool |  11461 MiB |  11461 MiB |  18099 GiB |  18088 GiB |
|       from small pool |      1 MiB |      2 MiB |     54 GiB |     54 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    3578    |    3593    |    1116 K  |    1113 K  |
|       from large pool |     565    |     577    |     568 K  |     568 K  |
|       from small pool |    3013    |    3023    |     547 K  |     544 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3578    |    3593    |    1116 K  |    1113 K  |
|       from large pool |     565    |     577    |     568 K  |     568 K  |
|       from small pool |    3013    |    3023    |     547 K  |     544 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     176    |     237    |     318    |     142    |
|       from large pool |     103    |     116    |     172    |      69    |
|       from small pool |      73    |     121    |     146    |      73    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     108    |     117    |  576457    |  576349    |
|       from large pool |      84    |      85    |  300611    |  300527    |
|       from small pool |      24    |      36    |  275846    |  275822    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:44 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:44 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:21:44 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    Traceback (most recent call last):
valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
  File "../../train.py", line 636, in <module>
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22892 closing signal SIGINT
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
Traceback (most recent call last):
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22893 closing signal SIGINT
  File "../../train.py", line 636, in <module>
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22894 closing signal SIGINT
    WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22895 closing signal SIGINT
_loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 272, in valid_step
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22896 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22897 closing signal SIGINT
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22898 closing signal SIGINT
    decoder_out = eval_model.decoder(valid_prev_output, encoder_out=new_encoder_out)
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22901 closing signal SIGINT
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
  File "../../train.py", line 629, in cli_main
  File "../../train.py", line 629, in cli_main
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1343, in forward
Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    x, extra = self.extract_features(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1367, in extract_features
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    return func(*args, **kwds)
  File "../../train.py", line 331, in train

            valid_losses, should_stop = validate_and_save(distributed_utils.call_main(cfg, main)return self.extract_features_scriptable(


  File "../../train.py", line 418, in validate_and_save
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1532, in extract_features_scriptable
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
    x, layer_attn, _ = layer(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)    
_loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 272, in valid_step
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
    decoder_out = eval_model.decoder(valid_prev_output, encoder_out=new_encoder_out)  File "../../train.py", line 206, in main

  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer_layer.py", line 501, in forward
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
    return forward_call(*args, **kwargs)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1343, in forward
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    x, extra = self.extract_features(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1367, in extract_features
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return self.extract_features_scriptable(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1491, in extract_features_scriptable
    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    if self.cross_self_attention or prev_output_tokens.eq(self.padding_idx).any():
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
  File "../../train.py", line 629, in cli_main
        valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)valid_losses, should_stop = validate_and_save(

  File "../../train.py", line 556, in validate
  File "../../train.py", line 418, in validate_and_save
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
    return func(*args, **kwds)  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main

  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
    main(cfg, **kwargs)    
logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)  File "../../train.py", line 206, in main

  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
KeyboardInterrupt
    _loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 272, in valid_step
    decoder_out = eval_model.decoder(valid_prev_output, encoder_out=new_encoder_out)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    _loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 272, in valid_step
    decoder_out = eval_model.decoder(valid_prev_output, encoder_out=new_encoder_out)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
Traceback (most recent call last):
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 272, in valid_step
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1343, in forward
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1343, in forward
    decoder_out = eval_model.decoder(valid_prev_output, encoder_out=new_encoder_out)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    x, extra = self.extract_features(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1367, in extract_features
    x, extra = self.extract_features(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1367, in extract_features
    return self.extract_features_scriptable(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1532, in extract_features_scriptable
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1343, in forward
    return self.extract_features_scriptable(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1465, in extract_features_scriptable
    x, extra = self.extract_features(
      File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1367, in extract_features
x, layer_attn, _ = layer(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return self.extract_features_scriptable(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1491, in extract_features_scriptable
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer_layer.py", line 501, in forward
    x = self.embed_scale * self.embed_tokens(prev_output_tokens)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    if self.cross_self_attention or prev_output_tokens.eq(self.padding_idx).any():
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    cli_main()
      File "../../train.py", line 629, in cli_main
return forward_call(*args, **kwargs)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/sparse.py", line 162, in forward
    return F.embedding(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/functional.py", line 2210, in embedding
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
KeyboardInterrupt
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
Traceback (most recent call last):
  File "../../train.py", line 636, in <module>
    _loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 272, in valid_step
    decoder_out = eval_model.decoder(valid_prev_output, encoder_out=new_encoder_out)
KeyboardInterrupt
    cli_main()
  File "../../train.py", line 629, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
    _loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 272, in valid_step
    decoder_out = eval_model.decoder(valid_prev_output, encoder_out=new_encoder_out)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1343, in forward
    x, extra = self.extract_features(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1367, in extract_features
    return self.extract_features_scriptable(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1491, in extract_features_scriptable
    if self.cross_self_attention or prev_output_tokens.eq(self.padding_idx).any():
KeyboardInterrupt
    x, attn = self.self_attn(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_multihead_attention.py", line 367, in forward
    attn_weights = attn_weights.masked_fill(
KeyboardInterrupt
    x, attn = self.self_attn(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_multihead_attention.py", line 214, in forward
    q = self.q_proj(query)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
  File "../../train.py", line 629, in cli_main
Exception in thread Thread-8:
Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    return forward_call(*args, **kwargs)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
        self.run()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
distributed_utils.call_main(cfg, main)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 377, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/data/cminus/fairseq/fairseq/distributed/utils.py", line 350, in distributed_main
    main(cfg, **kwargs)
  File "../../train.py", line 206, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "../../train.py", line 331, in train
    valid_losses, should_stop = validate_and_save(
  File "../../train.py", line 418, in validate_and_save
    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)
  File "../../train.py", line 556, in validate
    logging_output, logits, sample_ids, time_info = trainer.valid_step(sample)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/contextlib.py", line 75, in inner
    return func(*args, **kwds)
  File "/data/cminus/ofa/trainer.py", line 1154, in valid_step
    _loss, sample_size, logging_output, cal_sgg_metric, vs_time_cost_info = self.task.valid_step(
  File "/data/cminus/ofa/tasks/mm_tasks/vqa_gen.py", line 272, in valid_step
    decoder_out = eval_model.decoder(valid_prev_output, encoder_out=new_encoder_out)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1343, in forward
    x, extra = self.extract_features(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1367, in extract_features
    return self.extract_features_scriptable(
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1446, in extract_features_scriptable
    self_abs_pos_bias = self.get_pos_info(prev_output_tokens, tgt_pos_embed, use_image=False)
  File "/data/cminus/ofa/models/ofa/unify_transformer.py", line 1302, in get_pos_info
    pos_q = self.self_pos_q_linear(tgt_pos_embed).view(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/connection.py", line 629, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
Exception in thread Thread-8:
Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/connection.py", line 502, in Client
    c = SocketClient(address)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/connection.py", line 629, in SocketClient
    s.connect(address)
FileNotFoundError: [Errno 2] No such file or directory
Exception in thread Thread-8:
Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 51, in _pin_memory_loop
    do_one_step()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/queues.py", line 116, in get
    return _ForkingPickler.loads(res)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/resource_sharer.py", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/connection.py", line 509, in Client
    deliver_challenge(c, authkey)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/connection.py", line 739, in deliver_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22892 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22893 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22894 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22895 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22896 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22897 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22898 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 22901 closing signal SIGTERM
Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 723, in run
    result = self._invoke_run(role)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    time.sleep(monitor_interval)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 22815 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 730, in run
    self._shutdown(e.sigval)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 289, in _shutdown
    self._pcontext.close(death_sig)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 331, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 708, in _close
    handler.proc.wait(time_to_wait)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/subprocess.py", line 1079, in wait
    return self._wait(timeout=timeout)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/subprocess.py", line 1798, in _wait
    time.sleep(delay)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 22815 got signal: 2

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 192, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 196, in <module>
    main()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 192, in main
    launch(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py", line 177, in launch
    run(args)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 241, in launch_agent
    result = agent.run()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/api.py", line 735, in run
    self._shutdown()
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py", line 289, in _shutdown
    self._pcontext.close(death_sig)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 331, in close
    self._close(death_sig=death_sig, timeout=timeout)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 708, in _close
    handler.proc.wait(time_to_wait)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/subprocess.py", line 1079, in wait
    return self._wait(timeout=timeout)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/subprocess.py", line 1798, in _wait
    time.sleep(delay)
  File "/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 22815 got signal: 2
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
2023-10-04 19:22:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmph4047rhx
2023-10-04 19:22:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmph4047rhx/_remote_module_non_scriptable.py
2023-10-04 19:22:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp5hv86vf6
2023-10-04 19:22:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmp5hv86vf6/_remote_module_non_scriptable.py
2023-10-04 19:22:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpliy8nmyz
2023-10-04 19:22:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmpliy8nmyz/_remote_module_non_scriptable.py
2023-10-04 19:22:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpkyrnijn8
2023-10-04 19:22:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmpkyrnijn8/_remote_module_non_scriptable.py
2023-10-04 19:22:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpjhvnz3cs
2023-10-04 19:22:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmpjhvnz3cs/_remote_module_non_scriptable.py
2023-10-04 19:22:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmp4xlf2siy
2023-10-04 19:22:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmp4xlf2siy/_remote_module_non_scriptable.py
2023-10-04 19:22:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpasmmzbqu
2023-10-04 19:22:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmpasmmzbqu/_remote_module_non_scriptable.py
2023-10-04 19:22:45 - instantiator.py[line:21] - INFO: Created a temporary directory at /tmp/tmpqhp3otfx
2023-10-04 19:22:45 - instantiator.py[line:76] - INFO: Writing /tmp/tmpqhp3otfx/_remote_module_non_scriptable.py
3
qwqwqwqw 3
2023-10-04 19:22:47 - utils.py[line:256] - INFO: distributed init (rank 3): env://
2023-10-04 19:22:47 - utils.py[line:262] - INFO: Start init
2023-10-04 19:22:47 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 3
5
qwqwqwqw 5
2023-10-04 19:22:47 - utils.py[line:256] - INFO: distributed init (rank 5): env://
2023-10-04 19:22:47 - utils.py[line:262] - INFO: Start init
2023-10-04 19:22:47 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 5
7
qwqwqwqw 7
2023-10-04 19:22:47 - utils.py[line:256] - INFO: distributed init (rank 7): env://
2023-10-04 19:22:47 - utils.py[line:262] - INFO: Start init
2023-10-04 19:22:47 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 7
1
qwqwqwqw 1
2023-10-04 19:22:47 - utils.py[line:256] - INFO: distributed init (rank 1): env://
2023-10-04 19:22:47 - utils.py[line:262] - INFO: Start init
2023-10-04 19:22:47 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
0
qwqwqwqw 0
4
qwqwqwqw 4
2023-10-04 19:22:47 - utils.py[line:256] - INFO: distributed init (rank 0): env://
2023-10-04 19:22:47 - utils.py[line:262] - INFO: Start init
2023-10-04 19:22:47 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2023-10-04 19:22:47 - utils.py[line:256] - INFO: distributed init (rank 4): env://
2023-10-04 19:22:47 - utils.py[line:262] - INFO: Start init
2023-10-04 19:22:47 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 4
2
qwqwqwqw 2
6
qwqwqwqw 6
2023-10-04 19:22:47 - utils.py[line:256] - INFO: distributed init (rank 2): env://
2023-10-04 19:22:47 - utils.py[line:262] - INFO: Start init
2023-10-04 19:22:47 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 2
2023-10-04 19:22:47 - utils.py[line:256] - INFO: distributed init (rank 6): env://
2023-10-04 19:22:47 - utils.py[line:262] - INFO: Start init
2023-10-04 19:22:47 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:1 to store for rank: 6
2023-10-04 19:22:47 - distributed_c10d.py[line:476] - INFO: Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:22:47 - utils.py[line:272] - INFO: initialized host root as rank 6
single-machine distributed training is initialized.
2023-10-04 19:22:47 - distributed_c10d.py[line:476] - INFO: Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:22:47 - utils.py[line:272] - INFO: initialized host root as rank 1
single-machine distributed training is initialized.
2023-10-04 19:22:47 - distributed_c10d.py[line:476] - INFO: Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:22:47 - utils.py[line:272] - INFO: initialized host root as rank 7
single-machine distributed training is initialized.
2023-10-04 19:22:47 - distributed_c10d.py[line:476] - INFO: Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:22:47 - utils.py[line:272] - INFO: initialized host root as rank 3
single-machine distributed training is initialized.
2023-10-04 19:22:47 - distributed_c10d.py[line:476] - INFO: Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:22:47 - utils.py[line:272] - INFO: initialized host root as rank 4
single-machine distributed training is initialized.
2023-10-04 19:22:47 - distributed_c10d.py[line:476] - INFO: Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:22:47 - utils.py[line:272] - INFO: initialized host root as rank 5
single-machine distributed training is initialized.
2023-10-04 19:22:47 - distributed_c10d.py[line:476] - INFO: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:22:47 - utils.py[line:272] - INFO: initialized host root as rank 2
single-machine distributed training is initialized.
2023-10-04 19:22:47 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 8 nodes.
2023-10-04 19:22:47 - utils.py[line:272] - INFO: initialized host root as rank 0
single-machine distributed training is initialized.
2023-10-04 19:22:49 - train.py[line:84] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': './../../vqa_tensorboard/20_way_caption_five_filtered', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 12, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 10, 'validate_interval_updates': 200, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 8, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 9, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [5e-05], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': './../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480', 'restore_file': '../../SGG_0909_OFA_base.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 10, 'save_interval_updates': 200, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'R@100', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_base', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_object=True, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, ans2label_dict='{"no": 0, "yes":1}', ans2label_file='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', arch='ofa_base', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=12, batch_size_valid='8', best_checkpoint_metric='R@100', bf16=False, bitfit=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='adjust_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=12, decoder_drop_path_rate=0.1, decoder_embed_dim=768, decoder_embed_path=None, decoder_ffn_embed_dim=3072, decoder_input_dim=768, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=768, device_id='0', disable_entangle=True, disable_validation=False, distill='default', distill_alpha=1.0, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=8, distributed_port=-1, distributed_rank=0, distributed_world_size=8, drop_worst_after=0, drop_worst_ratio=0.0, dropout=0.1, ema_decay=0.9999, ema_fp32=True, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_drop_path_rate=0.1, encoder_embed_dim=768, encoder_embed_path=None, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=0.0, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"unnormalized":true,"temperature":1.0}', fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_eos=False, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_proxy='answer', label_smoothing=0.1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-05], lr_scheduler='polynomial_decay', max_epoch=9, max_object_length=30, max_source_positions=1024, max_src_length=128, max_target_positions=1024, max_tgt_length=30, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=8, num_bins=1000, num_shards=1, num_workers=8, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', orig_patch_image_size=256, pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, prompt_type='prev_output', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, reg_alpha=1.0, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet101', restore_file='../../SGG_0909_OFA_base.pt', sample_patch_num=196, save_dir='./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480', save_interval=10, save_interval_updates=200, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', seed=1, selected_cols='0,5,2,3,4', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=True, suppress_crashes=False, sync_bn=False, task='vqa_gen', tensorboard_logdir='./../../vqa_tensorboard/20_way_caption_five_filtered', threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[1], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_rdrop=False, use_sharded_state=False, user_dir='../../ofa_module', uses_ema=True, val_inference_type='allcand', valid_batch_size=51, valid_subset='valid', validate_after_updates=0, validate_interval=10, validate_interval_updates=200, wandb_project=None, warmup_ratio=0.05, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'vqa_gen', 'data': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E10.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E11.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E12.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E13.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E14.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E15.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E16.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E17.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E18.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E19.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E20.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E21.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E22.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E23.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E24.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E25.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E26.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E27.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E28.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E29.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E30.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E31.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E32.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E33.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E34.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E35.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E36.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E37.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E38.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E39.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E40.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E41.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E42.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E43.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E44.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E45.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E46.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E47.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E48.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E49.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E50.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E51.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E52.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E53.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E54.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E55.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E56.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E57.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E58.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E59.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E60.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E61.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E62.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E63.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E64.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E65.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E66.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E67.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E68.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E69.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E70.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E71.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E72.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E73.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E74.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E75.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E76.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E77.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E78.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E79.tsv,/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv', 'selected_cols': '0,5,2,3,4', 'bpe': None, 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'max_object_length': 30, 'ans2label_dict': '{"no": 0, "yes":1}', 'ans2label_file': '/data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/20_way_ans2label.pkl', 'add_object': True, 'valid_batch_size': 51, 'prompt_type': 'prev_output', 'uses_ema': True, 'val_inference_type': 'allcand', 'eval_args': '{"beam":5,"unnormalized":true,"temperature":1.0}', 'label_proxy': 'answer', 'distill': 'default', 'distill_alpha': 1.0}, 'criterion': {'_name': 'adjust_label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'ignore_eos': False, 'sentence_avg': False, 'drop_worst_ratio': 0.0, 'drop_worst_after': 0, 'use_rdrop': False, 'reg_alpha': 1.0, 'sample_patch_num': 196, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.05, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': True, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': True}}
2023-10-04 19:22:50 - ofa_task.py[line:111] - INFO: source dictionary: 59457 types
2023-10-04 19:22:50 - ofa_task.py[line:112] - INFO: target dictionary: 59457 types
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/data/cminus/anaconda3/envs/OFA/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-10-04 19:22:53 - train.py[line:117] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (encoder_dropout): Dropout(p=0.2, inplace=False)
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 768)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=768, bias=True)
    (patch_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 768, padding_idx=1)
    (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 768)
    (embed_image_positions): Embedding(1765, 768)
    (pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (self_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_q_linear): Linear(in_features=768, out_features=768, bias=True)
    (cross_pos_k_linear): Linear(in_features=768, out_features=768, bias=True)
    (code_layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.019999999552965164)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.03999999910593033)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.06000000238418579)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.07999999821186066)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (self_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath(p=0.10000000149011612)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=768, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(511, 12)
    )
    (image_rel_pos_table_list): ModuleList(
      (0-5): 6 x Embedding(6892, 12)
    )
  )
  (classification_heads): ModuleDict()
)
2023-10-04 19:22:53 - train.py[line:118] - INFO: task: VqaGenTask
2023-10-04 19:22:53 - train.py[line:119] - INFO: model: OFAModel
2023-10-04 19:22:53 - train.py[line:120] - INFO: criterion: AdjustLabelSmoothedCrossEntropyCriterion
2023-10-04 19:22:53 - train.py[line:121] - INFO: num. shared model params: 182,238,536 (num. trained: 136,575,560)
2023-10-04 19:22:53 - train.py[line:128] - INFO: num. expert model params: 0 (num. trained: 0)
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 4 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 3 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 2 row count 18702 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 0 row count 18702 total row count 149614file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 5 row count 18702 total row count 149614

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 7 row count 18701 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 6 row count 18701 total row count 149614
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_val_500.tsv slice_id 1 row count 18702 total row count 149614
2023-10-04 19:22:53 - distributed_c10d.py[line:442] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2023-10-04 19:22:54 - distributed_c10d.py[line:476] - INFO: Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2023-10-04 19:22:54 - trainer.py[line:125] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2023-10-04 19:22:54 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 8 workers***********************
2023-10-04 19:22:54 - utils.py[line:761] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:22:54 - utils.py[line:761] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:22:54 - utils.py[line:761] - INFO: rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:22:54 - utils.py[line:761] - INFO: rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:22:54 - utils.py[line:761] - INFO: rank   4: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:22:54 - utils.py[line:761] - INFO: rank   5: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:22:54 - utils.py[line:761] - INFO: rank   6: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:22:54 - utils.py[line:761] - INFO: rank   7: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-10-04 19:22:54 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 8 workers***********************
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
Done 0.95 cuda cpu, cpu
2023-10-04 19:22:55 - train.py[line:159] - INFO: training on 8 devices (GPUs/TPUs)
2023-10-04 19:22:55 - train.py[line:164] - INFO: max tokens per device = None and max sentences per device = 12
2023-10-04 19:22:55 - trainer.py[line:499] - INFO: Preparing to load checkpoint ../../SGG_0909_OFA_base.pt
2023-10-04 19:22:59 - trainer.py[line:564] - INFO: Load Model_m together with Model 2
2023-10-04 19:22:59 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:23:00 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:23:00 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:23:00 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:23:00 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:23:00 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:23:00 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:23:00 - trainer.py[line:644] - WARNING: EMA not found in checkpoint. But store_ema is True. EMA is re-initialized from checkpoint.
2023-10-04 19:23:00 - ema.py[line:85] - INFO: Copying EMA model to device cuda
2023-10-04 19:23:00 - trainer.py[line:313] - INFO: Exponential Moving Average Shadow Model is initialized.
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 6 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 2 row count 10874 total row count 86994
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 4 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 1 row count 10875 total row count 86994
2023-10-04 19:23:01 - trainer.py[line:672] - INFO: Loaded checkpoint ../../SGG_0909_OFA_base.pt (epoch 48 @ 0 updates)
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 7 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 3 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 5 row count 10874 total row count 86994
2023-10-04 19:23:01 - trainer.py[line:694] - INFO: loading train data for epoch 1
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E0.tsv slice_id 0 row count 10875 total row count 86994
2023-10-04 19:23:01 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
2023-10-04 19:23:01 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
Total steps 8163, warmup steps 408, warmup_factor 0.0024509803921568627
2023-10-04 19:23:01 - trainer.py[line:758] - INFO: begin training epoch 1
2023-10-04 19:23:01 - train.py[line:312] - INFO: Start iterating over samples
2023-10-04 19:23:16 - progress_bar.py[line:272] - INFO: epoch 001:     10 / 907 loss=1.041, loss_v1=0, loss_v2=0, nll_loss=0.884, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.85, wps=347.6, ups=1.29, wpb=270, bsz=96, num_updates=10, lr=1.22549e-06, gnorm=10.509, clip=100, loss_scale=128, train_wall=13, gb_free=6.5, ema_decay=0.9999, wall=22
2023-10-04 19:23:23 - progress_bar.py[line:272] - INFO: epoch 001:     20 / 907 loss=0.949, loss_v1=0, loss_v2=0, nll_loss=0.802, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.74, wps=381, ups=1.41, wpb=269.9, bsz=96, num_updates=20, lr=2.45098e-06, gnorm=8.559, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=29
2023-10-04 19:23:31 - progress_bar.py[line:272] - INFO: epoch 001:     30 / 907 loss=0.789, loss_v1=0, loss_v2=0, nll_loss=0.661, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.58, wps=373.9, ups=1.39, wpb=269.9, bsz=96, num_updates=30, lr=3.67647e-06, gnorm=4.916, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37
2023-10-04 19:23:38 - progress_bar.py[line:272] - INFO: epoch 001:     40 / 907 loss=0.685, loss_v1=0, loss_v2=0, nll_loss=0.55, ntokens=271.4, nsentences=96, sample_size=271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.46, wps=383.5, ups=1.41, wpb=271.4, bsz=96, num_updates=40, lr=4.90196e-06, gnorm=3.5, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=44
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 19:23:45 - progress_bar.py[line:272] - INFO: epoch 001:     50 / 907 loss=0.605, loss_v1=0, loss_v2=0, nll_loss=0.467, ntokens=267.6, nsentences=96, sample_size=267.6, sample_size_v1=0, sample_size_v2=0, ppl=1.38, wps=387.6, ups=1.45, wpb=267.6, bsz=96, num_updates=50, lr=6.12745e-06, gnorm=2.511, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=51
2023-10-04 19:23:52 - progress_bar.py[line:272] - INFO: epoch 001:     60 / 907 loss=0.55, loss_v1=0, loss_v2=0, nll_loss=0.407, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.33, wps=385.3, ups=1.42, wpb=271.3, bsz=96, num_updates=60, lr=7.35294e-06, gnorm=2.295, clip=100, loss_scale=128, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=58
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 19:23:59 - progress_bar.py[line:272] - INFO: epoch 001:     70 / 907 loss=0.496, loss_v1=0, loss_v2=0, nll_loss=0.344, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.27, wps=388.7, ups=1.43, wpb=271.2, bsz=96, num_updates=70, lr=8.57843e-06, gnorm=2.08, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=65
2023-10-04 19:24:06 - progress_bar.py[line:272] - INFO: epoch 001:     80 / 907 loss=0.488, loss_v1=0, loss_v2=0, nll_loss=0.323, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.25, wps=396.2, ups=1.47, wpb=269.6, bsz=96, num_updates=80, lr=9.80392e-06, gnorm=2.259, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=72
2023-10-04 19:24:12 - progress_bar.py[line:272] - INFO: epoch 001:     90 / 907 loss=0.46, loss_v1=0, loss_v2=0, nll_loss=0.295, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.23, wps=398.4, ups=1.47, wpb=271.2, bsz=96, num_updates=90, lr=1.10294e-05, gnorm=2.073, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=78
2023-10-04 19:24:19 - progress_bar.py[line:272] - INFO: epoch 001:    100 / 907 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.282, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.22, wps=390.7, ups=1.45, wpb=269.9, bsz=96, num_updates=100, lr=1.22549e-05, gnorm=1.784, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=85
2023-10-04 19:24:26 - progress_bar.py[line:272] - INFO: epoch 001:    110 / 907 loss=0.443, loss_v1=0, loss_v2=0, nll_loss=0.275, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.21, wps=391.9, ups=1.46, wpb=268.5, bsz=96, num_updates=110, lr=1.34804e-05, gnorm=1.877, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=92
2023-10-04 19:24:33 - progress_bar.py[line:272] - INFO: epoch 001:    120 / 907 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.255, ntokens=268.8, nsentences=96, sample_size=268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=396.1, ups=1.47, wpb=268.8, bsz=96, num_updates=120, lr=1.47059e-05, gnorm=1.686, clip=100, loss_scale=128, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=99
2023-10-04 19:24:40 - progress_bar.py[line:272] - INFO: epoch 001:    130 / 907 loss=0.419, loss_v1=0, loss_v2=0, nll_loss=0.253, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.19, wps=403, ups=1.49, wpb=270.2, bsz=96, num_updates=130, lr=1.59314e-05, gnorm=1.649, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=106
2023-10-04 19:24:46 - progress_bar.py[line:272] - INFO: epoch 001:    140 / 907 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=393.8, ups=1.47, wpb=268.4, bsz=96, num_updates=140, lr=1.71569e-05, gnorm=1.793, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=112
2023-10-04 19:24:53 - progress_bar.py[line:272] - INFO: epoch 001:    150 / 907 loss=0.386, loss_v1=0, loss_v2=0, nll_loss=0.214, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=395.2, ups=1.46, wpb=270, bsz=96, num_updates=150, lr=1.83824e-05, gnorm=1.602, clip=90, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=119
2023-10-04 19:25:00 - progress_bar.py[line:272] - INFO: epoch 001:    160 / 907 loss=0.382, loss_v1=0, loss_v2=0, nll_loss=0.215, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=400.5, ups=1.49, wpb=269.3, bsz=96, num_updates=160, lr=1.96078e-05, gnorm=1.499, clip=100, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=126
2023-10-04 19:25:07 - progress_bar.py[line:272] - INFO: epoch 001:    170 / 907 loss=0.379, loss_v1=0, loss_v2=0, nll_loss=0.21, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=384.8, ups=1.43, wpb=270, bsz=96, num_updates=170, lr=2.08333e-05, gnorm=1.326, clip=100, loss_scale=128, train_wall=7, gb_free=5.9, ema_decay=0.9999, wall=133
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 19:25:14 - progress_bar.py[line:272] - INFO: epoch 001:    180 / 907 loss=0.372, loss_v1=0, loss_v2=0, nll_loss=0.201, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=391.2, ups=1.45, wpb=269.3, bsz=96, num_updates=180, lr=2.20588e-05, gnorm=1.357, clip=100, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=140
2023-10-04 19:25:21 - progress_bar.py[line:272] - INFO: epoch 001:    190 / 907 loss=0.377, loss_v1=0, loss_v2=0, nll_loss=0.211, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=402, ups=1.49, wpb=269.1, bsz=96, num_updates=190, lr=2.32843e-05, gnorm=1.415, clip=90, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=147
2023-10-04 19:25:27 - progress_bar.py[line:272] - INFO: epoch 001:    200 / 907 loss=0.365, loss_v1=0, loss_v2=0, nll_loss=0.192, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=403.6, ups=1.5, wpb=269.2, bsz=96, num_updates=200, lr=2.45098e-05, gnorm=1.196, clip=70, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=153
2023-10-04 19:25:27 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 19:25:27 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-04 19:25:30 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 19:25:30 - train.py[line:550] - INFO: load:2.16 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 19:27:09 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 19:27:09 - train.py[line:550] - INFO: load:2.23 valid_run:99.17 task_valid:94.03 collect_output:4.07
2023-10-04 19:28:45 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 19:28:45 - train.py[line:550] - INFO: load:2.28 valid_run:195.04 task_valid:184.83 collect_output:8.15
2023-10-04 19:30:20 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 19:30:20 - train.py[line:550] - INFO: load:2.35 valid_run:290.07 task_valid:272.59 collect_output:14.37
2023-10-04 19:31:55 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 19:31:55 - train.py[line:550] - INFO: load:2.42 valid_run:385.30 task_valid:361.61 collect_output:19.58
2023-10-04 19:33:31 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 19:33:31 - train.py[line:550] - INFO: load:2.49 valid_run:480.63 task_valid:450.79 collect_output:24.70
2023-10-04 19:35:07 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 19:35:07 - train.py[line:550] - INFO: load:2.58 valid_run:576.24 task_valid:539.44 collect_output:30.67
2023-10-04 19:36:41 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 19:36:41 - train.py[line:550] - INFO: load:2.65 valid_run:670.57 task_valid:628.66 collect_output:34.86
2023-10-04 19:38:17 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 19:38:17 - train.py[line:550] - INFO: load:2.73 valid_run:766.94 task_valid:719.79 collect_output:39.15
2023-10-04 19:39:53 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 19:39:53 - train.py[line:550] - INFO: load:2.83 valid_run:862.64 task_valid:809.45 collect_output:44.20
2023-10-04 19:41:29 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 19:41:29 - train.py[line:550] - INFO: load:2.92 valid_run:958.14 task_valid:899.91 collect_output:48.22
2023-10-04 19:43:04 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 19:43:04 - train.py[line:550] - INFO: load:3.01 valid_run:1052.99 task_valid:990.14 collect_output:51.83

====================================================================================================
SGG eval:     R @ 50: 0.1401;     R @ 100: 0.2215;     R @ 500: 0.3089;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0688;    mR @ 100: 0.1182;    mR @ 500: 0.1718;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1922) (says:0.0000) (sitting on:0.2211) (standing on:0.4725) (using:0.1000) (walking in:0.0000) (walking on:0.0270) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1401;     R @ 100: 0.2215;     R @ 500: 0.3089;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0688;    mR @ 100: 0.1182;    mR @ 500: 0.1718;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1922) (says:0.0000) (sitting on:0.2211) (standing on:0.4725) (using:0.1000) (walking in:0.0000) (walking on:0.0270) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1401;     R @ 100: 0.2215;     R @ 500: 0.3089;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0688;    mR @ 100: 0.1182;    mR @ 500: 0.1718;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1922) (says:0.0000) (sitting on:0.2211) (standing on:0.4725) (using:0.1000) (walking in:0.0000) (walking on:0.0270) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1401;     R @ 100: 0.2215;     R @ 500: 0.3089;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0688;    mR @ 100: 0.1182;    mR @ 500: 0.1718;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1922) (says:0.0000) (sitting on:0.2211) (standing on:0.4725) (using:0.1000) (walking in:0.0000) (walking on:0.0270) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1401;     R @ 100: 0.2215;     R @ 500: 0.3089;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0688;    mR @ 100: 0.1182;    mR @ 500: 0.1718;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1922) (says:0.0000) (sitting on:0.2211) (standing on:0.4725) (using:0.1000) (walking in:0.0000) (walking on:0.0270) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1401;     R @ 100: 0.2215;     R @ 500: 0.3089;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0688;    mR @ 100: 0.1182;    mR @ 500: 0.1718;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1922) (says:0.0000) (sitting on:0.2211) (standing on:0.4725) (using:0.1000) (walking in:0.0000) (walking on:0.0270) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1401;     R @ 100: 0.2215;     R @ 500: 0.3089;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0688;    mR @ 100: 0.1182;    mR @ 500: 0.1718;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1922) (says:0.0000) (sitting on:0.2211) (standing on:0.4725) (using:0.1000) (walking in:0.0000) (walking on:0.0270) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1401;     R @ 100: 0.2215;     R @ 500: 0.3089;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0688;    mR @ 100: 0.1182;    mR @ 500: 0.1718;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1922) (says:0.0000) (sitting on:0.2211) (standing on:0.4725) (using:0.1000) (walking in:0.0000) (walking on:0.0270) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 19:44:19 - train.py[line:487] - INFO: 0.2215
2023-10-04 19:44:19 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-04 19:44:19 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.276 | loss_v1 0 | loss_v2 0 | nll_loss 0.104 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.2215 | ppl 1.07 | vqa_score 0.161 | wps 397.6 | wpb 191.9 | bsz 64 | num_updates 200
2023-10-04 19:44:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 200 updates
2023-10-04 19:44:19 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_200.pt
2023-10-04 19:44:26 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_200.pt
2023-10-04 19:44:31 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_200.pt (epoch 1 @ 200 updates, score 0.2215) (writing took 11.602590408176184 seconds)
2023-10-04 19:44:38 - progress_bar.py[line:272] - INFO: epoch 001:    210 / 907 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=2.3, ups=0.01, wpb=268.7, bsz=96, num_updates=210, lr=2.57353e-05, gnorm=1.117, clip=60, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=1304
2023-10-04 19:44:45 - progress_bar.py[line:272] - INFO: epoch 001:    220 / 907 loss=0.374, loss_v1=0, loss_v2=0, nll_loss=0.208, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=387.1, ups=1.44, wpb=269.1, bsz=96, num_updates=220, lr=2.69608e-05, gnorm=1.216, clip=100, loss_scale=128, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=1311
2023-10-04 19:44:51 - progress_bar.py[line:272] - INFO: epoch 001:    230 / 907 loss=0.375, loss_v1=0, loss_v2=0, nll_loss=0.209, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.16, wps=401.3, ups=1.48, wpb=270.6, bsz=96, num_updates=230, lr=2.81863e-05, gnorm=1.338, clip=90, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=1318
2023-10-04 19:45:01 - progress_bar.py[line:272] - INFO: epoch 001:    240 / 907 loss=0.368, loss_v1=0, loss_v2=0, nll_loss=0.198, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.15, wps=396.9, ups=1.48, wpb=268.5, bsz=96, num_updates=240, lr=2.94118e-05, gnorm=1.191, clip=80, loss_scale=128, train_wall=7, gb_free=6.6, ema_decay=0.9999, wall=1324
2023-10-04 19:45:08 - progress_bar.py[line:272] - INFO: epoch 001:    250 / 907 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=271.7, nsentences=96, sample_size=271.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=403, ups=1.48, wpb=271.7, bsz=96, num_updates=250, lr=3.06373e-05, gnorm=1.12, clip=80, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=1334
2023-10-04 19:45:15 - progress_bar.py[line:272] - INFO: epoch 001:    260 / 907 loss=0.354, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=397.9, ups=1.48, wpb=268.9, bsz=96, num_updates=260, lr=3.18627e-05, gnorm=1.171, clip=90, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=1341
2023-10-04 19:45:22 - progress_bar.py[line:272] - INFO: epoch 001:    270 / 907 loss=0.36, loss_v1=0, loss_v2=0, nll_loss=0.191, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=398.2, ups=1.48, wpb=268.4, bsz=96, num_updates=270, lr=3.30882e-05, gnorm=1.271, clip=80, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=1348
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 19:45:28 - progress_bar.py[line:272] - INFO: epoch 001:    280 / 907 loss=0.339, loss_v1=0, loss_v2=0, nll_loss=0.169, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=401.6, ups=1.49, wpb=270.1, bsz=96, num_updates=280, lr=3.43137e-05, gnorm=1.145, clip=80, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=1354
2023-10-04 19:45:35 - progress_bar.py[line:272] - INFO: epoch 001:    290 / 907 loss=0.333, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=395.1, ups=1.46, wpb=271.1, bsz=96, num_updates=290, lr=3.55392e-05, gnorm=1.094, clip=70, loss_scale=128, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=1361
2023-10-04 19:45:42 - progress_bar.py[line:272] - INFO: epoch 001:    300 / 907 loss=0.352, loss_v1=0, loss_v2=0, nll_loss=0.183, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=376.6, ups=1.4, wpb=268.2, bsz=96, num_updates=300, lr=3.67647e-05, gnorm=1.049, clip=50, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=1368
@@@@ ERROR IN DATA @@@@ play
2023-10-04 19:45:49 - progress_bar.py[line:272] - INFO: epoch 001:    310 / 907 loss=0.35, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=400.1, ups=1.49, wpb=268.5, bsz=96, num_updates=310, lr=3.79902e-05, gnorm=1.159, clip=80, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=1375
2023-10-04 19:45:56 - progress_bar.py[line:272] - INFO: epoch 001:    320 / 907 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.173, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=398.8, ups=1.48, wpb=268.7, bsz=96, num_updates=320, lr=3.92157e-05, gnorm=1.099, clip=70, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=1382
2023-10-04 19:46:02 - progress_bar.py[line:272] - INFO: epoch 001:    330 / 907 loss=0.349, loss_v1=0, loss_v2=0, nll_loss=0.18, ntokens=271.7, nsentences=96, sample_size=271.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=405.6, ups=1.49, wpb=271.7, bsz=96, num_updates=330, lr=4.04412e-05, gnorm=1.129, clip=70, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=1388
@@@@ ERROR IN DATA @@@@ stand on
@@@@ ERROR IN DATA @@@@ stand on
2023-10-04 19:46:09 - progress_bar.py[line:272] - INFO: epoch 001:    340 / 907 loss=0.344, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=401.8, ups=1.48, wpb=270.6, bsz=96, num_updates=340, lr=4.16667e-05, gnorm=1.123, clip=70, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=1395
2023-10-04 19:46:16 - progress_bar.py[line:272] - INFO: epoch 001:    350 / 907 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=402.1, ups=1.49, wpb=269.6, bsz=96, num_updates=350, lr=4.28922e-05, gnorm=0.997, clip=50, loss_scale=128, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=1402
2023-10-04 19:46:23 - progress_bar.py[line:272] - INFO: epoch 001:    360 / 907 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=398.1, ups=1.48, wpb=269.2, bsz=96, num_updates=360, lr=4.41176e-05, gnorm=1.185, clip=80, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=1409
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 19:46:30 - progress_bar.py[line:272] - INFO: epoch 001:    370 / 907 loss=0.345, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=389.1, ups=1.45, wpb=269.1, bsz=96, num_updates=370, lr=4.53431e-05, gnorm=1.246, clip=80, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=1416
@@@@ ERROR IN DATA @@@@ play
2023-10-04 19:46:37 - progress_bar.py[line:272] - INFO: epoch 001:    380 / 907 loss=0.361, loss_v1=0, loss_v2=0, nll_loss=0.194, ntokens=268.8, nsentences=96, sample_size=268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.14, wps=384.9, ups=1.43, wpb=268.8, bsz=96, num_updates=380, lr=4.65686e-05, gnorm=1.258, clip=90, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=1423
2023-10-04 19:46:44 - progress_bar.py[line:272] - INFO: epoch 001:    390 / 907 loss=0.341, loss_v1=0, loss_v2=0, nll_loss=0.175, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=382.6, ups=1.42, wpb=270.2, bsz=96, num_updates=390, lr=4.77941e-05, gnorm=1.155, clip=70, loss_scale=128, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=1430
2023-10-04 19:46:50 - progress_bar.py[line:272] - INFO: epoch 001:    400 / 907 loss=0.334, loss_v1=0, loss_v2=0, nll_loss=0.162, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=398, ups=1.48, wpb=268.6, bsz=96, num_updates=400, lr=4.90196e-05, gnorm=1.087, clip=60, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=1436
2023-10-04 19:46:50 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 19:46:54 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 19:46:54 - train.py[line:550] - INFO: load:2.99 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 19:47:32 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.31 GiB (GPU 1; 23.70 GiB total capacity; 6.81 GiB already allocated; 2.02 GiB free; 20.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-04 19:47:32 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:47:32 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6975 MiB |  10306 MiB | 177429 GiB | 177422 GiB |
|       from large pool |   6831 MiB |  10162 MiB | 176465 GiB | 176458 GiB |
|       from small pool |    144 MiB |    159 MiB |    964 GiB |    964 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   6975 MiB |  10306 MiB | 177429 GiB | 177422 GiB |
|       from large pool |   6831 MiB |  10162 MiB | 176465 GiB | 176458 GiB |
|       from small pool |    144 MiB |    159 MiB |    964 GiB |    964 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6922 MiB |  10253 MiB | 176961 GiB | 176955 GiB |
|       from large pool |   6777 MiB |  10109 MiB | 175998 GiB | 175992 GiB |
|       from small pool |    144 MiB |    158 MiB |    962 GiB |    962 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  20782 MiB |  21902 MiB |  65702 MiB |  44920 MiB |
|       from large pool |  20636 MiB |  21740 MiB |  65384 MiB |  44748 MiB |
|       from small pool |    146 MiB |    162 MiB |    318 MiB |    172 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  13806 MiB |  13806 MiB | 190761 GiB | 190748 GiB |
|       from large pool |  13804 MiB |  13804 MiB | 189771 GiB | 189758 GiB |
|       from small pool |      1 MiB |      7 MiB |    989 GiB |    989 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    3578    |    3593    |   10974 K  |   10970 K  |
|       from large pool |     565    |     577    |    4473 K  |    4472 K  |
|       from small pool |    3013    |    3027    |    6501 K  |    6498 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3578    |    3593    |   10974 K  |   10970 K  |
|       from large pool |     565    |     577    |    4473 K  |    4472 K  |
|       from small pool |    3013    |    3027    |    6501 K  |    6498 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     172    |     182    |     343    |     171    |
|       from large pool |      99    |     101    |     184    |      85    |
|       from small pool |      73    |      81    |     159    |      86    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     107    |     120    |    6019 K  |    6019 K  |
|       from large pool |      84    |      86    |    1644 K  |    1644 K  |
|       from small pool |      23    |      40    |    4375 K  |    4375 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:47:32 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:47:32 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:47:32 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:47:32 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:47:32 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:47:32 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:47:32 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-04 19:48:32 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 19:48:32 - train.py[line:550] - INFO: load:3.08 valid_run:98.33 task_valid:92.28 collect_output:4.96
2023-10-04 19:49:10 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.24 GiB (GPU 7; 23.70 GiB total capacity; 6.77 GiB already allocated; 1.31 GiB free; 21.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-04 19:49:10 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:49:10 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:49:10 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:49:10 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:49:10 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:49:10 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:49:10 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:49:10 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 15        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6928 MiB |  10067 MiB | 189212 GiB | 189205 GiB |
|       from large pool |   6783 MiB |   9922 MiB | 188231 GiB | 188225 GiB |
|       from small pool |    144 MiB |    159 MiB |    980 GiB |    980 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   6928 MiB |  10067 MiB | 189212 GiB | 189205 GiB |
|       from large pool |   6783 MiB |   9922 MiB | 188231 GiB | 188225 GiB |
|       from small pool |    144 MiB |    159 MiB |    980 GiB |    980 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6878 MiB |  10012 MiB | 188831 GiB | 188824 GiB |
|       from large pool |   6733 MiB |   9868 MiB | 187851 GiB | 187845 GiB |
|       from small pool |    144 MiB |    158 MiB |    979 GiB |    979 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  21504 MiB |  21552 MiB |  94316 MiB |  72812 MiB |
|       from large pool |  21358 MiB |  21390 MiB |  93930 MiB |  72572 MiB |
|       from small pool |    146 MiB |    162 MiB |    386 MiB |    240 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14575 MiB |  15093 MiB | 195142 GiB | 195128 GiB |
|       from large pool |  14574 MiB |  15091 MiB | 194134 GiB | 194120 GiB |
|       from small pool |      1 MiB |      7 MiB |   1008 GiB |   1008 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    3578    |    3593    |   11721 K  |   11718 K  |
|       from large pool |     565    |     577    |    4814 K  |    4813 K  |
|       from small pool |    3013    |    3027    |    6907 K  |    6904 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3578    |    3593    |   11721 K  |   11718 K  |
|       from large pool |     565    |     577    |    4814 K  |    4813 K  |
|       from small pool |    3013    |    3027    |    6907 K  |    6904 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     169    |     183    |     418    |     249    |
|       from large pool |      96    |     102    |     225    |     129    |
|       from small pool |      73    |      81    |     193    |     120    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     118    |     130    |    6681 K  |    6681 K  |
|       from large pool |      88    |      91    |    1680 K  |    1679 K  |
|       from small pool |      30    |      46    |    5001 K  |    5001 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 19:49:10 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-04 19:50:10 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 19:50:10 - train.py[line:550] - INFO: load:3.15 valid_run:195.96 task_valid:182.40 collect_output:11.53
2023-10-04 19:51:46 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 19:51:46 - train.py[line:550] - INFO: load:3.23 valid_run:292.57 task_valid:269.64 collect_output:19.97
2023-10-04 19:53:22 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 19:53:22 - train.py[line:550] - INFO: load:3.31 valid_run:387.86 task_valid:358.12 collect_output:25.89
2023-10-04 19:54:58 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 19:54:58 - train.py[line:550] - INFO: load:3.37 valid_run:484.27 task_valid:446.56 collect_output:32.89
2023-10-04 19:56:34 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 19:56:34 - train.py[line:550] - INFO: load:3.44 valid_run:580.25 task_valid:534.57 collect_output:39.90
2023-10-04 19:58:10 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 19:58:10 - train.py[line:550] - INFO: load:3.50 valid_run:675.54 task_valid:623.45 collect_output:45.40
2023-10-04 19:59:47 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 19:59:47 - train.py[line:550] - INFO: load:3.57 valid_run:772.86 task_valid:714.03 collect_output:51.17
2023-10-04 20:01:24 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 20:01:24 - train.py[line:550] - INFO: load:3.65 valid_run:869.45 task_valid:803.04 collect_output:57.81
2023-10-04 20:03:00 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 20:03:00 - train.py[line:550] - INFO: load:3.73 valid_run:965.75 task_valid:893.01 collect_output:63.21
2023-10-04 20:04:36 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 20:04:36 - train.py[line:550] - INFO: load:3.80 valid_run:1060.83 task_valid:982.89 collect_output:67.47

====================================================================================================
SGG eval:     R @ 50: 0.1512;     R @ 100: 0.2386;     R @ 500: 0.3233;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0729;    mR @ 100: 0.1230;    mR @ 500: 0.1759;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1961) (says:0.0000) (sitting on:0.2596) (standing on:0.4983) (using:0.1000) (walking in:0.0000) (walking on:0.0541) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1512;     R @ 100: 0.2386;     R @ 500: 0.3233;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0729;    mR @ 100: 0.1230;    mR @ 500: 0.1759;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1961) (says:0.0000) (sitting on:0.2596) (standing on:0.4983) (using:0.1000) (walking in:0.0000) (walking on:0.0541) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1512;     R @ 100: 0.2386;     R @ 500: 0.3233;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0729;    mR @ 100: 0.1230;    mR @ 500: 0.1759;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1961) (says:0.0000) (sitting on:0.2596) (standing on:0.4983) (using:0.1000) (walking in:0.0000) (walking on:0.0541) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1512;     R @ 100: 0.2386;     R @ 500: 0.3233;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0729;    mR @ 100: 0.1230;    mR @ 500: 0.1759;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1961) (says:0.0000) (sitting on:0.2596) (standing on:0.4983) (using:0.1000) (walking in:0.0000) (walking on:0.0541) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 20:05:51 - train.py[line:487] - INFO: 0.23863333333333334

====================================================================================================
SGG eval:     R @ 50: 0.1512;     R @ 100: 0.2386;     R @ 500: 0.3233;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0729;    mR @ 100: 0.1230;    mR @ 500: 0.1759;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1961) (says:0.0000) (sitting on:0.2596) (standing on:0.4983) (using:0.1000) (walking in:0.0000) (walking on:0.0541) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 20:05:51 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.1512;     R @ 100: 0.2386;     R @ 500: 0.3233;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0729;    mR @ 100: 0.1230;    mR @ 500: 0.1759;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1961) (says:0.0000) (sitting on:0.2596) (standing on:0.4983) (using:0.1000) (walking in:0.0000) (walking on:0.0541) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 20:05:51 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.256 | loss_v1 0 | loss_v2 0 | nll_loss 0.083 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.238633 | ppl 1.06 | vqa_score 0.17 | wps 394.5 | wpb 191.9 | bsz 64 | num_updates 400 | best_R@100 0.238633
2023-10-04 20:05:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 400 updates
2023-10-04 20:05:51 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_400.pt

====================================================================================================
SGG eval:     R @ 50: 0.1512;     R @ 100: 0.2386;     R @ 500: 0.3233;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0729;    mR @ 100: 0.1230;    mR @ 500: 0.1759;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1961) (says:0.0000) (sitting on:0.2596) (standing on:0.4983) (using:0.1000) (walking in:0.0000) (walking on:0.0541) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1512;     R @ 100: 0.2386;     R @ 500: 0.3233;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0729;    mR @ 100: 0.1230;    mR @ 500: 0.1759;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0049) (covered in:0.0000) (covering:0.0000) (eating:0.2353) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0000) (parked on:0.1250) (playing:0.0000) (riding:0.1961) (says:0.0000) (sitting on:0.2596) (standing on:0.4983) (using:0.1000) (walking in:0.0000) (walking on:0.0541) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 20:05:58 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_400.pt
2023-10-04 20:06:42 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_400.pt (epoch 1 @ 400 updates, score 0.23863333333333334) (writing took 51.26492848107591 seconds)
2023-10-04 20:06:49 - progress_bar.py[line:272] - INFO: epoch 001:    410 / 907 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=2.3, ups=0.01, wpb=269.9, bsz=96, num_updates=410, lr=4.99871e-05, gnorm=0.958, clip=40, loss_scale=128, train_wall=7, gb_free=6, ema_decay=0.9999, wall=2635
@@@@ ERROR IN DATA @@@@ watch
2023-10-04 20:06:56 - progress_bar.py[line:272] - INFO: epoch 001:    420 / 907 loss=0.348, loss_v1=0, loss_v2=0, nll_loss=0.181, ntokens=267.2, nsentences=96, sample_size=267.2, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=395.5, ups=1.48, wpb=267.2, bsz=96, num_updates=420, lr=4.99226e-05, gnorm=1.061, clip=60, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=2642
2023-10-04 20:07:03 - progress_bar.py[line:272] - INFO: epoch 001:    430 / 907 loss=0.343, loss_v1=0, loss_v2=0, nll_loss=0.174, ntokens=267.7, nsentences=96, sample_size=267.7, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=396, ups=1.48, wpb=267.7, bsz=96, num_updates=430, lr=4.98582e-05, gnorm=0.93, clip=20, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=2649
2023-10-04 20:07:10 - progress_bar.py[line:272] - INFO: epoch 001:    440 / 907 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=267.7, nsentences=96, sample_size=267.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=383.3, ups=1.43, wpb=267.7, bsz=96, num_updates=440, lr=4.97937e-05, gnorm=0.932, clip=20, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=2656
2023-10-04 20:07:17 - progress_bar.py[line:272] - INFO: epoch 001:    450 / 907 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.153, ntokens=272, nsentences=96, sample_size=272, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=377.2, ups=1.39, wpb=272, bsz=96, num_updates=450, lr=4.97292e-05, gnorm=0.901, clip=20, loss_scale=128, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=2663
@@@@ ERROR IN DATA @@@@ stand on
2023-10-04 20:07:24 - progress_bar.py[line:272] - INFO: epoch 001:    460 / 907 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=398.7, ups=1.48, wpb=269.2, bsz=96, num_updates=460, lr=4.96647e-05, gnorm=1.194, clip=60, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=2670
2023-10-04 20:07:30 - progress_bar.py[line:272] - INFO: epoch 001:    470 / 907 loss=0.327, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=399, ups=1.48, wpb=270, bsz=96, num_updates=470, lr=4.96003e-05, gnorm=0.922, clip=40, loss_scale=128, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=2676
2023-10-04 20:07:37 - progress_bar.py[line:272] - INFO: epoch 001:    480 / 907 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=400.1, ups=1.48, wpb=270.1, bsz=96, num_updates=480, lr=4.95358e-05, gnorm=0.92, clip=30, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=2683
2023-10-04 20:07:44 - progress_bar.py[line:272] - INFO: epoch 001:    490 / 907 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.157, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=400.4, ups=1.49, wpb=269.3, bsz=96, num_updates=490, lr=4.94713e-05, gnorm=1.046, clip=40, loss_scale=128, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=2690
2023-10-04 20:07:51 - progress_bar.py[line:272] - INFO: epoch 001:    500 / 907 loss=0.347, loss_v1=0, loss_v2=0, nll_loss=0.178, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=399.1, ups=1.49, wpb=267.8, bsz=96, num_updates=500, lr=4.94068e-05, gnorm=1.325, clip=90, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=2697
2023-10-04 20:07:57 - progress_bar.py[line:272] - INFO: epoch 001:    510 / 907 loss=0.337, loss_v1=0, loss_v2=0, nll_loss=0.17, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=398.5, ups=1.48, wpb=270.1, bsz=96, num_updates=510, lr=4.93424e-05, gnorm=0.967, clip=40, loss_scale=128, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=2703
2023-10-04 20:08:04 - progress_bar.py[line:272] - INFO: epoch 001:    520 / 907 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.159, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=403.6, ups=1.49, wpb=271, bsz=96, num_updates=520, lr=4.92779e-05, gnorm=0.918, clip=50, loss_scale=256, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=2710
2023-10-04 20:08:11 - progress_bar.py[line:272] - INFO: epoch 001:    530 / 907 loss=0.335, loss_v1=0, loss_v2=0, nll_loss=0.165, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=389.7, ups=1.44, wpb=270.7, bsz=96, num_updates=530, lr=4.92134e-05, gnorm=1.04, clip=60, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=2717
2023-10-04 20:08:18 - progress_bar.py[line:272] - INFO: epoch 001:    540 / 907 loss=0.346, loss_v1=0, loss_v2=0, nll_loss=0.179, ntokens=267.3, nsentences=96, sample_size=267.3, sample_size_v1=0, sample_size_v2=0, ppl=1.13, wps=383.5, ups=1.43, wpb=267.3, bsz=96, num_updates=540, lr=4.91489e-05, gnorm=1.067, clip=50, loss_scale=256, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=2724
2023-10-04 20:08:25 - progress_bar.py[line:272] - INFO: epoch 001:    550 / 907 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=399, ups=1.49, wpb=268.5, bsz=96, num_updates=550, lr=4.90845e-05, gnorm=0.97, clip=50, loss_scale=256, train_wall=7, gb_free=6, ema_decay=0.9999, wall=2731
2023-10-04 20:08:32 - progress_bar.py[line:272] - INFO: epoch 001:    560 / 907 loss=0.329, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=382.1, ups=1.42, wpb=269.6, bsz=96, num_updates=560, lr=4.902e-05, gnorm=1.032, clip=50, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=2738
2023-10-04 20:08:38 - progress_bar.py[line:272] - INFO: epoch 001:    570 / 907 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=401.1, ups=1.49, wpb=269.8, bsz=96, num_updates=570, lr=4.89555e-05, gnorm=0.908, clip=30, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=2744
2023-10-04 20:08:45 - progress_bar.py[line:272] - INFO: epoch 001:    580 / 907 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=400.5, ups=1.48, wpb=270.3, bsz=96, num_updates=580, lr=4.8891e-05, gnorm=0.949, clip=30, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=2751
2023-10-04 20:08:52 - progress_bar.py[line:272] - INFO: epoch 001:    590 / 907 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=399.2, ups=1.48, wpb=269.5, bsz=96, num_updates=590, lr=4.88266e-05, gnorm=0.897, clip=20, loss_scale=256, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=2758
2023-10-04 20:08:59 - progress_bar.py[line:272] - INFO: epoch 001:    600 / 907 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.132, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=400.8, ups=1.49, wpb=269.4, bsz=96, num_updates=600, lr=4.87621e-05, gnorm=0.958, clip=50, loss_scale=256, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=2765
2023-10-04 20:08:59 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 20:09:02 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 20:09:02 - train.py[line:550] - INFO: load:3.26 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 20:10:41 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 20:10:41 - train.py[line:550] - INFO: load:3.35 valid_run:98.84 task_valid:91.68 collect_output:6.19
2023-10-04 20:12:18 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 20:12:18 - train.py[line:550] - INFO: load:3.44 valid_run:195.72 task_valid:182.24 collect_output:11.58
2023-10-04 20:13:55 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 20:13:55 - train.py[line:550] - INFO: load:3.53 valid_run:292.10 task_valid:269.81 collect_output:19.46
2023-10-04 20:15:30 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 20:15:30 - train.py[line:550] - INFO: load:3.62 valid_run:387.86 task_valid:358.37 collect_output:25.78
2023-10-04 20:17:07 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 20:17:07 - train.py[line:550] - INFO: load:3.71 valid_run:484.13 task_valid:447.28 collect_output:32.25
2023-10-04 20:18:43 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 20:18:43 - train.py[line:550] - INFO: load:3.80 valid_run:580.12 task_valid:535.49 collect_output:39.11
2023-10-04 20:20:18 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 20:20:18 - train.py[line:550] - INFO: load:3.89 valid_run:675.33 task_valid:624.36 collect_output:44.52
2023-10-04 20:21:55 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 20:21:55 - train.py[line:550] - INFO: load:3.98 valid_run:771.49 task_valid:715.04 collect_output:49.09
2023-10-04 20:23:31 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 20:23:31 - train.py[line:550] - INFO: load:4.07 valid_run:867.65 task_valid:804.31 collect_output:55.06
2023-10-04 20:25:07 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 20:25:07 - train.py[line:550] - INFO: load:4.17 valid_run:963.92 task_valid:894.41 collect_output:60.34
2023-10-04 20:26:42 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 20:26:42 - train.py[line:550] - INFO: load:4.26 valid_run:1058.95 task_valid:984.33 collect_output:64.53

====================================================================================================
SGG eval:     R @ 50: 0.1954;     R @ 100: 0.2682;     R @ 500: 0.3563;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0927;    mR @ 100: 0.1409;    mR @ 500: 0.1978;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0293) (covered in:0.0000) (covering:0.0000) (eating:0.2941) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.2088) (says:0.0000) (sitting on:0.3129) (standing on:0.5233) (using:0.1500) (walking in:0.0000) (walking on:0.0631) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1954;     R @ 100: 0.2682;     R @ 500: 0.3563;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0927;    mR @ 100: 0.1409;    mR @ 500: 0.1978;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0293) (covered in:0.0000) (covering:0.0000) (eating:0.2941) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.2088) (says:0.0000) (sitting on:0.3129) (standing on:0.5233) (using:0.1500) (walking in:0.0000) (walking on:0.0631) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1954;     R @ 100: 0.2682;     R @ 500: 0.3563;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0927;    mR @ 100: 0.1409;    mR @ 500: 0.1978;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0293) (covered in:0.0000) (covering:0.0000) (eating:0.2941) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.2088) (says:0.0000) (sitting on:0.3129) (standing on:0.5233) (using:0.1500) (walking in:0.0000) (walking on:0.0631) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 20:27:58 - train.py[line:487] - INFO: 0.2682

====================================================================================================
SGG eval:     R @ 50: 0.1954;     R @ 100: 0.2682;     R @ 500: 0.3563;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0927;    mR @ 100: 0.1409;    mR @ 500: 0.1978;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0293) (covered in:0.0000) (covering:0.0000) (eating:0.2941) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.2088) (says:0.0000) (sitting on:0.3129) (standing on:0.5233) (using:0.1500) (walking in:0.0000) (walking on:0.0631) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 20:27:58 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-04 20:27:58 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.26 | loss_v1 0 | loss_v2 0 | nll_loss 0.09 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.2682 | ppl 1.06 | vqa_score 0.1847 | wps 395.1 | wpb 191.9 | bsz 64 | num_updates 600 | best_R@100 0.2682
2023-10-04 20:27:58 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 600 updates
2023-10-04 20:27:58 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_600.pt

====================================================================================================
SGG eval:     R @ 50: 0.1954;     R @ 100: 0.2682;     R @ 500: 0.3563;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0927;    mR @ 100: 0.1409;    mR @ 500: 0.1978;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0293) (covered in:0.0000) (covering:0.0000) (eating:0.2941) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.2088) (says:0.0000) (sitting on:0.3129) (standing on:0.5233) (using:0.1500) (walking in:0.0000) (walking on:0.0631) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1954;     R @ 100: 0.2682;     R @ 500: 0.3563;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0927;    mR @ 100: 0.1409;    mR @ 500: 0.1978;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0293) (covered in:0.0000) (covering:0.0000) (eating:0.2941) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.2088) (says:0.0000) (sitting on:0.3129) (standing on:0.5233) (using:0.1500) (walking in:0.0000) (walking on:0.0631) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1954;     R @ 100: 0.2682;     R @ 500: 0.3563;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0927;    mR @ 100: 0.1409;    mR @ 500: 0.1978;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0293) (covered in:0.0000) (covering:0.0000) (eating:0.2941) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.2088) (says:0.0000) (sitting on:0.3129) (standing on:0.5233) (using:0.1500) (walking in:0.0000) (walking on:0.0631) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.1954;     R @ 100: 0.2682;     R @ 500: 0.3563;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.0927;    mR @ 100: 0.1409;    mR @ 500: 0.1978;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0293) (covered in:0.0000) (covering:0.0000) (eating:0.2941) (flying in:0.5000) (growing on:0.1250) (hanging from:0.3613) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.1667) (playing:0.0000) (riding:0.2088) (says:0.0000) (sitting on:0.3129) (standing on:0.5233) (using:0.1500) (walking in:0.0000) (walking on:0.0631) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 20:28:05 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_600.pt
2023-10-04 20:28:49 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_600.pt (epoch 1 @ 600 updates, score 0.2682) (writing took 50.98219486279413 seconds)
2023-10-04 20:28:56 - progress_bar.py[line:272] - INFO: epoch 001:    610 / 907 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=2.2, ups=0.01, wpb=268.5, bsz=96, num_updates=610, lr=4.86976e-05, gnorm=1.08, clip=70, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=3962
2023-10-04 20:29:03 - progress_bar.py[line:272] - INFO: epoch 001:    620 / 907 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.146, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=402.5, ups=1.49, wpb=269.6, bsz=96, num_updates=620, lr=4.86331e-05, gnorm=1.001, clip=60, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=3969
2023-10-04 20:29:10 - progress_bar.py[line:272] - INFO: epoch 001:    630 / 907 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=401.4, ups=1.49, wpb=269, bsz=96, num_updates=630, lr=4.85687e-05, gnorm=0.891, clip=20, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=3976
2023-10-04 20:29:17 - progress_bar.py[line:272] - INFO: epoch 001:    640 / 907 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=402, ups=1.49, wpb=270.5, bsz=96, num_updates=640, lr=4.85042e-05, gnorm=0.854, clip=20, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=3983
@@@@ ERROR IN DATA @@@@ stand on
2023-10-04 20:29:23 - progress_bar.py[line:272] - INFO: epoch 001:    650 / 907 loss=0.326, loss_v1=0, loss_v2=0, nll_loss=0.156, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=403.2, ups=1.49, wpb=270.3, bsz=96, num_updates=650, lr=4.84397e-05, gnorm=0.912, clip=30, loss_scale=256, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=3989
2023-10-04 20:29:30 - progress_bar.py[line:272] - INFO: epoch 001:    660 / 907 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.163, ntokens=267.1, nsentences=96, sample_size=267.1, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=398.4, ups=1.49, wpb=267.1, bsz=96, num_updates=660, lr=4.83752e-05, gnorm=0.914, clip=40, loss_scale=256, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=3996
2023-10-04 20:29:37 - progress_bar.py[line:272] - INFO: epoch 001:    670 / 907 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.158, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=401.9, ups=1.49, wpb=269.9, bsz=96, num_updates=670, lr=4.83108e-05, gnorm=0.777, clip=10, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=4003
2023-10-04 20:29:44 - progress_bar.py[line:272] - INFO: epoch 001:    680 / 907 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=388.3, ups=1.44, wpb=270.6, bsz=96, num_updates=680, lr=4.82463e-05, gnorm=0.813, clip=0, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=4010
2023-10-04 20:29:50 - progress_bar.py[line:272] - INFO: epoch 001:    690 / 907 loss=0.319, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=268.8, nsentences=96, sample_size=268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=400.8, ups=1.49, wpb=268.8, bsz=96, num_updates=690, lr=4.81818e-05, gnorm=0.95, clip=40, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=4016
2023-10-04 20:29:57 - progress_bar.py[line:272] - INFO: epoch 001:    700 / 907 loss=0.325, loss_v1=0, loss_v2=0, nll_loss=0.16, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=389, ups=1.44, wpb=270.4, bsz=96, num_updates=700, lr=4.81173e-05, gnorm=0.975, clip=40, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=4023
2023-10-04 20:30:04 - progress_bar.py[line:272] - INFO: epoch 001:    710 / 907 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.141, ntokens=267.2, nsentences=96, sample_size=267.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=396.2, ups=1.48, wpb=267.2, bsz=96, num_updates=710, lr=4.80529e-05, gnorm=0.894, clip=10, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=4030
2023-10-04 20:30:11 - progress_bar.py[line:272] - INFO: epoch 001:    720 / 907 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.14, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=387.6, ups=1.44, wpb=268.5, bsz=96, num_updates=720, lr=4.79884e-05, gnorm=1.055, clip=50, loss_scale=256, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=4037
2023-10-04 20:30:18 - progress_bar.py[line:272] - INFO: epoch 001:    730 / 907 loss=0.316, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=271.4, nsentences=96, sample_size=271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=401.3, ups=1.48, wpb=271.4, bsz=96, num_updates=730, lr=4.79239e-05, gnorm=0.957, clip=40, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=4044
2023-10-04 20:30:24 - progress_bar.py[line:272] - INFO: epoch 001:    740 / 907 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.149, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=401.1, ups=1.49, wpb=269.3, bsz=96, num_updates=740, lr=4.78594e-05, gnorm=0.862, clip=30, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=4051
2023-10-04 20:30:31 - progress_bar.py[line:272] - INFO: epoch 001:    750 / 907 loss=0.322, loss_v1=0, loss_v2=0, nll_loss=0.152, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=402.1, ups=1.49, wpb=269.9, bsz=96, num_updates=750, lr=4.7795e-05, gnorm=0.931, clip=30, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=4057
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 20:30:38 - progress_bar.py[line:272] - INFO: epoch 001:    760 / 907 loss=0.323, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=387.1, ups=1.45, wpb=267.8, bsz=96, num_updates=760, lr=4.77305e-05, gnorm=0.859, clip=10, loss_scale=256, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=4064
2023-10-04 20:30:45 - progress_bar.py[line:272] - INFO: epoch 001:    770 / 907 loss=0.321, loss_v1=0, loss_v2=0, nll_loss=0.148, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=400.2, ups=1.49, wpb=268.3, bsz=96, num_updates=770, lr=4.7666e-05, gnorm=0.97, clip=40, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=4071
2023-10-04 20:30:52 - progress_bar.py[line:272] - INFO: epoch 001:    780 / 907 loss=0.32, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=400.9, ups=1.49, wpb=269.3, bsz=96, num_updates=780, lr=4.76015e-05, gnorm=0.951, clip=50, loss_scale=256, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=4078
2023-10-04 20:30:58 - progress_bar.py[line:272] - INFO: epoch 001:    790 / 907 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.147, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=400.1, ups=1.48, wpb=269.6, bsz=96, num_updates=790, lr=4.75371e-05, gnorm=0.852, clip=20, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=4084
2023-10-04 20:31:06 - progress_bar.py[line:272] - INFO: epoch 001:    800 / 907 loss=0.31, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=366.3, ups=1.35, wpb=270.5, bsz=96, num_updates=800, lr=4.74726e-05, gnorm=0.835, clip=20, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=4092
2023-10-04 20:31:06 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 20:31:09 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 20:31:09 - train.py[line:550] - INFO: load:3.16 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 20:32:47 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 20:32:47 - train.py[line:550] - INFO: load:3.24 valid_run:98.33 task_valid:91.64 collect_output:5.68
2023-10-04 20:34:25 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 20:34:25 - train.py[line:550] - INFO: load:3.34 valid_run:195.39 task_valid:184.27 collect_output:9.03
2023-10-04 20:36:02 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 20:36:02 - train.py[line:550] - INFO: load:3.44 valid_run:292.34 task_valid:273.94 collect_output:15.20
2023-10-04 20:37:38 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 20:37:38 - train.py[line:550] - INFO: load:3.55 valid_run:388.31 task_valid:364.54 collect_output:19.45
2023-10-04 20:39:14 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 20:39:14 - train.py[line:550] - INFO: load:3.65 valid_run:484.73 task_valid:455.04 collect_output:24.24
2023-10-04 20:40:52 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 20:40:52 - train.py[line:550] - INFO: load:3.75 valid_run:581.91 task_valid:545.22 collect_output:30.10
2023-10-04 20:42:27 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 20:42:27 - train.py[line:550] - INFO: load:3.85 valid_run:677.41 task_valid:636.01 collect_output:33.68
2023-10-04 20:44:04 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 20:44:04 - train.py[line:550] - INFO: load:3.94 valid_run:773.79 task_valid:728.48 collect_output:36.53
2023-10-04 20:45:41 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 20:45:41 - train.py[line:550] - INFO: load:4.03 valid_run:870.27 task_valid:819.69 collect_output:40.72
2023-10-04 20:47:18 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 20:47:18 - train.py[line:550] - INFO: load:4.13 valid_run:967.51 task_valid:911.57 collect_output:44.98
2023-10-04 20:48:55 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 20:48:55 - train.py[line:550] - INFO: load:4.24 valid_run:1064.62 task_valid:1003.58 collect_output:48.92

====================================================================================================
SGG eval:     R @ 50: 0.2310;     R @ 100: 0.3056;     R @ 500: 0.3802;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1013;    mR @ 100: 0.1617;    mR @ 500: 0.2055;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0537) (covered in:0.0000) (covering:0.0000) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.2971) (says:0.0000) (sitting on:0.3430) (standing on:0.5367) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2310;     R @ 100: 0.3056;     R @ 500: 0.3802;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1013;    mR @ 100: 0.1617;    mR @ 500: 0.2055;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0537) (covered in:0.0000) (covering:0.0000) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.2971) (says:0.0000) (sitting on:0.3430) (standing on:0.5367) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2310;     R @ 100: 0.3056;     R @ 500: 0.3802;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1013;    mR @ 100: 0.1617;    mR @ 500: 0.2055;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0537) (covered in:0.0000) (covering:0.0000) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.2971) (says:0.0000) (sitting on:0.3430) (standing on:0.5367) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2310;     R @ 100: 0.3056;     R @ 500: 0.3802;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1013;    mR @ 100: 0.1617;    mR @ 500: 0.2055;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0537) (covered in:0.0000) (covering:0.0000) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.2971) (says:0.0000) (sitting on:0.3430) (standing on:0.5367) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2310;     R @ 100: 0.3056;     R @ 500: 0.3802;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1013;    mR @ 100: 0.1617;    mR @ 500: 0.2055;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0537) (covered in:0.0000) (covering:0.0000) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.2971) (says:0.0000) (sitting on:0.3430) (standing on:0.5367) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2310;     R @ 100: 0.3056;     R @ 500: 0.3802;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1013;    mR @ 100: 0.1617;    mR @ 500: 0.2055;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0537) (covered in:0.0000) (covering:0.0000) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.2971) (says:0.0000) (sitting on:0.3430) (standing on:0.5367) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2310;     R @ 100: 0.3056;     R @ 500: 0.3802;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1013;    mR @ 100: 0.1617;    mR @ 500: 0.2055;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0537) (covered in:0.0000) (covering:0.0000) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.2971) (says:0.0000) (sitting on:0.3430) (standing on:0.5367) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2310;     R @ 100: 0.3056;     R @ 500: 0.3802;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1013;    mR @ 100: 0.1617;    mR @ 500: 0.2055;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0537) (covered in:0.0000) (covering:0.0000) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.4194) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.2971) (says:0.0000) (sitting on:0.3430) (standing on:0.5367) (using:0.1500) (walking in:0.0000) (walking on:0.1351) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 20:50:12 - train.py[line:487] - INFO: 0.30560000000000004
2023-10-04 20:50:12 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-04 20:50:12 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss 0.259 | loss_v1 0 | loss_v2 0 | nll_loss 0.098 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.3056 | ppl 1.07 | vqa_score 0.1881 | wps 392.9 | wpb 191.9 | bsz 64 | num_updates 800 | best_R@100 0.3056
2023-10-04 20:50:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 800 updates
2023-10-04 20:50:12 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_800.pt
2023-10-04 20:50:18 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_800.pt
2023-10-04 20:51:04 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_1_800.pt (epoch 1 @ 800 updates, score 0.30560000000000004) (writing took 52.01042151590809 seconds)
2023-10-04 20:51:11 - progress_bar.py[line:272] - INFO: epoch 001:    810 / 907 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.142, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=2.2, ups=0.01, wpb=271.1, bsz=96, num_updates=810, lr=4.74081e-05, gnorm=0.827, clip=30, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5297
2023-10-04 20:51:18 - progress_bar.py[line:272] - INFO: epoch 001:    820 / 907 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=405, ups=1.49, wpb=271.2, bsz=96, num_updates=820, lr=4.73436e-05, gnorm=0.858, clip=30, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5304
2023-10-04 20:51:24 - progress_bar.py[line:272] - INFO: epoch 001:    830 / 907 loss=0.314, loss_v1=0, loss_v2=0, nll_loss=0.144, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=404, ups=1.49, wpb=270.9, bsz=96, num_updates=830, lr=4.72792e-05, gnorm=0.915, clip=20, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5310
2023-10-04 20:51:31 - progress_bar.py[line:272] - INFO: epoch 001:    840 / 907 loss=0.332, loss_v1=0, loss_v2=0, nll_loss=0.161, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.12, wps=399.1, ups=1.49, wpb=268.5, bsz=96, num_updates=840, lr=4.72147e-05, gnorm=1.064, clip=60, loss_scale=256, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=5317
2023-10-04 20:51:38 - progress_bar.py[line:272] - INFO: epoch 001:    850 / 907 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.138, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=404.2, ups=1.49, wpb=271.1, bsz=96, num_updates=850, lr=4.71502e-05, gnorm=0.863, clip=0, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5324
2023-10-04 20:51:44 - progress_bar.py[line:272] - INFO: epoch 001:    860 / 907 loss=0.328, loss_v1=0, loss_v2=0, nll_loss=0.155, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=399.2, ups=1.48, wpb=269, bsz=96, num_updates=860, lr=4.70858e-05, gnorm=0.891, clip=30, loss_scale=256, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=5331
2023-10-04 20:51:51 - progress_bar.py[line:272] - INFO: epoch 001:    870 / 907 loss=0.305, loss_v1=0, loss_v2=0, nll_loss=0.134, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=390.1, ups=1.45, wpb=268.7, bsz=96, num_updates=870, lr=4.70213e-05, gnorm=0.756, clip=10, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5337
2023-10-04 20:51:58 - progress_bar.py[line:272] - INFO: epoch 001:    880 / 907 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.137, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=387.4, ups=1.44, wpb=268.7, bsz=96, num_updates=880, lr=4.69568e-05, gnorm=0.768, clip=10, loss_scale=256, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=5344
2023-10-04 20:52:05 - progress_bar.py[line:272] - INFO: epoch 001:    890 / 907 loss=0.317, loss_v1=0, loss_v2=0, nll_loss=0.151, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.11, wps=406.7, ups=1.5, wpb=270.3, bsz=96, num_updates=890, lr=4.68923e-05, gnorm=0.931, clip=30, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5351
2023-10-04 20:52:12 - progress_bar.py[line:272] - INFO: epoch 001:    900 / 907 loss=0.312, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=390, ups=1.45, wpb=268.5, bsz=96, num_updates=900, lr=4.68279e-05, gnorm=0.886, clip=20, loss_scale=256, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=5358
2023-10-04 20:52:16 - train.py[line:339] - INFO: end of epoch 1 (average epoch stats below)
2023-10-04 20:52:16 - progress_bar.py[line:282] - INFO: epoch 001 | loss 0.373 | loss_v1 0 | loss_v2 0 | nll_loss 0.205 | ntokens 269.255 | nsentences 95.914 | sample_size 269.255 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.15 | wps 45.6 | ups 0.17 | wpb 269.3 | bsz 95.9 | num_updates 907 | lr 4.67827e-05 | gnorm 1.398 | clip 57.1 | loss_scale 256 | train_wall 620 | gb_free 16.3 | ema_decay 0.9999 | wall 5362
2023-10-04 20:52:16 - trainer.py[line:694] - INFO: loading train data for epoch 2
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv slice_id 3 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv slice_id 7 row count 10874 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv slice_id 4 row count 10874 total row count 86994

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv slice_id 1 row count 10875 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv slice_id 6 row count 10874 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv slice_id 2 row count 10874 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv slice_id 5 row count 10874 total row count 86994


file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E1.tsv slice_id 0 row count 10875 total row count 86994
2023-10-04 20:52:16 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
2023-10-04 20:52:17 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-04 20:52:17 - trainer.py[line:758] - INFO: begin training epoch 2
2023-10-04 20:52:17 - train.py[line:312] - INFO: Start iterating over samples
2023-10-04 20:52:23 - progress_bar.py[line:272] - INFO: epoch 002:      3 / 907 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=246.6, nsentences=88.2, sample_size=246.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=229.5, ups=0.93, wpb=246.6, bsz=88.2, num_updates=910, lr=4.67634e-05, gnorm=0.962, clip=10, loss_scale=256, train_wall=8, gb_free=6.5, ema_decay=0.9999, wall=5369
2023-10-04 20:52:29 - progress_bar.py[line:272] - INFO: epoch 002:     13 / 907 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.104, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=399.3, ups=1.49, wpb=268.4, bsz=96, num_updates=920, lr=4.66989e-05, gnorm=0.791, clip=10, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5375
2023-10-04 20:52:36 - progress_bar.py[line:272] - INFO: epoch 002:     23 / 907 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=267.3, nsentences=96, sample_size=267.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=395.3, ups=1.48, wpb=267.3, bsz=96, num_updates=930, lr=4.66344e-05, gnorm=0.788, clip=20, loss_scale=256, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=5382
2023-10-04 20:52:43 - progress_bar.py[line:272] - INFO: epoch 002:     33 / 907 loss=0.299, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=399.1, ups=1.48, wpb=269.4, bsz=96, num_updates=940, lr=4.657e-05, gnorm=0.851, clip=10, loss_scale=256, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=5389
2023-10-04 20:52:50 - progress_bar.py[line:272] - INFO: epoch 002:     43 / 907 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.112, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=399.5, ups=1.48, wpb=269.8, bsz=96, num_updates=950, lr=4.65055e-05, gnorm=0.812, clip=20, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5396
2023-10-04 20:52:57 - progress_bar.py[line:272] - INFO: epoch 002:     53 / 907 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.112, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=385.9, ups=1.43, wpb=269.7, bsz=96, num_updates=960, lr=4.6441e-05, gnorm=0.91, clip=30, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5403
2023-10-04 20:53:04 - progress_bar.py[line:272] - INFO: epoch 002:     63 / 907 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.112, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=389.7, ups=1.44, wpb=271, bsz=96, num_updates=970, lr=4.63765e-05, gnorm=0.771, clip=10, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5410
@@@@ ERROR IN DATA @@@@ stand on
2023-10-04 20:53:11 - progress_bar.py[line:272] - INFO: epoch 002:     73 / 907 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.12, ntokens=272, nsentences=96, sample_size=272, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=380.7, ups=1.4, wpb=272, bsz=96, num_updates=980, lr=4.63121e-05, gnorm=0.988, clip=20, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5417
2023-10-04 20:53:18 - progress_bar.py[line:272] - INFO: epoch 002:     83 / 907 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=388.5, ups=1.43, wpb=270.9, bsz=96, num_updates=990, lr=4.62476e-05, gnorm=0.875, clip=20, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5424
2023-10-04 20:53:25 - progress_bar.py[line:272] - INFO: epoch 002:     93 / 907 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.118, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=361.7, ups=1.34, wpb=269.2, bsz=96, num_updates=1000, lr=4.61831e-05, gnorm=0.883, clip=20, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=5431
2023-10-04 20:53:25 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 20:53:27 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 20:53:27 - train.py[line:550] - INFO: load:1.75 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 20:53:28 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.09 GiB (GPU 6; 23.70 GiB total capacity; 6.68 GiB already allocated; 2.31 GiB free; 20.01 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-04 20:53:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:53:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:53:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:53:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:53:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:53:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:53:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 14        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6844 MiB |   7475 MiB | 637867 GiB | 637860 GiB |
|       from large pool |   6699 MiB |   7330 MiB | 634338 GiB | 634332 GiB |
|       from small pool |    144 MiB |    157 MiB |   3528 GiB |   3528 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   6844 MiB |   7475 MiB | 637867 GiB | 637860 GiB |
|       from large pool |   6699 MiB |   7330 MiB | 634338 GiB | 634332 GiB |
|       from small pool |    144 MiB |    157 MiB |   3528 GiB |   3528 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6789 MiB |   7419 MiB | 636286 GiB | 636280 GiB |
|       from large pool |   6645 MiB |   7275 MiB | 632763 GiB | 632756 GiB |
|       from small pool |    144 MiB |    157 MiB |   3523 GiB |   3523 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  20486 MiB |  20734 MiB |  85958 MiB |  65472 MiB |
|       from large pool |  20340 MiB |  20486 MiB |  85520 MiB |  65180 MiB |
|       from small pool |    146 MiB |    248 MiB |    438 MiB |    292 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  13641 MiB |  13641 MiB | 628591 GiB | 628578 GiB |
|       from large pool |  13640 MiB |  13640 MiB | 624985 GiB | 624971 GiB |
|       from small pool |      1 MiB |      5 MiB |   3606 GiB |   3606 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    3567    |    3582    |   39697 K  |   39693 K  |
|       from large pool |     565    |     577    |   15964 K  |   15963 K  |
|       from small pool |    3002    |    3021    |   23732 K  |   23729 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3567    |    3582    |   39697 K  |   39693 K  |
|       from large pool |     565    |     577    |   15964 K  |   15963 K  |
|       from small pool |    3002    |    3021    |   23732 K  |   23729 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     171    |     223    |     440    |     269    |
|       from large pool |      98    |      99    |     221    |     123    |
|       from small pool |      73    |     124    |     219    |     146    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     113    |     122    |   22448 K  |   22448 K  |
|       from large pool |      85    |      86    |    5971 K  |    5971 K  |
|       from small pool |      28    |      39    |   16476 K  |   16476 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:53:28 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:53:28 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-04 20:54:48 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.31 GiB (GPU 2; 23.70 GiB total capacity; 6.81 GiB already allocated; 2.71 GiB free; 19.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-04 20:54:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:54:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:54:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 9         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6977 MiB |   9887 MiB | 648192 GiB | 648186 GiB |
|       from large pool |   6833 MiB |   9742 MiB | 644724 GiB | 644717 GiB |
|       from small pool |    144 MiB |    159 MiB |   3468 GiB |   3468 GiB |
|---------------------------------------------------------------------------|
| Active memory         |   6977 MiB |   9887 MiB | 648192 GiB | 648186 GiB |
|       from large pool |   6833 MiB |   9742 MiB | 644724 GiB | 644717 GiB |
|       from small pool |    144 MiB |    159 MiB |   3468 GiB |   3468 GiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6922 MiB |   9832 MiB | 646946 GiB | 646940 GiB |
|       from large pool |   6777 MiB |   9687 MiB | 643483 GiB | 643477 GiB |
|       from small pool |    144 MiB |    158 MiB |   3463 GiB |   3463 GiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  20078 MiB |  20872 MiB |  69008 MiB |  48930 MiB |
|       from large pool |  19932 MiB |  20624 MiB |  68640 MiB |  48708 MiB |
|       from small pool |    146 MiB |    248 MiB |    368 MiB |    222 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  13100 MiB |  13100 MiB | 647719 GiB | 647706 GiB |
|       from large pool |  13098 MiB |  13098 MiB | 644171 GiB | 644159 GiB |
|       from small pool |      1 MiB |      7 MiB |   3547 GiB |   3547 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    3578    |    3593    |   40308 K  |   40305 K  |
|       from large pool |     565    |     577    |   16328 K  |   16327 K  |
|       from small pool |    3013    |    3027    |   23980 K  |   23977 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3578    |    3593    |   40308 K  |   40305 K  |
|       from large pool |     565    |     577    |   16328 K  |   16327 K  |
|       from small pool |    3013    |    3027    |   23980 K  |   23977 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     167    |     220    |     382    |     215    |
|       from large pool |      94    |      96    |     198    |     104    |
|       from small pool |      73    |     124    |     184    |     111    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     100    |     117    |   22511 K  |   22511 K  |
|       from large pool |      75    |      81    |    5442 K  |    5442 K  |
|       from small pool |      25    |      41    |   17068 K  |   17068 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:54:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:54:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:54:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:54:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:54:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 20:54:48 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-04 20:55:05 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 20:55:05 - train.py[line:550] - INFO: load:1.84 valid_run:98.09 task_valid:93.42 collect_output:3.64
2023-10-04 20:56:42 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 20:56:42 - train.py[line:550] - INFO: load:1.94 valid_run:194.26 task_valid:185.19 collect_output:7.05
2023-10-04 20:58:18 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 20:58:18 - train.py[line:550] - INFO: load:2.02 valid_run:289.99 task_valid:274.07 collect_output:12.93
2023-10-04 20:59:53 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 20:59:53 - train.py[line:550] - INFO: load:2.10 valid_run:384.97 task_valid:364.13 collect_output:16.89
2023-10-04 21:01:29 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 21:01:29 - train.py[line:550] - INFO: load:2.19 valid_run:480.91 task_valid:454.22 collect_output:21.80
2023-10-04 21:03:05 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 21:03:05 - train.py[line:550] - INFO: load:2.28 valid_run:576.62 task_valid:543.88 collect_output:26.89
2023-10-04 21:04:39 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 21:04:39 - train.py[line:550] - INFO: load:2.37 valid_run:671.30 task_valid:634.38 collect_output:30.02
2023-10-04 21:06:15 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 21:06:15 - train.py[line:550] - INFO: load:2.46 valid_run:766.93 task_valid:726.71 collect_output:32.37
2023-10-04 21:07:51 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 21:07:51 - train.py[line:550] - INFO: load:2.53 valid_run:863.05 task_valid:817.46 collect_output:36.80
2023-10-04 21:09:28 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 21:09:28 - train.py[line:550] - INFO: load:2.62 valid_run:959.52 task_valid:909.40 collect_output:40.34
2023-10-04 21:11:03 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 21:11:03 - train.py[line:550] - INFO: load:2.71 valid_run:1054.89 task_valid:1000.90 collect_output:43.28

====================================================================================================
SGG eval:     R @ 50: 0.2866;     R @ 100: 0.3503;     R @ 500: 0.4267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1361;    mR @ 100: 0.1848;    mR @ 500: 0.2249;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0683) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.3902) (says:0.0000) (sitting on:0.3974) (standing on:0.5425) (using:0.1500) (walking in:0.0000) (walking on:0.1892) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2866;     R @ 100: 0.3503;     R @ 500: 0.4267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1361;    mR @ 100: 0.1848;    mR @ 500: 0.2249;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0683) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.3902) (says:0.0000) (sitting on:0.3974) (standing on:0.5425) (using:0.1500) (walking in:0.0000) (walking on:0.1892) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2866;     R @ 100: 0.3503;     R @ 500: 0.4267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1361;    mR @ 100: 0.1848;    mR @ 500: 0.2249;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0683) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.3902) (says:0.0000) (sitting on:0.3974) (standing on:0.5425) (using:0.1500) (walking in:0.0000) (walking on:0.1892) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 21:12:19 - train.py[line:487] - INFO: 0.35030000000000006

====================================================================================================
SGG eval:     R @ 50: 0.2866;     R @ 100: 0.3503;     R @ 500: 0.4267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1361;    mR @ 100: 0.1848;    mR @ 500: 0.2249;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0683) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.3902) (says:0.0000) (sitting on:0.3974) (standing on:0.5425) (using:0.1500) (walking in:0.0000) (walking on:0.1892) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2866;     R @ 100: 0.3503;     R @ 500: 0.4267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1361;    mR @ 100: 0.1848;    mR @ 500: 0.2249;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0683) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.3902) (says:0.0000) (sitting on:0.3974) (standing on:0.5425) (using:0.1500) (walking in:0.0000) (walking on:0.1892) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2866;     R @ 100: 0.3503;     R @ 500: 0.4267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1361;    mR @ 100: 0.1848;    mR @ 500: 0.2249;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0683) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.3902) (says:0.0000) (sitting on:0.3974) (standing on:0.5425) (using:0.1500) (walking in:0.0000) (walking on:0.1892) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.2866;     R @ 100: 0.3503;     R @ 500: 0.4267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1361;    mR @ 100: 0.1848;    mR @ 500: 0.2249;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0683) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.3902) (says:0.0000) (sitting on:0.3974) (standing on:0.5425) (using:0.1500) (walking in:0.0000) (walking on:0.1892) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 21:12:19 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-04 21:12:19 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.244 | loss_v1 0 | loss_v2 0 | nll_loss 0.074 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.3503 | ppl 1.05 | vqa_score 0.1813 | wps 396.7 | wpb 191.9 | bsz 64 | num_updates 1000 | best_R@100 0.3503
2023-10-04 21:12:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 1000 updates
2023-10-04 21:12:19 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1000.pt

====================================================================================================
SGG eval:     R @ 50: 0.2866;     R @ 100: 0.3503;     R @ 500: 0.4267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1361;    mR @ 100: 0.1848;    mR @ 500: 0.2249;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.0683) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.0833) (parked on:0.2083) (playing:0.0000) (riding:0.3902) (says:0.0000) (sitting on:0.3974) (standing on:0.5425) (using:0.1500) (walking in:0.0000) (walking on:0.1892) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 21:12:24 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1000.pt
2023-10-04 21:13:06 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1000.pt (epoch 2 @ 1000 updates, score 0.35030000000000006) (writing took 47.68364491406828 seconds)
2023-10-04 21:13:13 - progress_bar.py[line:272] - INFO: epoch 002:    103 / 907 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=2.3, ups=0.01, wpb=271, bsz=96, num_updates=1010, lr=4.61186e-05, gnorm=0.986, clip=30, loss_scale=256, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6619
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 21:13:20 - progress_bar.py[line:272] - INFO: epoch 002:    113 / 907 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.115, ntokens=271.8, nsentences=96, sample_size=271.8, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=405.6, ups=1.49, wpb=271.8, bsz=96, num_updates=1020, lr=4.60542e-05, gnorm=0.914, clip=30, loss_scale=256, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=6626
2023-10-04 21:13:27 - progress_bar.py[line:272] - INFO: epoch 002:    123 / 907 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.11, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=394, ups=1.46, wpb=270.6, bsz=96, num_updates=1030, lr=4.59897e-05, gnorm=0.72, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6633
2023-10-04 21:13:34 - progress_bar.py[line:272] - INFO: epoch 002:    133 / 907 loss=0.311, loss_v1=0, loss_v2=0, nll_loss=0.139, ntokens=267.6, nsentences=96, sample_size=267.6, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=395.4, ups=1.48, wpb=267.6, bsz=96, num_updates=1040, lr=4.59252e-05, gnorm=0.88, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6640
2023-10-04 21:13:40 - progress_bar.py[line:272] - INFO: epoch 002:    143 / 907 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=400.8, ups=1.48, wpb=270.1, bsz=96, num_updates=1050, lr=4.58607e-05, gnorm=0.877, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6646
2023-10-04 21:13:47 - progress_bar.py[line:272] - INFO: epoch 002:    153 / 907 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.133, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=380.4, ups=1.41, wpb=269.1, bsz=96, num_updates=1060, lr=4.57963e-05, gnorm=0.868, clip=10, loss_scale=512, train_wall=7, gb_free=5.9, ema_decay=0.9999, wall=6653
2023-10-04 21:13:54 - progress_bar.py[line:272] - INFO: epoch 002:    163 / 907 loss=0.306, loss_v1=0, loss_v2=0, nll_loss=0.136, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.1, wps=389.4, ups=1.45, wpb=269.4, bsz=96, num_updates=1070, lr=4.57318e-05, gnorm=1.02, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6660
2023-10-04 21:14:01 - progress_bar.py[line:272] - INFO: epoch 002:    173 / 907 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.109, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=392.3, ups=1.45, wpb=270.8, bsz=96, num_updates=1080, lr=4.56673e-05, gnorm=0.863, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=6667
2023-10-04 21:14:08 - progress_bar.py[line:272] - INFO: epoch 002:    183 / 907 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=403.2, ups=1.49, wpb=271.2, bsz=96, num_updates=1090, lr=4.56028e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6674
2023-10-04 21:14:15 - progress_bar.py[line:272] - INFO: epoch 002:    193 / 907 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.121, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=398.9, ups=1.49, wpb=268.1, bsz=96, num_updates=1100, lr=4.55384e-05, gnorm=0.925, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6681
2023-10-04 21:14:21 - progress_bar.py[line:272] - INFO: epoch 002:    203 / 907 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.112, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=401.3, ups=1.49, wpb=270, bsz=96, num_updates=1110, lr=4.54739e-05, gnorm=0.752, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6687
2023-10-04 21:14:28 - progress_bar.py[line:272] - INFO: epoch 002:    213 / 907 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.11, ntokens=271.5, nsentences=96, sample_size=271.5, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=403.4, ups=1.49, wpb=271.5, bsz=96, num_updates=1120, lr=4.54094e-05, gnorm=0.839, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6694
2023-10-04 21:14:35 - progress_bar.py[line:272] - INFO: epoch 002:    223 / 907 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=400.5, ups=1.48, wpb=270.7, bsz=96, num_updates=1130, lr=4.53449e-05, gnorm=0.97, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6701
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 21:14:42 - progress_bar.py[line:272] - INFO: epoch 002:    233 / 907 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.113, ntokens=266.8, nsentences=96, sample_size=266.8, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=378, ups=1.42, wpb=266.8, bsz=96, num_updates=1140, lr=4.52805e-05, gnorm=0.867, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6708
2023-10-04 21:14:49 - progress_bar.py[line:272] - INFO: epoch 002:    243 / 907 loss=0.3, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=400.3, ups=1.48, wpb=269.7, bsz=96, num_updates=1150, lr=4.5216e-05, gnorm=0.87, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6715
2023-10-04 21:14:55 - progress_bar.py[line:272] - INFO: epoch 002:    253 / 907 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.125, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=403.5, ups=1.49, wpb=270.8, bsz=96, num_updates=1160, lr=4.51515e-05, gnorm=0.83, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=6721
2023-10-04 21:15:02 - progress_bar.py[line:272] - INFO: epoch 002:    263 / 907 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.115, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=388.4, ups=1.44, wpb=269.2, bsz=96, num_updates=1170, lr=4.5087e-05, gnorm=0.883, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=6728
2023-10-04 21:15:09 - progress_bar.py[line:272] - INFO: epoch 002:    273 / 907 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.115, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=388, ups=1.44, wpb=270.2, bsz=96, num_updates=1180, lr=4.50226e-05, gnorm=0.886, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6735
2023-10-04 21:15:16 - progress_bar.py[line:272] - INFO: epoch 002:    283 / 907 loss=0.289, loss_v1=0, loss_v2=0, nll_loss=0.117, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=390, ups=1.45, wpb=269.7, bsz=96, num_updates=1190, lr=4.49581e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=6742
2023-10-04 21:15:23 - progress_bar.py[line:272] - INFO: epoch 002:    293 / 907 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=391.2, ups=1.45, wpb=269.2, bsz=96, num_updates=1200, lr=4.48936e-05, gnorm=0.77, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=6749
2023-10-04 21:15:23 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 21:15:26 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 21:15:26 - train.py[line:550] - INFO: load:2.48 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 21:15:26 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.87 GiB (GPU 0; 23.70 GiB total capacity; 6.55 GiB already allocated; 1.56 GiB free; 20.76 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-04 21:15:26 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 9         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6708 MiB |   7313 MiB |    777 TiB |    777 TiB |
|       from large pool |   6564 MiB |   7169 MiB |    773 TiB |    773 TiB |
|       from small pool |    144 MiB |    156 MiB |      4 TiB |      4 TiB |
|---------------------------------------------------------------------------|
| Active memory         |   6708 MiB |   7313 MiB |    777 TiB |    777 TiB |
|       from large pool |   6564 MiB |   7169 MiB |    773 TiB |    773 TiB |
|       from small pool |    144 MiB |    156 MiB |      4 TiB |      4 TiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6657 MiB |   7261 MiB |    775 TiB |    775 TiB |
|       from large pool |   6512 MiB |   7116 MiB |    771 TiB |    771 TiB |
|       from small pool |    144 MiB |    156 MiB |      4 TiB |      4 TiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  21256 MiB |  21346 MiB |  62594 MiB |  41338 MiB |
|       from large pool |  21110 MiB |  21172 MiB |  62326 MiB |  41216 MiB |
|       from small pool |    146 MiB |    174 MiB |    268 MiB |    122 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14547 MiB |  14547 MiB | 770996 GiB | 770982 GiB |
|       from large pool |  14545 MiB |  14545 MiB | 766772 GiB | 766758 GiB |
|       from small pool |      1 MiB |      5 MiB |   4223 GiB |   4223 GiB |
|---------------------------------------------------------------------------|
| Allocations           |    3567    |    3582    |   49371 K  |   49368 K  |
|       from large pool |     565    |     577    |   20117 K  |   20116 K  |
|       from small pool |    3002    |    3021    |   29254 K  |   29251 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3567    |    3582    |   49371 K  |   49368 K  |
|       from large pool |     565    |     577    |   20117 K  |   20116 K  |
|       from small pool |    3002    |    3021    |   29254 K  |   29251 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     160    |     175    |     301    |     141    |
|       from large pool |      87    |      88    |     167    |      80    |
|       from small pool |      73    |      87    |     134    |      61    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     108    |     113    |   27501 K  |   27501 K  |
|       from large pool |      78    |      79    |    6882 K  |    6882 K  |
|       from small pool |      30    |      39    |   20618 K  |   20618 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:15:26 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:15:26 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:15:26 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:15:26 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:15:26 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:15:26 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:15:26 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:15:26 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-04 21:17:03 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 21:17:03 - train.py[line:550] - INFO: load:2.56 valid_run:97.32 task_valid:92.75 collect_output:2.82
2023-10-04 21:18:39 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 21:18:39 - train.py[line:550] - INFO: load:2.65 valid_run:193.45 task_valid:184.69 collect_output:6.04
2023-10-04 21:20:16 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 21:20:16 - train.py[line:550] - INFO: load:2.74 valid_run:289.62 task_valid:273.76 collect_output:12.14
2023-10-04 21:21:51 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 21:21:51 - train.py[line:550] - INFO: load:2.83 valid_run:384.59 task_valid:363.74 collect_output:16.19
2023-10-04 21:23:27 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 21:23:27 - train.py[line:550] - INFO: load:2.91 valid_run:480.62 task_valid:453.84 collect_output:21.16
2023-10-04 21:25:03 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 21:25:03 - train.py[line:550] - INFO: load:3.00 valid_run:576.54 task_valid:543.40 collect_output:26.54
2023-10-04 21:26:38 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 21:26:38 - train.py[line:550] - INFO: load:3.08 valid_run:671.48 task_valid:633.73 collect_output:30.15
2023-10-04 21:28:14 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 21:28:14 - train.py[line:550] - INFO: load:3.16 valid_run:767.55 task_valid:725.94 collect_output:33.06
2023-10-04 21:29:51 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 21:29:51 - train.py[line:550] - INFO: load:3.25 valid_run:863.81 task_valid:816.82 collect_output:37.46
2023-10-04 21:31:27 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 21:31:27 - train.py[line:550] - INFO: load:3.34 valid_run:960.42 task_valid:908.44 collect_output:41.44
2023-10-04 21:33:03 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 21:33:03 - train.py[line:550] - INFO: load:3.43 valid_run:1055.96 task_valid:999.79 collect_output:44.67

====================================================================================================
SGG eval:     R @ 50: 0.3233;     R @ 100: 0.3790;     R @ 500: 0.4502;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1502;    mR @ 100: 0.2026;    mR @ 500: 0.2349;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3125) (playing:0.0000) (riding:0.4441) (says:0.0000) (sitting on:0.4399) (standing on:0.5350) (using:0.1500) (walking in:0.0000) (walking on:0.2162) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3233;     R @ 100: 0.3790;     R @ 500: 0.4502;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1502;    mR @ 100: 0.2026;    mR @ 500: 0.2349;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3125) (playing:0.0000) (riding:0.4441) (says:0.0000) (sitting on:0.4399) (standing on:0.5350) (using:0.1500) (walking in:0.0000) (walking on:0.2162) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3233;     R @ 100: 0.3790;     R @ 500: 0.4502;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1502;    mR @ 100: 0.2026;    mR @ 500: 0.2349;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3125) (playing:0.0000) (riding:0.4441) (says:0.0000) (sitting on:0.4399) (standing on:0.5350) (using:0.1500) (walking in:0.0000) (walking on:0.2162) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 21:34:18 - train.py[line:487] - INFO: 0.3790333333333333

====================================================================================================
SGG eval:     R @ 50: 0.3233;     R @ 100: 0.3790;     R @ 500: 0.4502;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1502;    mR @ 100: 0.2026;    mR @ 500: 0.2349;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3125) (playing:0.0000) (riding:0.4441) (says:0.0000) (sitting on:0.4399) (standing on:0.5350) (using:0.1500) (walking in:0.0000) (walking on:0.2162) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3233;     R @ 100: 0.3790;     R @ 500: 0.4502;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1502;    mR @ 100: 0.2026;    mR @ 500: 0.2349;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3125) (playing:0.0000) (riding:0.4441) (says:0.0000) (sitting on:0.4399) (standing on:0.5350) (using:0.1500) (walking in:0.0000) (walking on:0.2162) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3233;     R @ 100: 0.3790;     R @ 500: 0.4502;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1502;    mR @ 100: 0.2026;    mR @ 500: 0.2349;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3125) (playing:0.0000) (riding:0.4441) (says:0.0000) (sitting on:0.4399) (standing on:0.5350) (using:0.1500) (walking in:0.0000) (walking on:0.2162) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3233;     R @ 100: 0.3790;     R @ 500: 0.4502;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1502;    mR @ 100: 0.2026;    mR @ 500: 0.2349;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3125) (playing:0.0000) (riding:0.4441) (says:0.0000) (sitting on:0.4399) (standing on:0.5350) (using:0.1500) (walking in:0.0000) (walking on:0.2162) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3233;     R @ 100: 0.3790;     R @ 500: 0.4502;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1502;    mR @ 100: 0.2026;    mR @ 500: 0.2349;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.0000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3125) (playing:0.0000) (riding:0.4441) (says:0.0000) (sitting on:0.4399) (standing on:0.5350) (using:0.1500) (walking in:0.0000) (walking on:0.2162) (watching:0.0000) 
--------------------------------------------------------
====================================================================================================

2023-10-04 21:34:19 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-04 21:34:19 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.253 | loss_v1 0 | loss_v2 0 | nll_loss 0.084 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.379033 | ppl 1.06 | vqa_score 0.1791 | wps 396.2 | wpb 191.9 | bsz 64 | num_updates 1200 | best_R@100 0.379033
2023-10-04 21:34:19 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 1200 updates
2023-10-04 21:34:19 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1200.pt
2023-10-04 21:34:25 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1200.pt
2023-10-04 21:35:09 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1200.pt (epoch 2 @ 1200 updates, score 0.3790333333333333) (writing took 50.600344844162464 seconds)
2023-10-04 21:35:16 - progress_bar.py[line:272] - INFO: epoch 002:    303 / 907 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.121, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=2.3, ups=0.01, wpb=269.1, bsz=96, num_updates=1210, lr=4.48291e-05, gnorm=0.785, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=7942
2023-10-04 21:35:23 - progress_bar.py[line:272] - INFO: epoch 002:    313 / 907 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=374.5, ups=1.39, wpb=269.1, bsz=96, num_updates=1220, lr=4.47647e-05, gnorm=0.82, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=7949
2023-10-04 21:35:30 - progress_bar.py[line:272] - INFO: epoch 002:    323 / 907 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.108, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=401.1, ups=1.49, wpb=268.6, bsz=96, num_updates=1230, lr=4.47002e-05, gnorm=0.844, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=7956
2023-10-04 21:35:37 - progress_bar.py[line:272] - INFO: epoch 002:    333 / 907 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=267.5, nsentences=96, sample_size=267.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=400.7, ups=1.5, wpb=267.5, bsz=96, num_updates=1240, lr=4.46357e-05, gnorm=0.979, clip=50, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=7963
2023-10-04 21:35:43 - progress_bar.py[line:272] - INFO: epoch 002:    343 / 907 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.114, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=402.5, ups=1.49, wpb=269.6, bsz=96, num_updates=1250, lr=4.45712e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=7969
2023-10-04 21:35:50 - progress_bar.py[line:272] - INFO: epoch 002:    353 / 907 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.111, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=389, ups=1.44, wpb=270.6, bsz=96, num_updates=1260, lr=4.45068e-05, gnorm=0.822, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=7976
2023-10-04 21:35:57 - progress_bar.py[line:272] - INFO: epoch 002:    363 / 907 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.105, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=389.7, ups=1.45, wpb=268.9, bsz=96, num_updates=1270, lr=4.44423e-05, gnorm=0.704, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=7983
2023-10-04 21:36:04 - progress_bar.py[line:272] - INFO: epoch 002:    373 / 907 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.12, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=401.3, ups=1.49, wpb=269.3, bsz=96, num_updates=1280, lr=4.43778e-05, gnorm=1.076, clip=50, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=7990
2023-10-04 21:36:11 - progress_bar.py[line:272] - INFO: epoch 002:    383 / 907 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=392.6, ups=1.45, wpb=270.6, bsz=96, num_updates=1290, lr=4.43133e-05, gnorm=0.914, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=7997
2023-10-04 21:36:18 - progress_bar.py[line:272] - INFO: epoch 002:    393 / 907 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.108, ntokens=267.9, nsentences=96, sample_size=267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=387.7, ups=1.45, wpb=267.9, bsz=96, num_updates=1300, lr=4.42489e-05, gnorm=0.942, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=8004
2023-10-04 21:36:24 - progress_bar.py[line:272] - INFO: epoch 002:    403 / 907 loss=0.303, loss_v1=0, loss_v2=0, nll_loss=0.13, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=402, ups=1.49, wpb=269.9, bsz=96, num_updates=1310, lr=4.41844e-05, gnorm=0.983, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=8010
2023-10-04 21:36:31 - progress_bar.py[line:272] - INFO: epoch 002:    413 / 907 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=399.1, ups=1.49, wpb=268.2, bsz=96, num_updates=1320, lr=4.41199e-05, gnorm=0.876, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=8017
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 21:36:38 - progress_bar.py[line:272] - INFO: epoch 002:    423 / 907 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.112, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=387.7, ups=1.44, wpb=268.4, bsz=96, num_updates=1330, lr=4.40554e-05, gnorm=0.84, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=8024
2023-10-04 21:36:45 - progress_bar.py[line:272] - INFO: epoch 002:    433 / 907 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=390.2, ups=1.44, wpb=270.5, bsz=96, num_updates=1340, lr=4.3991e-05, gnorm=1.068, clip=60, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=8031
2023-10-04 21:36:52 - progress_bar.py[line:272] - INFO: epoch 002:    443 / 907 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.128, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=380.3, ups=1.41, wpb=269.2, bsz=96, num_updates=1350, lr=4.39265e-05, gnorm=0.904, clip=40, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=8038
2023-10-04 21:36:59 - progress_bar.py[line:272] - INFO: epoch 002:    453 / 907 loss=0.292, loss_v1=0, loss_v2=0, nll_loss=0.119, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=399.3, ups=1.48, wpb=268.9, bsz=96, num_updates=1360, lr=4.3862e-05, gnorm=0.816, clip=30, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=8045
2023-10-04 21:37:05 - progress_bar.py[line:272] - INFO: epoch 002:    463 / 907 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.109, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=403.5, ups=1.49, wpb=270, bsz=96, num_updates=1370, lr=4.37975e-05, gnorm=0.769, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=8051
@@@@ ERROR IN DATA @@@@ play
2023-10-04 21:37:13 - progress_bar.py[line:272] - INFO: epoch 002:    473 / 907 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.117, ntokens=266.5, nsentences=96, sample_size=266.5, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=377.2, ups=1.42, wpb=266.5, bsz=96, num_updates=1380, lr=4.37331e-05, gnorm=0.778, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=8059
@@@@ ERROR IN DATA @@@@ stand on
2023-10-04 21:37:19 - progress_bar.py[line:272] - INFO: epoch 002:    483 / 907 loss=0.304, loss_v1=0, loss_v2=0, nll_loss=0.129, ntokens=267.3, nsentences=96, sample_size=267.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=386.8, ups=1.45, wpb=267.3, bsz=96, num_updates=1390, lr=4.36686e-05, gnorm=1.02, clip=30, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=8065
2023-10-04 21:37:26 - progress_bar.py[line:272] - INFO: epoch 002:    493 / 907 loss=0.297, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=388.8, ups=1.44, wpb=269.4, bsz=96, num_updates=1400, lr=4.36041e-05, gnorm=0.914, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=8072
2023-10-04 21:37:26 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 21:37:29 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 21:37:29 - train.py[line:550] - INFO: load:2.74 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 21:39:07 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 21:39:07 - train.py[line:550] - INFO: load:2.83 valid_run:97.37 task_valid:93.58 collect_output:2.78
2023-10-04 21:40:43 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 21:40:43 - train.py[line:550] - INFO: load:2.93 valid_run:193.65 task_valid:185.49 collect_output:6.17
2023-10-04 21:42:19 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 21:42:19 - train.py[line:550] - INFO: load:3.02 valid_run:289.48 task_valid:274.51 collect_output:12.04
2023-10-04 21:43:55 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 21:43:55 - train.py[line:550] - INFO: load:3.11 valid_run:384.98 task_valid:364.67 collect_output:16.37
2023-10-04 21:45:31 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 21:45:31 - train.py[line:550] - INFO: load:3.20 valid_run:480.85 task_valid:454.91 collect_output:21.00
2023-10-04 21:47:07 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 21:47:07 - train.py[line:550] - INFO: load:3.29 valid_run:576.62 task_valid:544.58 collect_output:26.16
2023-10-04 21:48:41 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 21:48:41 - train.py[line:550] - INFO: load:3.37 valid_run:671.21 task_valid:635.19 collect_output:29.19
2023-10-04 21:50:18 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 21:50:18 - train.py[line:550] - INFO: load:3.46 valid_run:767.33 task_valid:727.76 collect_output:31.73
2023-10-04 21:51:54 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 21:51:54 - train.py[line:550] - INFO: load:3.55 valid_run:863.49 task_valid:818.62 collect_output:36.01
2023-10-04 21:53:30 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 21:53:30 - train.py[line:550] - INFO: load:3.65 valid_run:959.22 task_valid:910.33 collect_output:39.07
2023-10-04 21:55:05 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 21:55:05 - train.py[line:550] - INFO: load:3.73 valid_run:1054.62 task_valid:1001.87 collect_output:41.97

====================================================================================================
SGG eval:     R @ 50: 0.3520;     R @ 100: 0.4074;     R @ 500: 0.4773;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1654;    mR @ 100: 0.2213;    mR @ 500: 0.2600;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3750) (playing:0.0000) (riding:0.5147) (says:0.0000) (sitting on:0.4785) (standing on:0.5267) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0278) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3520;     R @ 100: 0.4074;     R @ 500: 0.4773;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1654;    mR @ 100: 0.2213;    mR @ 500: 0.2600;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3750) (playing:0.0000) (riding:0.5147) (says:0.0000) (sitting on:0.4785) (standing on:0.5267) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0278) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3520;     R @ 100: 0.4074;     R @ 500: 0.4773;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1654;    mR @ 100: 0.2213;    mR @ 500: 0.2600;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3750) (playing:0.0000) (riding:0.5147) (says:0.0000) (sitting on:0.4785) (standing on:0.5267) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0278) 
--------------------------------------------------------
====================================================================================================

2023-10-04 21:56:21 - train.py[line:487] - INFO: 0.4074333333333333

====================================================================================================
SGG eval:     R @ 50: 0.3520;     R @ 100: 0.4074;     R @ 500: 0.4773;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1654;    mR @ 100: 0.2213;    mR @ 500: 0.2600;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3750) (playing:0.0000) (riding:0.5147) (says:0.0000) (sitting on:0.4785) (standing on:0.5267) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0278) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3520;     R @ 100: 0.4074;     R @ 500: 0.4773;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1654;    mR @ 100: 0.2213;    mR @ 500: 0.2600;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3750) (playing:0.0000) (riding:0.5147) (says:0.0000) (sitting on:0.4785) (standing on:0.5267) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0278) 
--------------------------------------------------------
====================================================================================================

2023-10-04 21:56:21 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-04 21:56:21 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.246 | loss_v1 0 | loss_v2 0 | nll_loss 0.075 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.407433 | ppl 1.05 | vqa_score 0.1858 | wps 396.6 | wpb 191.9 | bsz 64 | num_updates 1400 | best_R@100 0.407433
2023-10-04 21:56:21 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 1400 updates
2023-10-04 21:56:21 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1400.pt

====================================================================================================
SGG eval:     R @ 50: 0.3520;     R @ 100: 0.4074;     R @ 500: 0.4773;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1654;    mR @ 100: 0.2213;    mR @ 500: 0.2600;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3750) (playing:0.0000) (riding:0.5147) (says:0.0000) (sitting on:0.4785) (standing on:0.5267) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0278) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3520;     R @ 100: 0.4074;     R @ 500: 0.4773;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1654;    mR @ 100: 0.2213;    mR @ 500: 0.2600;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3750) (playing:0.0000) (riding:0.5147) (says:0.0000) (sitting on:0.4785) (standing on:0.5267) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0278) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.3520;     R @ 100: 0.4074;     R @ 500: 0.4773;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1654;    mR @ 100: 0.2213;    mR @ 500: 0.2600;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1220) (covered in:0.0000) (covering:0.1429) (eating:0.3824) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5484) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.3750) (playing:0.0000) (riding:0.5147) (says:0.0000) (sitting on:0.4785) (standing on:0.5267) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0278) 
--------------------------------------------------------
====================================================================================================

2023-10-04 21:56:26 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1400.pt
2023-10-04 21:57:10 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1400.pt (epoch 2 @ 1400 updates, score 0.4074333333333333) (writing took 49.47777589596808 seconds)
2023-10-04 21:57:17 - progress_bar.py[line:272] - INFO: epoch 002:    503 / 907 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.116, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=2.3, ups=0.01, wpb=270.4, bsz=96, num_updates=1410, lr=4.35397e-05, gnorm=0.903, clip=20, loss_scale=512, train_wall=7, gb_free=6, ema_decay=0.9999, wall=9263
2023-10-04 21:57:24 - progress_bar.py[line:272] - INFO: epoch 002:    513 / 907 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.119, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=402.1, ups=1.5, wpb=268.9, bsz=96, num_updates=1420, lr=4.34752e-05, gnorm=0.893, clip=40, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=9270
2023-10-04 21:57:30 - progress_bar.py[line:272] - INFO: epoch 002:    523 / 907 loss=0.298, loss_v1=0, loss_v2=0, nll_loss=0.127, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=402.8, ups=1.49, wpb=271.2, bsz=96, num_updates=1430, lr=4.34107e-05, gnorm=0.874, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=9276
2023-10-04 21:57:37 - progress_bar.py[line:272] - INFO: epoch 002:    533 / 907 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.106, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=395.2, ups=1.47, wpb=268, bsz=96, num_updates=1440, lr=4.33462e-05, gnorm=0.95, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=9283
2023-10-04 21:57:44 - progress_bar.py[line:272] - INFO: epoch 002:    543 / 907 loss=0.302, loss_v1=0, loss_v2=0, nll_loss=0.126, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=391.8, ups=1.46, wpb=268.4, bsz=96, num_updates=1450, lr=4.32818e-05, gnorm=0.956, clip=50, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=9290
2023-10-04 21:57:51 - progress_bar.py[line:272] - INFO: epoch 002:    553 / 907 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.111, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=389.9, ups=1.45, wpb=269.3, bsz=96, num_updates=1460, lr=4.32173e-05, gnorm=0.617, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=9297
2023-10-04 21:57:58 - progress_bar.py[line:272] - INFO: epoch 002:    563 / 907 loss=0.295, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=401.5, ups=1.49, wpb=268.6, bsz=96, num_updates=1470, lr=4.31528e-05, gnorm=0.836, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=9304
2023-10-04 21:58:04 - progress_bar.py[line:272] - INFO: epoch 002:    573 / 907 loss=0.301, loss_v1=0, loss_v2=0, nll_loss=0.121, ntokens=267.2, nsentences=96, sample_size=267.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=395.7, ups=1.48, wpb=267.2, bsz=96, num_updates=1480, lr=4.30883e-05, gnorm=0.905, clip=20, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=9310
2023-10-04 21:58:11 - progress_bar.py[line:272] - INFO: epoch 002:    583 / 907 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=399.5, ups=1.49, wpb=268.1, bsz=96, num_updates=1490, lr=4.30239e-05, gnorm=0.807, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=9317
2023-10-04 21:58:18 - progress_bar.py[line:272] - INFO: epoch 002:    593 / 907 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.106, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=391.8, ups=1.45, wpb=269.4, bsz=96, num_updates=1500, lr=4.29594e-05, gnorm=0.636, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=9324
2023-10-04 21:58:25 - progress_bar.py[line:272] - INFO: epoch 002:    603 / 907 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.112, ntokens=271.4, nsentences=96, sample_size=271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=402.8, ups=1.48, wpb=271.4, bsz=96, num_updates=1510, lr=4.28949e-05, gnorm=0.745, clip=10, loss_scale=512, train_wall=7, gb_free=6.6, ema_decay=0.9999, wall=9331
2023-10-04 21:58:32 - progress_bar.py[line:272] - INFO: epoch 002:    613 / 907 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.113, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=387.6, ups=1.45, wpb=268, bsz=96, num_updates=1520, lr=4.28304e-05, gnorm=0.818, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=9338
@@@@ ERROR IN DATA @@@@ watch
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 21:58:38 - progress_bar.py[line:272] - INFO: epoch 002:    623 / 907 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.123, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=402.4, ups=1.49, wpb=270.2, bsz=96, num_updates=1530, lr=4.2766e-05, gnorm=0.877, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=9344
2023-10-04 21:58:45 - progress_bar.py[line:272] - INFO: epoch 002:    633 / 907 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.107, ntokens=267.7, nsentences=96, sample_size=267.7, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=388, ups=1.45, wpb=267.7, bsz=96, num_updates=1540, lr=4.27015e-05, gnorm=0.808, clip=20, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=9351
2023-10-04 21:58:50 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-10-04 21:58:53 - progress_bar.py[line:272] - INFO: epoch 002:    644 / 907 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.105, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=369.4, ups=1.37, wpb=270.5, bsz=96, num_updates=1550, lr=4.2637e-05, gnorm=0.763, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=9359
2023-10-04 21:58:59 - progress_bar.py[line:272] - INFO: epoch 002:    654 / 907 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.116, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=401.1, ups=1.49, wpb=269.3, bsz=96, num_updates=1560, lr=4.25725e-05, gnorm=0.941, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=9365
2023-10-04 21:59:06 - progress_bar.py[line:272] - INFO: epoch 002:    664 / 907 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.108, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=382.7, ups=1.41, wpb=271, bsz=96, num_updates=1570, lr=4.25081e-05, gnorm=0.812, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=9372
2023-10-04 21:59:13 - progress_bar.py[line:272] - INFO: epoch 002:    674 / 907 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.111, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=385.4, ups=1.44, wpb=268.3, bsz=96, num_updates=1580, lr=4.24436e-05, gnorm=0.906, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=9379
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 21:59:20 - progress_bar.py[line:272] - INFO: epoch 002:    684 / 907 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.107, ntokens=271.7, nsentences=96, sample_size=271.7, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=394.6, ups=1.45, wpb=271.7, bsz=96, num_updates=1590, lr=4.23791e-05, gnorm=0.734, clip=0, loss_scale=512, train_wall=7, gb_free=5.9, ema_decay=0.9999, wall=9386
2023-10-04 21:59:27 - progress_bar.py[line:272] - INFO: epoch 002:    694 / 907 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.106, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=397.9, ups=1.48, wpb=268, bsz=96, num_updates=1600, lr=4.23146e-05, gnorm=0.807, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=9393
2023-10-04 21:59:27 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 21:59:29 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 21:59:29 - train.py[line:550] - INFO: load:1.91 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 21:59:30 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.90 GiB (GPU 2; 23.70 GiB total capacity; 6.57 GiB already allocated; 1.40 GiB free; 20.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-04 21:59:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:59:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:59:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 10        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6731 MiB |   7339 MiB |   1077 TiB |   1077 TiB |
|       from large pool |   6586 MiB |   7195 MiB |   1071 TiB |   1071 TiB |
|       from small pool |    144 MiB |    156 MiB |      5 TiB |      5 TiB |
|---------------------------------------------------------------------------|
| Active memory         |   6731 MiB |   7339 MiB |   1077 TiB |   1077 TiB |
|       from large pool |   6586 MiB |   7195 MiB |   1071 TiB |   1071 TiB |
|       from small pool |    144 MiB |    156 MiB |      5 TiB |      5 TiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6679 MiB |   7287 MiB |   1075 TiB |   1075 TiB |
|       from large pool |   6535 MiB |   7142 MiB |   1070 TiB |   1070 TiB |
|       from small pool |    144 MiB |    156 MiB |      5 TiB |      5 TiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  21414 MiB |  21966 MiB |  81676 MiB |  60262 MiB |
|       from large pool |  21268 MiB |  21804 MiB |  81268 MiB |  60000 MiB |
|       from small pool |    146 MiB |    162 MiB |    408 MiB |    262 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14682 MiB |  14682 MiB |   1056 TiB |   1056 TiB |
|       from large pool |  14681 MiB |  14681 MiB |   1050 TiB |   1050 TiB |
|       from small pool |      1 MiB |      5 MiB |      5 TiB |      5 TiB |
|---------------------------------------------------------------------------|
| Allocations           |    3567    |    3582    |   68710 K  |   68707 K  |
|       from large pool |     565    |     577    |   27778 K  |   27778 K  |
|       from small pool |    3002    |    3021    |   40931 K  |   40928 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3567    |    3582    |   68710 K  |   68707 K  |
|       from large pool |     565    |     577    |   27778 K  |   27778 K  |
|       from small pool |    3002    |    3021    |   40931 K  |   40928 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     143    |     153    |     418    |     275    |
|       from large pool |      70    |      72    |     214    |     144    |
|       from small pool |      73    |      81    |     204    |     131    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      88    |      91    |   38624 K  |   38623 K  |
|       from large pool |      60    |      60    |    9599 K  |    9599 K  |
|       from small pool |      28    |      37    |   29024 K  |   29024 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:59:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:59:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:59:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:59:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:59:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 21:59:30 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-04 22:01:07 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 22:01:07 - train.py[line:550] - INFO: load:1.99 valid_run:97.69 task_valid:93.32 collect_output:3.41
2023-10-04 22:02:44 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 22:02:44 - train.py[line:550] - INFO: load:2.07 valid_run:194.32 task_valid:185.40 collect_output:7.02
2023-10-04 22:04:20 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 22:04:20 - train.py[line:550] - INFO: load:2.17 valid_run:290.17 task_valid:274.39 collect_output:12.87
2023-10-04 22:05:55 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 22:05:55 - train.py[line:550] - INFO: load:2.25 valid_run:385.21 task_valid:364.52 collect_output:16.81
2023-10-04 22:07:31 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 22:07:31 - train.py[line:550] - INFO: load:2.33 valid_run:481.02 task_valid:454.65 collect_output:21.55
2023-10-04 22:09:07 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 22:09:07 - train.py[line:550] - INFO: load:2.42 valid_run:576.95 task_valid:544.37 collect_output:26.79
2023-10-04 22:10:42 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 22:10:42 - train.py[line:550] - INFO: load:2.49 valid_run:671.78 task_valid:634.84 collect_output:30.17
2023-10-04 22:12:18 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 22:12:18 - train.py[line:550] - INFO: load:2.57 valid_run:767.92 task_valid:727.15 collect_output:33.02
2023-10-04 22:13:54 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 22:13:54 - train.py[line:550] - INFO: load:2.67 valid_run:863.76 task_valid:818.00 collect_output:36.99
2023-10-04 22:15:30 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 22:15:30 - train.py[line:550] - INFO: load:2.75 valid_run:960.00 task_valid:909.72 collect_output:40.49
2023-10-04 22:17:06 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 22:17:06 - train.py[line:550] - INFO: load:2.85 valid_run:1055.72 task_valid:1001.38 collect_output:43.55

====================================================================================================
SGG eval:     R @ 50: 0.4009;     R @ 100: 0.4423;     R @ 500: 0.5082;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1946;    mR @ 100: 0.2372;    mR @ 500: 0.2788;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1951) (covered in:0.0000) (covering:0.1429) (eating:0.4118) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.5490) (says:0.0000) (sitting on:0.5091) (standing on:0.5858) (using:0.2000) (walking in:0.0000) (walking on:0.2432) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4009;     R @ 100: 0.4423;     R @ 500: 0.5082;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1946;    mR @ 100: 0.2372;    mR @ 500: 0.2788;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1951) (covered in:0.0000) (covering:0.1429) (eating:0.4118) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.5490) (says:0.0000) (sitting on:0.5091) (standing on:0.5858) (using:0.2000) (walking in:0.0000) (walking on:0.2432) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4009;     R @ 100: 0.4423;     R @ 500: 0.5082;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1946;    mR @ 100: 0.2372;    mR @ 500: 0.2788;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1951) (covered in:0.0000) (covering:0.1429) (eating:0.4118) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.5490) (says:0.0000) (sitting on:0.5091) (standing on:0.5858) (using:0.2000) (walking in:0.0000) (walking on:0.2432) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4009;     R @ 100: 0.4423;     R @ 500: 0.5082;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1946;    mR @ 100: 0.2372;    mR @ 500: 0.2788;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1951) (covered in:0.0000) (covering:0.1429) (eating:0.4118) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.5490) (says:0.0000) (sitting on:0.5091) (standing on:0.5858) (using:0.2000) (walking in:0.0000) (walking on:0.2432) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4009;     R @ 100: 0.4423;     R @ 500: 0.5082;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1946;    mR @ 100: 0.2372;    mR @ 500: 0.2788;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1951) (covered in:0.0000) (covering:0.1429) (eating:0.4118) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.5490) (says:0.0000) (sitting on:0.5091) (standing on:0.5858) (using:0.2000) (walking in:0.0000) (walking on:0.2432) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4009;     R @ 100: 0.4423;     R @ 500: 0.5082;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1946;    mR @ 100: 0.2372;    mR @ 500: 0.2788;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1951) (covered in:0.0000) (covering:0.1429) (eating:0.4118) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.5490) (says:0.0000) (sitting on:0.5091) (standing on:0.5858) (using:0.2000) (walking in:0.0000) (walking on:0.2432) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================

2023-10-04 22:18:22 - train.py[line:487] - INFO: 0.44226666666666664

====================================================================================================
SGG eval:     R @ 50: 0.4009;     R @ 100: 0.4423;     R @ 500: 0.5082;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1946;    mR @ 100: 0.2372;    mR @ 500: 0.2788;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1951) (covered in:0.0000) (covering:0.1429) (eating:0.4118) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.5490) (says:0.0000) (sitting on:0.5091) (standing on:0.5858) (using:0.2000) (walking in:0.0000) (walking on:0.2432) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4009;     R @ 100: 0.4423;     R @ 500: 0.5082;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.1946;    mR @ 100: 0.2372;    mR @ 500: 0.2788;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.1951) (covered in:0.0000) (covering:0.1429) (eating:0.4118) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5161) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.5490) (says:0.0000) (sitting on:0.5091) (standing on:0.5858) (using:0.2000) (walking in:0.0000) (walking on:0.2432) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================

2023-10-04 22:18:22 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-04 22:18:22 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.263 | loss_v1 0 | loss_v2 0 | nll_loss 0.098 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.442267 | ppl 1.07 | vqa_score 0.1914 | wps 396.3 | wpb 191.9 | bsz 64 | num_updates 1600 | best_R@100 0.442267
2023-10-04 22:18:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 1600 updates
2023-10-04 22:18:22 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1600.pt
2023-10-04 22:18:28 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1600.pt
2023-10-04 22:19:11 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1600.pt (epoch 2 @ 1600 updates, score 0.44226666666666664) (writing took 48.744967475067824 seconds)
2023-10-04 22:19:18 - progress_bar.py[line:272] - INFO: epoch 002:    704 / 907 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.104, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=2.3, ups=0.01, wpb=269.4, bsz=96, num_updates=1610, lr=4.22502e-05, gnorm=0.72, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10584
2023-10-04 22:19:24 - progress_bar.py[line:272] - INFO: epoch 002:    714 / 907 loss=0.291, loss_v1=0, loss_v2=0, nll_loss=0.117, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=404.7, ups=1.5, wpb=270.6, bsz=96, num_updates=1620, lr=4.21857e-05, gnorm=0.866, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10591
2023-10-04 22:19:31 - progress_bar.py[line:272] - INFO: epoch 002:    724 / 907 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.111, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=400.9, ups=1.48, wpb=270.2, bsz=96, num_updates=1630, lr=4.21212e-05, gnorm=0.802, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10597
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 22:19:38 - progress_bar.py[line:272] - INFO: epoch 002:    734 / 907 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.1, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=403.7, ups=1.49, wpb=270.4, bsz=96, num_updates=1640, lr=4.20567e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10604
@@@@ ERROR IN DATA @@@@ stand on
2023-10-04 22:19:45 - progress_bar.py[line:272] - INFO: epoch 002:    744 / 907 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.099, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=387.3, ups=1.44, wpb=268.9, bsz=96, num_updates=1650, lr=4.19923e-05, gnorm=0.794, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10611
2023-10-04 22:19:52 - progress_bar.py[line:272] - INFO: epoch 002:    754 / 907 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.113, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=402.1, ups=1.49, wpb=270.1, bsz=96, num_updates=1660, lr=4.19278e-05, gnorm=0.848, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10618
2023-10-04 22:19:58 - progress_bar.py[line:272] - INFO: epoch 002:    764 / 907 loss=0.296, loss_v1=0, loss_v2=0, nll_loss=0.124, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=392.5, ups=1.46, wpb=269.7, bsz=96, num_updates=1670, lr=4.18633e-05, gnorm=0.882, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=10624
2023-10-04 22:20:05 - progress_bar.py[line:272] - INFO: epoch 002:    774 / 907 loss=0.287, loss_v1=0, loss_v2=0, nll_loss=0.114, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=404.7, ups=1.5, wpb=270.4, bsz=96, num_updates=1680, lr=4.17988e-05, gnorm=0.835, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10631
@@@@ ERROR IN DATA @@@@ stand on
2023-10-04 22:20:12 - progress_bar.py[line:272] - INFO: epoch 002:    784 / 907 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.103, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=399.7, ups=1.49, wpb=268.1, bsz=96, num_updates=1690, lr=4.17344e-05, gnorm=0.689, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=10638
2023-10-04 22:20:19 - progress_bar.py[line:272] - INFO: epoch 002:    794 / 907 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.103, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=389.8, ups=1.45, wpb=269.2, bsz=96, num_updates=1700, lr=4.16699e-05, gnorm=0.789, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10645
2023-10-04 22:20:26 - progress_bar.py[line:272] - INFO: epoch 002:    804 / 907 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.111, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=388.1, ups=1.44, wpb=269, bsz=96, num_updates=1710, lr=4.16054e-05, gnorm=0.804, clip=20, loss_scale=512, train_wall=7, gb_free=5.9, ema_decay=0.9999, wall=10652
2023-10-04 22:20:32 - progress_bar.py[line:272] - INFO: epoch 002:    814 / 907 loss=0.284, loss_v1=0, loss_v2=0, nll_loss=0.107, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=401.1, ups=1.49, wpb=269.7, bsz=96, num_updates=1720, lr=4.15409e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=10658
2023-10-04 22:20:39 - progress_bar.py[line:272] - INFO: epoch 002:    824 / 907 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.111, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=390.8, ups=1.44, wpb=270.5, bsz=96, num_updates=1730, lr=4.14765e-05, gnorm=0.987, clip=50, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10665
@@@@ ERROR IN DATA @@@@ play
2023-10-04 22:20:46 - progress_bar.py[line:272] - INFO: epoch 002:    834 / 907 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.12, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=400.3, ups=1.49, wpb=268, bsz=96, num_updates=1740, lr=4.1412e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10672
2023-10-04 22:20:53 - progress_bar.py[line:272] - INFO: epoch 002:    844 / 907 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.104, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400.9, ups=1.48, wpb=270.1, bsz=96, num_updates=1750, lr=4.13475e-05, gnorm=0.825, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10679
2023-10-04 22:21:00 - progress_bar.py[line:272] - INFO: epoch 002:    854 / 907 loss=0.293, loss_v1=0, loss_v2=0, nll_loss=0.116, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=391.3, ups=1.46, wpb=268.6, bsz=96, num_updates=1760, lr=4.1283e-05, gnorm=0.853, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10686
2023-10-04 22:21:07 - progress_bar.py[line:272] - INFO: epoch 002:    864 / 907 loss=0.294, loss_v1=0, loss_v2=0, nll_loss=0.122, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.09, wps=393.8, ups=1.46, wpb=270.3, bsz=96, num_updates=1770, lr=4.12186e-05, gnorm=0.798, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10693
2023-10-04 22:21:14 - progress_bar.py[line:272] - INFO: epoch 002:    874 / 907 loss=0.288, loss_v1=0, loss_v2=0, nll_loss=0.11, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=371.1, ups=1.38, wpb=268.7, bsz=96, num_updates=1780, lr=4.11541e-05, gnorm=0.78, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=10700
2023-10-04 22:21:20 - progress_bar.py[line:272] - INFO: epoch 002:    884 / 907 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.106, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=405.3, ups=1.5, wpb=270.7, bsz=96, num_updates=1790, lr=4.10896e-05, gnorm=0.796, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=10707
2023-10-04 22:21:27 - progress_bar.py[line:272] - INFO: epoch 002:    894 / 907 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.103, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=399.9, ups=1.48, wpb=270.9, bsz=96, num_updates=1800, lr=4.10251e-05, gnorm=0.758, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=10713
2023-10-04 22:21:27 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 22:21:29 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 22:21:29 - train.py[line:550] - INFO: load:2.06 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 22:23:07 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 22:23:07 - train.py[line:550] - INFO: load:2.15 valid_run:97.57 task_valid:93.23 collect_output:3.28
2023-10-04 22:24:44 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 22:24:44 - train.py[line:550] - INFO: load:2.24 valid_run:193.87 task_valid:185.10 collect_output:6.72
2023-10-04 22:26:20 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 22:26:20 - train.py[line:550] - INFO: load:2.33 valid_run:289.95 task_valid:274.04 collect_output:12.90
2023-10-04 22:27:55 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 22:27:55 - train.py[line:550] - INFO: load:2.41 valid_run:385.17 task_valid:364.04 collect_output:17.16
2023-10-04 22:29:31 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 22:29:31 - train.py[line:550] - INFO: load:2.49 valid_run:481.08 task_valid:454.17 collect_output:21.97
2023-10-04 22:31:07 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 22:31:07 - train.py[line:550] - INFO: load:2.57 valid_run:576.79 task_valid:543.84 collect_output:27.08
2023-10-04 22:32:42 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 22:32:42 - train.py[line:550] - INFO: load:2.65 valid_run:671.95 task_valid:634.22 collect_output:30.93
2023-10-04 22:34:18 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 22:34:18 - train.py[line:550] - INFO: load:2.74 valid_run:767.60 task_valid:726.39 collect_output:33.45
2023-10-04 22:35:54 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 22:35:54 - train.py[line:550] - INFO: load:2.82 valid_run:863.89 task_valid:817.42 collect_output:37.70
2023-10-04 22:37:31 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 22:37:31 - train.py[line:550] - INFO: load:2.91 valid_run:960.21 task_valid:909.08 collect_output:41.41
2023-10-04 22:39:06 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 22:39:06 - train.py[line:550] - INFO: load:2.99 valid_run:1055.60 task_valid:1000.46 collect_output:44.48

====================================================================================================
SGG eval:     R @ 50: 0.4215;     R @ 100: 0.4676;     R @ 500: 0.5405;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2212;    mR @ 100: 0.2531;    mR @ 500: 0.3087;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2244) (covered in:0.0625) (covering:0.1429) (eating:0.5147) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5548) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.6144) (says:0.0000) (sitting on:0.5295) (standing on:0.6108) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4215;     R @ 100: 0.4676;     R @ 500: 0.5405;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2212;    mR @ 100: 0.2531;    mR @ 500: 0.3087;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2244) (covered in:0.0625) (covering:0.1429) (eating:0.5147) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5548) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.6144) (says:0.0000) (sitting on:0.5295) (standing on:0.6108) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4215;     R @ 100: 0.4676;     R @ 500: 0.5405;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2212;    mR @ 100: 0.2531;    mR @ 500: 0.3087;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2244) (covered in:0.0625) (covering:0.1429) (eating:0.5147) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5548) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.6144) (says:0.0000) (sitting on:0.5295) (standing on:0.6108) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4215;     R @ 100: 0.4676;     R @ 500: 0.5405;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2212;    mR @ 100: 0.2531;    mR @ 500: 0.3087;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2244) (covered in:0.0625) (covering:0.1429) (eating:0.5147) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5548) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.6144) (says:0.0000) (sitting on:0.5295) (standing on:0.6108) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4215;     R @ 100: 0.4676;     R @ 500: 0.5405;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2212;    mR @ 100: 0.2531;    mR @ 500: 0.3087;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2244) (covered in:0.0625) (covering:0.1429) (eating:0.5147) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5548) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.6144) (says:0.0000) (sitting on:0.5295) (standing on:0.6108) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================

2023-10-04 22:40:22 - train.py[line:487] - INFO: 0.46756666666666674

====================================================================================================
SGG eval:     R @ 50: 0.4215;     R @ 100: 0.4676;     R @ 500: 0.5405;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2212;    mR @ 100: 0.2531;    mR @ 500: 0.3087;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2244) (covered in:0.0625) (covering:0.1429) (eating:0.5147) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5548) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.6144) (says:0.0000) (sitting on:0.5295) (standing on:0.6108) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4215;     R @ 100: 0.4676;     R @ 500: 0.5405;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2212;    mR @ 100: 0.2531;    mR @ 500: 0.3087;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2244) (covered in:0.0625) (covering:0.1429) (eating:0.5147) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5548) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.6144) (says:0.0000) (sitting on:0.5295) (standing on:0.6108) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================

2023-10-04 22:40:22 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-04 22:40:22 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss 0.248 | loss_v1 0 | loss_v2 0 | nll_loss 0.078 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.467567 | ppl 1.06 | vqa_score 0.1982 | wps 396.3 | wpb 191.9 | bsz 64 | num_updates 1800 | best_R@100 0.467567
2023-10-04 22:40:22 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 1800 updates
2023-10-04 22:40:22 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1800.pt

====================================================================================================
SGG eval:     R @ 50: 0.4215;     R @ 100: 0.4676;     R @ 500: 0.5405;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2212;    mR @ 100: 0.2531;    mR @ 500: 0.3087;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.2244) (covered in:0.0625) (covering:0.1429) (eating:0.5147) (flying in:0.5000) (growing on:0.1250) (hanging from:0.5548) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.4583) (playing:0.0000) (riding:0.6144) (says:0.0000) (sitting on:0.5295) (standing on:0.6108) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.0417) 
--------------------------------------------------------
====================================================================================================

2023-10-04 22:40:29 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1800.pt
2023-10-04 22:41:19 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_2_1800.pt (epoch 2 @ 1800 updates, score 0.46756666666666674) (writing took 56.80331844184548 seconds)
2023-10-04 22:41:26 - progress_bar.py[line:272] - INFO: epoch 002:    904 / 907 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.107, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=2.3, ups=0.01, wpb=269.8, bsz=96, num_updates=1810, lr=4.09607e-05, gnorm=0.819, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=11912
2023-10-04 22:41:28 - train.py[line:339] - INFO: end of epoch 2 (average epoch stats below)
2023-10-04 22:41:28 - progress_bar.py[line:282] - INFO: epoch 002 | loss 0.291 | loss_v1 0 | loss_v2 0 | nll_loss 0.116 | ntokens 269.245 | nsentences 95.914 | sample_size 269.245 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.08 | wps 37.2 | ups 0.14 | wpb 269.2 | bsz 95.9 | num_updates 1813 | lr 4.09413e-05 | gnorm 0.848 | clip 20.4 | loss_scale 512 | train_wall 617 | gb_free 16.4 | ema_decay 0.9999 | wall 11914
2023-10-04 22:41:28 - trainer.py[line:694] - INFO: loading train data for epoch 3
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv slice_id 3 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv slice_id 0 row count 10875 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv slice_id 4 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv slice_id 7 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv slice_id 5 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv slice_id 1 row count 10875 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv slice_id 6 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E2.tsv slice_id 2 row count 10874 total row count 86994
2023-10-04 22:41:28 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
2023-10-04 22:41:28 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-04 22:41:28 - trainer.py[line:758] - INFO: begin training epoch 3
2023-10-04 22:41:28 - train.py[line:312] - INFO: Start iterating over samples
2023-10-04 22:41:37 - progress_bar.py[line:272] - INFO: epoch 003:      7 / 907 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.094, ntokens=246.7, nsentences=88.2, sample_size=246.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=233.7, ups=0.95, wpb=246.7, bsz=88.2, num_updates=1820, lr=4.08962e-05, gnorm=0.869, clip=10, loss_scale=512, train_wall=8, gb_free=6.4, ema_decay=0.9999, wall=11923
2023-10-04 22:41:44 - progress_bar.py[line:272] - INFO: epoch 003:     17 / 907 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.095, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=390, ups=1.44, wpb=270.6, bsz=96, num_updates=1830, lr=4.08317e-05, gnorm=0.724, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=11930
2023-10-04 22:41:51 - progress_bar.py[line:272] - INFO: epoch 003:     27 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.093, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=387.1, ups=1.44, wpb=268.9, bsz=96, num_updates=1840, lr=4.07672e-05, gnorm=0.708, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=11937
2023-10-04 22:41:58 - progress_bar.py[line:272] - INFO: epoch 003:     37 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.2, ups=1.44, wpb=270.1, bsz=96, num_updates=1850, lr=4.07028e-05, gnorm=0.761, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=11944
2023-10-04 22:42:04 - progress_bar.py[line:272] - INFO: epoch 003:     47 / 907 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.095, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=403.6, ups=1.5, wpb=269.7, bsz=96, num_updates=1860, lr=4.06383e-05, gnorm=0.711, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=11950
2023-10-04 22:42:11 - progress_bar.py[line:272] - INFO: epoch 003:     57 / 907 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.1, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=402.7, ups=1.49, wpb=270.7, bsz=96, num_updates=1870, lr=4.05738e-05, gnorm=0.938, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=11957
2023-10-04 22:42:18 - progress_bar.py[line:272] - INFO: epoch 003:     67 / 907 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.096, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=401.8, ups=1.49, wpb=270.4, bsz=96, num_updates=1880, lr=4.05093e-05, gnorm=0.785, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=11964
2023-10-04 22:42:25 - progress_bar.py[line:272] - INFO: epoch 003:     77 / 907 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.089, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=377.9, ups=1.4, wpb=269, bsz=96, num_updates=1890, lr=4.04449e-05, gnorm=0.848, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=11971
2023-10-04 22:42:32 - progress_bar.py[line:272] - INFO: epoch 003:     87 / 907 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.101, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400.6, ups=1.49, wpb=268.5, bsz=96, num_updates=1900, lr=4.03804e-05, gnorm=0.973, clip=40, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=11978
2023-10-04 22:42:38 - progress_bar.py[line:272] - INFO: epoch 003:     97 / 907 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.098, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=401.9, ups=1.49, wpb=269.7, bsz=96, num_updates=1910, lr=4.03159e-05, gnorm=0.867, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=11984
@@@@ ERROR IN DATA @@@@ stand on
2023-10-04 22:42:45 - progress_bar.py[line:272] - INFO: epoch 003:    107 / 907 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.089, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=373.4, ups=1.38, wpb=270.9, bsz=96, num_updates=1920, lr=4.02515e-05, gnorm=0.81, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=11992
2023-10-04 22:42:52 - progress_bar.py[line:272] - INFO: epoch 003:    117 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=402.7, ups=1.49, wpb=271, bsz=96, num_updates=1930, lr=4.0187e-05, gnorm=0.651, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=11998
2023-10-04 22:42:59 - progress_bar.py[line:272] - INFO: epoch 003:    127 / 907 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.092, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=384.1, ups=1.43, wpb=268.2, bsz=96, num_updates=1940, lr=4.01225e-05, gnorm=0.813, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=12005
2023-10-04 22:43:06 - progress_bar.py[line:272] - INFO: epoch 003:    137 / 907 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.092, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=393.8, ups=1.45, wpb=271, bsz=96, num_updates=1950, lr=4.0058e-05, gnorm=0.728, clip=10, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=12012
2023-10-04 22:43:13 - progress_bar.py[line:272] - INFO: epoch 003:    147 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.088, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=391.7, ups=1.45, wpb=269.9, bsz=96, num_updates=1960, lr=3.99936e-05, gnorm=0.71, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=12019
2023-10-04 22:43:20 - progress_bar.py[line:272] - INFO: epoch 003:    157 / 907 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.096, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=388.2, ups=1.44, wpb=269.3, bsz=96, num_updates=1970, lr=3.99291e-05, gnorm=0.745, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=12026
2023-10-04 22:43:27 - progress_bar.py[line:272] - INFO: epoch 003:    167 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.096, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=386.1, ups=1.44, wpb=268.9, bsz=96, num_updates=1980, lr=3.98646e-05, gnorm=0.808, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=12033
2023-10-04 22:43:34 - progress_bar.py[line:272] - INFO: epoch 003:    177 / 907 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.105, ntokens=267.7, nsentences=96, sample_size=267.7, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=398.7, ups=1.49, wpb=267.7, bsz=96, num_updates=1990, lr=3.98001e-05, gnorm=0.804, clip=40, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=12040
2023-10-04 22:43:41 - progress_bar.py[line:272] - INFO: epoch 003:    187 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.1, ups=1.45, wpb=269.6, bsz=96, num_updates=2000, lr=3.97357e-05, gnorm=0.836, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=12047
2023-10-04 22:43:41 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 22:43:43 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 22:43:43 - train.py[line:550] - INFO: load:1.97 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 22:45:20 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 22:45:20 - train.py[line:550] - INFO: load:2.06 valid_run:97.30 task_valid:93.25 collect_output:3.01
2023-10-04 22:46:57 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 22:46:57 - train.py[line:550] - INFO: load:2.15 valid_run:193.69 task_valid:185.35 collect_output:6.31
2023-10-04 22:48:33 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 22:48:33 - train.py[line:550] - INFO: load:2.24 valid_run:289.72 task_valid:274.90 collect_output:11.74
2023-10-04 22:50:09 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 22:50:09 - train.py[line:550] - INFO: load:2.33 valid_run:385.24 task_valid:365.19 collect_output:15.99
2023-10-04 22:51:45 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 22:51:45 - train.py[line:550] - INFO: load:2.42 valid_run:481.15 task_valid:455.29 collect_output:20.79
2023-10-04 22:53:20 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 22:53:20 - train.py[line:550] - INFO: load:2.51 valid_run:576.93 task_valid:545.19 collect_output:25.72
2023-10-04 22:54:56 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 22:54:56 - train.py[line:550] - INFO: load:2.60 valid_run:672.33 task_valid:635.68 collect_output:29.65
2023-10-04 22:56:32 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 22:56:32 - train.py[line:550] - INFO: load:2.68 valid_run:768.12 task_valid:728.08 collect_output:32.03
2023-10-04 22:58:08 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 22:58:08 - train.py[line:550] - INFO: load:2.77 valid_run:863.93 task_valid:818.88 collect_output:36.09
2023-10-04 22:59:44 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 22:59:44 - train.py[line:550] - INFO: load:2.85 valid_run:959.75 task_valid:910.65 collect_output:39.14
2023-10-04 23:01:19 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 23:01:19 - train.py[line:550] - INFO: load:2.94 valid_run:1055.32 task_valid:1002.22 collect_output:42.19

====================================================================================================
SGG eval:     R @ 50: 0.4492;     R @ 100: 0.5021;     R @ 500: 0.5756;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2392;    mR @ 100: 0.2844;    mR @ 500: 0.3607;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.0625) (covering:0.2857) (eating:0.5294) (flying in:0.5909) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.5000) (playing:0.0000) (riding:0.6765) (says:0.0000) (sitting on:0.5677) (standing on:0.6275) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4492;     R @ 100: 0.5021;     R @ 500: 0.5756;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2392;    mR @ 100: 0.2844;    mR @ 500: 0.3607;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.0625) (covering:0.2857) (eating:0.5294) (flying in:0.5909) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.5000) (playing:0.0000) (riding:0.6765) (says:0.0000) (sitting on:0.5677) (standing on:0.6275) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4492;     R @ 100: 0.5021;     R @ 500: 0.5756;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2392;    mR @ 100: 0.2844;    mR @ 500: 0.3607;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.0625) (covering:0.2857) (eating:0.5294) (flying in:0.5909) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.5000) (playing:0.0000) (riding:0.6765) (says:0.0000) (sitting on:0.5677) (standing on:0.6275) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4492;     R @ 100: 0.5021;     R @ 500: 0.5756;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2392;    mR @ 100: 0.2844;    mR @ 500: 0.3607;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.0625) (covering:0.2857) (eating:0.5294) (flying in:0.5909) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.5000) (playing:0.0000) (riding:0.6765) (says:0.0000) (sitting on:0.5677) (standing on:0.6275) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4492;     R @ 100: 0.5021;     R @ 500: 0.5756;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2392;    mR @ 100: 0.2844;    mR @ 500: 0.3607;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.0625) (covering:0.2857) (eating:0.5294) (flying in:0.5909) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.5000) (playing:0.0000) (riding:0.6765) (says:0.0000) (sitting on:0.5677) (standing on:0.6275) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4492;     R @ 100: 0.5021;     R @ 500: 0.5756;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2392;    mR @ 100: 0.2844;    mR @ 500: 0.3607;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.0625) (covering:0.2857) (eating:0.5294) (flying in:0.5909) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.5000) (playing:0.0000) (riding:0.6765) (says:0.0000) (sitting on:0.5677) (standing on:0.6275) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================

2023-10-04 23:02:35 - train.py[line:487] - INFO: 0.5020969696969697

====================================================================================================
SGG eval:     R @ 50: 0.4492;     R @ 100: 0.5021;     R @ 500: 0.5756;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2392;    mR @ 100: 0.2844;    mR @ 500: 0.3607;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.0625) (covering:0.2857) (eating:0.5294) (flying in:0.5909) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.5000) (playing:0.0000) (riding:0.6765) (says:0.0000) (sitting on:0.5677) (standing on:0.6275) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4492;     R @ 100: 0.5021;     R @ 500: 0.5756;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2392;    mR @ 100: 0.2844;    mR @ 500: 0.3607;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.0625) (covering:0.2857) (eating:0.5294) (flying in:0.5909) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.5000) (playing:0.0000) (riding:0.6765) (says:0.0000) (sitting on:0.5677) (standing on:0.6275) (using:0.2000) (walking in:0.0000) (walking on:0.2162) (watching:0.1250) 
--------------------------------------------------------
====================================================================================================

2023-10-04 23:02:35 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-04 23:02:35 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.243 | loss_v1 0 | loss_v2 0 | nll_loss 0.068 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.502097 | ppl 1.05 | vqa_score 0.214 | wps 396.2 | wpb 191.9 | bsz 64 | num_updates 2000 | best_R@100 0.502097
2023-10-04 23:02:35 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 2000 updates
2023-10-04 23:02:35 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2000.pt
2023-10-04 23:02:42 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2000.pt
2023-10-04 23:03:27 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2000.pt (epoch 3 @ 2000 updates, score 0.5020969696969697) (writing took 51.877993133850396 seconds)
2023-10-04 23:03:34 - progress_bar.py[line:272] - INFO: epoch 003:    197 / 907 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.102, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=2.3, ups=0.01, wpb=270, bsz=96, num_updates=2010, lr=3.96712e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13240
2023-10-04 23:03:41 - progress_bar.py[line:272] - INFO: epoch 003:    207 / 907 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.098, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=401.1, ups=1.48, wpb=270.1, bsz=96, num_updates=2020, lr=3.96067e-05, gnorm=0.981, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13247
2023-10-04 23:03:48 - progress_bar.py[line:272] - INFO: epoch 003:    217 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.089, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=398.6, ups=1.48, wpb=268.4, bsz=96, num_updates=2030, lr=3.95422e-05, gnorm=0.851, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=13254
2023-10-04 23:03:54 - progress_bar.py[line:272] - INFO: epoch 003:    227 / 907 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.088, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=402.5, ups=1.49, wpb=269.8, bsz=96, num_updates=2040, lr=3.94778e-05, gnorm=0.911, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=13260
2023-10-04 23:04:01 - progress_bar.py[line:272] - INFO: epoch 003:    237 / 907 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.096, ntokens=272.3, nsentences=96, sample_size=272.3, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=405.3, ups=1.49, wpb=272.3, bsz=96, num_updates=2050, lr=3.94133e-05, gnorm=0.833, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13267
2023-10-04 23:04:08 - progress_bar.py[line:272] - INFO: epoch 003:    247 / 907 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.096, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=401.2, ups=1.48, wpb=270.3, bsz=96, num_updates=2060, lr=3.93488e-05, gnorm=0.797, clip=10, loss_scale=1024, train_wall=7, gb_free=6.6, ema_decay=0.9999, wall=13274
2023-10-04 23:04:15 - progress_bar.py[line:272] - INFO: epoch 003:    257 / 907 loss=0.29, loss_v1=0, loss_v2=0, nll_loss=0.114, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=387.6, ups=1.44, wpb=268.3, bsz=96, num_updates=2070, lr=3.92843e-05, gnorm=1.015, clip=50, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13281
2023-10-04 23:04:22 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 23:04:22 - progress_bar.py[line:272] - INFO: epoch 003:    268 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.085, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=366.5, ups=1.36, wpb=269.3, bsz=96, num_updates=2080, lr=3.92199e-05, gnorm=0.61, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13288
2023-10-04 23:04:29 - progress_bar.py[line:272] - INFO: epoch 003:    278 / 907 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.094, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400.7, ups=1.49, wpb=269, bsz=96, num_updates=2090, lr=3.91554e-05, gnorm=0.678, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13295
@@@@ ERROR IN DATA @@@@ stand on
2023-10-04 23:04:36 - progress_bar.py[line:272] - INFO: epoch 003:    288 / 907 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.105, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=389.7, ups=1.44, wpb=270.4, bsz=96, num_updates=2100, lr=3.90909e-05, gnorm=0.923, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13302
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 23:04:43 - progress_bar.py[line:272] - INFO: epoch 003:    298 / 907 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.097, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=399.5, ups=1.48, wpb=269.8, bsz=96, num_updates=2110, lr=3.90264e-05, gnorm=0.761, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13309
2023-10-04 23:04:50 - progress_bar.py[line:272] - INFO: epoch 003:    308 / 907 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.1, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=383.4, ups=1.42, wpb=269.4, bsz=96, num_updates=2120, lr=3.8962e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13316
2023-10-04 23:04:56 - progress_bar.py[line:272] - INFO: epoch 003:    318 / 907 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.103, ntokens=267.6, nsentences=96, sample_size=267.6, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=398.7, ups=1.49, wpb=267.6, bsz=96, num_updates=2130, lr=3.88975e-05, gnorm=0.681, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13322
2023-10-04 23:05:03 - progress_bar.py[line:272] - INFO: epoch 003:    328 / 907 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.099, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=402.3, ups=1.49, wpb=269.8, bsz=96, num_updates=2140, lr=3.8833e-05, gnorm=0.804, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13329
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 23:05:10 - progress_bar.py[line:272] - INFO: epoch 003:    338 / 907 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.098, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=390.3, ups=1.45, wpb=270, bsz=96, num_updates=2150, lr=3.87685e-05, gnorm=0.746, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13336
2023-10-04 23:05:17 - progress_bar.py[line:272] - INFO: epoch 003:    348 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.088, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=400.1, ups=1.49, wpb=268.7, bsz=96, num_updates=2160, lr=3.87041e-05, gnorm=0.66, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=13343
@@@@ ERROR IN DATA @@@@ stand on
2023-10-04 23:05:24 - progress_bar.py[line:272] - INFO: epoch 003:    358 / 907 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=392.4, ups=1.45, wpb=270.6, bsz=96, num_updates=2170, lr=3.86396e-05, gnorm=0.849, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13350
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 23:05:30 - progress_bar.py[line:272] - INFO: epoch 003:    368 / 907 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.101, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=391.6, ups=1.46, wpb=269, bsz=96, num_updates=2180, lr=3.85751e-05, gnorm=0.782, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=13356
2023-10-04 23:05:37 - progress_bar.py[line:272] - INFO: epoch 003:    378 / 907 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=271.6, nsentences=96, sample_size=271.6, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=404.3, ups=1.49, wpb=271.6, bsz=96, num_updates=2190, lr=3.85106e-05, gnorm=0.869, clip=40, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=13363
2023-10-04 23:05:44 - progress_bar.py[line:272] - INFO: epoch 003:    388 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=377.9, ups=1.41, wpb=268.7, bsz=96, num_updates=2200, lr=3.84462e-05, gnorm=0.721, clip=0, loss_scale=512, train_wall=7, gb_free=6, ema_decay=0.9999, wall=13370
2023-10-04 23:05:44 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 23:05:47 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 23:05:47 - train.py[line:550] - INFO: load:2.37 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 23:07:24 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 23:07:24 - train.py[line:550] - INFO: load:2.45 valid_run:96.97 task_valid:93.07 collect_output:2.81
2023-10-04 23:09:00 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 23:09:00 - train.py[line:550] - INFO: load:2.53 valid_run:193.30 task_valid:184.68 collect_output:6.61
2023-10-04 23:10:36 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 23:10:36 - train.py[line:550] - INFO: load:2.63 valid_run:288.99 task_valid:273.50 collect_output:12.49
2023-10-04 23:12:12 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 23:12:12 - train.py[line:550] - INFO: load:2.71 valid_run:384.34 task_valid:363.53 collect_output:16.92
2023-10-04 23:13:47 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 23:13:47 - train.py[line:550] - INFO: load:2.80 valid_run:480.02 task_valid:453.61 collect_output:21.55
2023-10-04 23:15:24 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 23:15:24 - train.py[line:550] - INFO: load:2.89 valid_run:575.95 task_valid:543.58 collect_output:26.57
2023-10-04 23:16:58 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 23:16:58 - train.py[line:550] - INFO: load:2.98 valid_run:670.45 task_valid:633.96 collect_output:29.70
2023-10-04 23:18:34 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 23:18:34 - train.py[line:550] - INFO: load:3.06 valid_run:766.52 task_valid:726.21 collect_output:32.60
2023-10-04 23:20:10 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 23:20:10 - train.py[line:550] - INFO: load:3.16 valid_run:862.27 task_valid:817.02 collect_output:36.58
2023-10-04 23:21:46 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 23:21:46 - train.py[line:550] - INFO: load:3.26 valid_run:958.28 task_valid:908.80 collect_output:39.84
2023-10-04 23:23:22 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 23:23:22 - train.py[line:550] - INFO: load:3.34 valid_run:1054.05 task_valid:1000.17 collect_output:43.27

====================================================================================================
SGG eval:     R @ 50: 0.4782;     R @ 100: 0.5394;     R @ 500: 0.6055;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2583;    mR @ 100: 0.3125;    mR @ 500: 0.3794;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.1250) (covering:0.2857) (eating:0.6176) (flying in:0.6364) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6250) (playing:0.0000) (riding:0.7549) (says:0.0000) (sitting on:0.5933) (standing on:0.6464) (using:0.2500) (walking in:0.0000) (walking on:0.2432) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4782;     R @ 100: 0.5394;     R @ 500: 0.6055;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2583;    mR @ 100: 0.3125;    mR @ 500: 0.3794;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.1250) (covering:0.2857) (eating:0.6176) (flying in:0.6364) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6250) (playing:0.0000) (riding:0.7549) (says:0.0000) (sitting on:0.5933) (standing on:0.6464) (using:0.2500) (walking in:0.0000) (walking on:0.2432) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4782;     R @ 100: 0.5394;     R @ 500: 0.6055;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2583;    mR @ 100: 0.3125;    mR @ 500: 0.3794;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.1250) (covering:0.2857) (eating:0.6176) (flying in:0.6364) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6250) (playing:0.0000) (riding:0.7549) (says:0.0000) (sitting on:0.5933) (standing on:0.6464) (using:0.2500) (walking in:0.0000) (walking on:0.2432) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4782;     R @ 100: 0.5394;     R @ 500: 0.6055;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2583;    mR @ 100: 0.3125;    mR @ 500: 0.3794;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.1250) (covering:0.2857) (eating:0.6176) (flying in:0.6364) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6250) (playing:0.0000) (riding:0.7549) (says:0.0000) (sitting on:0.5933) (standing on:0.6464) (using:0.2500) (walking in:0.0000) (walking on:0.2432) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4782;     R @ 100: 0.5394;     R @ 500: 0.6055;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2583;    mR @ 100: 0.3125;    mR @ 500: 0.3794;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.1250) (covering:0.2857) (eating:0.6176) (flying in:0.6364) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6250) (playing:0.0000) (riding:0.7549) (says:0.0000) (sitting on:0.5933) (standing on:0.6464) (using:0.2500) (walking in:0.0000) (walking on:0.2432) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4782;     R @ 100: 0.5394;     R @ 500: 0.6055;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2583;    mR @ 100: 0.3125;    mR @ 500: 0.3794;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.1250) (covering:0.2857) (eating:0.6176) (flying in:0.6364) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6250) (playing:0.0000) (riding:0.7549) (says:0.0000) (sitting on:0.5933) (standing on:0.6464) (using:0.2500) (walking in:0.0000) (walking on:0.2432) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.4782;     R @ 100: 0.5394;     R @ 500: 0.6055;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2583;    mR @ 100: 0.3125;    mR @ 500: 0.3794;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.1250) (covering:0.2857) (eating:0.6176) (flying in:0.6364) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6250) (playing:0.0000) (riding:0.7549) (says:0.0000) (sitting on:0.5933) (standing on:0.6464) (using:0.2500) (walking in:0.0000) (walking on:0.2432) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================

2023-10-04 23:24:38 - train.py[line:487] - INFO: 0.5393888719124014

====================================================================================================
SGG eval:     R @ 50: 0.4782;     R @ 100: 0.5394;     R @ 500: 0.6055;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2583;    mR @ 100: 0.3125;    mR @ 500: 0.3794;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3317) (covered in:0.1250) (covering:0.2857) (eating:0.6176) (flying in:0.6364) (growing on:0.2500) (hanging from:0.4581) (lying on:0.1000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6250) (playing:0.0000) (riding:0.7549) (says:0.0000) (sitting on:0.5933) (standing on:0.6464) (using:0.2500) (walking in:0.0000) (walking on:0.2432) (watching:0.1667) 
--------------------------------------------------------
====================================================================================================

2023-10-04 23:24:38 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-04 23:24:38 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.253 | loss_v1 0 | loss_v2 0 | nll_loss 0.086 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.539389 | ppl 1.06 | vqa_score 0.2432 | wps 396.7 | wpb 191.9 | bsz 64 | num_updates 2200 | best_R@100 0.539389
2023-10-04 23:24:38 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 2200 updates
2023-10-04 23:24:38 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2200.pt
2023-10-04 23:24:45 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2200.pt
2023-10-04 23:25:29 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2200.pt (epoch 3 @ 2200 updates, score 0.5393888719124014) (writing took 50.326687143184245 seconds)
2023-10-04 23:25:35 - progress_bar.py[line:272] - INFO: epoch 003:    398 / 907 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.086, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=2.3, ups=0.01, wpb=270.8, bsz=96, num_updates=2210, lr=3.83817e-05, gnorm=0.741, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=14562
2023-10-04 23:25:42 - progress_bar.py[line:272] - INFO: epoch 003:    408 / 907 loss=0.286, loss_v1=0, loss_v2=0, nll_loss=0.113, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=393.3, ups=1.45, wpb=271.1, bsz=96, num_updates=2220, lr=3.83172e-05, gnorm=0.903, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=14568
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 23:25:49 - progress_bar.py[line:272] - INFO: epoch 003:    418 / 907 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.104, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400, ups=1.49, wpb=268, bsz=96, num_updates=2230, lr=3.82527e-05, gnorm=0.737, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=14575
2023-10-04 23:25:56 - progress_bar.py[line:272] - INFO: epoch 003:    428 / 907 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.093, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400.9, ups=1.5, wpb=268.1, bsz=96, num_updates=2240, lr=3.81883e-05, gnorm=0.753, clip=10, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=14582
2023-10-04 23:26:03 - progress_bar.py[line:272] - INFO: epoch 003:    438 / 907 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.097, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400.6, ups=1.48, wpb=270.2, bsz=96, num_updates=2250, lr=3.81238e-05, gnorm=0.914, clip=20, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=14589
2023-10-04 23:26:09 - progress_bar.py[line:272] - INFO: epoch 003:    448 / 907 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.099, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400.3, ups=1.49, wpb=269.1, bsz=96, num_updates=2260, lr=3.80593e-05, gnorm=0.714, clip=10, loss_scale=512, train_wall=7, gb_free=5.9, ema_decay=0.9999, wall=14595
2023-10-04 23:26:16 - progress_bar.py[line:272] - INFO: epoch 003:    458 / 907 loss=0.283, loss_v1=0, loss_v2=0, nll_loss=0.108, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=393.2, ups=1.46, wpb=269.8, bsz=96, num_updates=2270, lr=3.79948e-05, gnorm=0.819, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=14602
2023-10-04 23:26:23 - progress_bar.py[line:272] - INFO: epoch 003:    468 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.095, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=401.6, ups=1.49, wpb=270.4, bsz=96, num_updates=2280, lr=3.79304e-05, gnorm=0.685, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=14609
2023-10-04 23:26:30 - progress_bar.py[line:272] - INFO: epoch 003:    478 / 907 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.096, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=391.8, ups=1.45, wpb=270.1, bsz=96, num_updates=2290, lr=3.78659e-05, gnorm=0.714, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=14616
2023-10-04 23:26:37 - progress_bar.py[line:272] - INFO: epoch 003:    488 / 907 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.094, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=389, ups=1.44, wpb=269.3, bsz=96, num_updates=2300, lr=3.78014e-05, gnorm=1.008, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=14623
2023-10-04 23:26:43 - progress_bar.py[line:272] - INFO: epoch 003:    498 / 907 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.102, ntokens=267.9, nsentences=96, sample_size=267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=398.7, ups=1.49, wpb=267.9, bsz=96, num_updates=2310, lr=3.77369e-05, gnorm=0.671, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=14629
2023-10-04 23:26:50 - progress_bar.py[line:272] - INFO: epoch 003:    508 / 907 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.102, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=402.2, ups=1.49, wpb=269.2, bsz=96, num_updates=2320, lr=3.76725e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=14636
2023-10-04 23:26:57 - progress_bar.py[line:272] - INFO: epoch 003:    518 / 907 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.093, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=395, ups=1.46, wpb=271.1, bsz=96, num_updates=2330, lr=3.7608e-05, gnorm=0.638, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=14643
2023-10-04 23:27:04 - progress_bar.py[line:272] - INFO: epoch 003:    528 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.096, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=402.9, ups=1.49, wpb=270.2, bsz=96, num_updates=2340, lr=3.75435e-05, gnorm=0.808, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=14650
2023-10-04 23:27:11 - progress_bar.py[line:272] - INFO: epoch 003:    538 / 907 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.101, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=381.1, ups=1.41, wpb=270.6, bsz=96, num_updates=2350, lr=3.7479e-05, gnorm=0.849, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=14657
2023-10-04 23:27:17 - progress_bar.py[line:272] - INFO: epoch 003:    548 / 907 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.099, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=402, ups=1.49, wpb=270, bsz=96, num_updates=2360, lr=3.74146e-05, gnorm=0.712, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=14664
2023-10-04 23:27:24 - progress_bar.py[line:272] - INFO: epoch 003:    558 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=266.9, nsentences=96, sample_size=266.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=398.3, ups=1.49, wpb=266.9, bsz=96, num_updates=2370, lr=3.73501e-05, gnorm=0.73, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=14670
2023-10-04 23:27:31 - progress_bar.py[line:272] - INFO: epoch 003:    568 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.2, ups=1.45, wpb=269.5, bsz=96, num_updates=2380, lr=3.72856e-05, gnorm=0.747, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=14677
2023-10-04 23:27:38 - progress_bar.py[line:272] - INFO: epoch 003:    578 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.095, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400.1, ups=1.49, wpb=268.2, bsz=96, num_updates=2390, lr=3.72211e-05, gnorm=0.741, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=14684
2023-10-04 23:27:45 - progress_bar.py[line:272] - INFO: epoch 003:    588 / 907 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.092, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=367.4, ups=1.37, wpb=268.4, bsz=96, num_updates=2400, lr=3.71567e-05, gnorm=0.706, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=14691
2023-10-04 23:27:45 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 23:27:48 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 23:27:48 - train.py[line:550] - INFO: load:2.35 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 23:29:25 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 23:29:25 - train.py[line:550] - INFO: load:2.45 valid_run:97.31 task_valid:93.20 collect_output:3.05
2023-10-04 23:31:02 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 23:31:02 - train.py[line:550] - INFO: load:2.53 valid_run:193.68 task_valid:184.89 collect_output:6.69
2023-10-04 23:32:37 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 23:32:37 - train.py[line:550] - INFO: load:2.62 valid_run:289.46 task_valid:273.98 collect_output:12.41
2023-10-04 23:34:13 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 23:34:13 - train.py[line:550] - INFO: load:2.71 valid_run:385.10 task_valid:364.10 collect_output:16.96
2023-10-04 23:35:49 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 23:35:49 - train.py[line:550] - INFO: load:2.80 valid_run:481.09 task_valid:454.15 collect_output:21.91
2023-10-04 23:37:25 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 23:37:25 - train.py[line:550] - INFO: load:2.88 valid_run:576.88 task_valid:543.63 collect_output:27.30
2023-10-04 23:39:00 - train.py[line:549] - INFO: 1400 / 2338
2023-10-04 23:39:00 - train.py[line:550] - INFO: load:2.96 valid_run:671.56 task_valid:633.95 collect_output:30.74
2023-10-04 23:40:36 - train.py[line:549] - INFO: 1600 / 2338
2023-10-04 23:40:36 - train.py[line:550] - INFO: load:3.05 valid_run:767.43 task_valid:726.02 collect_output:33.61
2023-10-04 23:42:12 - train.py[line:549] - INFO: 1800 / 2338
2023-10-04 23:42:12 - train.py[line:550] - INFO: load:3.13 valid_run:863.27 task_valid:816.65 collect_output:37.90
2023-10-04 23:43:49 - train.py[line:549] - INFO: 2000 / 2338
2023-10-04 23:43:49 - train.py[line:550] - INFO: load:3.20 valid_run:959.64 task_valid:908.42 collect_output:41.52
2023-10-04 23:45:24 - train.py[line:549] - INFO: 2200 / 2338
2023-10-04 23:45:24 - train.py[line:550] - INFO: load:3.29 valid_run:1055.19 task_valid:999.63 collect_output:44.89

====================================================================================================
SGG eval:     R @ 50: 0.5102;     R @ 100: 0.5616;     R @ 500: 0.6262;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2819;    mR @ 100: 0.3279;    mR @ 500: 0.4032;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3854) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6786) (playing:0.0000) (riding:0.7794) (says:0.0000) (sitting on:0.5984) (standing on:0.6496) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5102;     R @ 100: 0.5616;     R @ 500: 0.6262;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2819;    mR @ 100: 0.3279;    mR @ 500: 0.4032;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3854) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6786) (playing:0.0000) (riding:0.7794) (says:0.0000) (sitting on:0.5984) (standing on:0.6496) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5102;     R @ 100: 0.5616;     R @ 500: 0.6262;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2819;    mR @ 100: 0.3279;    mR @ 500: 0.4032;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3854) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6786) (playing:0.0000) (riding:0.7794) (says:0.0000) (sitting on:0.5984) (standing on:0.6496) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5102;     R @ 100: 0.5616;     R @ 500: 0.6262;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2819;    mR @ 100: 0.3279;    mR @ 500: 0.4032;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3854) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6786) (playing:0.0000) (riding:0.7794) (says:0.0000) (sitting on:0.5984) (standing on:0.6496) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5102;     R @ 100: 0.5616;     R @ 500: 0.6262;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2819;    mR @ 100: 0.3279;    mR @ 500: 0.4032;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3854) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6786) (playing:0.0000) (riding:0.7794) (says:0.0000) (sitting on:0.5984) (standing on:0.6496) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5102;     R @ 100: 0.5616;     R @ 500: 0.6262;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2819;    mR @ 100: 0.3279;    mR @ 500: 0.4032;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3854) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6786) (playing:0.0000) (riding:0.7794) (says:0.0000) (sitting on:0.5984) (standing on:0.6496) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5102;     R @ 100: 0.5616;     R @ 500: 0.6262;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2819;    mR @ 100: 0.3279;    mR @ 500: 0.4032;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3854) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6786) (playing:0.0000) (riding:0.7794) (says:0.0000) (sitting on:0.5984) (standing on:0.6496) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5102;     R @ 100: 0.5616;     R @ 500: 0.6262;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.2819;    mR @ 100: 0.3279;    mR @ 500: 0.4032;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3854) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4710) (lying on:0.2000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.6786) (playing:0.0000) (riding:0.7794) (says:0.0000) (sitting on:0.5984) (standing on:0.6496) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2083) 
--------------------------------------------------------
====================================================================================================

2023-10-04 23:46:40 - train.py[line:487] - INFO: 0.5616364909600204
2023-10-04 23:46:40 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-04 23:46:40 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.25 | loss_v1 0 | loss_v2 0 | nll_loss 0.08 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.561636 | ppl 1.06 | vqa_score 0.2669 | wps 396.3 | wpb 191.9 | bsz 64 | num_updates 2400 | best_R@100 0.561636
2023-10-04 23:46:40 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 2400 updates
2023-10-04 23:46:40 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2400.pt
2023-10-04 23:46:47 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2400.pt
2023-10-04 23:47:34 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2400.pt (epoch 3 @ 2400 updates, score 0.5616364909600204) (writing took 53.92139270482585 seconds)
2023-10-04 23:47:41 - progress_bar.py[line:272] - INFO: epoch 003:    598 / 907 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.089, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=2.3, ups=0.01, wpb=271, bsz=96, num_updates=2410, lr=3.70922e-05, gnorm=0.647, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=15887
2023-10-04 23:47:48 - progress_bar.py[line:272] - INFO: epoch 003:    608 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.098, ntokens=266.5, nsentences=96, sample_size=266.5, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=398.7, ups=1.5, wpb=266.5, bsz=96, num_updates=2420, lr=3.70277e-05, gnorm=0.755, clip=30, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=15894
2023-10-04 23:47:55 - progress_bar.py[line:272] - INFO: epoch 003:    618 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=398, ups=1.49, wpb=267.8, bsz=96, num_updates=2430, lr=3.69632e-05, gnorm=0.776, clip=30, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=15901
2023-10-04 23:48:01 - progress_bar.py[line:272] - INFO: epoch 003:    628 / 907 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.09, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=403, ups=1.49, wpb=270.5, bsz=96, num_updates=2440, lr=3.68988e-05, gnorm=0.862, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=15907
2023-10-04 23:48:08 - progress_bar.py[line:272] - INFO: epoch 003:    638 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.093, ntokens=267.7, nsentences=96, sample_size=267.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=398.9, ups=1.49, wpb=267.7, bsz=96, num_updates=2450, lr=3.68343e-05, gnorm=0.828, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=15914
2023-10-04 23:48:15 - progress_bar.py[line:272] - INFO: epoch 003:    648 / 907 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.103, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=397.7, ups=1.48, wpb=269.1, bsz=96, num_updates=2460, lr=3.67698e-05, gnorm=0.815, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=15921
@@@@ ERROR IN DATA @@@@ watch
2023-10-04 23:48:21 - progress_bar.py[line:272] - INFO: epoch 003:    658 / 907 loss=0.275, loss_v1=0, loss_v2=0, nll_loss=0.097, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=398.3, ups=1.48, wpb=269.6, bsz=96, num_updates=2470, lr=3.67054e-05, gnorm=0.868, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=15928
2023-10-04 23:48:29 - progress_bar.py[line:272] - INFO: epoch 003:    668 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.098, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=369.1, ups=1.36, wpb=270.8, bsz=96, num_updates=2480, lr=3.66409e-05, gnorm=0.742, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=15935
@@@@ ERROR IN DATA @@@@ ride
2023-10-04 23:48:36 - progress_bar.py[line:272] - INFO: epoch 003:    678 / 907 loss=0.285, loss_v1=0, loss_v2=0, nll_loss=0.11, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=403.6, ups=1.49, wpb=270.5, bsz=96, num_updates=2490, lr=3.65764e-05, gnorm=0.882, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=15942
2023-10-04 23:48:42 - progress_bar.py[line:272] - INFO: epoch 003:    688 / 907 loss=0.278, loss_v1=0, loss_v2=0, nll_loss=0.1, ntokens=267.4, nsentences=96, sample_size=267.4, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=387.2, ups=1.45, wpb=267.4, bsz=96, num_updates=2500, lr=3.65119e-05, gnorm=0.808, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=15948
2023-10-04 23:48:49 - progress_bar.py[line:272] - INFO: epoch 003:    698 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.089, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=400.8, ups=1.49, wpb=268.4, bsz=96, num_updates=2510, lr=3.64475e-05, gnorm=0.73, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=15955
2023-10-04 23:48:56 - progress_bar.py[line:272] - INFO: epoch 003:    708 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.09, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401.1, ups=1.49, wpb=269.5, bsz=96, num_updates=2520, lr=3.6383e-05, gnorm=0.719, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=15962
2023-10-04 23:49:03 - progress_bar.py[line:272] - INFO: epoch 003:    718 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.088, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=399.6, ups=1.48, wpb=269.3, bsz=96, num_updates=2530, lr=3.63185e-05, gnorm=0.804, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=15969
2023-10-04 23:49:09 - progress_bar.py[line:272] - INFO: epoch 003:    728 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.097, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=392.9, ups=1.45, wpb=270.7, bsz=96, num_updates=2540, lr=3.6254e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=15976
2023-10-04 23:49:16 - progress_bar.py[line:272] - INFO: epoch 003:    738 / 907 loss=0.28, loss_v1=0, loss_v2=0, nll_loss=0.104, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=400.7, ups=1.49, wpb=268.9, bsz=96, num_updates=2550, lr=3.61896e-05, gnorm=0.935, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=15982
2023-10-04 23:49:23 - progress_bar.py[line:272] - INFO: epoch 003:    748 / 907 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.092, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=401, ups=1.48, wpb=270.2, bsz=96, num_updates=2560, lr=3.61251e-05, gnorm=0.874, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=15989
2023-10-04 23:49:30 - progress_bar.py[line:272] - INFO: epoch 003:    758 / 907 loss=0.282, loss_v1=0, loss_v2=0, nll_loss=0.108, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=382.9, ups=1.42, wpb=269.8, bsz=96, num_updates=2570, lr=3.60606e-05, gnorm=0.882, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=15996
2023-10-04 23:49:37 - progress_bar.py[line:272] - INFO: epoch 003:    768 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.092, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=388.3, ups=1.44, wpb=269.4, bsz=96, num_updates=2580, lr=3.59961e-05, gnorm=0.806, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=16003
2023-10-04 23:49:44 - progress_bar.py[line:272] - INFO: epoch 003:    778 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.095, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=388.2, ups=1.45, wpb=268.2, bsz=96, num_updates=2590, lr=3.59317e-05, gnorm=0.737, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=16010
2023-10-04 23:49:51 - progress_bar.py[line:272] - INFO: epoch 003:    788 / 907 loss=0.279, loss_v1=0, loss_v2=0, nll_loss=0.098, ntokens=267, nsentences=96, sample_size=267, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=387.8, ups=1.45, wpb=267, bsz=96, num_updates=2600, lr=3.58672e-05, gnorm=0.65, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=16017
2023-10-04 23:49:51 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-04 23:49:54 - train.py[line:549] - INFO: 0 / 2338
2023-10-04 23:49:54 - train.py[line:550] - INFO: load:2.70 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-04 23:51:14 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.31 GiB (GPU 2; 23.70 GiB total capacity; 6.81 GiB already allocated; 1.57 GiB free; 20.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-04 23:51:14 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 23:51:14 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 23:51:14 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 15        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6971 MiB |   9881 MiB |   1842 TiB |   1842 TiB |
|       from large pool |   6826 MiB |   9736 MiB |   1832 TiB |   1832 TiB |
|       from small pool |    144 MiB |    159 MiB |      9 TiB |      9 TiB |
|---------------------------------------------------------------------------|
| Active memory         |   6971 MiB |   9881 MiB |   1842 TiB |   1842 TiB |
|       from large pool |   6826 MiB |   9736 MiB |   1832 TiB |   1832 TiB |
|       from small pool |    144 MiB |    159 MiB |      9 TiB |      9 TiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6922 MiB |   9832 MiB |   1840 TiB |   1840 TiB |
|       from large pool |   6777 MiB |   9687 MiB |   1830 TiB |   1830 TiB |
|       from small pool |    144 MiB |    158 MiB |      9 TiB |      9 TiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  21242 MiB |  21882 MiB | 102284 MiB |  81042 MiB |
|       from large pool |  21096 MiB |  21634 MiB | 101706 MiB |  80610 MiB |
|       from small pool |    146 MiB |    248 MiB |    578 MiB |    432 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14270 MiB |  14270 MiB |   1861 TiB |   1861 TiB |
|       from large pool |  14269 MiB |  14269 MiB |   1851 TiB |   1851 TiB |
|       from small pool |      1 MiB |      7 MiB |     10 TiB |     10 TiB |
|---------------------------------------------------------------------------|
| Allocations           |    3578    |    3593    |  117670 K  |  117666 K  |
|       from large pool |     565    |     577    |   47468 K  |   47468 K  |
|       from small pool |    3013    |    3027    |   70201 K  |   70198 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3578    |    3593    |  117670 K  |  117666 K  |
|       from large pool |     565    |     577    |   47468 K  |   47468 K  |
|       from small pool |    3013    |    3027    |   70201 K  |   70198 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     129    |     181    |     513    |     384    |
|       from large pool |      56    |      57    |     224    |     168    |
|       from small pool |      73    |     124    |     289    |     216    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      78    |      92    |   65830 K  |   65830 K  |
|       from large pool |      51    |      53    |   16168 K  |   16168 K  |
|       from small pool |      27    |      46    |   49662 K  |   49662 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 23:51:14 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 23:51:14 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 23:51:14 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 23:51:14 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 23:51:14 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-04 23:51:14 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-04 23:51:31 - train.py[line:549] - INFO: 200 / 2338
2023-10-04 23:51:31 - train.py[line:550] - INFO: load:2.80 valid_run:97.36 task_valid:92.92 collect_output:3.34
2023-10-04 23:53:07 - train.py[line:549] - INFO: 400 / 2338
2023-10-04 23:53:07 - train.py[line:550] - INFO: load:2.88 valid_run:193.38 task_valid:184.66 collect_output:6.67
2023-10-04 23:54:43 - train.py[line:549] - INFO: 600 / 2338
2023-10-04 23:54:43 - train.py[line:550] - INFO: load:2.96 valid_run:289.38 task_valid:273.60 collect_output:12.76
2023-10-04 23:56:19 - train.py[line:549] - INFO: 800 / 2338
2023-10-04 23:56:19 - train.py[line:550] - INFO: load:3.05 valid_run:384.66 task_valid:363.58 collect_output:17.11
2023-10-04 23:57:55 - train.py[line:549] - INFO: 1000 / 2338
2023-10-04 23:57:55 - train.py[line:550] - INFO: load:3.14 valid_run:480.49 task_valid:453.57 collect_output:21.94
2023-10-04 23:59:31 - train.py[line:549] - INFO: 1200 / 2338
2023-10-04 23:59:31 - train.py[line:550] - INFO: load:3.23 valid_run:576.46 task_valid:543.16 collect_output:27.36
2023-10-05 00:01:06 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 00:01:06 - train.py[line:550] - INFO: load:3.31 valid_run:671.58 task_valid:633.51 collect_output:31.21
2023-10-05 00:02:42 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 00:02:42 - train.py[line:550] - INFO: load:3.40 valid_run:767.48 task_valid:725.96 collect_output:33.70
2023-10-05 00:04:18 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 00:04:18 - train.py[line:550] - INFO: load:3.48 valid_run:863.53 task_valid:816.74 collect_output:38.04
2023-10-05 00:05:55 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 00:05:55 - train.py[line:550] - INFO: load:3.56 valid_run:959.99 task_valid:908.15 collect_output:42.15
2023-10-05 00:07:30 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 00:07:30 - train.py[line:550] - INFO: load:3.65 valid_run:1055.31 task_valid:999.41 collect_output:45.28

====================================================================================================
SGG eval:     R @ 50: 0.5329;     R @ 100: 0.5766;     R @ 500: 0.6360;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3085;    mR @ 100: 0.3460;    mR @ 500: 0.4173;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3902) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.7083) (playing:0.0000) (riding:0.8137) (says:0.0000) (sitting on:0.6128) (standing on:0.6310) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5329;     R @ 100: 0.5766;     R @ 500: 0.6360;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3085;    mR @ 100: 0.3460;    mR @ 500: 0.4173;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3902) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.7083) (playing:0.0000) (riding:0.8137) (says:0.0000) (sitting on:0.6128) (standing on:0.6310) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5329;     R @ 100: 0.5766;     R @ 500: 0.6360;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3085;    mR @ 100: 0.3460;    mR @ 500: 0.4173;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3902) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.7083) (playing:0.0000) (riding:0.8137) (says:0.0000) (sitting on:0.6128) (standing on:0.6310) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5329;     R @ 100: 0.5766;     R @ 500: 0.6360;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3085;    mR @ 100: 0.3460;    mR @ 500: 0.4173;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3902) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.7083) (playing:0.0000) (riding:0.8137) (says:0.0000) (sitting on:0.6128) (standing on:0.6310) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5329;     R @ 100: 0.5766;     R @ 500: 0.6360;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3085;    mR @ 100: 0.3460;    mR @ 500: 0.4173;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3902) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.7083) (playing:0.0000) (riding:0.8137) (says:0.0000) (sitting on:0.6128) (standing on:0.6310) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================

2023-10-05 00:08:46 - train.py[line:487] - INFO: 0.5765841100076394

====================================================================================================
SGG eval:     R @ 50: 0.5329;     R @ 100: 0.5766;     R @ 500: 0.6360;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3085;    mR @ 100: 0.3460;    mR @ 500: 0.4173;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3902) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.7083) (playing:0.0000) (riding:0.8137) (says:0.0000) (sitting on:0.6128) (standing on:0.6310) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5329;     R @ 100: 0.5766;     R @ 500: 0.6360;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3085;    mR @ 100: 0.3460;    mR @ 500: 0.4173;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3902) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.7083) (playing:0.0000) (riding:0.8137) (says:0.0000) (sitting on:0.6128) (standing on:0.6310) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5329;     R @ 100: 0.5766;     R @ 500: 0.6360;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3085;    mR @ 100: 0.3460;    mR @ 500: 0.4173;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.3902) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.6364) (growing on:0.1250) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.7083) (playing:0.0000) (riding:0.8137) (says:0.0000) (sitting on:0.6128) (standing on:0.6310) (using:0.3000) (walking in:0.0000) (walking on:0.2432) (watching:0.2917) 
--------------------------------------------------------
====================================================================================================

2023-10-05 00:08:46 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 00:08:46 - progress_bar.py[line:282] - INFO: epoch 003 | valid on 'valid' subset | loss 0.249 | loss_v1 0 | loss_v2 0 | nll_loss 0.078 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.576584 | ppl 1.06 | vqa_score 0.3029 | wps 396.2 | wpb 191.9 | bsz 64 | num_updates 2600 | best_R@100 0.576584
2023-10-05 00:08:46 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 3 @ 2600 updates
2023-10-05 00:08:46 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2600.pt
2023-10-05 00:08:52 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2600.pt
2023-10-05 00:09:41 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_3_2600.pt (epoch 3 @ 2600 updates, score 0.5765841100076394) (writing took 54.537597007118165 seconds)
2023-10-05 00:09:48 - progress_bar.py[line:272] - INFO: epoch 003:    798 / 907 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.105, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.08, wps=2.2, ups=0.01, wpb=269.1, bsz=96, num_updates=2610, lr=3.58027e-05, gnorm=0.769, clip=20, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=17214
2023-10-05 00:09:54 - progress_bar.py[line:272] - INFO: epoch 003:    808 / 907 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.089, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=404.4, ups=1.49, wpb=270.6, bsz=96, num_updates=2620, lr=3.57382e-05, gnorm=0.719, clip=10, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=17220
2023-10-05 00:10:01 - progress_bar.py[line:272] - INFO: epoch 003:    818 / 907 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=271.6, nsentences=96, sample_size=271.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=405.7, ups=1.49, wpb=271.6, bsz=96, num_updates=2630, lr=3.56738e-05, gnorm=0.645, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=17227
@@@@ ERROR IN DATA @@@@ play
2023-10-05 00:10:06 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-10-05 00:10:08 - progress_bar.py[line:272] - INFO: epoch 003:    829 / 907 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.089, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=370, ups=1.37, wpb=270.7, bsz=96, num_updates=2640, lr=3.56093e-05, gnorm=0.754, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=17235
2023-10-05 00:10:15 - progress_bar.py[line:272] - INFO: epoch 003:    839 / 907 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.098, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=392.4, ups=1.45, wpb=270.5, bsz=96, num_updates=2650, lr=3.55448e-05, gnorm=0.798, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=17241
2023-10-05 00:10:22 - progress_bar.py[line:272] - INFO: epoch 003:    849 / 907 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.101, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400.3, ups=1.48, wpb=269.9, bsz=96, num_updates=2660, lr=3.54803e-05, gnorm=0.827, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=17248
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 00:10:29 - progress_bar.py[line:272] - INFO: epoch 003:    859 / 907 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=376.8, ups=1.4, wpb=268.4, bsz=96, num_updates=2670, lr=3.54159e-05, gnorm=0.628, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=17255
2023-10-05 00:10:36 - progress_bar.py[line:272] - INFO: epoch 003:    869 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.097, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=404.1, ups=1.49, wpb=270.3, bsz=96, num_updates=2680, lr=3.53514e-05, gnorm=0.712, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=17262
@@@@ ERROR IN DATA @@@@ play
2023-10-05 00:10:43 - progress_bar.py[line:272] - INFO: epoch 003:    879 / 907 loss=0.277, loss_v1=0, loss_v2=0, nll_loss=0.101, ntokens=267.9, nsentences=96, sample_size=267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=397.9, ups=1.49, wpb=267.9, bsz=96, num_updates=2690, lr=3.52869e-05, gnorm=0.737, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=17269
2023-10-05 00:10:49 - progress_bar.py[line:272] - INFO: epoch 003:    889 / 907 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.094, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=402.7, ups=1.5, wpb=268.4, bsz=96, num_updates=2700, lr=3.52224e-05, gnorm=0.673, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=17275
2023-10-05 00:10:56 - progress_bar.py[line:272] - INFO: epoch 003:    899 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=390.8, ups=1.45, wpb=269.7, bsz=96, num_updates=2710, lr=3.5158e-05, gnorm=0.772, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=17282
2023-10-05 00:11:01 - train.py[line:339] - INFO: end of epoch 3 (average epoch stats below)
2023-10-05 00:11:01 - progress_bar.py[line:282] - INFO: epoch 003 | loss 0.274 | loss_v1 0 | loss_v2 0 | nll_loss 0.096 | ntokens 269.262 | nsentences 95.914 | sample_size 269.262 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.07 | wps 45.3 | ups 0.17 | wpb 269.3 | bsz 95.9 | num_updates 2718 | lr 3.51064e-05 | gnorm 0.786 | clip 16.2 | loss_scale 512 | train_wall 616 | gb_free 16.3 | ema_decay 0.9999 | wall 17287
2023-10-05 00:11:01 - trainer.py[line:694] - INFO: loading train data for epoch 4
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv slice_id 1 row count 10875 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv slice_id 4 row count 10874 total row count 86994

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv slice_id 5 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv slice_id 2 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv slice_id 0 row count 10875 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv slice_id 6 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv slice_id 3 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E3.tsv slice_id 7 row count 10874 total row count 86994
2023-10-05 00:11:02 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
2023-10-05 00:11:02 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 00:11:02 - trainer.py[line:758] - INFO: begin training epoch 4
2023-10-05 00:11:02 - train.py[line:312] - INFO: Start iterating over samples
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 00:11:07 - progress_bar.py[line:272] - INFO: epoch 004:      2 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.093, ntokens=248.7, nsentences=88.2, sample_size=248.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=237.6, ups=0.96, wpb=248.7, bsz=88.2, num_updates=2720, lr=3.50935e-05, gnorm=1.154, clip=40, loss_scale=512, train_wall=8, gb_free=6.5, ema_decay=0.9999, wall=17293
2023-10-05 00:11:14 - progress_bar.py[line:272] - INFO: epoch 004:     12 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=395.9, ups=1.47, wpb=268.6, bsz=96, num_updates=2730, lr=3.5029e-05, gnorm=0.61, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=17300
2023-10-05 00:11:20 - progress_bar.py[line:272] - INFO: epoch 004:     22 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.4, ups=1.48, wpb=269.7, bsz=96, num_updates=2740, lr=3.49645e-05, gnorm=0.595, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=17306
2023-10-05 00:11:27 - progress_bar.py[line:272] - INFO: epoch 004:     32 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.086, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=373.8, ups=1.39, wpb=268.1, bsz=96, num_updates=2750, lr=3.49001e-05, gnorm=0.79, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=17313
2023-10-05 00:11:34 - progress_bar.py[line:272] - INFO: epoch 004:     42 / 907 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=267.1, nsentences=96, sample_size=267.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=383.8, ups=1.44, wpb=267.1, bsz=96, num_updates=2760, lr=3.48356e-05, gnorm=0.775, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=17320
@@@@ ERROR IN DATA @@@@ play
2023-10-05 00:11:41 - progress_bar.py[line:272] - INFO: epoch 004:     52 / 907 loss=0.273, loss_v1=0, loss_v2=0, nll_loss=0.095, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=383.7, ups=1.43, wpb=268.3, bsz=96, num_updates=2770, lr=3.47711e-05, gnorm=0.886, clip=40, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=17327
2023-10-05 00:11:48 - progress_bar.py[line:272] - INFO: epoch 004:     62 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=398.3, ups=1.48, wpb=268.7, bsz=96, num_updates=2780, lr=3.47066e-05, gnorm=0.663, clip=10, loss_scale=512, train_wall=7, gb_free=6, ema_decay=0.9999, wall=17334
2023-10-05 00:11:55 - progress_bar.py[line:272] - INFO: epoch 004:     72 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401.8, ups=1.49, wpb=269.9, bsz=96, num_updates=2790, lr=3.46422e-05, gnorm=0.731, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=17341
2023-10-05 00:12:02 - progress_bar.py[line:272] - INFO: epoch 004:     82 / 907 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=387.7, ups=1.44, wpb=269.5, bsz=96, num_updates=2800, lr=3.45777e-05, gnorm=0.654, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=17348
2023-10-05 00:12:02 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 00:12:04 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 00:12:04 - train.py[line:550] - INFO: load:1.91 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 00:12:05 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.28 GiB (GPU 4; 23.70 GiB total capacity; 6.79 GiB already allocated; 2.17 GiB free; 20.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-05 00:12:05 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:12:05 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:12:05 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:12:05 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:12:05 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 1            |        cudaMalloc retries: 11        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6954 MiB |   7607 MiB |   2000 TiB |   2000 TiB |
|       from large pool |   6809 MiB |   7462 MiB |   1989 TiB |   1989 TiB |
|       from small pool |    144 MiB |    145 MiB |     10 TiB |     10 TiB |
|---------------------------------------------------------------------------|
| Active memory         |   6954 MiB |   7607 MiB |   2000 TiB |   2000 TiB |
|       from large pool |   6809 MiB |   7462 MiB |   1989 TiB |   1989 TiB |
|       from small pool |    144 MiB |    145 MiB |     10 TiB |     10 TiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6900 MiB |   7553 MiB |   1996 TiB |   1996 TiB |
|       from large pool |   6755 MiB |   7408 MiB |   1986 TiB |   1986 TiB |
|       from small pool |    144 MiB |    145 MiB |     10 TiB |     10 TiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  20620 MiB |  21008 MiB |  83332 MiB |  62712 MiB |
|       from large pool |  20474 MiB |  20758 MiB |  82944 MiB |  62470 MiB |
|       from small pool |    146 MiB |    250 MiB |    388 MiB |    242 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  13665 MiB |  13665 MiB |   1927 TiB |   1927 TiB |
|       from large pool |  13664 MiB |  13664 MiB |   1917 TiB |   1917 TiB |
|       from small pool |      1 MiB |      2 MiB |     10 TiB |     10 TiB |
|---------------------------------------------------------------------------|
| Allocations           |    3567    |    3582    |  126730 K  |  126726 K  |
|       from large pool |     565    |     577    |   51666 K  |   51665 K  |
|       from small pool |    3002    |    3021    |   75063 K  |   75060 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3567    |    3582    |  126730 K  |  126726 K  |
|       from large pool |     565    |     577    |   51666 K  |   51665 K  |
|       from small pool |    3002    |    3021    |   75063 K  |   75060 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     163    |     217    |     418    |     255    |
|       from large pool |      90    |      92    |     224    |     134    |
|       from small pool |      73    |     125    |     194    |     121    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     107    |     112    |   71323 K  |   71323 K  |
|       from large pool |      72    |      75    |   17538 K  |   17538 K  |
|       from small pool |      35    |      43    |   53784 K  |   53784 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:12:05 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:12:05 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:12:05 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:12:05 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-05 00:13:42 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 00:13:42 - train.py[line:550] - INFO: load:2.01 valid_run:97.88 task_valid:93.28 collect_output:3.51
2023-10-05 00:15:18 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 00:15:18 - train.py[line:550] - INFO: load:2.10 valid_run:194.16 task_valid:185.12 collect_output:6.92
2023-10-05 00:16:55 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 00:16:55 - train.py[line:550] - INFO: load:2.18 valid_run:290.29 task_valid:273.92 collect_output:13.26
2023-10-05 00:18:30 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 00:18:30 - train.py[line:550] - INFO: load:2.27 valid_run:385.47 task_valid:364.01 collect_output:17.37
2023-10-05 00:20:06 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 00:20:06 - train.py[line:550] - INFO: load:2.35 valid_run:481.76 task_valid:454.07 collect_output:22.63
2023-10-05 00:21:42 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 00:21:42 - train.py[line:550] - INFO: load:2.44 valid_run:577.75 task_valid:543.82 collect_output:27.90
2023-10-05 00:23:18 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 00:23:18 - train.py[line:550] - INFO: load:2.53 valid_run:672.73 task_valid:634.28 collect_output:31.44
2023-10-05 00:24:54 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 00:24:54 - train.py[line:550] - INFO: load:2.61 valid_run:768.66 task_valid:726.64 collect_output:34.06
2023-10-05 00:26:30 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 00:26:30 - train.py[line:550] - INFO: load:2.70 valid_run:864.70 task_valid:817.41 collect_output:38.33
2023-10-05 00:28:06 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 00:28:06 - train.py[line:550] - INFO: load:2.79 valid_run:961.18 task_valid:909.12 collect_output:42.12
2023-10-05 00:29:42 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 00:29:42 - train.py[line:550] - INFO: load:2.87 valid_run:1056.53 task_valid:1000.56 collect_output:45.05

====================================================================================================
SGG eval:     R @ 50: 0.5486;     R @ 100: 0.5945;     R @ 500: 0.6473;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3262;    mR @ 100: 0.3716;    mR @ 500: 0.4426;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4350) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8627) (says:0.0000) (sitting on:0.6094) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.3243) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-10-05 00:30:58 - train.py[line:487] - INFO: 0.5945144130379424

====================================================================================================
SGG eval:     R @ 50: 0.5486;     R @ 100: 0.5945;     R @ 500: 0.6473;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3262;    mR @ 100: 0.3716;    mR @ 500: 0.4426;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4350) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8627) (says:0.0000) (sitting on:0.6094) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.3243) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5486;     R @ 100: 0.5945;     R @ 500: 0.6473;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3262;    mR @ 100: 0.3716;    mR @ 500: 0.4426;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4350) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8627) (says:0.0000) (sitting on:0.6094) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.3243) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5486;     R @ 100: 0.5945;     R @ 500: 0.6473;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3262;    mR @ 100: 0.3716;    mR @ 500: 0.4426;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4350) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8627) (says:0.0000) (sitting on:0.6094) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.3243) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5486;     R @ 100: 0.5945;     R @ 500: 0.6473;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3262;    mR @ 100: 0.3716;    mR @ 500: 0.4426;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4350) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8627) (says:0.0000) (sitting on:0.6094) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.3243) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-10-05 00:30:58 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 00:30:58 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.244 | loss_v1 0 | loss_v2 0 | nll_loss 0.076 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.594514 | ppl 1.05 | vqa_score 0.3322 | wps 395.9 | wpb 191.9 | bsz 64 | num_updates 2800 | best_R@100 0.594514
2023-10-05 00:30:58 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 2800 updates
2023-10-05 00:30:58 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_2800.pt

====================================================================================================
SGG eval:     R @ 50: 0.5486;     R @ 100: 0.5945;     R @ 500: 0.6473;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3262;    mR @ 100: 0.3716;    mR @ 500: 0.4426;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4350) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8627) (says:0.0000) (sitting on:0.6094) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.3243) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5486;     R @ 100: 0.5945;     R @ 500: 0.6473;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3262;    mR @ 100: 0.3716;    mR @ 500: 0.4426;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4350) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8627) (says:0.0000) (sitting on:0.6094) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.3243) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5486;     R @ 100: 0.5945;     R @ 500: 0.6473;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3262;    mR @ 100: 0.3716;    mR @ 500: 0.4426;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4350) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.1250) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8627) (says:0.0000) (sitting on:0.6094) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.3243) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-10-05 00:31:04 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_2800.pt
2023-10-05 00:31:51 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_2800.pt (epoch 4 @ 2800 updates, score 0.5945144130379424) (writing took 53.396667602006346 seconds)
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 00:31:58 - progress_bar.py[line:272] - INFO: epoch 004:     92 / 907 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=272.7, nsentences=96, sample_size=272.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=2.3, ups=0.01, wpb=272.7, bsz=96, num_updates=2810, lr=3.45132e-05, gnorm=0.831, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=18544
2023-10-05 00:32:05 - progress_bar.py[line:272] - INFO: epoch 004:    102 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401, ups=1.5, wpb=268.1, bsz=96, num_updates=2820, lr=3.44487e-05, gnorm=0.711, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=18551
2023-10-05 00:32:11 - progress_bar.py[line:272] - INFO: epoch 004:    112 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.096, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=402.3, ups=1.49, wpb=269.7, bsz=96, num_updates=2830, lr=3.43843e-05, gnorm=0.877, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=18557
2023-10-05 00:32:18 - progress_bar.py[line:272] - INFO: epoch 004:    122 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.4, ups=1.49, wpb=268.7, bsz=96, num_updates=2840, lr=3.43198e-05, gnorm=0.575, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=18564
2023-10-05 00:32:25 - progress_bar.py[line:272] - INFO: epoch 004:    132 / 907 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.085, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=400.3, ups=1.49, wpb=268.9, bsz=96, num_updates=2850, lr=3.42553e-05, gnorm=0.68, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=18571
2023-10-05 00:32:32 - progress_bar.py[line:272] - INFO: epoch 004:    142 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.092, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400.4, ups=1.49, wpb=268.7, bsz=96, num_updates=2860, lr=3.41908e-05, gnorm=0.717, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=18578
2023-10-05 00:32:38 - progress_bar.py[line:272] - INFO: epoch 004:    152 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401.3, ups=1.5, wpb=268.3, bsz=96, num_updates=2870, lr=3.41264e-05, gnorm=0.647, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=18584
2023-10-05 00:32:45 - progress_bar.py[line:272] - INFO: epoch 004:    162 / 907 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=394.7, ups=1.46, wpb=271.3, bsz=96, num_updates=2880, lr=3.40619e-05, gnorm=0.646, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=18591
2023-10-05 00:32:52 - progress_bar.py[line:272] - INFO: epoch 004:    172 / 907 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.088, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.5, ups=1.45, wpb=270, bsz=96, num_updates=2890, lr=3.39974e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=18598
2023-10-05 00:32:59 - progress_bar.py[line:272] - INFO: epoch 004:    182 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=400.5, ups=1.49, wpb=269.1, bsz=96, num_updates=2900, lr=3.39329e-05, gnorm=0.753, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=18605
2023-10-05 00:33:06 - progress_bar.py[line:272] - INFO: epoch 004:    192 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.092, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=402.3, ups=1.49, wpb=270.7, bsz=96, num_updates=2910, lr=3.38685e-05, gnorm=0.697, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=18612
2023-10-05 00:33:12 - progress_bar.py[line:272] - INFO: epoch 004:    202 / 907 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.092, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400, ups=1.49, wpb=267.8, bsz=96, num_updates=2920, lr=3.3804e-05, gnorm=0.757, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=18618
2023-10-05 00:33:19 - progress_bar.py[line:272] - INFO: epoch 004:    212 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=404, ups=1.49, wpb=270.8, bsz=96, num_updates=2930, lr=3.37395e-05, gnorm=0.674, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=18625
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 00:33:26 - progress_bar.py[line:272] - INFO: epoch 004:    222 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.086, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.1, ups=1.45, wpb=269.2, bsz=96, num_updates=2940, lr=3.3675e-05, gnorm=0.797, clip=20, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=18632
@@@@ ERROR IN DATA @@@@ watch
2023-10-05 00:33:33 - progress_bar.py[line:272] - INFO: epoch 004:    232 / 907 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=401.2, ups=1.49, wpb=269.3, bsz=96, num_updates=2950, lr=3.36106e-05, gnorm=0.671, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=18639
2023-10-05 00:33:39 - progress_bar.py[line:272] - INFO: epoch 004:    242 / 907 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=271.4, nsentences=96, sample_size=271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=405.2, ups=1.49, wpb=271.4, bsz=96, num_updates=2960, lr=3.35461e-05, gnorm=0.706, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=18645
2023-10-05 00:33:46 - progress_bar.py[line:272] - INFO: epoch 004:    252 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.6, ups=1.45, wpb=269, bsz=96, num_updates=2970, lr=3.34816e-05, gnorm=0.738, clip=20, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=18652
2023-10-05 00:33:53 - progress_bar.py[line:272] - INFO: epoch 004:    262 / 907 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=271.5, nsentences=96, sample_size=271.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=405.7, ups=1.49, wpb=271.5, bsz=96, num_updates=2980, lr=3.34172e-05, gnorm=0.781, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=18659
2023-10-05 00:34:00 - progress_bar.py[line:272] - INFO: epoch 004:    272 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.086, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=383.7, ups=1.42, wpb=270.2, bsz=96, num_updates=2990, lr=3.33527e-05, gnorm=0.892, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=18666
2023-10-05 00:34:07 - progress_bar.py[line:272] - INFO: epoch 004:    282 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=394.2, ups=1.45, wpb=271.3, bsz=96, num_updates=3000, lr=3.32882e-05, gnorm=0.648, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=18673
2023-10-05 00:34:07 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 00:34:10 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 00:34:10 - train.py[line:550] - INFO: load:2.93 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 00:35:47 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 00:35:47 - train.py[line:550] - INFO: load:3.02 valid_run:96.82 task_valid:93.03 collect_output:2.82
2023-10-05 00:37:23 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 00:37:23 - train.py[line:550] - INFO: load:3.10 valid_run:192.86 task_valid:184.88 collect_output:6.07
2023-10-05 00:38:59 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 00:38:59 - train.py[line:550] - INFO: load:3.20 valid_run:289.12 task_valid:273.93 collect_output:12.28
2023-10-05 00:40:35 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 00:40:35 - train.py[line:550] - INFO: load:3.29 valid_run:384.63 task_valid:364.08 collect_output:16.68
2023-10-05 00:42:11 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 00:42:11 - train.py[line:550] - INFO: load:3.37 valid_run:480.56 task_valid:454.25 collect_output:21.50
2023-10-05 00:43:47 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 00:43:47 - train.py[line:550] - INFO: load:3.46 valid_run:576.52 task_valid:543.80 collect_output:26.95
2023-10-05 00:45:22 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 00:45:22 - train.py[line:550] - INFO: load:3.55 valid_run:671.16 task_valid:634.20 collect_output:30.20
2023-10-05 00:46:58 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 00:46:58 - train.py[line:550] - INFO: load:3.63 valid_run:766.73 task_valid:726.43 collect_output:32.56
2023-10-05 00:48:34 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 00:48:34 - train.py[line:550] - INFO: load:3.72 valid_run:862.61 task_valid:817.15 collect_output:36.75
2023-10-05 00:50:10 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 00:50:10 - train.py[line:550] - INFO: load:3.80 valid_run:958.98 task_valid:909.10 collect_output:40.21
2023-10-05 00:51:46 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 00:51:46 - train.py[line:550] - INFO: load:3.89 valid_run:1054.51 task_valid:1000.58 collect_output:43.32

====================================================================================================
SGG eval:     R @ 50: 0.5718;     R @ 100: 0.6187;     R @ 500: 0.6683;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3440;    mR @ 100: 0.3888;    mR @ 500: 0.4526;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4756) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8784) (says:0.0000) (sitting on:0.6366) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.4595) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5718;     R @ 100: 0.6187;     R @ 500: 0.6683;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3440;    mR @ 100: 0.3888;    mR @ 500: 0.4526;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4756) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8784) (says:0.0000) (sitting on:0.6366) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.4595) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5718;     R @ 100: 0.6187;     R @ 500: 0.6683;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3440;    mR @ 100: 0.3888;    mR @ 500: 0.4526;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4756) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8784) (says:0.0000) (sitting on:0.6366) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.4595) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5718;     R @ 100: 0.6187;     R @ 500: 0.6683;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3440;    mR @ 100: 0.3888;    mR @ 500: 0.4526;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4756) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8784) (says:0.0000) (sitting on:0.6366) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.4595) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-10-05 00:53:01 - train.py[line:487] - INFO: 0.6187144130379425

====================================================================================================
SGG eval:     R @ 50: 0.5718;     R @ 100: 0.6187;     R @ 500: 0.6683;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3440;    mR @ 100: 0.3888;    mR @ 500: 0.4526;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4756) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8784) (says:0.0000) (sitting on:0.6366) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.4595) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5718;     R @ 100: 0.6187;     R @ 500: 0.6683;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3440;    mR @ 100: 0.3888;    mR @ 500: 0.4526;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4756) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8784) (says:0.0000) (sitting on:0.6366) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.4595) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-10-05 00:53:02 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 00:53:02 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.242 | loss_v1 0 | loss_v2 0 | nll_loss 0.07 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.618714 | ppl 1.05 | vqa_score 0.3581 | wps 396.4 | wpb 191.9 | bsz 64 | num_updates 3000 | best_R@100 0.618714
2023-10-05 00:53:02 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 3000 updates
2023-10-05 00:53:02 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3000.pt

====================================================================================================
SGG eval:     R @ 50: 0.5718;     R @ 100: 0.6187;     R @ 500: 0.6683;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3440;    mR @ 100: 0.3888;    mR @ 500: 0.4526;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4756) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8784) (says:0.0000) (sitting on:0.6366) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.4595) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5718;     R @ 100: 0.6187;     R @ 500: 0.6683;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3440;    mR @ 100: 0.3888;    mR @ 500: 0.4526;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.4756) (covered in:0.1250) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8333) (playing:0.0000) (riding:0.8784) (says:0.0000) (sitting on:0.6366) (standing on:0.6143) (using:0.3000) (walking in:0.0000) (walking on:0.4595) (watching:0.3333) 
--------------------------------------------------------
====================================================================================================

2023-10-05 00:53:08 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3000.pt
2023-10-05 00:53:56 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3000.pt (epoch 4 @ 3000 updates, score 0.6187144130379425) (writing took 54.67136662499979 seconds)
2023-10-05 00:54:03 - progress_bar.py[line:272] - INFO: epoch 004:    292 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.3, ups=0.01, wpb=270.6, bsz=96, num_updates=3010, lr=3.32237e-05, gnorm=0.622, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19869
2023-10-05 00:54:10 - progress_bar.py[line:272] - INFO: epoch 004:    302 / 907 loss=0.272, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=402.4, ups=1.5, wpb=268.7, bsz=96, num_updates=3020, lr=3.31593e-05, gnorm=0.833, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19876
2023-10-05 00:54:16 - progress_bar.py[line:272] - INFO: epoch 004:    312 / 907 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.088, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=400.9, ups=1.49, wpb=268.9, bsz=96, num_updates=3030, lr=3.30948e-05, gnorm=0.689, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19882
2023-10-05 00:54:23 - progress_bar.py[line:272] - INFO: epoch 004:    322 / 907 loss=0.276, loss_v1=0, loss_v2=0, nll_loss=0.101, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=399.2, ups=1.48, wpb=269.7, bsz=96, num_updates=3040, lr=3.30303e-05, gnorm=0.789, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19889
2023-10-05 00:54:30 - progress_bar.py[line:272] - INFO: epoch 004:    332 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.085, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=389.3, ups=1.45, wpb=268.2, bsz=96, num_updates=3050, lr=3.29658e-05, gnorm=0.663, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19896
2023-10-05 00:54:37 - progress_bar.py[line:272] - INFO: epoch 004:    342 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=268.8, nsentences=96, sample_size=268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.5, ups=1.5, wpb=268.8, bsz=96, num_updates=3060, lr=3.29014e-05, gnorm=0.6, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19903
@@@@ ERROR IN DATA @@@@ ride
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 00:54:44 - progress_bar.py[line:272] - INFO: epoch 004:    352 / 907 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=392, ups=1.45, wpb=269.6, bsz=96, num_updates=3070, lr=3.28369e-05, gnorm=0.699, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19910
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 00:54:51 - progress_bar.py[line:272] - INFO: epoch 004:    362 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=267.5, nsentences=96, sample_size=267.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=387.5, ups=1.45, wpb=267.5, bsz=96, num_updates=3080, lr=3.27724e-05, gnorm=0.623, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=19917
2023-10-05 00:54:57 - progress_bar.py[line:272] - INFO: epoch 004:    372 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=403.1, ups=1.5, wpb=269.2, bsz=96, num_updates=3090, lr=3.27079e-05, gnorm=0.66, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=19923
2023-10-05 00:55:04 - progress_bar.py[line:272] - INFO: epoch 004:    382 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=403.2, ups=1.49, wpb=270, bsz=96, num_updates=3100, lr=3.26435e-05, gnorm=0.691, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=19930
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 00:55:11 - progress_bar.py[line:272] - INFO: epoch 004:    392 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.089, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401.5, ups=1.49, wpb=269.4, bsz=96, num_updates=3110, lr=3.2579e-05, gnorm=0.728, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19937
2023-10-05 00:55:17 - progress_bar.py[line:272] - INFO: epoch 004:    402 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403, ups=1.49, wpb=270.6, bsz=96, num_updates=3120, lr=3.25145e-05, gnorm=0.593, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=19943
2023-10-05 00:55:24 - progress_bar.py[line:272] - INFO: epoch 004:    412 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401.6, ups=1.49, wpb=269.6, bsz=96, num_updates=3130, lr=3.245e-05, gnorm=0.602, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19950
2023-10-05 00:55:31 - progress_bar.py[line:272] - INFO: epoch 004:    422 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=391.5, ups=1.45, wpb=270.6, bsz=96, num_updates=3140, lr=3.23856e-05, gnorm=0.716, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19957
2023-10-05 00:55:38 - progress_bar.py[line:272] - INFO: epoch 004:    432 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=389.4, ups=1.45, wpb=268.7, bsz=96, num_updates=3150, lr=3.23211e-05, gnorm=0.692, clip=0, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=19964
2023-10-05 00:55:45 - progress_bar.py[line:272] - INFO: epoch 004:    442 / 907 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=380.4, ups=1.41, wpb=269.2, bsz=96, num_updates=3160, lr=3.22566e-05, gnorm=0.757, clip=0, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=19971
2023-10-05 00:55:47 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-10-05 00:55:52 - progress_bar.py[line:272] - INFO: epoch 004:    453 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.095, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=369.8, ups=1.37, wpb=270.2, bsz=96, num_updates=3170, lr=3.21921e-05, gnorm=0.953, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19978
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 00:55:59 - progress_bar.py[line:272] - INFO: epoch 004:    463 / 907 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=377.8, ups=1.41, wpb=268.5, bsz=96, num_updates=3180, lr=3.21277e-05, gnorm=0.859, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19985
2023-10-05 00:56:06 - progress_bar.py[line:272] - INFO: epoch 004:    473 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=388.9, ups=1.45, wpb=269, bsz=96, num_updates=3190, lr=3.20632e-05, gnorm=0.804, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=19992
2023-10-05 00:56:13 - progress_bar.py[line:272] - INFO: epoch 004:    483 / 907 loss=0.27, loss_v1=0, loss_v2=0, nll_loss=0.091, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=401.2, ups=1.49, wpb=268.7, bsz=96, num_updates=3200, lr=3.19987e-05, gnorm=0.803, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=19999
2023-10-05 00:56:13 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 00:56:15 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 00:56:15 - train.py[line:550] - INFO: load:2.20 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 00:56:16 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.28 GiB (GPU 4; 23.70 GiB total capacity; 6.79 GiB already allocated; 1.05 GiB free; 21.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-05 00:56:16 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:56:16 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:56:16 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:56:16 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:56:16 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 17        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6951 MiB |   7604 MiB |   2304 TiB |   2304 TiB |
|       from large pool |   6806 MiB |   7459 MiB |   2293 TiB |   2293 TiB |
|       from small pool |    144 MiB |    145 MiB |     11 TiB |     11 TiB |
|---------------------------------------------------------------------------|
| Active memory         |   6951 MiB |   7604 MiB |   2304 TiB |   2304 TiB |
|       from large pool |   6806 MiB |   7459 MiB |   2293 TiB |   2293 TiB |
|       from small pool |    144 MiB |    145 MiB |     11 TiB |     11 TiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6900 MiB |   7553 MiB |   2300 TiB |   2300 TiB |
|       from large pool |   6755 MiB |   7408 MiB |   2288 TiB |   2288 TiB |
|       from small pool |    144 MiB |    145 MiB |     11 TiB |     11 TiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  21774 MiB |  21790 MiB | 114028 MiB |  92254 MiB |
|       from large pool |  21628 MiB |  21628 MiB | 113580 MiB |  91952 MiB |
|       from small pool |    146 MiB |    162 MiB |    448 MiB |    302 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14822 MiB |  14822 MiB |   2218 TiB |   2218 TiB |
|       from large pool |  14821 MiB |  14821 MiB |   2205 TiB |   2205 TiB |
|       from small pool |      1 MiB |      2 MiB |     12 TiB |     12 TiB |
|---------------------------------------------------------------------------|
| Allocations           |    3567    |    3582    |  146075 K  |  146071 K  |
|       from large pool |     565    |     577    |   59536 K  |   59535 K  |
|       from small pool |    3002    |    3021    |   86538 K  |   86535 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3567    |    3582    |  146075 K  |  146071 K  |
|       from large pool |     565    |     577    |   59536 K  |   59535 K  |
|       from small pool |    3002    |    3021    |   86538 K  |   86535 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     146    |     154    |     478    |     332    |
|       from large pool |      73    |      73    |     254    |     181    |
|       from small pool |      73    |      81    |     224    |     151    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |     100    |     107    |   82576 K  |   82576 K  |
|       from large pool |      68    |      69    |   20871 K  |   20871 K  |
|       from small pool |      32    |      40    |   61704 K  |   61704 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:56:16 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:56:16 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:56:16 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 00:56:16 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-05 00:57:53 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 00:57:53 - train.py[line:550] - INFO: load:2.29 valid_run:97.37 task_valid:93.29 collect_output:3.00
2023-10-05 00:59:29 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 00:59:29 - train.py[line:550] - INFO: load:2.37 valid_run:193.78 task_valid:185.11 collect_output:6.61
2023-10-05 01:01:05 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 01:01:05 - train.py[line:550] - INFO: load:2.46 valid_run:289.76 task_valid:274.14 collect_output:12.59
2023-10-05 01:02:41 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 01:02:41 - train.py[line:550] - INFO: load:2.54 valid_run:385.19 task_valid:364.27 collect_output:16.93
2023-10-05 01:04:17 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 01:04:17 - train.py[line:550] - INFO: load:2.62 valid_run:481.15 task_valid:454.35 collect_output:21.82
2023-10-05 01:05:54 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 01:05:54 - train.py[line:550] - INFO: load:2.70 valid_run:577.49 task_valid:544.34 collect_output:27.22
2023-10-05 01:07:28 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 01:07:28 - train.py[line:550] - INFO: load:2.79 valid_run:672.22 task_valid:634.93 collect_output:30.34
2023-10-05 01:09:05 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 01:09:05 - train.py[line:550] - INFO: load:2.87 valid_run:768.33 task_valid:727.27 collect_output:33.09
2023-10-05 01:10:41 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 01:10:41 - train.py[line:550] - INFO: load:2.95 valid_run:864.40 task_valid:818.23 collect_output:37.22
2023-10-05 01:12:17 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 01:12:17 - train.py[line:550] - INFO: load:3.04 valid_run:960.33 task_valid:909.90 collect_output:40.52
2023-10-05 01:13:52 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 01:13:52 - train.py[line:550] - INFO: load:3.12 valid_run:1055.46 task_valid:1001.32 collect_output:43.30

====================================================================================================
SGG eval:     R @ 50: 0.5844;     R @ 100: 0.6369;     R @ 500: 0.6828;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3533;    mR @ 100: 0.4047;    mR @ 500: 0.4652;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5122) (covered in:0.1875) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5161) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8750) (playing:0.0000) (riding:0.8686) (says:0.0000) (sitting on:0.6502) (standing on:0.6193) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5844;     R @ 100: 0.6369;     R @ 500: 0.6828;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3533;    mR @ 100: 0.4047;    mR @ 500: 0.4652;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5122) (covered in:0.1875) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5161) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8750) (playing:0.0000) (riding:0.8686) (says:0.0000) (sitting on:0.6502) (standing on:0.6193) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5844;     R @ 100: 0.6369;     R @ 500: 0.6828;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3533;    mR @ 100: 0.4047;    mR @ 500: 0.4652;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5122) (covered in:0.1875) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5161) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8750) (playing:0.0000) (riding:0.8686) (says:0.0000) (sitting on:0.6502) (standing on:0.6193) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5844;     R @ 100: 0.6369;     R @ 500: 0.6828;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3533;    mR @ 100: 0.4047;    mR @ 500: 0.4652;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5122) (covered in:0.1875) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5161) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8750) (playing:0.0000) (riding:0.8686) (says:0.0000) (sitting on:0.6502) (standing on:0.6193) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5844;     R @ 100: 0.6369;     R @ 500: 0.6828;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3533;    mR @ 100: 0.4047;    mR @ 500: 0.4652;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5122) (covered in:0.1875) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5161) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8750) (playing:0.0000) (riding:0.8686) (says:0.0000) (sitting on:0.6502) (standing on:0.6193) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5844;     R @ 100: 0.6369;     R @ 500: 0.6828;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3533;    mR @ 100: 0.4047;    mR @ 500: 0.4652;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5122) (covered in:0.1875) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5161) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8750) (playing:0.0000) (riding:0.8686) (says:0.0000) (sitting on:0.6502) (standing on:0.6193) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5844;     R @ 100: 0.6369;     R @ 500: 0.6828;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3533;    mR @ 100: 0.4047;    mR @ 500: 0.4652;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5122) (covered in:0.1875) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5161) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8750) (playing:0.0000) (riding:0.8686) (says:0.0000) (sitting on:0.6502) (standing on:0.6193) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================

2023-10-05 01:15:08 - train.py[line:487] - INFO: 0.636881079704609

====================================================================================================
SGG eval:     R @ 50: 0.5844;     R @ 100: 0.6369;     R @ 500: 0.6828;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3533;    mR @ 100: 0.4047;    mR @ 500: 0.4652;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5122) (covered in:0.1875) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5161) (lying on:0.5000) (mounted on:0.0000) (painted on:0.1667) (parked on:0.8750) (playing:0.0000) (riding:0.8686) (says:0.0000) (sitting on:0.6502) (standing on:0.6193) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================

2023-10-05 01:15:08 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 01:15:08 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.251 | loss_v1 0 | loss_v2 0 | nll_loss 0.084 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.636881 | ppl 1.06 | vqa_score 0.3773 | wps 396.3 | wpb 191.9 | bsz 64 | num_updates 3200 | best_R@100 0.636881
2023-10-05 01:15:08 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 3200 updates
2023-10-05 01:15:08 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3200.pt
2023-10-05 01:15:14 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3200.pt
2023-10-05 01:16:03 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3200.pt (epoch 4 @ 3200 updates, score 0.636881079704609) (writing took 54.764839701820165 seconds)
2023-10-05 01:16:10 - progress_bar.py[line:272] - INFO: epoch 004:    493 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=272, nsentences=96, sample_size=272, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=2.3, ups=0.01, wpb=272, bsz=96, num_updates=3210, lr=3.19342e-05, gnorm=0.696, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=21196
2023-10-05 01:16:16 - progress_bar.py[line:272] - INFO: epoch 004:    503 / 907 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.092, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=404.8, ups=1.5, wpb=269.7, bsz=96, num_updates=3220, lr=3.18698e-05, gnorm=0.69, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=21202
2023-10-05 01:16:23 - progress_bar.py[line:272] - INFO: epoch 004:    513 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.3, ups=1.49, wpb=269.1, bsz=96, num_updates=3230, lr=3.18053e-05, gnorm=0.647, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=21209
2023-10-05 01:16:30 - progress_bar.py[line:272] - INFO: epoch 004:    523 / 907 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.088, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=402.8, ups=1.48, wpb=271.3, bsz=96, num_updates=3240, lr=3.17408e-05, gnorm=0.844, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=21216
2023-10-05 01:16:37 - progress_bar.py[line:272] - INFO: epoch 004:    533 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=381.2, ups=1.41, wpb=269.7, bsz=96, num_updates=3250, lr=3.16763e-05, gnorm=0.729, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=21223
2023-10-05 01:16:44 - progress_bar.py[line:272] - INFO: epoch 004:    543 / 907 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.089, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=402.7, ups=1.5, wpb=269.3, bsz=96, num_updates=3260, lr=3.16119e-05, gnorm=0.777, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=21230
2023-10-05 01:16:50 - progress_bar.py[line:272] - INFO: epoch 004:    553 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=403.6, ups=1.49, wpb=270.4, bsz=96, num_updates=3270, lr=3.15474e-05, gnorm=0.646, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=21236
2023-10-05 01:16:57 - progress_bar.py[line:272] - INFO: epoch 004:    563 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=400.8, ups=1.48, wpb=270.2, bsz=96, num_updates=3280, lr=3.14829e-05, gnorm=0.731, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=21243
2023-10-05 01:17:04 - progress_bar.py[line:272] - INFO: epoch 004:    573 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.086, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=402.2, ups=1.49, wpb=269.9, bsz=96, num_updates=3290, lr=3.14184e-05, gnorm=0.715, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=21250
2023-10-05 01:17:10 - progress_bar.py[line:272] - INFO: epoch 004:    583 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=404.7, ups=1.49, wpb=270.9, bsz=96, num_updates=3300, lr=3.1354e-05, gnorm=0.639, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=21256
2023-10-05 01:17:17 - progress_bar.py[line:272] - INFO: epoch 004:    593 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=399.7, ups=1.49, wpb=268.5, bsz=96, num_updates=3310, lr=3.12895e-05, gnorm=0.703, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=21263
2023-10-05 01:17:24 - progress_bar.py[line:272] - INFO: epoch 004:    603 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=392.1, ups=1.45, wpb=269.5, bsz=96, num_updates=3320, lr=3.1225e-05, gnorm=0.825, clip=10, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=21270
2023-10-05 01:17:31 - progress_bar.py[line:272] - INFO: epoch 004:    613 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=271.8, nsentences=96, sample_size=271.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=394.5, ups=1.45, wpb=271.8, bsz=96, num_updates=3330, lr=3.11605e-05, gnorm=0.668, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=21277
2023-10-05 01:17:38 - progress_bar.py[line:272] - INFO: epoch 004:    623 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=267, nsentences=96, sample_size=267, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=397.1, ups=1.49, wpb=267, bsz=96, num_updates=3340, lr=3.10961e-05, gnorm=0.796, clip=20, loss_scale=512, train_wall=7, gb_free=6, ema_decay=0.9999, wall=21284
2023-10-05 01:17:44 - progress_bar.py[line:272] - INFO: epoch 004:    633 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=404.2, ups=1.5, wpb=270.1, bsz=96, num_updates=3350, lr=3.10316e-05, gnorm=0.737, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=21290
2023-10-05 01:17:51 - progress_bar.py[line:272] - INFO: epoch 004:    643 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.7, ups=1.45, wpb=269.4, bsz=96, num_updates=3360, lr=3.09671e-05, gnorm=0.712, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=21297
2023-10-05 01:17:58 - progress_bar.py[line:272] - INFO: epoch 004:    653 / 907 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=268.8, nsentences=96, sample_size=268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=380.6, ups=1.42, wpb=268.8, bsz=96, num_updates=3370, lr=3.09026e-05, gnorm=0.871, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=21304
2023-10-05 01:18:05 - progress_bar.py[line:272] - INFO: epoch 004:    663 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401.4, ups=1.49, wpb=269.3, bsz=96, num_updates=3380, lr=3.08382e-05, gnorm=0.738, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=21311
2023-10-05 01:18:12 - progress_bar.py[line:272] - INFO: epoch 004:    673 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.2, ups=1.45, wpb=269.7, bsz=96, num_updates=3390, lr=3.07737e-05, gnorm=0.681, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=21318
2023-10-05 01:18:19 - progress_bar.py[line:272] - INFO: epoch 004:    683 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=267.6, nsentences=96, sample_size=267.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=376.1, ups=1.41, wpb=267.6, bsz=96, num_updates=3400, lr=3.07092e-05, gnorm=0.596, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=21325
2023-10-05 01:18:19 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 01:18:21 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 01:18:21 - train.py[line:550] - INFO: load:1.92 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 01:19:59 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 01:19:59 - train.py[line:550] - INFO: load:2.01 valid_run:97.35 task_valid:93.01 collect_output:3.35
2023-10-05 01:21:35 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 01:21:35 - train.py[line:550] - INFO: load:2.11 valid_run:193.59 task_valid:184.81 collect_output:6.84
2023-10-05 01:23:11 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 01:23:11 - train.py[line:550] - INFO: load:2.19 valid_run:289.59 task_valid:273.74 collect_output:12.95
2023-10-05 01:24:46 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 01:24:46 - train.py[line:550] - INFO: load:2.28 valid_run:384.66 task_valid:363.79 collect_output:16.98
2023-10-05 01:26:22 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 01:26:22 - train.py[line:550] - INFO: load:2.37 valid_run:480.45 task_valid:453.97 collect_output:21.62
2023-10-05 01:27:58 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 01:27:58 - train.py[line:550] - INFO: load:2.46 valid_run:576.13 task_valid:543.70 collect_output:26.52
2023-10-05 01:29:33 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 01:29:33 - train.py[line:550] - INFO: load:2.55 valid_run:671.27 task_valid:634.20 collect_output:30.23
2023-10-05 01:31:09 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 01:31:09 - train.py[line:550] - INFO: load:2.64 valid_run:767.13 task_valid:726.64 collect_output:32.69
2023-10-05 01:32:45 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 01:32:45 - train.py[line:550] - INFO: load:2.74 valid_run:863.01 task_valid:817.64 collect_output:36.57
2023-10-05 01:34:22 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 01:34:22 - train.py[line:550] - INFO: load:2.83 valid_run:959.60 task_valid:909.64 collect_output:40.13
2023-10-05 01:35:57 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 01:35:57 - train.py[line:550] - INFO: load:2.92 valid_run:1054.90 task_valid:1001.08 collect_output:42.99

====================================================================================================
SGG eval:     R @ 50: 0.5953;     R @ 100: 0.6488;     R @ 500: 0.6992;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3746;    mR @ 100: 0.4198;    mR @ 500: 0.4834;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8696) (says:0.0000) (sitting on:0.6672) (standing on:0.6293) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5953;     R @ 100: 0.6488;     R @ 500: 0.6992;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3746;    mR @ 100: 0.4198;    mR @ 500: 0.4834;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8696) (says:0.0000) (sitting on:0.6672) (standing on:0.6293) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5953;     R @ 100: 0.6488;     R @ 500: 0.6992;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3746;    mR @ 100: 0.4198;    mR @ 500: 0.4834;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8696) (says:0.0000) (sitting on:0.6672) (standing on:0.6293) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5953;     R @ 100: 0.6488;     R @ 500: 0.6992;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3746;    mR @ 100: 0.4198;    mR @ 500: 0.4834;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8696) (says:0.0000) (sitting on:0.6672) (standing on:0.6293) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5953;     R @ 100: 0.6488;     R @ 500: 0.6992;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3746;    mR @ 100: 0.4198;    mR @ 500: 0.4834;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8696) (says:0.0000) (sitting on:0.6672) (standing on:0.6293) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5953;     R @ 100: 0.6488;     R @ 500: 0.6992;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3746;    mR @ 100: 0.4198;    mR @ 500: 0.4834;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8696) (says:0.0000) (sitting on:0.6672) (standing on:0.6293) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.5953;     R @ 100: 0.6488;     R @ 500: 0.6992;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3746;    mR @ 100: 0.4198;    mR @ 500: 0.4834;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8696) (says:0.0000) (sitting on:0.6672) (standing on:0.6293) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================

2023-10-05 01:37:13 - train.py[line:487] - INFO: 0.6488144130379424

====================================================================================================
SGG eval:     R @ 50: 0.5953;     R @ 100: 0.6488;     R @ 500: 0.6992;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3746;    mR @ 100: 0.4198;    mR @ 500: 0.4834;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8696) (says:0.0000) (sitting on:0.6672) (standing on:0.6293) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4167) 
--------------------------------------------------------
====================================================================================================

2023-10-05 01:37:14 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 01:37:14 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.243 | loss_v1 0 | loss_v2 0 | nll_loss 0.075 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.648814 | ppl 1.05 | vqa_score 0.3964 | wps 396.3 | wpb 191.9 | bsz 64 | num_updates 3400 | best_R@100 0.648814
2023-10-05 01:37:14 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 3400 updates
2023-10-05 01:37:14 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3400.pt
2023-10-05 01:37:19 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3400.pt
2023-10-05 01:38:06 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3400.pt (epoch 4 @ 3400 updates, score 0.6488144130379424) (writing took 52.503946704789996 seconds)
2023-10-05 01:38:13 - progress_bar.py[line:272] - INFO: epoch 004:    693 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=2.2, ups=0.01, wpb=268, bsz=96, num_updates=3410, lr=3.06447e-05, gnorm=0.853, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22519
2023-10-05 01:38:20 - progress_bar.py[line:272] - INFO: epoch 004:    703 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=400.8, ups=1.49, wpb=269.1, bsz=96, num_updates=3420, lr=3.05803e-05, gnorm=0.85, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22526
2023-10-05 01:38:27 - progress_bar.py[line:272] - INFO: epoch 004:    713 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.09, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=400.3, ups=1.49, wpb=268.5, bsz=96, num_updates=3430, lr=3.05158e-05, gnorm=0.846, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=22533
2023-10-05 01:38:33 - progress_bar.py[line:272] - INFO: epoch 004:    723 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=267.6, nsentences=96, sample_size=267.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=400.2, ups=1.5, wpb=267.6, bsz=96, num_updates=3440, lr=3.04513e-05, gnorm=0.679, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22539
2023-10-05 01:38:40 - progress_bar.py[line:272] - INFO: epoch 004:    733 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.086, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=403.6, ups=1.5, wpb=269.8, bsz=96, num_updates=3450, lr=3.03868e-05, gnorm=0.669, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=22546
2023-10-05 01:38:47 - progress_bar.py[line:272] - INFO: epoch 004:    743 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.089, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=384.4, ups=1.42, wpb=271.3, bsz=96, num_updates=3460, lr=3.03224e-05, gnorm=0.813, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=22553
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 01:38:54 - progress_bar.py[line:272] - INFO: epoch 004:    753 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=394.3, ups=1.46, wpb=270.6, bsz=96, num_updates=3470, lr=3.02579e-05, gnorm=0.6, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=22560
2023-10-05 01:39:01 - progress_bar.py[line:272] - INFO: epoch 004:    763 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.095, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=400.8, ups=1.49, wpb=269, bsz=96, num_updates=3480, lr=3.01934e-05, gnorm=0.758, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22567
2023-10-05 01:39:08 - progress_bar.py[line:272] - INFO: epoch 004:    773 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.094, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=393.4, ups=1.46, wpb=270.1, bsz=96, num_updates=3490, lr=3.01289e-05, gnorm=0.811, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22574
2023-10-05 01:39:15 - progress_bar.py[line:272] - INFO: epoch 004:    783 / 907 loss=0.281, loss_v1=0, loss_v2=0, nll_loss=0.102, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=379.5, ups=1.41, wpb=268.6, bsz=96, num_updates=3500, lr=3.00645e-05, gnorm=0.934, clip=30, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=22581
@@@@ ERROR IN DATA @@@@ play
2023-10-05 01:39:21 - progress_bar.py[line:272] - INFO: epoch 004:    793 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=403.8, ups=1.49, wpb=271, bsz=96, num_updates=3510, lr=3e-05, gnorm=0.695, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22587
2023-10-05 01:39:28 - progress_bar.py[line:272] - INFO: epoch 004:    803 / 907 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.085, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=392.6, ups=1.46, wpb=269.1, bsz=96, num_updates=3520, lr=2.99355e-05, gnorm=0.655, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=22594
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 01:39:35 - progress_bar.py[line:272] - INFO: epoch 004:    813 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.8, ups=1.49, wpb=269.7, bsz=96, num_updates=3530, lr=2.98711e-05, gnorm=0.695, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22601
2023-10-05 01:39:42 - progress_bar.py[line:272] - INFO: epoch 004:    823 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=399.9, ups=1.49, wpb=268.3, bsz=96, num_updates=3540, lr=2.98066e-05, gnorm=0.824, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=22608
2023-10-05 01:39:49 - progress_bar.py[line:272] - INFO: epoch 004:    833 / 907 loss=0.266, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=381.1, ups=1.41, wpb=269.9, bsz=96, num_updates=3550, lr=2.97421e-05, gnorm=0.805, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=22615
2023-10-05 01:39:56 - progress_bar.py[line:272] - INFO: epoch 004:    843 / 907 loss=0.269, loss_v1=0, loss_v2=0, nll_loss=0.092, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=396, ups=1.48, wpb=268, bsz=96, num_updates=3560, lr=2.96776e-05, gnorm=0.769, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22622
2023-10-05 01:40:02 - progress_bar.py[line:272] - INFO: epoch 004:    853 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.9, ups=1.45, wpb=269.5, bsz=96, num_updates=3570, lr=2.96132e-05, gnorm=0.654, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22628
2023-10-05 01:40:09 - progress_bar.py[line:272] - INFO: epoch 004:    863 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=384.7, ups=1.42, wpb=270.9, bsz=96, num_updates=3580, lr=2.95487e-05, gnorm=0.7, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22636
2023-10-05 01:40:16 - progress_bar.py[line:272] - INFO: epoch 004:    873 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=392, ups=1.45, wpb=269.7, bsz=96, num_updates=3590, lr=2.94842e-05, gnorm=0.653, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22642
2023-10-05 01:40:23 - progress_bar.py[line:272] - INFO: epoch 004:    883 / 907 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.084, ntokens=273.3, nsentences=96, sample_size=273.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=399.1, ups=1.46, wpb=273.3, bsz=96, num_updates=3600, lr=2.94197e-05, gnorm=0.752, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=22649
2023-10-05 01:40:23 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 01:40:26 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 01:40:26 - train.py[line:550] - INFO: load:2.42 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 01:42:03 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 01:42:03 - train.py[line:550] - INFO: load:2.53 valid_run:97.03 task_valid:93.03 collect_output:2.94
2023-10-05 01:43:39 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 01:43:39 - train.py[line:550] - INFO: load:2.63 valid_run:192.97 task_valid:184.78 collect_output:6.17
2023-10-05 01:45:15 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 01:45:15 - train.py[line:550] - INFO: load:2.71 valid_run:289.16 task_valid:273.69 collect_output:12.46
2023-10-05 01:46:51 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 01:46:51 - train.py[line:550] - INFO: load:2.80 valid_run:384.56 task_valid:363.74 collect_output:16.87
2023-10-05 01:48:27 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 01:48:27 - train.py[line:550] - INFO: load:2.88 valid_run:480.20 task_valid:453.68 collect_output:21.65
2023-10-05 01:50:03 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 01:50:03 - train.py[line:550] - INFO: load:2.96 valid_run:576.02 task_valid:543.24 collect_output:27.00
2023-10-05 01:51:38 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 01:51:38 - train.py[line:550] - INFO: load:3.05 valid_run:671.01 task_valid:633.77 collect_output:30.49
2023-10-05 01:53:14 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 01:53:14 - train.py[line:550] - INFO: load:3.13 valid_run:766.90 task_valid:725.91 collect_output:33.29
2023-10-05 01:54:50 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 01:54:50 - train.py[line:550] - INFO: load:3.21 valid_run:862.99 task_valid:816.55 collect_output:37.80
2023-10-05 01:56:26 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 01:56:26 - train.py[line:550] - INFO: load:3.29 valid_run:959.05 task_valid:908.08 collect_output:41.36
2023-10-05 01:58:02 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 01:58:02 - train.py[line:550] - INFO: load:3.38 valid_run:1054.40 task_valid:999.40 collect_output:44.39

====================================================================================================
SGG eval:     R @ 50: 0.6012;     R @ 100: 0.6445;     R @ 500: 0.6914;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3835;    mR @ 100: 0.4204;    mR @ 500: 0.4828;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8912) (says:0.0000) (sitting on:0.6502) (standing on:0.5943) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6012;     R @ 100: 0.6445;     R @ 500: 0.6914;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3835;    mR @ 100: 0.4204;    mR @ 500: 0.4828;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8912) (says:0.0000) (sitting on:0.6502) (standing on:0.5943) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6012;     R @ 100: 0.6445;     R @ 500: 0.6914;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3835;    mR @ 100: 0.4204;    mR @ 500: 0.4828;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8912) (says:0.0000) (sitting on:0.6502) (standing on:0.5943) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6012;     R @ 100: 0.6445;     R @ 500: 0.6914;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3835;    mR @ 100: 0.4204;    mR @ 500: 0.4828;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8912) (says:0.0000) (sitting on:0.6502) (standing on:0.5943) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6012;     R @ 100: 0.6445;     R @ 500: 0.6914;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3835;    mR @ 100: 0.4204;    mR @ 500: 0.4828;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8912) (says:0.0000) (sitting on:0.6502) (standing on:0.5943) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================

2023-10-05 01:59:17 - train.py[line:487] - INFO: 0.6445477463712757

====================================================================================================
SGG eval:     R @ 50: 0.6012;     R @ 100: 0.6445;     R @ 500: 0.6914;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3835;    mR @ 100: 0.4204;    mR @ 500: 0.4828;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8912) (says:0.0000) (sitting on:0.6502) (standing on:0.5943) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6012;     R @ 100: 0.6445;     R @ 500: 0.6914;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3835;    mR @ 100: 0.4204;    mR @ 500: 0.4828;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8912) (says:0.0000) (sitting on:0.6502) (standing on:0.5943) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================

2023-10-05 01:59:17 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 01:59:17 - progress_bar.py[line:282] - INFO: epoch 004 | valid on 'valid' subset | loss 0.25 | loss_v1 0 | loss_v2 0 | nll_loss 0.084 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.644548 | ppl 1.06 | vqa_score 0.4234 | wps 396.6 | wpb 191.9 | bsz 64 | num_updates 3600 | best_R@100 0.648814
2023-10-05 01:59:17 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 4 @ 3600 updates
2023-10-05 01:59:17 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3600.pt

====================================================================================================
SGG eval:     R @ 50: 0.6012;     R @ 100: 0.6445;     R @ 500: 0.6914;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3835;    mR @ 100: 0.4204;    mR @ 500: 0.4828;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.5976) (covered in:0.3125) (covering:0.2857) (eating:0.6765) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.8912) (says:0.0000) (sitting on:0.6502) (standing on:0.5943) (using:0.3000) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================

2023-10-05 01:59:24 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3600.pt
2023-10-05 02:00:00 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_4_3600.pt (epoch 4 @ 3600 updates, score 0.6445477463712757) (writing took 42.5707112387754 seconds)
2023-10-05 02:00:07 - progress_bar.py[line:272] - INFO: epoch 004:    893 / 907 loss=0.268, loss_v1=0, loss_v2=0, nll_loss=0.086, ntokens=266.9, nsentences=96, sample_size=266.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=2.3, ups=0.01, wpb=266.9, bsz=96, num_updates=3610, lr=2.93553e-05, gnorm=0.938, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=23833
2023-10-05 02:00:14 - progress_bar.py[line:272] - INFO: epoch 004:    903 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.096, ntokens=267.9, nsentences=96, sample_size=267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=384.3, ups=1.43, wpb=267.9, bsz=96, num_updates=3620, lr=2.92908e-05, gnorm=0.745, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23840
2023-10-05 02:00:16 - train.py[line:339] - INFO: end of epoch 4 (average epoch stats below)
2023-10-05 02:00:16 - progress_bar.py[line:282] - INFO: epoch 004 | loss 0.264 | loss_v1 0 | loss_v2 0 | nll_loss 0.085 | ntokens 269.257 | nsentences 95.914 | sample_size 269.257 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.06 | wps 37.2 | ups 0.14 | wpb 269.3 | bsz 95.9 | num_updates 3624 | lr 2.9265e-05 | gnorm 0.731 | clip 11.8 | loss_scale 512 | train_wall 614 | gb_free 16.3 | ema_decay 0.9999 | wall 23842
2023-10-05 02:00:16 - trainer.py[line:694] - INFO: loading train data for epoch 5
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv slice_id 5 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv slice_id 7 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv slice_id 0 row count 10875 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv slice_id 3 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv slice_id 2 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv slice_id 1 row count 10875 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv slice_id 6 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E4.tsv slice_id 4 row count 10874 total row count 86994
2023-10-05 02:00:16 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
2023-10-05 02:00:16 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 02:00:16 - trainer.py[line:758] - INFO: begin training epoch 5
2023-10-05 02:00:16 - train.py[line:312] - INFO: Start iterating over samples
2023-10-05 02:00:24 - progress_bar.py[line:272] - INFO: epoch 005:      6 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.095, ntokens=247.3, nsentences=88.2, sample_size=247.3, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=235.4, ups=0.95, wpb=247.3, bsz=88.2, num_updates=3630, lr=2.92263e-05, gnorm=0.855, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23850
@@@@ ERROR IN DATA @@@@ play
2023-10-05 02:00:31 - progress_bar.py[line:272] - INFO: epoch 005:     16 / 907 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=402.3, ups=1.49, wpb=269.8, bsz=96, num_updates=3640, lr=2.91618e-05, gnorm=0.64, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=23857
2023-10-05 02:00:38 - progress_bar.py[line:272] - INFO: epoch 005:     26 / 907 loss=0.274, loss_v1=0, loss_v2=0, nll_loss=0.096, ntokens=271.5, nsentences=96, sample_size=271.5, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=388.3, ups=1.43, wpb=271.5, bsz=96, num_updates=3650, lr=2.90974e-05, gnorm=0.683, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23864
@@@@ ERROR IN DATA @@@@ play
2023-10-05 02:00:45 - progress_bar.py[line:272] - INFO: epoch 005:     36 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.5, ups=1.45, wpb=270.1, bsz=96, num_updates=3660, lr=2.90329e-05, gnorm=0.631, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=23871
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 02:00:51 - progress_bar.py[line:272] - INFO: epoch 005:     46 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=267.4, nsentences=96, sample_size=267.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=397.5, ups=1.49, wpb=267.4, bsz=96, num_updates=3670, lr=2.89684e-05, gnorm=0.615, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23878
2023-10-05 02:00:58 - progress_bar.py[line:272] - INFO: epoch 005:     56 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.4, ups=1.49, wpb=270.3, bsz=96, num_updates=3680, lr=2.89039e-05, gnorm=0.568, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23884
2023-10-05 02:01:05 - progress_bar.py[line:272] - INFO: epoch 005:     66 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.7, ups=1.49, wpb=269.2, bsz=96, num_updates=3690, lr=2.88395e-05, gnorm=0.52, clip=10, loss_scale=1024, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=23891
2023-10-05 02:01:12 - progress_bar.py[line:272] - INFO: epoch 005:     76 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=372.6, ups=1.38, wpb=269.9, bsz=96, num_updates=3700, lr=2.8775e-05, gnorm=0.573, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23898
2023-10-05 02:01:14 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-10-05 02:01:20 - progress_bar.py[line:272] - INFO: epoch 005:     87 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=272.4, nsentences=96, sample_size=272.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=372.2, ups=1.37, wpb=272.4, bsz=96, num_updates=3710, lr=2.87105e-05, gnorm=0.629, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=23906
@@@@ ERROR IN DATA @@@@ watch
2023-10-05 02:01:26 - progress_bar.py[line:272] - INFO: epoch 005:     97 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=267.2, nsentences=96, sample_size=267.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=386, ups=1.44, wpb=267.2, bsz=96, num_updates=3720, lr=2.8646e-05, gnorm=0.657, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=23912
2023-10-05 02:01:33 - progress_bar.py[line:272] - INFO: epoch 005:    107 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=402.1, ups=1.49, wpb=270.4, bsz=96, num_updates=3730, lr=2.85816e-05, gnorm=0.588, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23919
2023-10-05 02:01:40 - progress_bar.py[line:272] - INFO: epoch 005:    117 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=391.5, ups=1.45, wpb=269.4, bsz=96, num_updates=3740, lr=2.85171e-05, gnorm=0.74, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=23926
2023-10-05 02:01:47 - progress_bar.py[line:272] - INFO: epoch 005:    127 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.1, ups=1.49, wpb=269.5, bsz=96, num_updates=3750, lr=2.84526e-05, gnorm=0.726, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23933
2023-10-05 02:01:54 - progress_bar.py[line:272] - INFO: epoch 005:    137 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=267.3, nsentences=96, sample_size=267.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=375.7, ups=1.41, wpb=267.3, bsz=96, num_updates=3760, lr=2.83881e-05, gnorm=0.739, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23940
2023-10-05 02:02:01 - progress_bar.py[line:272] - INFO: epoch 005:    147 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.6, ups=1.49, wpb=269.6, bsz=96, num_updates=3770, lr=2.83237e-05, gnorm=0.737, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=23947
2023-10-05 02:02:07 - progress_bar.py[line:272] - INFO: epoch 005:    157 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403, ups=1.49, wpb=270, bsz=96, num_updates=3780, lr=2.82592e-05, gnorm=0.648, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23953
2023-10-05 02:02:14 - progress_bar.py[line:272] - INFO: epoch 005:    167 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=379, ups=1.4, wpb=270.2, bsz=96, num_updates=3790, lr=2.81947e-05, gnorm=0.654, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23960
2023-10-05 02:02:21 - progress_bar.py[line:272] - INFO: epoch 005:    177 / 907 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.086, ntokens=266.8, nsentences=96, sample_size=266.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=385.9, ups=1.45, wpb=266.8, bsz=96, num_updates=3800, lr=2.81302e-05, gnorm=0.63, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=23967
2023-10-05 02:02:21 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 02:02:23 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 02:02:23 - train.py[line:550] - INFO: load:1.57 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 02:04:02 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 02:04:02 - train.py[line:550] - INFO: load:1.66 valid_run:98.72 task_valid:93.32 collect_output:4.34
2023-10-05 02:05:38 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 02:05:38 - train.py[line:550] - INFO: load:1.75 valid_run:194.98 task_valid:185.17 collect_output:7.81
2023-10-05 02:07:14 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 02:07:14 - train.py[line:550] - INFO: load:1.84 valid_run:290.88 task_valid:274.13 collect_output:13.76
2023-10-05 02:08:50 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 02:08:50 - train.py[line:550] - INFO: load:1.94 valid_run:386.31 task_valid:364.10 collect_output:18.21
2023-10-05 02:10:26 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 02:10:26 - train.py[line:550] - INFO: load:2.04 valid_run:482.19 task_valid:454.14 collect_output:23.04
2023-10-05 02:12:02 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 02:12:02 - train.py[line:550] - INFO: load:2.14 valid_run:578.08 task_valid:543.84 collect_output:28.21
2023-10-05 02:13:37 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 02:13:37 - train.py[line:550] - INFO: load:2.22 valid_run:672.69 task_valid:634.37 collect_output:31.35
2023-10-05 02:15:13 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 02:15:13 - train.py[line:550] - INFO: load:2.31 valid_run:768.37 task_valid:726.63 collect_output:33.81
2023-10-05 02:16:49 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 02:16:49 - train.py[line:550] - INFO: load:2.41 valid_run:864.35 task_valid:817.43 collect_output:38.02
2023-10-05 02:18:25 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 02:18:25 - train.py[line:550] - INFO: load:2.50 valid_run:960.47 task_valid:909.37 collect_output:41.18
2023-10-05 02:20:00 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 02:20:00 - train.py[line:550] - INFO: load:2.60 valid_run:1055.80 task_valid:1001.02 collect_output:43.84

====================================================================================================
SGG eval:     R @ 50: 0.6106;     R @ 100: 0.6534;     R @ 500: 0.6959;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3958;    mR @ 100: 0.4271;    mR @ 500: 0.4934;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6098) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5000) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6502) (standing on:0.6043) (using:0.3500) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6106;     R @ 100: 0.6534;     R @ 500: 0.6959;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3958;    mR @ 100: 0.4271;    mR @ 500: 0.4934;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6098) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5000) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6502) (standing on:0.6043) (using:0.3500) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================

2023-10-05 02:21:16 - train.py[line:487] - INFO: 0.6534144130379423

====================================================================================================
SGG eval:     R @ 50: 0.6106;     R @ 100: 0.6534;     R @ 500: 0.6959;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3958;    mR @ 100: 0.4271;    mR @ 500: 0.4934;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6098) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5000) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6502) (standing on:0.6043) (using:0.3500) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6106;     R @ 100: 0.6534;     R @ 500: 0.6959;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3958;    mR @ 100: 0.4271;    mR @ 500: 0.4934;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6098) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5000) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6502) (standing on:0.6043) (using:0.3500) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6106;     R @ 100: 0.6534;     R @ 500: 0.6959;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3958;    mR @ 100: 0.4271;    mR @ 500: 0.4934;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6098) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5000) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6502) (standing on:0.6043) (using:0.3500) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6106;     R @ 100: 0.6534;     R @ 500: 0.6959;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3958;    mR @ 100: 0.4271;    mR @ 500: 0.4934;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6098) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5000) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6502) (standing on:0.6043) (using:0.3500) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6106;     R @ 100: 0.6534;     R @ 500: 0.6959;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3958;    mR @ 100: 0.4271;    mR @ 500: 0.4934;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6098) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5000) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6502) (standing on:0.6043) (using:0.3500) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================

2023-10-05 02:21:16 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 02:21:16 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 0.238 | loss_v1 0 | loss_v2 0 | nll_loss 0.065 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.653414 | ppl 1.05 | vqa_score 0.4369 | wps 396.3 | wpb 191.9 | bsz 64 | num_updates 3800 | best_R@100 0.653414
2023-10-05 02:21:16 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 3800 updates
2023-10-05 02:21:16 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_3800.pt

====================================================================================================
SGG eval:     R @ 50: 0.6106;     R @ 100: 0.6534;     R @ 500: 0.6959;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3958;    mR @ 100: 0.4271;    mR @ 500: 0.4934;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6098) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.5000) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6502) (standing on:0.6043) (using:0.3500) (walking in:0.0000) (walking on:0.5135) (watching:0.4583) 
--------------------------------------------------------
====================================================================================================

2023-10-05 02:21:22 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_3800.pt
2023-10-05 02:22:11 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_3800.pt (epoch 5 @ 3800 updates, score 0.6534144130379423) (writing took 54.4610905428417 seconds)
2023-10-05 02:22:18 - progress_bar.py[line:272] - INFO: epoch 005:    187 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=2.3, ups=0.01, wpb=269.6, bsz=96, num_updates=3810, lr=2.80658e-05, gnorm=0.708, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=25164
2023-10-05 02:22:24 - progress_bar.py[line:272] - INFO: epoch 005:    197 / 907 loss=0.264, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=404.1, ups=1.5, wpb=269.8, bsz=96, num_updates=3820, lr=2.80013e-05, gnorm=0.697, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25170
2023-10-05 02:22:31 - progress_bar.py[line:272] - INFO: epoch 005:    207 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.9, ups=1.49, wpb=270.8, bsz=96, num_updates=3830, lr=2.79368e-05, gnorm=0.562, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25177
2023-10-05 02:22:38 - progress_bar.py[line:272] - INFO: epoch 005:    217 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=383.1, ups=1.42, wpb=269.2, bsz=96, num_updates=3840, lr=2.78723e-05, gnorm=0.516, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=25184
2023-10-05 02:22:45 - progress_bar.py[line:272] - INFO: epoch 005:    227 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=393, ups=1.46, wpb=269.5, bsz=96, num_updates=3850, lr=2.78079e-05, gnorm=0.84, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25191
2023-10-05 02:22:51 - progress_bar.py[line:272] - INFO: epoch 005:    237 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.085, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=400.6, ups=1.49, wpb=268.2, bsz=96, num_updates=3860, lr=2.77434e-05, gnorm=0.677, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25198
2023-10-05 02:22:58 - progress_bar.py[line:272] - INFO: epoch 005:    247 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=388.3, ups=1.45, wpb=268.5, bsz=96, num_updates=3870, lr=2.76789e-05, gnorm=0.737, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=25204
2023-10-05 02:23:05 - progress_bar.py[line:272] - INFO: epoch 005:    257 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.1, ups=1.48, wpb=269.8, bsz=96, num_updates=3880, lr=2.76144e-05, gnorm=0.626, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25211
2023-10-05 02:23:12 - progress_bar.py[line:272] - INFO: epoch 005:    267 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.6, ups=1.49, wpb=270.3, bsz=96, num_updates=3890, lr=2.755e-05, gnorm=0.63, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25218
2023-10-05 02:23:19 - progress_bar.py[line:272] - INFO: epoch 005:    277 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=267.3, nsentences=96, sample_size=267.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=397.1, ups=1.49, wpb=267.3, bsz=96, num_updates=3900, lr=2.74855e-05, gnorm=0.619, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25225
2023-10-05 02:23:25 - progress_bar.py[line:272] - INFO: epoch 005:    287 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=402, ups=1.49, wpb=269.9, bsz=96, num_updates=3910, lr=2.7421e-05, gnorm=0.715, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=25231
2023-10-05 02:23:32 - progress_bar.py[line:272] - INFO: epoch 005:    297 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=391.6, ups=1.45, wpb=270.1, bsz=96, num_updates=3920, lr=2.73565e-05, gnorm=0.674, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25238
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 02:23:39 - progress_bar.py[line:272] - INFO: epoch 005:    307 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.9, ups=1.45, wpb=269, bsz=96, num_updates=3930, lr=2.72921e-05, gnorm=0.667, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=25245
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 02:23:46 - progress_bar.py[line:272] - INFO: epoch 005:    317 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.6, ups=1.49, wpb=269, bsz=96, num_updates=3940, lr=2.72276e-05, gnorm=0.78, clip=40, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25252
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 02:23:53 - progress_bar.py[line:272] - INFO: epoch 005:    327 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=388.3, ups=1.44, wpb=268.9, bsz=96, num_updates=3950, lr=2.71631e-05, gnorm=0.766, clip=20, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=25259
2023-10-05 02:24:00 - progress_bar.py[line:272] - INFO: epoch 005:    337 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.084, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=392, ups=1.46, wpb=269.1, bsz=96, num_updates=3960, lr=2.70986e-05, gnorm=0.883, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25266
2023-10-05 02:24:07 - progress_bar.py[line:272] - INFO: epoch 005:    347 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=392.6, ups=1.45, wpb=270.4, bsz=96, num_updates=3970, lr=2.70342e-05, gnorm=0.536, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=25273
2023-10-05 02:24:13 - progress_bar.py[line:272] - INFO: epoch 005:    357 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=272.2, nsentences=96, sample_size=272.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=395.4, ups=1.45, wpb=272.2, bsz=96, num_updates=3980, lr=2.69697e-05, gnorm=0.494, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25279
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 02:24:20 - progress_bar.py[line:272] - INFO: epoch 005:    367 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=392, ups=1.46, wpb=269, bsz=96, num_updates=3990, lr=2.69052e-05, gnorm=0.653, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25286
2023-10-05 02:24:27 - progress_bar.py[line:272] - INFO: epoch 005:    377 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.3, ups=1.45, wpb=270, bsz=96, num_updates=4000, lr=2.68407e-05, gnorm=0.596, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=25293
2023-10-05 02:24:27 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 02:24:30 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 02:24:30 - train.py[line:550] - INFO: load:2.16 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 02:26:07 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 02:26:07 - train.py[line:550] - INFO: load:2.25 valid_run:96.94 task_valid:93.14 collect_output:2.72
2023-10-05 02:27:43 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 02:27:43 - train.py[line:550] - INFO: load:2.34 valid_run:193.28 task_valid:185.19 collect_output:6.01
2023-10-05 02:29:19 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 02:29:19 - train.py[line:550] - INFO: load:2.43 valid_run:289.06 task_valid:274.47 collect_output:11.50
2023-10-05 02:30:54 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 02:30:54 - train.py[line:550] - INFO: load:2.52 valid_run:384.19 task_valid:364.63 collect_output:15.54
2023-10-05 02:32:30 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 02:32:30 - train.py[line:550] - INFO: load:2.60 valid_run:479.85 task_valid:454.75 collect_output:20.13
2023-10-05 02:34:06 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 02:34:06 - train.py[line:550] - INFO: load:2.68 valid_run:575.53 task_valid:544.45 collect_output:25.16
2023-10-05 02:35:41 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 02:35:41 - train.py[line:550] - INFO: load:2.78 valid_run:670.36 task_valid:634.91 collect_output:28.47
2023-10-05 02:37:17 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 02:37:17 - train.py[line:550] - INFO: load:2.86 valid_run:766.25 task_valid:727.35 collect_output:30.92
2023-10-05 02:38:53 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 02:38:53 - train.py[line:550] - INFO: load:2.97 valid_run:862.27 task_valid:818.09 collect_output:35.22
2023-10-05 02:40:29 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 02:40:29 - train.py[line:550] - INFO: load:3.05 valid_run:958.27 task_valid:909.81 collect_output:38.55
2023-10-05 02:42:04 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 02:42:04 - train.py[line:550] - INFO: load:3.14 valid_run:1053.41 task_valid:1001.31 collect_output:41.25

====================================================================================================
SGG eval:     R @ 50: 0.6118;     R @ 100: 0.6554;     R @ 500: 0.6994;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3997;    mR @ 100: 0.4309;    mR @ 500: 0.4987;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6220) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6536) (standing on:0.5893) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6118;     R @ 100: 0.6554;     R @ 500: 0.6994;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3997;    mR @ 100: 0.4309;    mR @ 500: 0.4987;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6220) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6536) (standing on:0.5893) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6118;     R @ 100: 0.6554;     R @ 500: 0.6994;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3997;    mR @ 100: 0.4309;    mR @ 500: 0.4987;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6220) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6536) (standing on:0.5893) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6118;     R @ 100: 0.6554;     R @ 500: 0.6994;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3997;    mR @ 100: 0.4309;    mR @ 500: 0.4987;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6220) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6536) (standing on:0.5893) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6118;     R @ 100: 0.6554;     R @ 500: 0.6994;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3997;    mR @ 100: 0.4309;    mR @ 500: 0.4987;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6220) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6536) (standing on:0.5893) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6118;     R @ 100: 0.6554;     R @ 500: 0.6994;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3997;    mR @ 100: 0.4309;    mR @ 500: 0.4987;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6220) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6536) (standing on:0.5893) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6118;     R @ 100: 0.6554;     R @ 500: 0.6994;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3997;    mR @ 100: 0.4309;    mR @ 500: 0.4987;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6220) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6536) (standing on:0.5893) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6118;     R @ 100: 0.6554;     R @ 500: 0.6994;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3997;    mR @ 100: 0.4309;    mR @ 500: 0.4987;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6220) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9069) (says:0.0000) (sitting on:0.6536) (standing on:0.5893) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================

2023-10-05 02:43:20 - train.py[line:487] - INFO: 0.6554144130379425
2023-10-05 02:43:20 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 02:43:20 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 0.237 | loss_v1 0 | loss_v2 0 | nll_loss 0.069 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.655414 | ppl 1.05 | vqa_score 0.4505 | wps 396.8 | wpb 191.9 | bsz 64 | num_updates 4000 | best_R@100 0.655414
2023-10-05 02:43:20 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 4000 updates
2023-10-05 02:43:20 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_4000.pt
2023-10-05 02:43:26 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_4000.pt
2023-10-05 02:44:10 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_4000.pt (epoch 5 @ 4000 updates, score 0.6554144130379425) (writing took 50.133601426146924 seconds)
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 02:44:18 - progress_bar.py[line:272] - INFO: epoch 005:    387 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.3, ups=0.01, wpb=268.2, bsz=96, num_updates=4010, lr=2.67763e-05, gnorm=0.614, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=26484
2023-10-05 02:44:24 - progress_bar.py[line:272] - INFO: epoch 005:    397 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=404.9, ups=1.5, wpb=270.7, bsz=96, num_updates=4020, lr=2.67118e-05, gnorm=0.662, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=26490
2023-10-05 02:44:31 - progress_bar.py[line:272] - INFO: epoch 005:    407 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.7, ups=1.49, wpb=269.1, bsz=96, num_updates=4030, lr=2.66473e-05, gnorm=0.672, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=26497
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 02:44:38 - progress_bar.py[line:272] - INFO: epoch 005:    417 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=393, ups=1.46, wpb=270, bsz=96, num_updates=4040, lr=2.65828e-05, gnorm=0.546, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=26504
2023-10-05 02:44:44 - progress_bar.py[line:272] - INFO: epoch 005:    427 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=404.3, ups=1.5, wpb=270.1, bsz=96, num_updates=4050, lr=2.65184e-05, gnorm=0.745, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=26511
2023-10-05 02:44:51 - progress_bar.py[line:272] - INFO: epoch 005:    437 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.085, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=393.6, ups=1.46, wpb=269.8, bsz=96, num_updates=4060, lr=2.64539e-05, gnorm=0.728, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=26517
2023-10-05 02:44:58 - progress_bar.py[line:272] - INFO: epoch 005:    447 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.087, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=384.5, ups=1.43, wpb=268, bsz=96, num_updates=4070, lr=2.63894e-05, gnorm=0.871, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=26524
2023-10-05 02:45:05 - progress_bar.py[line:272] - INFO: epoch 005:    457 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.7, ups=1.49, wpb=269.3, bsz=96, num_updates=4080, lr=2.6325e-05, gnorm=0.582, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=26531
2023-10-05 02:45:12 - progress_bar.py[line:272] - INFO: epoch 005:    467 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401.1, ups=1.48, wpb=270.6, bsz=96, num_updates=4090, lr=2.62605e-05, gnorm=0.66, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=26538
2023-10-05 02:45:19 - progress_bar.py[line:272] - INFO: epoch 005:    477 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=393.7, ups=1.46, wpb=269.8, bsz=96, num_updates=4100, lr=2.6196e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=26545
2023-10-05 02:45:25 - progress_bar.py[line:272] - INFO: epoch 005:    487 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=403.5, ups=1.5, wpb=269.9, bsz=96, num_updates=4110, lr=2.61315e-05, gnorm=0.661, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=26551
2023-10-05 02:45:32 - progress_bar.py[line:272] - INFO: epoch 005:    497 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.084, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=400.4, ups=1.48, wpb=270.9, bsz=96, num_updates=4120, lr=2.60671e-05, gnorm=0.751, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=26558
2023-10-05 02:45:39 - progress_bar.py[line:272] - INFO: epoch 005:    507 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=380.3, ups=1.41, wpb=269.2, bsz=96, num_updates=4130, lr=2.60026e-05, gnorm=0.701, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=26565
2023-10-05 02:45:46 - progress_bar.py[line:272] - INFO: epoch 005:    517 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.6, ups=1.44, wpb=269.7, bsz=96, num_updates=4140, lr=2.59381e-05, gnorm=0.635, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=26572
2023-10-05 02:45:53 - progress_bar.py[line:272] - INFO: epoch 005:    527 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401.4, ups=1.49, wpb=269.2, bsz=96, num_updates=4150, lr=2.58736e-05, gnorm=0.675, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=26579
2023-10-05 02:46:00 - progress_bar.py[line:272] - INFO: epoch 005:    537 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=388.2, ups=1.45, wpb=268.1, bsz=96, num_updates=4160, lr=2.58092e-05, gnorm=0.771, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=26586
2023-10-05 02:46:07 - progress_bar.py[line:272] - INFO: epoch 005:    547 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.1, ups=1.45, wpb=268.9, bsz=96, num_updates=4170, lr=2.57447e-05, gnorm=0.729, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=26593
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 02:46:13 - progress_bar.py[line:272] - INFO: epoch 005:    557 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.8, ups=1.49, wpb=269.9, bsz=96, num_updates=4180, lr=2.56802e-05, gnorm=0.597, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=26599
2023-10-05 02:46:20 - progress_bar.py[line:272] - INFO: epoch 005:    567 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.1, ups=1.45, wpb=268.6, bsz=96, num_updates=4190, lr=2.56157e-05, gnorm=0.782, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=26606
2023-10-05 02:46:27 - progress_bar.py[line:272] - INFO: epoch 005:    577 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=394.7, ups=1.46, wpb=270.8, bsz=96, num_updates=4200, lr=2.55513e-05, gnorm=0.642, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=26613
2023-10-05 02:46:27 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 02:46:29 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 02:46:29 - train.py[line:550] - INFO: load:1.80 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 02:46:30 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.28 GiB (GPU 4; 23.70 GiB total capacity; 6.78 GiB already allocated; 1.02 GiB free; 21.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-05 02:46:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 02:46:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 02:46:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 02:46:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 02:46:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 38        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6947 MiB |   7600 MiB |   3066 TiB |   3066 TiB |
|       from large pool |   6802 MiB |   7455 MiB |   3050 TiB |   3050 TiB |
|       from small pool |    144 MiB |    145 MiB |     15 TiB |     15 TiB |
|---------------------------------------------------------------------------|
| Active memory         |   6947 MiB |   7600 MiB |   3066 TiB |   3066 TiB |
|       from large pool |   6802 MiB |   7455 MiB |   3050 TiB |   3050 TiB |
|       from small pool |    144 MiB |    145 MiB |     15 TiB |     15 TiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6900 MiB |   7553 MiB |   3061 TiB |   3061 TiB |
|       from large pool |   6755 MiB |   7408 MiB |   3045 TiB |   3045 TiB |
|       from small pool |    144 MiB |    145 MiB |     15 TiB |     15 TiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  21802 MiB |  21818 MiB | 194988 MiB | 173186 MiB |
|       from large pool |  21656 MiB |  21656 MiB | 194236 MiB | 172580 MiB |
|       from small pool |    146 MiB |    162 MiB |    752 MiB |    606 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14854 MiB |  14854 MiB |   2989 TiB |   2989 TiB |
|       from large pool |  14853 MiB |  14853 MiB |   2973 TiB |   2973 TiB |
|       from small pool |      1 MiB |      2 MiB |     16 TiB |     16 TiB |
|---------------------------------------------------------------------------|
| Allocations           |    3567    |    3582    |  194426 K  |  194422 K  |
|       from large pool |     565    |     577    |   79203 K  |   79203 K  |
|       from small pool |    3002    |    3021    |  115222 K  |  115219 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3567    |    3582    |  194426 K  |  194422 K  |
|       from large pool |     565    |     577    |   79203 K  |   79203 K  |
|       from small pool |    3002    |    3021    |  115222 K  |  115219 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     138    |     146    |     670    |     532    |
|       from large pool |      65    |      65    |     294    |     229    |
|       from small pool |      73    |      81    |     376    |     303    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      90    |      97    |  109409 K  |  109409 K  |
|       from large pool |      58    |      58    |   27462 K  |   27462 K  |
|       from small pool |      32    |      41    |   81947 K  |   81947 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 02:46:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 02:46:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 02:46:30 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 02:46:30 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-05 02:48:06 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 02:48:06 - train.py[line:550] - INFO: load:1.88 valid_run:97.24 task_valid:92.91 collect_output:3.30
2023-10-05 02:49:43 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 02:49:43 - train.py[line:550] - INFO: load:1.97 valid_run:193.55 task_valid:184.73 collect_output:6.83
2023-10-05 02:51:19 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 02:51:19 - train.py[line:550] - INFO: load:2.06 valid_run:290.00 task_valid:273.58 collect_output:13.48
2023-10-05 02:52:54 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 02:52:54 - train.py[line:550] - INFO: load:2.14 valid_run:384.91 task_valid:363.60 collect_output:17.41
2023-10-05 02:54:30 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 02:54:30 - train.py[line:550] - INFO: load:2.22 valid_run:480.56 task_valid:453.52 collect_output:22.20
2023-10-05 02:56:06 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 02:56:06 - train.py[line:550] - INFO: load:2.31 valid_run:576.17 task_valid:542.95 collect_output:27.45
2023-10-05 02:57:41 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 02:57:41 - train.py[line:550] - INFO: load:2.39 valid_run:670.92 task_valid:633.51 collect_output:30.71
2023-10-05 02:59:17 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 02:59:17 - train.py[line:550] - INFO: load:2.48 valid_run:766.51 task_valid:725.71 collect_output:33.07
2023-10-05 03:00:53 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 03:00:53 - train.py[line:550] - INFO: load:2.57 valid_run:862.40 task_valid:816.47 collect_output:37.26
2023-10-05 03:02:28 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 03:02:28 - train.py[line:550] - INFO: load:2.66 valid_run:958.12 task_valid:908.30 collect_output:40.18
2023-10-05 03:04:04 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 03:04:04 - train.py[line:550] - INFO: load:2.76 valid_run:1053.43 task_valid:999.76 collect_output:42.98

====================================================================================================
SGG eval:     R @ 50: 0.6129;     R @ 100: 0.6582;     R @ 500: 0.7034;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4002;    mR @ 100: 0.4326;    mR @ 500: 0.5039;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6707) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9059) (says:0.0000) (sitting on:0.6604) (standing on:0.5693) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6129;     R @ 100: 0.6582;     R @ 500: 0.7034;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4002;    mR @ 100: 0.4326;    mR @ 500: 0.5039;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6707) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9059) (says:0.0000) (sitting on:0.6604) (standing on:0.5693) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6129;     R @ 100: 0.6582;     R @ 500: 0.7034;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4002;    mR @ 100: 0.4326;    mR @ 500: 0.5039;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6707) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9059) (says:0.0000) (sitting on:0.6604) (standing on:0.5693) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6129;     R @ 100: 0.6582;     R @ 500: 0.7034;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4002;    mR @ 100: 0.4326;    mR @ 500: 0.5039;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6707) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9059) (says:0.0000) (sitting on:0.6604) (standing on:0.5693) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6129;     R @ 100: 0.6582;     R @ 500: 0.7034;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4002;    mR @ 100: 0.4326;    mR @ 500: 0.5039;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6707) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9059) (says:0.0000) (sitting on:0.6604) (standing on:0.5693) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6129;     R @ 100: 0.6582;     R @ 500: 0.7034;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4002;    mR @ 100: 0.4326;    mR @ 500: 0.5039;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6707) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9059) (says:0.0000) (sitting on:0.6604) (standing on:0.5693) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6129;     R @ 100: 0.6582;     R @ 500: 0.7034;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4002;    mR @ 100: 0.4326;    mR @ 500: 0.5039;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6707) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9059) (says:0.0000) (sitting on:0.6604) (standing on:0.5693) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================

2023-10-05 03:05:20 - train.py[line:487] - INFO: 0.6582144130379425

====================================================================================================
SGG eval:     R @ 50: 0.6129;     R @ 100: 0.6582;     R @ 500: 0.7034;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4002;    mR @ 100: 0.4326;    mR @ 500: 0.5039;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6707) (covered in:0.3125) (covering:0.2857) (eating:0.7059) (flying in:0.7273) (growing on:0.2500) (hanging from:0.4839) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9059) (says:0.0000) (sitting on:0.6604) (standing on:0.5693) (using:0.4000) (walking in:0.0000) (walking on:0.5135) (watching:0.5000) 
--------------------------------------------------------
====================================================================================================

2023-10-05 03:05:20 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 03:05:20 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 0.235 | loss_v1 0 | loss_v2 0 | nll_loss 0.062 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.658214 | ppl 1.04 | vqa_score 0.4718 | wps 397 | wpb 191.9 | bsz 64 | num_updates 4200 | best_R@100 0.658214
2023-10-05 03:05:20 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 4200 updates
2023-10-05 03:05:20 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_4200.pt
2023-10-05 03:05:26 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_4200.pt
2023-10-05 03:06:15 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_4200.pt (epoch 5 @ 4200 updates, score 0.6582144130379425) (writing took 54.905305672902614 seconds)
2023-10-05 03:06:22 - progress_bar.py[line:272] - INFO: epoch 005:    587 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.084, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=2.2, ups=0.01, wpb=268.3, bsz=96, num_updates=4210, lr=2.54868e-05, gnorm=0.716, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=27808
2023-10-05 03:06:28 - progress_bar.py[line:272] - INFO: epoch 005:    597 / 907 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=271.4, nsentences=96, sample_size=271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=406.5, ups=1.5, wpb=271.4, bsz=96, num_updates=4220, lr=2.54223e-05, gnorm=0.518, clip=0, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=27814
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 03:06:35 - progress_bar.py[line:272] - INFO: epoch 005:    607 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403, ups=1.5, wpb=269.5, bsz=96, num_updates=4230, lr=2.53578e-05, gnorm=0.532, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27821
2023-10-05 03:06:42 - progress_bar.py[line:272] - INFO: epoch 005:    617 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.084, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=403.1, ups=1.49, wpb=270.8, bsz=96, num_updates=4240, lr=2.52934e-05, gnorm=0.7, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27828
2023-10-05 03:06:48 - progress_bar.py[line:272] - INFO: epoch 005:    627 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=392.5, ups=1.45, wpb=270.1, bsz=96, num_updates=4250, lr=2.52289e-05, gnorm=0.675, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27835
2023-10-05 03:06:55 - progress_bar.py[line:272] - INFO: epoch 005:    637 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400, ups=1.49, wpb=268.9, bsz=96, num_updates=4260, lr=2.51644e-05, gnorm=0.538, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27841
2023-10-05 03:07:02 - progress_bar.py[line:272] - INFO: epoch 005:    647 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=392.4, ups=1.45, wpb=270.5, bsz=96, num_updates=4270, lr=2.50999e-05, gnorm=0.517, clip=0, loss_scale=1024, train_wall=7, gb_free=6.1, ema_decay=0.9999, wall=27848
2023-10-05 03:07:09 - progress_bar.py[line:272] - INFO: epoch 005:    657 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.2, ups=1.48, wpb=270.6, bsz=96, num_updates=4280, lr=2.50355e-05, gnorm=0.57, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27855
2023-10-05 03:07:16 - progress_bar.py[line:272] - INFO: epoch 005:    667 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.9, ups=1.49, wpb=270.2, bsz=96, num_updates=4290, lr=2.4971e-05, gnorm=0.602, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27862
2023-10-05 03:07:22 - progress_bar.py[line:272] - INFO: epoch 005:    677 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=390.3, ups=1.45, wpb=268.9, bsz=96, num_updates=4300, lr=2.49065e-05, gnorm=0.618, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27868
2023-10-05 03:07:29 - progress_bar.py[line:272] - INFO: epoch 005:    687 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=399.8, ups=1.48, wpb=269.5, bsz=96, num_updates=4310, lr=2.4842e-05, gnorm=0.726, clip=10, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=27875
2023-10-05 03:07:30 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-10-05 03:07:37 - progress_bar.py[line:272] - INFO: epoch 005:    698 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=368.5, ups=1.37, wpb=269.4, bsz=96, num_updates=4320, lr=2.47776e-05, gnorm=0.58, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=27883
2023-10-05 03:07:43 - progress_bar.py[line:272] - INFO: epoch 005:    708 / 907 loss=0.267, loss_v1=0, loss_v2=0, nll_loss=0.09, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=391.2, ups=1.46, wpb=268.6, bsz=96, num_updates=4330, lr=2.47131e-05, gnorm=0.647, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27889
2023-10-05 03:07:50 - progress_bar.py[line:272] - INFO: epoch 005:    718 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401.9, ups=1.49, wpb=269.9, bsz=96, num_updates=4340, lr=2.46486e-05, gnorm=0.651, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27896
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 03:07:57 - progress_bar.py[line:272] - INFO: epoch 005:    728 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402, ups=1.49, wpb=269.6, bsz=96, num_updates=4350, lr=2.45841e-05, gnorm=0.562, clip=0, loss_scale=512, train_wall=7, gb_free=6.1, ema_decay=0.9999, wall=27903
2023-10-05 03:08:04 - progress_bar.py[line:272] - INFO: epoch 005:    738 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=382.9, ups=1.42, wpb=269.5, bsz=96, num_updates=4360, lr=2.45197e-05, gnorm=0.734, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27910
2023-10-05 03:08:11 - progress_bar.py[line:272] - INFO: epoch 005:    748 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=381.9, ups=1.41, wpb=270.1, bsz=96, num_updates=4370, lr=2.44552e-05, gnorm=0.605, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27917
2023-10-05 03:08:18 - progress_bar.py[line:272] - INFO: epoch 005:    758 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.081, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.7, ups=1.45, wpb=270.1, bsz=96, num_updates=4380, lr=2.43907e-05, gnorm=0.705, clip=10, loss_scale=512, train_wall=7, gb_free=5.9, ema_decay=0.9999, wall=27924
2023-10-05 03:08:25 - progress_bar.py[line:272] - INFO: epoch 005:    768 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=402.4, ups=1.49, wpb=270.6, bsz=96, num_updates=4390, lr=2.43262e-05, gnorm=0.627, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27931
2023-10-05 03:08:32 - progress_bar.py[line:272] - INFO: epoch 005:    778 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=387.7, ups=1.45, wpb=267.8, bsz=96, num_updates=4400, lr=2.42618e-05, gnorm=0.544, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=27938
2023-10-05 03:08:32 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 03:08:33 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 03:08:33 - train.py[line:550] - INFO: load:1.75 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 03:10:11 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 03:10:11 - train.py[line:550] - INFO: load:1.84 valid_run:97.61 task_valid:93.18 collect_output:3.45
2023-10-05 03:11:48 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 03:11:48 - train.py[line:550] - INFO: load:1.93 valid_run:193.79 task_valid:184.99 collect_output:6.83
2023-10-05 03:13:23 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 03:13:23 - train.py[line:550] - INFO: load:2.01 valid_run:289.66 task_valid:273.87 collect_output:12.85
2023-10-05 03:14:59 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 03:14:59 - train.py[line:550] - INFO: load:2.11 valid_run:385.16 task_valid:363.90 collect_output:17.34
2023-10-05 03:16:35 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 03:16:35 - train.py[line:550] - INFO: load:2.20 valid_run:481.22 task_valid:454.08 collect_output:22.24
2023-10-05 03:18:12 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 03:18:12 - train.py[line:550] - INFO: load:2.29 valid_run:577.37 task_valid:543.70 collect_output:27.77
2023-10-05 03:19:46 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 03:19:46 - train.py[line:550] - INFO: load:2.38 valid_run:671.95 task_valid:634.11 collect_output:30.93
2023-10-05 03:21:22 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 03:21:22 - train.py[line:550] - INFO: load:2.48 valid_run:767.76 task_valid:726.50 collect_output:33.41
2023-10-05 03:22:58 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 03:22:58 - train.py[line:550] - INFO: load:2.58 valid_run:863.35 task_valid:817.19 collect_output:37.35
2023-10-05 03:24:34 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 03:24:34 - train.py[line:550] - INFO: load:2.67 valid_run:959.06 task_valid:909.00 collect_output:40.25
2023-10-05 03:26:10 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 03:26:10 - train.py[line:550] - INFO: load:2.76 valid_run:1054.77 task_valid:1000.76 collect_output:43.22

====================================================================================================
SGG eval:     R @ 50: 0.6142;     R @ 100: 0.6623;     R @ 500: 0.7017;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3941;    mR @ 100: 0.4312;    mR @ 500: 0.5008;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.3125) (covering:0.1429) (eating:0.7059) (flying in:0.7727) (growing on:0.2500) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9167) (says:0.0000) (sitting on:0.6774) (standing on:0.5493) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5417) 
--------------------------------------------------------
====================================================================================================

2023-10-05 03:27:25 - train.py[line:487] - INFO: 0.6622628978864272

====================================================================================================
SGG eval:     R @ 50: 0.6142;     R @ 100: 0.6623;     R @ 500: 0.7017;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3941;    mR @ 100: 0.4312;    mR @ 500: 0.5008;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.3125) (covering:0.1429) (eating:0.7059) (flying in:0.7727) (growing on:0.2500) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9167) (says:0.0000) (sitting on:0.6774) (standing on:0.5493) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6142;     R @ 100: 0.6623;     R @ 500: 0.7017;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3941;    mR @ 100: 0.4312;    mR @ 500: 0.5008;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.3125) (covering:0.1429) (eating:0.7059) (flying in:0.7727) (growing on:0.2500) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9167) (says:0.0000) (sitting on:0.6774) (standing on:0.5493) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6142;     R @ 100: 0.6623;     R @ 500: 0.7017;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3941;    mR @ 100: 0.4312;    mR @ 500: 0.5008;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.3125) (covering:0.1429) (eating:0.7059) (flying in:0.7727) (growing on:0.2500) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9167) (says:0.0000) (sitting on:0.6774) (standing on:0.5493) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6142;     R @ 100: 0.6623;     R @ 500: 0.7017;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3941;    mR @ 100: 0.4312;    mR @ 500: 0.5008;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.3125) (covering:0.1429) (eating:0.7059) (flying in:0.7727) (growing on:0.2500) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9167) (says:0.0000) (sitting on:0.6774) (standing on:0.5493) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6142;     R @ 100: 0.6623;     R @ 500: 0.7017;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3941;    mR @ 100: 0.4312;    mR @ 500: 0.5008;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.3125) (covering:0.1429) (eating:0.7059) (flying in:0.7727) (growing on:0.2500) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9167) (says:0.0000) (sitting on:0.6774) (standing on:0.5493) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5417) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6142;     R @ 100: 0.6623;     R @ 500: 0.7017;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3941;    mR @ 100: 0.4312;    mR @ 500: 0.5008;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.3125) (covering:0.1429) (eating:0.7059) (flying in:0.7727) (growing on:0.2500) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9167) (says:0.0000) (sitting on:0.6774) (standing on:0.5493) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5417) 
--------------------------------------------------------
====================================================================================================

2023-10-05 03:27:25 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 03:27:25 - progress_bar.py[line:282] - INFO: epoch 005 | valid on 'valid' subset | loss 0.24 | loss_v1 0 | loss_v2 0 | nll_loss 0.068 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.662263 | ppl 1.05 | vqa_score 0.4775 | wps 396.6 | wpb 191.9 | bsz 64 | num_updates 4400 | best_R@100 0.662263
2023-10-05 03:27:25 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 5 @ 4400 updates
2023-10-05 03:27:25 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_4400.pt

====================================================================================================
SGG eval:     R @ 50: 0.6142;     R @ 100: 0.6623;     R @ 500: 0.7017;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.3941;    mR @ 100: 0.4312;    mR @ 500: 0.5008;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.6951) (covered in:0.3125) (covering:0.1429) (eating:0.7059) (flying in:0.7727) (growing on:0.2500) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.0000) (painted on:0.2500) (parked on:0.9167) (playing:0.0000) (riding:0.9167) (says:0.0000) (sitting on:0.6774) (standing on:0.5493) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5417) 
--------------------------------------------------------
====================================================================================================

2023-10-05 03:27:31 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_4400.pt
2023-10-05 03:28:18 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_5_4400.pt (epoch 5 @ 4400 updates, score 0.6622628978864272) (writing took 52.14270893577486 seconds)
2023-10-05 03:28:24 - progress_bar.py[line:272] - INFO: epoch 005:    788 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=267.9, nsentences=96, sample_size=267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.2, ups=0.01, wpb=267.9, bsz=96, num_updates=4410, lr=2.41973e-05, gnorm=0.564, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=29130
2023-10-05 03:28:31 - progress_bar.py[line:272] - INFO: epoch 005:    798 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.086, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=406.6, ups=1.5, wpb=271.3, bsz=96, num_updates=4420, lr=2.41328e-05, gnorm=0.645, clip=0, loss_scale=512, train_wall=7, gb_free=6, ema_decay=0.9999, wall=29137
2023-10-05 03:28:38 - progress_bar.py[line:272] - INFO: epoch 005:    808 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.6, ups=1.48, wpb=270.4, bsz=96, num_updates=4430, lr=2.40683e-05, gnorm=0.676, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=29144
2023-10-05 03:28:45 - progress_bar.py[line:272] - INFO: epoch 005:    818 / 907 loss=0.263, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=267.9, nsentences=96, sample_size=267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=388, ups=1.45, wpb=267.9, bsz=96, num_updates=4440, lr=2.40039e-05, gnorm=0.608, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=29151
2023-10-05 03:28:52 - progress_bar.py[line:272] - INFO: epoch 005:    828 / 907 loss=0.271, loss_v1=0, loss_v2=0, nll_loss=0.093, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.07, wps=390.4, ups=1.45, wpb=269.2, bsz=96, num_updates=4450, lr=2.39394e-05, gnorm=0.85, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=29158
2023-10-05 03:28:58 - progress_bar.py[line:272] - INFO: epoch 005:    838 / 907 loss=0.265, loss_v1=0, loss_v2=0, nll_loss=0.086, ntokens=267.1, nsentences=96, sample_size=267.1, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=399, ups=1.49, wpb=267.1, bsz=96, num_updates=4460, lr=2.38749e-05, gnorm=0.759, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=29164
2023-10-05 03:29:05 - progress_bar.py[line:272] - INFO: epoch 005:    848 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=404.2, ups=1.49, wpb=270.9, bsz=96, num_updates=4470, lr=2.38104e-05, gnorm=0.608, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=29171
2023-10-05 03:29:12 - progress_bar.py[line:272] - INFO: epoch 005:    858 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.7, ups=1.49, wpb=271.1, bsz=96, num_updates=4480, lr=2.3746e-05, gnorm=0.606, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=29178
2023-10-05 03:29:18 - progress_bar.py[line:272] - INFO: epoch 005:    868 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=267.7, nsentences=96, sample_size=267.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=399.8, ups=1.49, wpb=267.7, bsz=96, num_updates=4490, lr=2.36815e-05, gnorm=0.632, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=29184
2023-10-05 03:29:25 - progress_bar.py[line:272] - INFO: epoch 005:    878 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401.8, ups=1.5, wpb=268.4, bsz=96, num_updates=4500, lr=2.3617e-05, gnorm=0.648, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=29191
2023-10-05 03:29:32 - progress_bar.py[line:272] - INFO: epoch 005:    888 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=395.8, ups=1.46, wpb=270.8, bsz=96, num_updates=4510, lr=2.35525e-05, gnorm=0.677, clip=10, loss_scale=512, train_wall=7, gb_free=6, ema_decay=0.9999, wall=29198
2023-10-05 03:29:39 - progress_bar.py[line:272] - INFO: epoch 005:    898 / 907 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.6, ups=1.5, wpb=268.3, bsz=96, num_updates=4520, lr=2.34881e-05, gnorm=0.674, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=29205
2023-10-05 03:29:45 - train.py[line:339] - INFO: end of epoch 5 (average epoch stats below)
2023-10-05 03:29:45 - progress_bar.py[line:282] - INFO: epoch 005 | loss 0.258 | loss_v1 0 | loss_v2 0 | nll_loss 0.078 | ntokens 269.263 | nsentences 95.914 | sample_size 269.263 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.06 | wps 45.4 | ups 0.17 | wpb 269.3 | bsz 95.9 | num_updates 4529 | lr 2.343e-05 | gnorm 0.668 | clip 8 | loss_scale 512 | train_wall 614 | gb_free 16.3 | ema_decay 0.9999 | wall 29211
2023-10-05 03:29:45 - trainer.py[line:694] - INFO: loading train data for epoch 6
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv slice_id 0 row count 10875 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv slice_id 5 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv slice_id 1 row count 10875 total row count 86994

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv slice_id 7 row count 10874 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv slice_id 3 row count 10874 total row count 86994

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv slice_id 6 row count 10874 total row count 86994
2023-10-05 03:29:45 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv slice_id 2 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E5.tsv slice_id 4 row count 10874 total row count 86994
2023-10-05 03:29:45 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 03:29:45 - trainer.py[line:758] - INFO: begin training epoch 6
2023-10-05 03:29:45 - train.py[line:312] - INFO: Start iterating over samples
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 03:29:49 - progress_bar.py[line:272] - INFO: epoch 006:      1 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=247.7, nsentences=88.2, sample_size=247.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=236.6, ups=0.96, wpb=247.7, bsz=88.2, num_updates=4530, lr=2.34236e-05, gnorm=1.788, clip=20, loss_scale=512, train_wall=8, gb_free=6.5, ema_decay=0.9999, wall=29215
2023-10-05 03:29:56 - progress_bar.py[line:272] - INFO: epoch 006:     11 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=385.5, ups=1.43, wpb=268.7, bsz=96, num_updates=4540, lr=2.33591e-05, gnorm=0.655, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=29222
2023-10-05 03:30:03 - progress_bar.py[line:272] - INFO: epoch 006:     21 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=267, nsentences=96, sample_size=267, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=397.2, ups=1.49, wpb=267, bsz=96, num_updates=4550, lr=2.32946e-05, gnorm=0.531, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=29229
2023-10-05 03:30:09 - progress_bar.py[line:272] - INFO: epoch 006:     31 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.7, ups=1.49, wpb=270.5, bsz=96, num_updates=4560, lr=2.32302e-05, gnorm=0.779, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=29235
2023-10-05 03:30:16 - progress_bar.py[line:272] - INFO: epoch 006:     41 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.8, ups=1.49, wpb=270.4, bsz=96, num_updates=4570, lr=2.31657e-05, gnorm=0.49, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=29242
2023-10-05 03:30:23 - progress_bar.py[line:272] - INFO: epoch 006:     51 / 907 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=386.9, ups=1.44, wpb=267.8, bsz=96, num_updates=4580, lr=2.31012e-05, gnorm=0.63, clip=10, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=29249
@@@@ ERROR IN DATA @@@@ play
2023-10-05 03:30:30 - progress_bar.py[line:272] - INFO: epoch 006:     61 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.5, ups=1.49, wpb=269.2, bsz=96, num_updates=4590, lr=2.30368e-05, gnorm=0.628, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=29256
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 03:30:37 - progress_bar.py[line:272] - INFO: epoch 006:     71 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.9, ups=1.48, wpb=269.3, bsz=96, num_updates=4600, lr=2.29723e-05, gnorm=0.626, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=29263
2023-10-05 03:30:37 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 03:30:39 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 03:30:39 - train.py[line:550] - INFO: load:1.91 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 03:32:16 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 03:32:16 - train.py[line:550] - INFO: load:2.00 valid_run:97.65 task_valid:93.09 collect_output:3.60
2023-10-05 03:33:53 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 03:33:53 - train.py[line:550] - INFO: load:2.08 valid_run:194.11 task_valid:184.80 collect_output:7.39
2023-10-05 03:35:29 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 03:35:29 - train.py[line:550] - INFO: load:2.15 valid_run:290.11 task_valid:273.68 collect_output:13.57
2023-10-05 03:37:04 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 03:37:04 - train.py[line:550] - INFO: load:2.23 valid_run:385.04 task_valid:363.61 collect_output:17.64
2023-10-05 03:38:40 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 03:38:40 - train.py[line:550] - INFO: load:2.32 valid_run:480.73 task_valid:453.51 collect_output:22.49
2023-10-05 03:40:16 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 03:40:16 - train.py[line:550] - INFO: load:2.40 valid_run:576.43 task_valid:542.88 collect_output:27.87
2023-10-05 03:41:51 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 03:41:51 - train.py[line:550] - INFO: load:2.49 valid_run:671.03 task_valid:633.16 collect_output:31.23
2023-10-05 03:43:26 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 03:43:26 - train.py[line:550] - INFO: load:2.58 valid_run:766.65 task_valid:725.24 collect_output:33.81
2023-10-05 03:45:02 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 03:45:02 - train.py[line:550] - INFO: load:2.66 valid_run:862.49 task_valid:815.78 collect_output:38.16
2023-10-05 03:46:38 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 03:46:38 - train.py[line:550] - INFO: load:2.75 valid_run:958.33 task_valid:907.20 collect_output:41.64
2023-10-05 03:48:14 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 03:48:14 - train.py[line:550] - INFO: load:2.84 valid_run:1053.72 task_valid:998.49 collect_output:44.75

====================================================================================================
SGG eval:     R @ 50: 0.6273;     R @ 100: 0.6733;     R @ 500: 0.7098;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4145;    mR @ 100: 0.4653;    mR @ 500: 0.5184;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.6774) (standing on:0.5593) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6273;     R @ 100: 0.6733;     R @ 500: 0.7098;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4145;    mR @ 100: 0.4653;    mR @ 500: 0.5184;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.6774) (standing on:0.5593) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6273;     R @ 100: 0.6733;     R @ 500: 0.7098;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4145;    mR @ 100: 0.4653;    mR @ 500: 0.5184;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.6774) (standing on:0.5593) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6273;     R @ 100: 0.6733;     R @ 500: 0.7098;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4145;    mR @ 100: 0.4653;    mR @ 500: 0.5184;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.6774) (standing on:0.5593) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6273;     R @ 100: 0.6733;     R @ 500: 0.7098;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4145;    mR @ 100: 0.4653;    mR @ 500: 0.5184;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.6774) (standing on:0.5593) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6273;     R @ 100: 0.6733;     R @ 500: 0.7098;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4145;    mR @ 100: 0.4653;    mR @ 500: 0.5184;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.6774) (standing on:0.5593) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6273;     R @ 100: 0.6733;     R @ 500: 0.7098;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4145;    mR @ 100: 0.4653;    mR @ 500: 0.5184;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.6774) (standing on:0.5593) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2023-10-05 03:49:30 - train.py[line:487] - INFO: 0.6732750190985485

====================================================================================================
SGG eval:     R @ 50: 0.6273;     R @ 100: 0.6733;     R @ 500: 0.7098;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4145;    mR @ 100: 0.4653;    mR @ 500: 0.5184;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.3333) (parked on:0.9167) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.6774) (standing on:0.5593) (using:0.4000) (walking in:0.0000) (walking on:0.5405) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2023-10-05 03:49:30 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 03:49:30 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 0.237 | loss_v1 0 | loss_v2 0 | nll_loss 0.067 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.673275 | ppl 1.05 | vqa_score 0.4831 | wps 396.7 | wpb 191.9 | bsz 64 | num_updates 4600 | best_R@100 0.673275
2023-10-05 03:49:30 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 4600 updates
2023-10-05 03:49:30 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_4600.pt
2023-10-05 03:49:36 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_4600.pt
2023-10-05 03:50:25 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_4600.pt (epoch 6 @ 4600 updates, score 0.6732750190985485) (writing took 54.53245152113959 seconds)
2023-10-05 03:50:31 - progress_bar.py[line:272] - INFO: epoch 006:     81 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.3, ups=0.01, wpb=270.5, bsz=96, num_updates=4610, lr=2.29078e-05, gnorm=0.774, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=30457
2023-10-05 03:50:38 - progress_bar.py[line:272] - INFO: epoch 006:     91 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=388.6, ups=1.45, wpb=268.6, bsz=96, num_updates=4620, lr=2.28433e-05, gnorm=0.556, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=30464
2023-10-05 03:50:45 - progress_bar.py[line:272] - INFO: epoch 006:    101 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=404.7, ups=1.5, wpb=270, bsz=96, num_updates=4630, lr=2.27789e-05, gnorm=0.764, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=30471
2023-10-05 03:50:52 - progress_bar.py[line:272] - INFO: epoch 006:    111 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=271.5, nsentences=96, sample_size=271.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=405.5, ups=1.49, wpb=271.5, bsz=96, num_updates=4640, lr=2.27144e-05, gnorm=0.666, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=30478
2023-10-05 03:50:58 - progress_bar.py[line:272] - INFO: epoch 006:    121 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=404.9, ups=1.49, wpb=271.2, bsz=96, num_updates=4650, lr=2.26499e-05, gnorm=0.445, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=30484
2023-10-05 03:51:05 - progress_bar.py[line:272] - INFO: epoch 006:    131 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.8, ups=1.49, wpb=269.9, bsz=96, num_updates=4660, lr=2.25854e-05, gnorm=0.54, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=30491
2023-10-05 03:51:12 - progress_bar.py[line:272] - INFO: epoch 006:    141 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.4, ups=1.49, wpb=270.5, bsz=96, num_updates=4670, lr=2.2521e-05, gnorm=0.495, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=30498
2023-10-05 03:51:18 - progress_bar.py[line:272] - INFO: epoch 006:    151 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=404, ups=1.49, wpb=270.9, bsz=96, num_updates=4680, lr=2.24565e-05, gnorm=0.673, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=30504
2023-10-05 03:51:25 - progress_bar.py[line:272] - INFO: epoch 006:    161 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.2, ups=1.45, wpb=268.7, bsz=96, num_updates=4690, lr=2.2392e-05, gnorm=0.502, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=30511
2023-10-05 03:51:32 - progress_bar.py[line:272] - INFO: epoch 006:    171 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=392.1, ups=1.45, wpb=270.5, bsz=96, num_updates=4700, lr=2.23275e-05, gnorm=0.483, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=30518
2023-10-05 03:51:39 - progress_bar.py[line:272] - INFO: epoch 006:    181 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=390.8, ups=1.45, wpb=268.9, bsz=96, num_updates=4710, lr=2.22631e-05, gnorm=0.676, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=30525
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 03:51:46 - progress_bar.py[line:272] - INFO: epoch 006:    191 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=388.8, ups=1.45, wpb=268.4, bsz=96, num_updates=4720, lr=2.21986e-05, gnorm=0.746, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=30532
2023-10-05 03:51:53 - progress_bar.py[line:272] - INFO: epoch 006:    201 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.9, ups=1.49, wpb=270.4, bsz=96, num_updates=4730, lr=2.21341e-05, gnorm=0.622, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=30539
2023-10-05 03:51:59 - progress_bar.py[line:272] - INFO: epoch 006:    211 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=266.6, nsentences=96, sample_size=266.6, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=397.2, ups=1.49, wpb=266.6, bsz=96, num_updates=4740, lr=2.20696e-05, gnorm=0.807, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=30545
2023-10-05 03:52:06 - progress_bar.py[line:272] - INFO: epoch 006:    221 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=379.6, ups=1.41, wpb=269.7, bsz=96, num_updates=4750, lr=2.20052e-05, gnorm=0.513, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=30552
2023-10-05 03:52:13 - progress_bar.py[line:272] - INFO: epoch 006:    231 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=388.2, ups=1.45, wpb=268, bsz=96, num_updates=4760, lr=2.19407e-05, gnorm=0.616, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=30559
2023-10-05 03:52:20 - progress_bar.py[line:272] - INFO: epoch 006:    241 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=392, ups=1.45, wpb=269.8, bsz=96, num_updates=4770, lr=2.18762e-05, gnorm=0.638, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=30566
2023-10-05 03:52:27 - progress_bar.py[line:272] - INFO: epoch 006:    251 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=381.6, ups=1.41, wpb=270.1, bsz=96, num_updates=4780, lr=2.18117e-05, gnorm=0.595, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=30573
2023-10-05 03:52:34 - progress_bar.py[line:272] - INFO: epoch 006:    261 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=404.8, ups=1.49, wpb=270.9, bsz=96, num_updates=4790, lr=2.17473e-05, gnorm=0.61, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=30580
2023-10-05 03:52:41 - progress_bar.py[line:272] - INFO: epoch 006:    271 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.2, ups=1.5, wpb=269.7, bsz=96, num_updates=4800, lr=2.16828e-05, gnorm=0.663, clip=20, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=30587
2023-10-05 03:52:41 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 03:52:43 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 03:52:43 - train.py[line:550] - INFO: load:1.80 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 03:54:21 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 03:54:21 - train.py[line:550] - INFO: load:1.88 valid_run:97.77 task_valid:93.25 collect_output:3.52
2023-10-05 03:55:57 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 03:55:57 - train.py[line:550] - INFO: load:1.96 valid_run:193.82 task_valid:185.11 collect_output:6.73
2023-10-05 03:57:33 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 03:57:33 - train.py[line:550] - INFO: load:2.05 valid_run:289.56 task_valid:274.03 collect_output:12.59
2023-10-05 03:59:08 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 03:59:08 - train.py[line:550] - INFO: load:2.14 valid_run:385.01 task_valid:364.18 collect_output:16.90
2023-10-05 04:00:44 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 04:00:44 - train.py[line:550] - INFO: load:2.23 valid_run:480.66 task_valid:454.27 collect_output:21.48
2023-10-05 04:02:20 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 04:02:20 - train.py[line:550] - INFO: load:2.31 valid_run:576.79 task_valid:543.87 collect_output:26.99
2023-10-05 04:03:55 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 04:03:55 - train.py[line:550] - INFO: load:2.40 valid_run:671.65 task_valid:634.22 collect_output:30.57
2023-10-05 04:05:31 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 04:05:31 - train.py[line:550] - INFO: load:2.48 valid_run:767.76 task_valid:726.48 collect_output:33.44
2023-10-05 04:07:07 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 04:07:07 - train.py[line:550] - INFO: load:2.56 valid_run:863.70 task_valid:817.17 collect_output:37.74
2023-10-05 04:08:44 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 04:08:44 - train.py[line:550] - INFO: load:2.65 valid_run:959.65 task_valid:908.92 collect_output:40.98
2023-10-05 04:10:19 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 04:10:19 - train.py[line:550] - INFO: load:2.75 valid_run:1055.16 task_valid:1000.21 collect_output:44.23

====================================================================================================
SGG eval:     R @ 50: 0.6333;     R @ 100: 0.6831;     R @ 500: 0.7175;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4197;    mR @ 100: 0.4742;    mR @ 500: 0.5269;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9363) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5586) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6333;     R @ 100: 0.6831;     R @ 500: 0.7175;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4197;    mR @ 100: 0.4742;    mR @ 500: 0.5269;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9363) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5586) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6333;     R @ 100: 0.6831;     R @ 500: 0.7175;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4197;    mR @ 100: 0.4742;    mR @ 500: 0.5269;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9363) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5586) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2023-10-05 04:11:35 - train.py[line:487] - INFO: 0.6831416857652153

====================================================================================================
SGG eval:     R @ 50: 0.6333;     R @ 100: 0.6831;     R @ 500: 0.7175;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4197;    mR @ 100: 0.4742;    mR @ 500: 0.5269;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9363) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5586) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2023-10-05 04:11:35 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.6333;     R @ 100: 0.6831;     R @ 500: 0.7175;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4197;    mR @ 100: 0.4742;    mR @ 500: 0.5269;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9363) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5586) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2023-10-05 04:11:35 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 0.238 | loss_v1 0 | loss_v2 0 | nll_loss 0.07 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.683142 | ppl 1.05 | vqa_score 0.4921 | wps 396.6 | wpb 191.9 | bsz 64 | num_updates 4800 | best_R@100 0.683142
2023-10-05 04:11:35 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 4800 updates
2023-10-05 04:11:35 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_4800.pt

====================================================================================================
SGG eval:     R @ 50: 0.6333;     R @ 100: 0.6831;     R @ 500: 0.7175;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4197;    mR @ 100: 0.4742;    mR @ 500: 0.5269;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9363) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5586) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6333;     R @ 100: 0.6831;     R @ 500: 0.7175;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4197;    mR @ 100: 0.4742;    mR @ 500: 0.5269;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9363) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5586) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6333;     R @ 100: 0.6831;     R @ 500: 0.7175;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4197;    mR @ 100: 0.4742;    mR @ 500: 0.5269;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9363) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5586) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2023-10-05 04:11:41 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_4800.pt
2023-10-05 04:12:36 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_4800.pt (epoch 6 @ 4800 updates, score 0.6831416857652153) (writing took 61.172840325161815 seconds)
2023-10-05 04:12:43 - progress_bar.py[line:272] - INFO: epoch 006:    281 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.2, ups=0.01, wpb=269.7, bsz=96, num_updates=4810, lr=2.16183e-05, gnorm=0.663, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=31789
2023-10-05 04:12:50 - progress_bar.py[line:272] - INFO: epoch 006:    291 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=268.8, nsentences=96, sample_size=268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=399.2, ups=1.49, wpb=268.8, bsz=96, num_updates=4820, lr=2.15538e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=31796
2023-10-05 04:12:57 - progress_bar.py[line:272] - INFO: epoch 006:    301 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=383.2, ups=1.41, wpb=271, bsz=96, num_updates=4830, lr=2.14894e-05, gnorm=0.577, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=31803
@@@@ ERROR IN DATA @@@@ ride
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 04:13:04 - progress_bar.py[line:272] - INFO: epoch 006:    311 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=267.5, nsentences=96, sample_size=267.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.3, ups=1.49, wpb=267.5, bsz=96, num_updates=4840, lr=2.14249e-05, gnorm=0.659, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=31810
2023-10-05 04:13:10 - progress_bar.py[line:272] - INFO: epoch 006:    321 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.7, ups=1.49, wpb=270.1, bsz=96, num_updates=4850, lr=2.13604e-05, gnorm=0.54, clip=0, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=31816
2023-10-05 04:13:17 - progress_bar.py[line:272] - INFO: epoch 006:    331 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.8, ups=1.49, wpb=268.2, bsz=96, num_updates=4860, lr=2.12959e-05, gnorm=0.656, clip=10, loss_scale=1024, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=31823
2023-10-05 04:13:24 - progress_bar.py[line:272] - INFO: epoch 006:    341 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=390.5, ups=1.46, wpb=268.1, bsz=96, num_updates=4870, lr=2.12315e-05, gnorm=0.762, clip=30, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=31830
2023-10-05 04:13:31 - progress_bar.py[line:272] - INFO: epoch 006:    351 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.4, ups=1.49, wpb=268.1, bsz=96, num_updates=4880, lr=2.1167e-05, gnorm=0.797, clip=20, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=31837
2023-10-05 04:13:37 - progress_bar.py[line:272] - INFO: epoch 006:    361 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.8, ups=1.46, wpb=268.3, bsz=96, num_updates=4890, lr=2.11025e-05, gnorm=0.631, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=31843
2023-10-05 04:13:44 - progress_bar.py[line:272] - INFO: epoch 006:    371 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.3, ups=1.49, wpb=269.8, bsz=96, num_updates=4900, lr=2.1038e-05, gnorm=0.53, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=31850
2023-10-05 04:13:51 - progress_bar.py[line:272] - INFO: epoch 006:    381 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=403.6, ups=1.49, wpb=270.2, bsz=96, num_updates=4910, lr=2.09736e-05, gnorm=0.675, clip=10, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=31857
2023-10-05 04:13:58 - progress_bar.py[line:272] - INFO: epoch 006:    391 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.8, ups=1.45, wpb=269.3, bsz=96, num_updates=4920, lr=2.09091e-05, gnorm=0.522, clip=0, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=31864
2023-10-05 04:14:04 - progress_bar.py[line:272] - INFO: epoch 006:    401 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.5, ups=1.48, wpb=270, bsz=96, num_updates=4930, lr=2.08446e-05, gnorm=0.553, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=31870
2023-10-05 04:14:11 - progress_bar.py[line:272] - INFO: epoch 006:    411 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=271.8, nsentences=96, sample_size=271.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=394, ups=1.45, wpb=271.8, bsz=96, num_updates=4940, lr=2.07801e-05, gnorm=0.535, clip=0, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=31877
2023-10-05 04:14:18 - progress_bar.py[line:272] - INFO: epoch 006:    421 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=267.7, nsentences=96, sample_size=267.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.3, ups=1.45, wpb=267.7, bsz=96, num_updates=4950, lr=2.07157e-05, gnorm=0.524, clip=0, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=31884
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 04:14:23 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-10-05 04:14:25 - progress_bar.py[line:272] - INFO: epoch 006:    432 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=366.8, ups=1.36, wpb=268.9, bsz=96, num_updates=4960, lr=2.06512e-05, gnorm=0.602, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=31892
@@@@ ERROR IN DATA @@@@ play
2023-10-05 04:14:32 - progress_bar.py[line:272] - INFO: epoch 006:    442 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.9, ups=1.49, wpb=268.5, bsz=96, num_updates=4970, lr=2.05867e-05, gnorm=0.521, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=31898
2023-10-05 04:14:39 - progress_bar.py[line:272] - INFO: epoch 006:    452 / 907 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=402.2, ups=1.49, wpb=269.5, bsz=96, num_updates=4980, lr=2.05222e-05, gnorm=0.738, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=31905
2023-10-05 04:14:46 - progress_bar.py[line:272] - INFO: epoch 006:    462 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=271.8, nsentences=96, sample_size=271.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=392.8, ups=1.45, wpb=271.8, bsz=96, num_updates=4990, lr=2.04578e-05, gnorm=0.499, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=31912
2023-10-05 04:14:53 - progress_bar.py[line:272] - INFO: epoch 006:    472 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=388.7, ups=1.44, wpb=269.4, bsz=96, num_updates=5000, lr=2.03933e-05, gnorm=0.641, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=31919
2023-10-05 04:14:53 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 04:14:55 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 04:14:55 - train.py[line:550] - INFO: load:1.97 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 04:15:34 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.31 GiB (GPU 1; 23.70 GiB total capacity; 6.81 GiB already allocated; 796.56 MiB free; 21.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-05 04:15:34 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:15:34 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 2            |        cudaMalloc retries: 17        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6969 MiB |  10300 MiB |   3622 TiB |   3622 TiB |
|       from large pool |   6824 MiB |  10155 MiB |   3601 TiB |   3601 TiB |
|       from small pool |    144 MiB |    159 MiB |     20 TiB |     20 TiB |
|---------------------------------------------------------------------------|
| Active memory         |   6969 MiB |  10300 MiB |   3622 TiB |   3622 TiB |
|       from large pool |   6824 MiB |  10155 MiB |   3601 TiB |   3601 TiB |
|       from small pool |    144 MiB |    159 MiB |     20 TiB |     20 TiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6922 MiB |  10253 MiB |   3618 TiB |   3617 TiB |
|       from large pool |   6777 MiB |  10109 MiB |   3597 TiB |   3597 TiB |
|       from small pool |    144 MiB |    158 MiB |     20 TiB |     20 TiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  22052 MiB |  22082 MiB |  94814 MiB |  72762 MiB |
|       from large pool |  21906 MiB |  21906 MiB |  94384 MiB |  72478 MiB |
|       from small pool |    146 MiB |    176 MiB |    430 MiB |    284 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  15082 MiB |  15082 MiB |   3482 TiB |   3482 TiB |
|       from large pool |  15081 MiB |  15081 MiB |   3461 TiB |   3461 TiB |
|       from small pool |      1 MiB |      7 MiB |     21 TiB |     21 TiB |
|---------------------------------------------------------------------------|
| Allocations           |    3578    |    3593    |  233370 K  |  233366 K  |
|       from large pool |     565    |     577    |   92631 K  |   92630 K  |
|       from small pool |    3013    |    3027    |  140739 K  |  140736 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3578    |    3593    |  233370 K  |  233366 K  |
|       from large pool |     565    |     577    |   92631 K  |   92630 K  |
|       from small pool |    3013    |    3027    |  140739 K  |  140736 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     148    |     163    |     425    |     277    |
|       from large pool |      75    |      75    |     210    |     135    |
|       from small pool |      73    |      88    |     215    |     142    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      96    |     108    |  125163 K  |  125163 K  |
|       from large pool |      64    |      67    |   24436 K  |   24436 K  |
|       from small pool |      32    |      48    |  100727 K  |  100727 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:15:34 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:15:34 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:15:34 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:15:34 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:15:34 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:15:34 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:15:34 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-05 04:16:34 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 04:16:34 - train.py[line:550] - INFO: load:2.05 valid_run:98.71 task_valid:93.17 collect_output:4.47
2023-10-05 04:18:10 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 04:18:10 - train.py[line:550] - INFO: load:2.14 valid_run:194.88 task_valid:184.96 collect_output:7.90
2023-10-05 04:19:46 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 04:19:46 - train.py[line:550] - INFO: load:2.22 valid_run:290.98 task_valid:274.04 collect_output:13.96
2023-10-05 04:21:22 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 04:21:22 - train.py[line:550] - INFO: load:2.30 valid_run:386.25 task_valid:363.92 collect_output:18.41
2023-10-05 04:22:58 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 04:22:58 - train.py[line:550] - INFO: load:2.38 valid_run:482.15 task_valid:453.92 collect_output:23.36
2023-10-05 04:24:34 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 04:24:34 - train.py[line:550] - INFO: load:2.46 valid_run:578.17 task_valid:543.69 collect_output:28.62
2023-10-05 04:26:09 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 04:26:09 - train.py[line:550] - INFO: load:2.56 valid_run:672.90 task_valid:634.05 collect_output:32.03
2023-10-05 04:27:45 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 04:27:45 - train.py[line:550] - INFO: load:2.64 valid_run:768.66 task_valid:726.07 collect_output:34.82
2023-10-05 04:29:21 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 04:29:21 - train.py[line:550] - INFO: load:2.72 valid_run:864.57 task_valid:816.80 collect_output:39.03
2023-10-05 04:30:57 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 04:30:57 - train.py[line:550] - INFO: load:2.81 valid_run:960.70 task_valid:908.37 collect_output:42.62
2023-10-05 04:32:32 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 04:32:32 - train.py[line:550] - INFO: load:2.89 valid_run:1056.03 task_valid:999.57 collect_output:45.85

====================================================================================================
SGG eval:     R @ 50: 0.6313;     R @ 100: 0.6816;     R @ 500: 0.7166;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4192;    mR @ 100: 0.4741;    mR @ 500: 0.5281;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5676) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6313;     R @ 100: 0.6816;     R @ 500: 0.7166;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4192;    mR @ 100: 0.4741;    mR @ 500: 0.5281;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5676) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6313;     R @ 100: 0.6816;     R @ 500: 0.7166;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4192;    mR @ 100: 0.4741;    mR @ 500: 0.5281;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5676) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6313;     R @ 100: 0.6816;     R @ 500: 0.7166;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4192;    mR @ 100: 0.4741;    mR @ 500: 0.5281;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5676) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6313;     R @ 100: 0.6816;     R @ 500: 0.7166;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4192;    mR @ 100: 0.4741;    mR @ 500: 0.5281;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5676) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6313;     R @ 100: 0.6816;     R @ 500: 0.7166;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4192;    mR @ 100: 0.4741;    mR @ 500: 0.5281;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5676) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2023-10-05 04:33:49 - train.py[line:487] - INFO: 0.6816416857652152

====================================================================================================
SGG eval:     R @ 50: 0.6313;     R @ 100: 0.6816;     R @ 500: 0.7166;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4192;    mR @ 100: 0.4741;    mR @ 500: 0.5281;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5676) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6313;     R @ 100: 0.6816;     R @ 500: 0.7166;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4192;    mR @ 100: 0.4741;    mR @ 500: 0.5281;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.5000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.6978) (standing on:0.5643) (using:0.4500) (walking in:0.0000) (walking on:0.5676) (watching:0.5833) 
--------------------------------------------------------
====================================================================================================

2023-10-05 04:33:49 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 04:33:49 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 0.24 | loss_v1 0 | loss_v2 0 | nll_loss 0.07 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.681642 | ppl 1.05 | vqa_score 0.4932 | wps 396 | wpb 191.9 | bsz 64 | num_updates 5000 | best_R@100 0.683142
2023-10-05 04:33:49 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 5000 updates
2023-10-05 04:33:49 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_5000.pt
2023-10-05 04:33:55 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_5000.pt
2023-10-05 04:34:33 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_5000.pt (epoch 6 @ 5000 updates, score 0.6816416857652152) (writing took 43.904207564890385 seconds)
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 04:34:39 - progress_bar.py[line:272] - INFO: epoch 006:    482 / 907 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=2.3, ups=0.01, wpb=267.8, bsz=96, num_updates=5010, lr=2.03288e-05, gnorm=0.727, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=33105
2023-10-05 04:34:46 - progress_bar.py[line:272] - INFO: epoch 006:    492 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.8, ups=1.49, wpb=269.5, bsz=96, num_updates=5020, lr=2.02643e-05, gnorm=0.579, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=33112
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 04:34:53 - progress_bar.py[line:272] - INFO: epoch 006:    502 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.4, ups=1.49, wpb=270.5, bsz=96, num_updates=5030, lr=2.01999e-05, gnorm=0.626, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=33119
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 04:35:00 - progress_bar.py[line:272] - INFO: epoch 006:    512 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.4, ups=1.49, wpb=269.7, bsz=96, num_updates=5040, lr=2.01354e-05, gnorm=0.742, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=33126
2023-10-05 04:35:06 - progress_bar.py[line:272] - INFO: epoch 006:    522 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.3, ups=1.45, wpb=269.1, bsz=96, num_updates=5050, lr=2.00709e-05, gnorm=0.642, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=33132
2023-10-05 04:35:13 - progress_bar.py[line:272] - INFO: epoch 006:    532 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=405.9, ups=1.5, wpb=271.3, bsz=96, num_updates=5060, lr=2.00064e-05, gnorm=0.648, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=33139
2023-10-05 04:35:20 - progress_bar.py[line:272] - INFO: epoch 006:    542 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=404.6, ups=1.5, wpb=270.1, bsz=96, num_updates=5070, lr=1.9942e-05, gnorm=0.578, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=33146
2023-10-05 04:35:27 - progress_bar.py[line:272] - INFO: epoch 006:    552 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.083, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=395.4, ups=1.47, wpb=269.8, bsz=96, num_updates=5080, lr=1.98775e-05, gnorm=0.646, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=33153
2023-10-05 04:35:33 - progress_bar.py[line:272] - INFO: epoch 006:    562 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402, ups=1.49, wpb=269.1, bsz=96, num_updates=5090, lr=1.9813e-05, gnorm=0.676, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=33159
2023-10-05 04:35:40 - progress_bar.py[line:272] - INFO: epoch 006:    572 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=386, ups=1.43, wpb=269.3, bsz=96, num_updates=5100, lr=1.97485e-05, gnorm=0.678, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=33166
2023-10-05 04:35:47 - progress_bar.py[line:272] - INFO: epoch 006:    582 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.2, ups=1.49, wpb=270.1, bsz=96, num_updates=5110, lr=1.96841e-05, gnorm=0.732, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=33173
2023-10-05 04:35:54 - progress_bar.py[line:272] - INFO: epoch 006:    592 / 907 loss=0.262, loss_v1=0, loss_v2=0, nll_loss=0.084, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=386.6, ups=1.44, wpb=269.2, bsz=96, num_updates=5120, lr=1.96196e-05, gnorm=0.655, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=33180
2023-10-05 04:36:01 - progress_bar.py[line:272] - INFO: epoch 006:    602 / 907 loss=0.26, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=271.4, nsentences=96, sample_size=271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=404.9, ups=1.49, wpb=271.4, bsz=96, num_updates=5130, lr=1.95551e-05, gnorm=0.596, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=33187
2023-10-05 04:36:07 - progress_bar.py[line:272] - INFO: epoch 006:    612 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.4, ups=1.49, wpb=270.9, bsz=96, num_updates=5140, lr=1.94907e-05, gnorm=0.544, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=33193
2023-10-05 04:36:14 - progress_bar.py[line:272] - INFO: epoch 006:    622 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=392.3, ups=1.45, wpb=270.7, bsz=96, num_updates=5150, lr=1.94262e-05, gnorm=0.46, clip=0, loss_scale=512, train_wall=7, gb_free=6.1, ema_decay=0.9999, wall=33200
2023-10-05 04:36:21 - progress_bar.py[line:272] - INFO: epoch 006:    632 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=383.1, ups=1.42, wpb=269.9, bsz=96, num_updates=5160, lr=1.93617e-05, gnorm=0.741, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=33207
2023-10-05 04:36:28 - progress_bar.py[line:272] - INFO: epoch 006:    642 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.9, ups=1.48, wpb=270.7, bsz=96, num_updates=5170, lr=1.92972e-05, gnorm=0.549, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=33214
2023-10-05 04:36:35 - progress_bar.py[line:272] - INFO: epoch 006:    652 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=267.6, nsentences=96, sample_size=267.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.7, ups=1.46, wpb=267.6, bsz=96, num_updates=5180, lr=1.92328e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=33221
2023-10-05 04:36:42 - progress_bar.py[line:272] - INFO: epoch 006:    662 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.7, ups=1.45, wpb=268.2, bsz=96, num_updates=5190, lr=1.91683e-05, gnorm=0.542, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=33228
2023-10-05 04:36:49 - progress_bar.py[line:272] - INFO: epoch 006:    672 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.3, ups=1.49, wpb=270.6, bsz=96, num_updates=5200, lr=1.91038e-05, gnorm=0.501, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=33235
2023-10-05 04:36:49 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 04:36:52 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 04:36:52 - train.py[line:550] - INFO: load:2.84 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 04:38:30 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 04:38:30 - train.py[line:550] - INFO: load:2.94 valid_run:97.78 task_valid:93.28 collect_output:3.44
2023-10-05 04:40:06 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 04:40:06 - train.py[line:550] - INFO: load:3.02 valid_run:193.76 task_valid:184.99 collect_output:6.74
2023-10-05 04:41:42 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 04:41:42 - train.py[line:550] - INFO: load:3.11 valid_run:289.71 task_valid:273.82 collect_output:12.87
2023-10-05 04:43:18 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 04:43:18 - train.py[line:550] - INFO: load:3.19 valid_run:385.34 task_valid:363.60 collect_output:17.74
2023-10-05 04:44:53 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 04:44:53 - train.py[line:550] - INFO: load:3.28 valid_run:481.04 task_valid:453.59 collect_output:22.50
2023-10-05 04:46:29 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 04:46:29 - train.py[line:550] - INFO: load:3.37 valid_run:577.00 task_valid:543.02 collect_output:28.10
2023-10-05 04:48:04 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 04:48:04 - train.py[line:550] - INFO: load:3.44 valid_run:671.81 task_valid:633.23 collect_output:31.74
2023-10-05 04:49:40 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 04:49:40 - train.py[line:550] - INFO: load:3.52 valid_run:767.49 task_valid:725.32 collect_output:34.42
2023-10-05 04:51:16 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 04:51:16 - train.py[line:550] - INFO: load:3.61 valid_run:863.46 task_valid:815.76 collect_output:39.00
2023-10-05 04:52:52 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 04:52:52 - train.py[line:550] - INFO: load:3.69 valid_run:959.42 task_valid:907.18 collect_output:42.52
2023-10-05 04:54:28 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 04:54:28 - train.py[line:550] - INFO: load:3.79 valid_run:1054.63 task_valid:998.38 collect_output:45.58

====================================================================================================
SGG eval:     R @ 50: 0.6323;     R @ 100: 0.6841;     R @ 500: 0.7171;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4153;    mR @ 100: 0.4715;    mR @ 500: 0.5238;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7115) (standing on:0.5593) (using:0.4500) (walking in:0.0000) (walking on:0.5315) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6323;     R @ 100: 0.6841;     R @ 500: 0.7171;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4153;    mR @ 100: 0.4715;    mR @ 500: 0.5238;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7115) (standing on:0.5593) (using:0.4500) (walking in:0.0000) (walking on:0.5315) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6323;     R @ 100: 0.6841;     R @ 500: 0.7171;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4153;    mR @ 100: 0.4715;    mR @ 500: 0.5238;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7115) (standing on:0.5593) (using:0.4500) (walking in:0.0000) (walking on:0.5315) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6323;     R @ 100: 0.6841;     R @ 500: 0.7171;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4153;    mR @ 100: 0.4715;    mR @ 500: 0.5238;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7115) (standing on:0.5593) (using:0.4500) (walking in:0.0000) (walking on:0.5315) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6323;     R @ 100: 0.6841;     R @ 500: 0.7171;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4153;    mR @ 100: 0.4715;    mR @ 500: 0.5238;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7115) (standing on:0.5593) (using:0.4500) (walking in:0.0000) (walking on:0.5315) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================

2023-10-05 04:55:43 - train.py[line:487] - INFO: 0.6841416857652153
2023-10-05 04:55:44 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 04:55:44 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 0.242 | loss_v1 0 | loss_v2 0 | nll_loss 0.071 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.684142 | ppl 1.05 | vqa_score 0.4955 | wps 396.4 | wpb 191.9 | bsz 64 | num_updates 5200 | best_R@100 0.684142

====================================================================================================
SGG eval:     R @ 50: 0.6323;     R @ 100: 0.6841;     R @ 500: 0.7171;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4153;    mR @ 100: 0.4715;    mR @ 500: 0.5238;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7115) (standing on:0.5593) (using:0.4500) (walking in:0.0000) (walking on:0.5315) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================

2023-10-05 04:55:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 5200 updates
2023-10-05 04:55:44 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_5200.pt

====================================================================================================
SGG eval:     R @ 50: 0.6323;     R @ 100: 0.6841;     R @ 500: 0.7171;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4153;    mR @ 100: 0.4715;    mR @ 500: 0.5238;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7115) (standing on:0.5593) (using:0.4500) (walking in:0.0000) (walking on:0.5315) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6323;     R @ 100: 0.6841;     R @ 500: 0.7171;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4153;    mR @ 100: 0.4715;    mR @ 500: 0.5238;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4839) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7115) (standing on:0.5593) (using:0.4500) (walking in:0.0000) (walking on:0.5315) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================

2023-10-05 04:55:50 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_5200.pt
2023-10-05 04:56:43 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_5200.pt (epoch 6 @ 5200 updates, score 0.6841416857652153) (writing took 59.3984102839604 seconds)
2023-10-05 04:56:50 - progress_bar.py[line:272] - INFO: epoch 006:    682 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.2, ups=0.01, wpb=267.8, bsz=96, num_updates=5210, lr=1.90393e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=34436
2023-10-05 04:56:57 - progress_bar.py[line:272] - INFO: epoch 006:    692 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=393, ups=1.46, wpb=269.3, bsz=96, num_updates=5220, lr=1.89749e-05, gnorm=0.538, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=34443
2023-10-05 04:57:03 - progress_bar.py[line:272] - INFO: epoch 006:    702 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.2, ups=1.5, wpb=269.5, bsz=96, num_updates=5230, lr=1.89104e-05, gnorm=0.688, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=34449
2023-10-05 04:57:10 - progress_bar.py[line:272] - INFO: epoch 006:    712 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.079, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=402.4, ups=1.49, wpb=270.7, bsz=96, num_updates=5240, lr=1.88459e-05, gnorm=0.756, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=34456
2023-10-05 04:57:17 - progress_bar.py[line:272] - INFO: epoch 006:    722 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.9, ups=1.49, wpb=268.1, bsz=96, num_updates=5250, lr=1.87814e-05, gnorm=0.679, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=34463
2023-10-05 04:57:23 - progress_bar.py[line:272] - INFO: epoch 006:    732 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=401.7, ups=1.49, wpb=269.4, bsz=96, num_updates=5260, lr=1.8717e-05, gnorm=0.534, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=34469
2023-10-05 04:57:30 - progress_bar.py[line:272] - INFO: epoch 006:    742 / 907 loss=0.261, loss_v1=0, loss_v2=0, nll_loss=0.082, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=391.9, ups=1.46, wpb=268.3, bsz=96, num_updates=5270, lr=1.86525e-05, gnorm=0.641, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=34476
2023-10-05 04:57:37 - progress_bar.py[line:272] - INFO: epoch 006:    752 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400, ups=1.49, wpb=268.6, bsz=96, num_updates=5280, lr=1.8588e-05, gnorm=0.575, clip=10, loss_scale=512, train_wall=7, gb_free=6.6, ema_decay=0.9999, wall=34483
@@@@ ERROR IN DATA @@@@ watch
2023-10-05 04:57:44 - progress_bar.py[line:272] - INFO: epoch 006:    762 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=386.3, ups=1.42, wpb=271.3, bsz=96, num_updates=5290, lr=1.85235e-05, gnorm=0.577, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=34490
2023-10-05 04:57:51 - progress_bar.py[line:272] - INFO: epoch 006:    772 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.4, ups=1.48, wpb=268.5, bsz=96, num_updates=5300, lr=1.84591e-05, gnorm=0.779, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=34497
2023-10-05 04:57:57 - progress_bar.py[line:272] - INFO: epoch 006:    782 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.9, ups=1.49, wpb=268.6, bsz=96, num_updates=5310, lr=1.83946e-05, gnorm=0.572, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=34504
2023-10-05 04:58:04 - progress_bar.py[line:272] - INFO: epoch 006:    792 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=392.6, ups=1.45, wpb=271.1, bsz=96, num_updates=5320, lr=1.83301e-05, gnorm=0.546, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=34510
2023-10-05 04:58:11 - progress_bar.py[line:272] - INFO: epoch 006:    802 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.7, ups=1.46, wpb=269.2, bsz=96, num_updates=5330, lr=1.82656e-05, gnorm=0.592, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=34517
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 04:58:18 - progress_bar.py[line:272] - INFO: epoch 006:    812 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=267, nsentences=96, sample_size=267, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.8, ups=1.49, wpb=267, bsz=96, num_updates=5340, lr=1.82012e-05, gnorm=0.611, clip=0, loss_scale=512, train_wall=7, gb_free=5.9, ema_decay=0.9999, wall=34524
2023-10-05 04:58:25 - progress_bar.py[line:272] - INFO: epoch 006:    822 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.8, ups=1.49, wpb=270.4, bsz=96, num_updates=5350, lr=1.81367e-05, gnorm=0.58, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=34531
2023-10-05 04:58:32 - progress_bar.py[line:272] - INFO: epoch 006:    832 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.7, ups=1.44, wpb=270.1, bsz=96, num_updates=5360, lr=1.80722e-05, gnorm=0.485, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=34538
2023-10-05 04:58:39 - progress_bar.py[line:272] - INFO: epoch 006:    842 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=378.3, ups=1.41, wpb=268.4, bsz=96, num_updates=5370, lr=1.80077e-05, gnorm=0.602, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=34545
2023-10-05 04:58:46 - progress_bar.py[line:272] - INFO: epoch 006:    852 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=393, ups=1.45, wpb=271.1, bsz=96, num_updates=5380, lr=1.79433e-05, gnorm=0.581, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=34552
2023-10-05 04:58:52 - progress_bar.py[line:272] - INFO: epoch 006:    862 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.5, ups=1.49, wpb=269.7, bsz=96, num_updates=5390, lr=1.78788e-05, gnorm=0.652, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=34558
2023-10-05 04:58:59 - progress_bar.py[line:272] - INFO: epoch 006:    872 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=400.6, ups=1.49, wpb=268.7, bsz=96, num_updates=5400, lr=1.78143e-05, gnorm=0.582, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=34565
2023-10-05 04:58:59 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 04:59:02 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 04:59:02 - train.py[line:550] - INFO: load:2.46 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 04:59:36 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 3.24 GiB (GPU 1; 23.70 GiB total capacity; 6.76 GiB already allocated; 1.73 GiB free; 20.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-05 04:59:36 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:59:36 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 3            |        cudaMalloc retries: 23        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6923 MiB |   9939 MiB |   3922 TiB |   3922 TiB |
|       from large pool |   6779 MiB |   9794 MiB |   3899 TiB |   3899 TiB |
|       from small pool |    144 MiB |    159 MiB |     22 TiB |     22 TiB |
|---------------------------------------------------------------------------|
| Active memory         |   6923 MiB |   9939 MiB |   3922 TiB |   3922 TiB |
|       from large pool |   6779 MiB |   9794 MiB |   3899 TiB |   3899 TiB |
|       from small pool |    144 MiB |    159 MiB |     22 TiB |     22 TiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6878 MiB |   9892 MiB |   3917 TiB |   3917 TiB |
|       from large pool |   6733 MiB |   9747 MiB |   3894 TiB |   3894 TiB |
|       from small pool |    144 MiB |    158 MiB |     22 TiB |     22 TiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  21080 MiB |  21096 MiB | 123942 MiB | 102862 MiB |
|       from large pool |  20934 MiB |  20934 MiB | 123414 MiB | 102480 MiB |
|       from small pool |    146 MiB |    162 MiB |    528 MiB |    382 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  14156 MiB |  14156 MiB |   3781 TiB |   3781 TiB |
|       from large pool |  14154 MiB |  14154 MiB |   3758 TiB |   3758 TiB |
|       from small pool |      1 MiB |      7 MiB |     23 TiB |     23 TiB |
|---------------------------------------------------------------------------|
| Allocations           |    3578    |    3593    |  252683 K  |  252680 K  |
|       from large pool |     565    |     577    |  100286 K  |  100285 K  |
|       from small pool |    3013    |    3027    |  152397 K  |  152394 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3578    |    3593    |  252683 K  |  252680 K  |
|       from large pool |     565    |     577    |  100286 K  |  100285 K  |
|       from small pool |    3013    |    3027    |  152397 K  |  152394 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     139    |     147    |     497    |     358    |
|       from large pool |      66    |      66    |     233    |     167    |
|       from small pool |      73    |      81    |     264    |     191    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      91    |     102    |  135815 K  |  135815 K  |
|       from large pool |      59    |      59    |   26915 K  |   26915 K  |
|       from small pool |      32    |      47    |  108899 K  |  108899 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:59:36 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:59:36 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:59:36 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:59:36 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:59:36 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:59:36 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 04:59:36 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-05 05:00:39 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 05:00:39 - train.py[line:550] - INFO: load:2.55 valid_run:97.64 task_valid:93.11 collect_output:3.49
2023-10-05 05:02:16 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 05:02:16 - train.py[line:550] - INFO: load:2.64 valid_run:193.95 task_valid:184.80 collect_output:7.13
2023-10-05 05:03:52 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 05:03:52 - train.py[line:550] - INFO: load:2.73 valid_run:290.28 task_valid:273.45 collect_output:13.82
2023-10-05 05:05:28 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 05:05:28 - train.py[line:550] - INFO: load:2.82 valid_run:385.45 task_valid:363.42 collect_output:18.02
2023-10-05 05:07:04 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 05:07:04 - train.py[line:550] - INFO: load:2.91 valid_run:481.43 task_valid:453.34 collect_output:23.12
2023-10-05 05:08:40 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 05:08:40 - train.py[line:550] - INFO: load:3.00 valid_run:577.84 task_valid:542.85 collect_output:29.06
2023-10-05 05:10:15 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 05:10:15 - train.py[line:550] - INFO: load:3.08 valid_run:672.73 task_valid:633.28 collect_output:32.55
2023-10-05 05:11:51 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 05:11:51 - train.py[line:550] - INFO: load:3.16 valid_run:768.66 task_valid:725.38 collect_output:35.39
2023-10-05 05:13:28 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 05:13:28 - train.py[line:550] - INFO: load:3.24 valid_run:864.91 task_valid:816.03 collect_output:40.01
2023-10-05 05:15:04 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 05:15:04 - train.py[line:550] - INFO: load:3.33 valid_run:960.89 task_valid:907.62 collect_output:43.41
2023-10-05 05:16:40 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 05:16:40 - train.py[line:550] - INFO: load:3.42 valid_run:1056.47 task_valid:999.04 collect_output:46.59

====================================================================================================
SGG eval:     R @ 50: 0.6376;     R @ 100: 0.6876;     R @ 500: 0.7211;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4183;    mR @ 100: 0.4746;    mR @ 500: 0.5272;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.5405) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6376;     R @ 100: 0.6876;     R @ 500: 0.7211;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4183;    mR @ 100: 0.4746;    mR @ 500: 0.5272;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.5405) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6376;     R @ 100: 0.6876;     R @ 500: 0.7211;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4183;    mR @ 100: 0.4746;    mR @ 500: 0.5272;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.5405) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6376;     R @ 100: 0.6876;     R @ 500: 0.7211;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4183;    mR @ 100: 0.4746;    mR @ 500: 0.5272;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.5405) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6376;     R @ 100: 0.6876;     R @ 500: 0.7211;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4183;    mR @ 100: 0.4746;    mR @ 500: 0.5272;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.5405) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6376;     R @ 100: 0.6876;     R @ 500: 0.7211;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4183;    mR @ 100: 0.4746;    mR @ 500: 0.5272;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.5405) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================

2023-10-05 05:17:56 - train.py[line:487] - INFO: 0.6876083524318818

====================================================================================================
SGG eval:     R @ 50: 0.6376;     R @ 100: 0.6876;     R @ 500: 0.7211;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4183;    mR @ 100: 0.4746;    mR @ 500: 0.5272;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.5405) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6376;     R @ 100: 0.6876;     R @ 500: 0.7211;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4183;    mR @ 100: 0.4746;    mR @ 500: 0.5272;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.3542) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.4167) (parked on:0.9167) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.5405) (watching:0.6250) 
--------------------------------------------------------
====================================================================================================

2023-10-05 05:17:56 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 05:17:56 - progress_bar.py[line:282] - INFO: epoch 006 | valid on 'valid' subset | loss 0.241 | loss_v1 0 | loss_v2 0 | nll_loss 0.076 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.687608 | ppl 1.05 | vqa_score 0.5011 | wps 395.7 | wpb 191.9 | bsz 64 | num_updates 5400 | best_R@100 0.687608
2023-10-05 05:17:56 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 6 @ 5400 updates
2023-10-05 05:17:56 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_5400.pt
2023-10-05 05:18:02 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_5400.pt
2023-10-05 05:19:00 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_6_5400.pt (epoch 6 @ 5400 updates, score 0.6876083524318818) (writing took 63.796012782957405 seconds)
2023-10-05 05:19:06 - progress_bar.py[line:272] - INFO: epoch 006:    882 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.078, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=2.2, ups=0.01, wpb=269, bsz=96, num_updates=5410, lr=1.77498e-05, gnorm=0.647, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35772
2023-10-05 05:19:13 - progress_bar.py[line:272] - INFO: epoch 006:    892 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.6, ups=1.48, wpb=269.9, bsz=96, num_updates=5420, lr=1.76854e-05, gnorm=0.635, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35779
2023-10-05 05:19:20 - progress_bar.py[line:272] - INFO: epoch 006:    902 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.8, ups=1.48, wpb=270.5, bsz=96, num_updates=5430, lr=1.76209e-05, gnorm=0.533, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=35786
2023-10-05 05:19:23 - train.py[line:339] - INFO: end of epoch 6 (average epoch stats below)
2023-10-05 05:19:23 - progress_bar.py[line:282] - INFO: epoch 006 | loss 0.253 | loss_v1 0 | loss_v2 0 | nll_loss 0.072 | ntokens 269.256 | nsentences 95.914 | sample_size 269.256 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.05 | wps 37.1 | ups 0.14 | wpb 269.3 | bsz 95.9 | num_updates 5435 | lr 1.75887e-05 | gnorm 0.615 | clip 6.6 | loss_scale 512 | train_wall 612 | gb_free 16.3 | ema_decay 0.9999 | wall 35789
2023-10-05 05:19:23 - trainer.py[line:694] - INFO: loading train data for epoch 7
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv slice_id 0 row count 10875 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv slice_id 3 row count 10874 total row count 86994

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv slice_id 7 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv slice_id 2 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv slice_id 1 row count 10875 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv slice_id 6 row count 10874 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv slice_id 5 row count 10874 total row count 86994

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E6.tsv slice_id 4 row count 10874 total row count 86994
2023-10-05 05:19:23 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
2023-10-05 05:19:23 - trainer.py[line:758] - INFO: begin training epoch 7
2023-10-05 05:19:23 - train.py[line:312] - INFO: Start iterating over samples
2023-10-05 05:19:24 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 05:19:24 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 05:19:24 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 05:19:24 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 05:19:24 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 05:19:24 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 05:19:24 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 05:19:25 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 05:19:31 - progress_bar.py[line:272] - INFO: epoch 007:      5 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=245.7, nsentences=88.2, sample_size=245.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=230.6, ups=0.94, wpb=245.7, bsz=88.2, num_updates=5440, lr=1.75564e-05, gnorm=0.63, clip=20, loss_scale=512, train_wall=8, gb_free=6.5, ema_decay=0.9999, wall=35797
2023-10-05 05:19:37 - progress_bar.py[line:272] - INFO: epoch 007:     15 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=397.7, ups=1.47, wpb=270.4, bsz=96, num_updates=5450, lr=1.74919e-05, gnorm=0.517, clip=0, loss_scale=512, train_wall=7, gb_free=6.1, ema_decay=0.9999, wall=35803
2023-10-05 05:19:44 - progress_bar.py[line:272] - INFO: epoch 007:     25 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.2, ups=1.49, wpb=268.9, bsz=96, num_updates=5460, lr=1.74275e-05, gnorm=0.51, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35810
2023-10-05 05:19:51 - progress_bar.py[line:272] - INFO: epoch 007:     35 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.1, ups=1.49, wpb=269.5, bsz=96, num_updates=5470, lr=1.7363e-05, gnorm=0.753, clip=20, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35817
2023-10-05 05:19:57 - progress_bar.py[line:272] - INFO: epoch 007:     45 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.4, ups=1.49, wpb=269, bsz=96, num_updates=5480, lr=1.72985e-05, gnorm=0.58, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35824
2023-10-05 05:20:04 - progress_bar.py[line:272] - INFO: epoch 007:     55 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=271.9, nsentences=96, sample_size=271.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=405.2, ups=1.49, wpb=271.9, bsz=96, num_updates=5490, lr=1.7234e-05, gnorm=0.572, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35830
2023-10-05 05:20:11 - progress_bar.py[line:272] - INFO: epoch 007:     65 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.5, ups=1.49, wpb=269.9, bsz=96, num_updates=5500, lr=1.71696e-05, gnorm=0.494, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35837
2023-10-05 05:20:18 - progress_bar.py[line:272] - INFO: epoch 007:     75 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=388.4, ups=1.44, wpb=270.1, bsz=96, num_updates=5510, lr=1.71051e-05, gnorm=0.517, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35844
2023-10-05 05:20:25 - progress_bar.py[line:272] - INFO: epoch 007:     85 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.7, ups=1.49, wpb=269.3, bsz=96, num_updates=5520, lr=1.70406e-05, gnorm=0.548, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35851
2023-10-05 05:20:31 - progress_bar.py[line:272] - INFO: epoch 007:     95 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.3, ups=1.49, wpb=268.2, bsz=96, num_updates=5530, lr=1.69761e-05, gnorm=0.475, clip=10, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=35857
2023-10-05 05:20:38 - progress_bar.py[line:272] - INFO: epoch 007:    105 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=271.4, nsentences=96, sample_size=271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=390.1, ups=1.44, wpb=271.4, bsz=96, num_updates=5540, lr=1.69117e-05, gnorm=0.578, clip=0, loss_scale=1024, train_wall=7, gb_free=6.1, ema_decay=0.9999, wall=35864
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 05:20:43 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-10-05 05:20:46 - progress_bar.py[line:272] - INFO: epoch 007:    116 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=346, ups=1.28, wpb=270.4, bsz=96, num_updates=5550, lr=1.68472e-05, gnorm=0.418, clip=0, loss_scale=512, train_wall=8, gb_free=6.5, ema_decay=0.9999, wall=35872
2023-10-05 05:20:53 - progress_bar.py[line:272] - INFO: epoch 007:    126 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.1, ups=1.49, wpb=269.6, bsz=96, num_updates=5560, lr=1.67827e-05, gnorm=0.417, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35879
2023-10-05 05:21:00 - progress_bar.py[line:272] - INFO: epoch 007:    136 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=271.6, nsentences=96, sample_size=271.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=406.1, ups=1.5, wpb=271.6, bsz=96, num_updates=5570, lr=1.67182e-05, gnorm=0.479, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35886
2023-10-05 05:21:07 - progress_bar.py[line:272] - INFO: epoch 007:    146 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=376.7, ups=1.39, wpb=271.3, bsz=96, num_updates=5580, lr=1.66538e-05, gnorm=0.766, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=35893
2023-10-05 05:21:14 - progress_bar.py[line:272] - INFO: epoch 007:    156 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=272.2, nsentences=96, sample_size=272.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.7, ups=1.44, wpb=272.2, bsz=96, num_updates=5590, lr=1.65893e-05, gnorm=0.52, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=35900
2023-10-05 05:21:21 - progress_bar.py[line:272] - INFO: epoch 007:    166 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=266.6, nsentences=96, sample_size=266.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=372, ups=1.4, wpb=266.6, bsz=96, num_updates=5600, lr=1.65248e-05, gnorm=0.64, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=35907
2023-10-05 05:21:21 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 05:21:23 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 05:21:23 - train.py[line:550] - INFO: load:1.79 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 05:23:01 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 05:23:01 - train.py[line:550] - INFO: load:1.87 valid_run:97.74 task_valid:93.04 collect_output:3.70
2023-10-05 05:24:37 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 05:24:37 - train.py[line:550] - INFO: load:1.96 valid_run:193.90 task_valid:184.76 collect_output:7.18
2023-10-05 05:26:13 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 05:26:13 - train.py[line:550] - INFO: load:2.04 valid_run:289.74 task_valid:273.58 collect_output:13.19
2023-10-05 05:27:48 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 05:27:48 - train.py[line:550] - INFO: load:2.14 valid_run:384.87 task_valid:363.61 collect_output:17.30
2023-10-05 05:29:24 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 05:29:24 - train.py[line:550] - INFO: load:2.23 valid_run:480.78 task_valid:453.50 collect_output:22.34
2023-10-05 05:31:00 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 05:31:00 - train.py[line:550] - INFO: load:2.31 valid_run:576.38 task_valid:542.93 collect_output:27.59
2023-10-05 05:32:34 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 05:32:34 - train.py[line:550] - INFO: load:2.39 valid_run:670.71 task_valid:633.22 collect_output:30.72
2023-10-05 05:34:10 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 05:34:10 - train.py[line:550] - INFO: load:2.47 valid_run:766.42 task_valid:725.58 collect_output:33.11
2023-10-05 05:35:47 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 05:35:47 - train.py[line:550] - INFO: load:2.55 valid_run:862.61 task_valid:816.34 collect_output:37.63
2023-10-05 05:37:23 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 05:37:23 - train.py[line:550] - INFO: load:2.65 valid_run:958.67 task_valid:907.93 collect_output:41.18
2023-10-05 05:38:58 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 05:38:58 - train.py[line:550] - INFO: load:2.74 valid_run:1054.04 task_valid:999.25 collect_output:44.26

====================================================================================================
SGG eval:     R @ 50: 0.6390;     R @ 100: 0.6890;     R @ 500: 0.7223;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4265;    mR @ 100: 0.4834;    mR @ 500: 0.5359;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6458) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6390;     R @ 100: 0.6890;     R @ 500: 0.7223;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4265;    mR @ 100: 0.4834;    mR @ 500: 0.5359;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6458) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6390;     R @ 100: 0.6890;     R @ 500: 0.7223;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4265;    mR @ 100: 0.4834;    mR @ 500: 0.5359;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6458) 
--------------------------------------------------------
====================================================================================================

2023-10-05 05:40:14 - train.py[line:487] - INFO: 0.6890083524318819

====================================================================================================
SGG eval:     R @ 50: 0.6390;     R @ 100: 0.6890;     R @ 500: 0.7223;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4265;    mR @ 100: 0.4834;    mR @ 500: 0.5359;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6458) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6390;     R @ 100: 0.6890;     R @ 500: 0.7223;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4265;    mR @ 100: 0.4834;    mR @ 500: 0.5359;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6458) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6390;     R @ 100: 0.6890;     R @ 500: 0.7223;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4265;    mR @ 100: 0.4834;    mR @ 500: 0.5359;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6458) 
--------------------------------------------------------
====================================================================================================

2023-10-05 05:40:14 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 05:40:14 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 0.236 | loss_v1 0 | loss_v2 0 | nll_loss 0.07 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.689008 | ppl 1.05 | vqa_score 0.4955 | wps 396.7 | wpb 191.9 | bsz 64 | num_updates 5600 | best_R@100 0.689008
2023-10-05 05:40:14 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 5600 updates
2023-10-05 05:40:14 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_5600.pt

====================================================================================================
SGG eval:     R @ 50: 0.6390;     R @ 100: 0.6890;     R @ 500: 0.7223;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4265;    mR @ 100: 0.4834;    mR @ 500: 0.5359;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6458) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6390;     R @ 100: 0.6890;     R @ 500: 0.7223;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4265;    mR @ 100: 0.4834;    mR @ 500: 0.5359;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7132) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6458) 
--------------------------------------------------------
====================================================================================================

2023-10-05 05:40:20 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_5600.pt
2023-10-05 05:41:28 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_5600.pt (epoch 7 @ 5600 updates, score 0.6890083524318819) (writing took 73.47673733904958 seconds)
2023-10-05 05:41:34 - progress_bar.py[line:272] - INFO: epoch 007:    176 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.2, ups=0.01, wpb=270.8, bsz=96, num_updates=5610, lr=1.64603e-05, gnorm=0.565, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37120
2023-10-05 05:41:41 - progress_bar.py[line:272] - INFO: epoch 007:    186 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.5, ups=1.5, wpb=269.4, bsz=96, num_updates=5620, lr=1.63959e-05, gnorm=0.489, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=37127
2023-10-05 05:41:48 - progress_bar.py[line:272] - INFO: epoch 007:    196 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=394.3, ups=1.46, wpb=269.7, bsz=96, num_updates=5630, lr=1.63314e-05, gnorm=0.609, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=37134
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 05:41:55 - progress_bar.py[line:272] - INFO: epoch 007:    206 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.5, ups=1.49, wpb=268.6, bsz=96, num_updates=5640, lr=1.62669e-05, gnorm=0.556, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37141
2023-10-05 05:42:01 - progress_bar.py[line:272] - INFO: epoch 007:    216 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=389.4, ups=1.45, wpb=268.1, bsz=96, num_updates=5650, lr=1.62025e-05, gnorm=0.494, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37147
2023-10-05 05:42:08 - progress_bar.py[line:272] - INFO: epoch 007:    226 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=388.4, ups=1.45, wpb=267.8, bsz=96, num_updates=5660, lr=1.6138e-05, gnorm=0.552, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37154
2023-10-05 05:42:15 - progress_bar.py[line:272] - INFO: epoch 007:    236 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.3, ups=1.45, wpb=270.7, bsz=96, num_updates=5670, lr=1.60735e-05, gnorm=0.677, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=37161
2023-10-05 05:42:22 - progress_bar.py[line:272] - INFO: epoch 007:    246 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.1, ups=1.49, wpb=270, bsz=96, num_updates=5680, lr=1.6009e-05, gnorm=0.6, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37168
2023-10-05 05:42:29 - progress_bar.py[line:272] - INFO: epoch 007:    256 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=388.7, ups=1.45, wpb=268.6, bsz=96, num_updates=5690, lr=1.59446e-05, gnorm=0.729, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37175
2023-10-05 05:42:36 - progress_bar.py[line:272] - INFO: epoch 007:    266 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=397.8, ups=1.48, wpb=268.2, bsz=96, num_updates=5700, lr=1.58801e-05, gnorm=0.48, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37182
2023-10-05 05:42:42 - progress_bar.py[line:272] - INFO: epoch 007:    276 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.4, ups=1.49, wpb=269.9, bsz=96, num_updates=5710, lr=1.58156e-05, gnorm=0.466, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=37188
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 05:42:49 - progress_bar.py[line:272] - INFO: epoch 007:    286 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=266.9, nsentences=96, sample_size=266.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=395.5, ups=1.48, wpb=266.9, bsz=96, num_updates=5720, lr=1.57511e-05, gnorm=0.445, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37195
2023-10-05 05:42:56 - progress_bar.py[line:272] - INFO: epoch 007:    296 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=267.5, nsentences=96, sample_size=267.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=396, ups=1.48, wpb=267.5, bsz=96, num_updates=5730, lr=1.56867e-05, gnorm=0.531, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=37202
@@@@ ERROR IN DATA @@@@ watch
2023-10-05 05:43:03 - progress_bar.py[line:272] - INFO: epoch 007:    306 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=267.9, nsentences=96, sample_size=267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=390.2, ups=1.46, wpb=267.9, bsz=96, num_updates=5740, lr=1.56222e-05, gnorm=0.557, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37209
2023-10-05 05:43:10 - progress_bar.py[line:272] - INFO: epoch 007:    316 / 907 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=379.4, ups=1.4, wpb=271.1, bsz=96, num_updates=5750, lr=1.55577e-05, gnorm=0.444, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37216
2023-10-05 05:43:17 - progress_bar.py[line:272] - INFO: epoch 007:    326 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=392.2, ups=1.45, wpb=269.6, bsz=96, num_updates=5760, lr=1.54932e-05, gnorm=0.671, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=37223
2023-10-05 05:43:23 - progress_bar.py[line:272] - INFO: epoch 007:    336 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.9, ups=1.49, wpb=267.8, bsz=96, num_updates=5770, lr=1.54288e-05, gnorm=0.502, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=37230
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 05:43:31 - progress_bar.py[line:272] - INFO: epoch 007:    346 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.08, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.06, wps=379.8, ups=1.41, wpb=269.4, bsz=96, num_updates=5780, lr=1.53643e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37237
2023-10-05 05:43:37 - progress_bar.py[line:272] - INFO: epoch 007:    356 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=395.1, ups=1.46, wpb=271.2, bsz=96, num_updates=5790, lr=1.52998e-05, gnorm=0.54, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=37243
2023-10-05 05:43:44 - progress_bar.py[line:272] - INFO: epoch 007:    366 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=387, ups=1.44, wpb=268.3, bsz=96, num_updates=5800, lr=1.52353e-05, gnorm=0.51, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=37250
2023-10-05 05:43:44 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 05:43:48 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 05:43:48 - train.py[line:550] - INFO: load:3.33 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 05:45:25 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 05:45:25 - train.py[line:550] - INFO: load:3.42 valid_run:97.42 task_valid:92.98 collect_output:3.34
2023-10-05 05:47:01 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 05:47:01 - train.py[line:550] - INFO: load:3.51 valid_run:193.07 task_valid:184.28 collect_output:6.72
2023-10-05 05:48:37 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 05:48:37 - train.py[line:550] - INFO: load:3.60 valid_run:288.52 task_valid:272.85 collect_output:12.66
2023-10-05 05:50:13 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 05:50:13 - train.py[line:550] - INFO: load:3.69 valid_run:384.11 task_valid:362.45 collect_output:17.69
2023-10-05 05:51:49 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 05:51:49 - train.py[line:550] - INFO: load:3.78 valid_run:480.00 task_valid:452.13 collect_output:23.01
2023-10-05 05:53:24 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 05:53:24 - train.py[line:550] - INFO: load:3.87 valid_run:575.65 task_valid:541.28 collect_output:28.53
2023-10-05 05:54:59 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 05:54:59 - train.py[line:550] - INFO: load:3.95 valid_run:670.25 task_valid:631.11 collect_output:32.39
2023-10-05 05:56:35 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 05:56:35 - train.py[line:550] - INFO: load:4.03 valid_run:765.73 task_valid:722.83 collect_output:35.22
2023-10-05 05:58:11 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 05:58:11 - train.py[line:550] - INFO: load:4.11 valid_run:861.60 task_valid:813.36 collect_output:39.62
2023-10-05 05:59:47 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 05:59:47 - train.py[line:550] - INFO: load:4.19 valid_run:957.46 task_valid:904.39 collect_output:43.52
2023-10-05 06:01:22 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 06:01:22 - train.py[line:550] - INFO: load:4.27 valid_run:1052.95 task_valid:995.30 collect_output:47.18

====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6908;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4313;    mR @ 100: 0.4846;    mR @ 500: 0.5369;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7177) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6908;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4313;    mR @ 100: 0.4846;    mR @ 500: 0.5369;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7177) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6908;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4313;    mR @ 100: 0.4846;    mR @ 500: 0.5369;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7177) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6908;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4313;    mR @ 100: 0.4846;    mR @ 500: 0.5369;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7177) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6908;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4313;    mR @ 100: 0.4846;    mR @ 500: 0.5369;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7177) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================

2023-10-05 06:02:38 - train.py[line:487] - INFO: 0.6908083524318819

====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6908;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4313;    mR @ 100: 0.4846;    mR @ 500: 0.5369;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7177) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================

2023-10-05 06:02:38 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 06:02:38 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 0.235 | loss_v1 0 | loss_v2 0 | nll_loss 0.07 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.690808 | ppl 1.05 | vqa_score 0.4966 | wps 397.3 | wpb 191.9 | bsz 64 | num_updates 5800 | best_R@100 0.690808
2023-10-05 06:02:38 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 5800 updates
2023-10-05 06:02:38 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_5800.pt

====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6908;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4313;    mR @ 100: 0.4846;    mR @ 500: 0.5369;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7177) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6908;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4313;    mR @ 100: 0.4846;    mR @ 500: 0.5369;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9167) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7177) (standing on:0.5693) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================

2023-10-05 06:02:45 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_5800.pt
2023-10-05 06:03:55 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_5800.pt (epoch 7 @ 5800 updates, score 0.6908083524318819) (writing took 77.25538422400132 seconds)
2023-10-05 06:04:02 - progress_bar.py[line:272] - INFO: epoch 007:    376 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=267, nsentences=96, sample_size=267, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.2, ups=0.01, wpb=267, bsz=96, num_updates=5810, lr=1.51709e-05, gnorm=0.59, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=38468
2023-10-05 06:04:09 - progress_bar.py[line:272] - INFO: epoch 007:    386 / 907 loss=0.257, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.8, ups=1.5, wpb=269.1, bsz=96, num_updates=5820, lr=1.51064e-05, gnorm=0.582, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=38475
2023-10-05 06:04:16 - progress_bar.py[line:272] - INFO: epoch 007:    396 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=392.4, ups=1.46, wpb=268.3, bsz=96, num_updates=5830, lr=1.50419e-05, gnorm=0.645, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=38482
2023-10-05 06:04:23 - progress_bar.py[line:272] - INFO: epoch 007:    406 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.6, ups=1.45, wpb=269.7, bsz=96, num_updates=5840, lr=1.49774e-05, gnorm=0.713, clip=30, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=38489
2023-10-05 06:04:29 - progress_bar.py[line:272] - INFO: epoch 007:    416 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403, ups=1.5, wpb=269, bsz=96, num_updates=5850, lr=1.4913e-05, gnorm=0.577, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=38495
2023-10-05 06:04:36 - progress_bar.py[line:272] - INFO: epoch 007:    426 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.2, ups=1.5, wpb=268.4, bsz=96, num_updates=5860, lr=1.48485e-05, gnorm=0.737, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=38502
2023-10-05 06:04:43 - progress_bar.py[line:272] - INFO: epoch 007:    436 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.3, ups=1.49, wpb=268.3, bsz=96, num_updates=5870, lr=1.4784e-05, gnorm=0.647, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=38509
2023-10-05 06:04:49 - progress_bar.py[line:272] - INFO: epoch 007:    446 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=405.8, ups=1.5, wpb=271.1, bsz=96, num_updates=5880, lr=1.47195e-05, gnorm=0.416, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=38515
2023-10-05 06:04:56 - progress_bar.py[line:272] - INFO: epoch 007:    456 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=268.8, nsentences=96, sample_size=268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=385.1, ups=1.43, wpb=268.8, bsz=96, num_updates=5890, lr=1.46551e-05, gnorm=0.624, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=38522
2023-10-05 06:05:03 - progress_bar.py[line:272] - INFO: epoch 007:    466 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=388.7, ups=1.44, wpb=269.5, bsz=96, num_updates=5900, lr=1.45906e-05, gnorm=0.588, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=38529
2023-10-05 06:05:10 - progress_bar.py[line:272] - INFO: epoch 007:    476 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.5, ups=1.48, wpb=271.1, bsz=96, num_updates=5910, lr=1.45261e-05, gnorm=0.649, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=38536
2023-10-05 06:05:17 - progress_bar.py[line:272] - INFO: epoch 007:    486 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.2, ups=1.45, wpb=270.5, bsz=96, num_updates=5920, lr=1.44616e-05, gnorm=0.681, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=38543
2023-10-05 06:05:24 - progress_bar.py[line:272] - INFO: epoch 007:    496 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.6, ups=1.44, wpb=270.5, bsz=96, num_updates=5930, lr=1.43972e-05, gnorm=0.658, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=38550
2023-10-05 06:05:31 - progress_bar.py[line:272] - INFO: epoch 007:    506 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.7, ups=1.48, wpb=269.1, bsz=96, num_updates=5940, lr=1.43327e-05, gnorm=0.486, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=38557
2023-10-05 06:05:37 - progress_bar.py[line:272] - INFO: epoch 007:    516 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.2, ups=1.48, wpb=270, bsz=96, num_updates=5950, lr=1.42682e-05, gnorm=0.594, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=38563
2023-10-05 06:05:44 - progress_bar.py[line:272] - INFO: epoch 007:    526 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=267.2, nsentences=96, sample_size=267.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=385.9, ups=1.44, wpb=267.2, bsz=96, num_updates=5960, lr=1.42037e-05, gnorm=0.626, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=38570
2023-10-05 06:05:51 - progress_bar.py[line:272] - INFO: epoch 007:    536 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.4, ups=1.45, wpb=269.4, bsz=96, num_updates=5970, lr=1.41393e-05, gnorm=0.567, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=38577
2023-10-05 06:05:58 - progress_bar.py[line:272] - INFO: epoch 007:    546 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.1, ups=1.49, wpb=268.5, bsz=96, num_updates=5980, lr=1.40748e-05, gnorm=0.385, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=38584
2023-10-05 06:06:05 - progress_bar.py[line:272] - INFO: epoch 007:    556 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=390.8, ups=1.45, wpb=270.1, bsz=96, num_updates=5990, lr=1.40103e-05, gnorm=0.484, clip=0, loss_scale=512, train_wall=7, gb_free=6.1, ema_decay=0.9999, wall=38591
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 06:06:12 - progress_bar.py[line:272] - INFO: epoch 007:    566 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=267.5, nsentences=96, sample_size=267.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=386.3, ups=1.44, wpb=267.5, bsz=96, num_updates=6000, lr=1.39458e-05, gnorm=0.544, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=38598
2023-10-05 06:06:12 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 06:06:15 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 06:06:15 - train.py[line:550] - INFO: load:3.30 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 06:07:53 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 06:07:53 - train.py[line:550] - INFO: load:3.39 valid_run:97.81 task_valid:93.50 collect_output:3.23
2023-10-05 06:09:29 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 06:09:29 - train.py[line:550] - INFO: load:3.48 valid_run:193.93 task_valid:185.22 collect_output:6.68
2023-10-05 06:11:05 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 06:11:05 - train.py[line:550] - INFO: load:3.57 valid_run:289.65 task_valid:273.78 collect_output:12.89
2023-10-05 06:12:41 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 06:12:41 - train.py[line:550] - INFO: load:3.65 valid_run:384.88 task_valid:363.33 collect_output:17.65
2023-10-05 06:14:16 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 06:14:16 - train.py[line:550] - INFO: load:3.74 valid_run:480.53 task_valid:452.87 collect_output:22.86
2023-10-05 06:15:52 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 06:15:52 - train.py[line:550] - INFO: load:3.82 valid_run:576.39 task_valid:542.05 collect_output:28.62
2023-10-05 06:17:27 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 06:17:27 - train.py[line:550] - INFO: load:3.90 valid_run:671.24 task_valid:631.91 collect_output:32.71
2023-10-05 06:19:02 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 06:19:02 - train.py[line:550] - INFO: load:3.97 valid_run:766.23 task_valid:723.51 collect_output:35.23
2023-10-05 06:20:38 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 06:20:38 - train.py[line:550] - INFO: load:4.06 valid_run:862.05 task_valid:813.67 collect_output:39.99
2023-10-05 06:22:14 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 06:22:14 - train.py[line:550] - INFO: load:4.14 valid_run:957.97 task_valid:904.66 collect_output:43.99
2023-10-05 06:23:50 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 06:23:50 - train.py[line:550] - INFO: load:4.23 valid_run:1053.14 task_valid:995.58 collect_output:47.34

====================================================================================================
SGG eval:     R @ 50: 0.6412;     R @ 100: 0.6936;     R @ 500: 0.7225;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4374;    mR @ 100: 0.4868;    mR @ 500: 0.5335;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9583) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6412;     R @ 100: 0.6936;     R @ 500: 0.7225;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4374;    mR @ 100: 0.4868;    mR @ 500: 0.5335;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9583) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6412;     R @ 100: 0.6936;     R @ 500: 0.7225;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4374;    mR @ 100: 0.4868;    mR @ 500: 0.5335;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9583) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6412;     R @ 100: 0.6936;     R @ 500: 0.7225;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4374;    mR @ 100: 0.4868;    mR @ 500: 0.5335;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9583) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6412;     R @ 100: 0.6936;     R @ 500: 0.7225;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4374;    mR @ 100: 0.4868;    mR @ 500: 0.5335;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9583) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6412;     R @ 100: 0.6936;     R @ 500: 0.7225;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4374;    mR @ 100: 0.4868;    mR @ 500: 0.5335;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9583) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6412;     R @ 100: 0.6936;     R @ 500: 0.7225;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4374;    mR @ 100: 0.4868;    mR @ 500: 0.5335;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9583) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================

2023-10-05 06:25:06 - train.py[line:487] - INFO: 0.6936083524318819

====================================================================================================
SGG eval:     R @ 50: 0.6412;     R @ 100: 0.6936;     R @ 500: 0.7225;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4374;    mR @ 100: 0.4868;    mR @ 500: 0.5335;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:0.9583) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6667) 
--------------------------------------------------------
====================================================================================================

2023-10-05 06:25:06 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 06:25:06 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 0.235 | loss_v1 0 | loss_v2 0 | nll_loss 0.066 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.693608 | ppl 1.05 | vqa_score 0.4955 | wps 396.9 | wpb 191.9 | bsz 64 | num_updates 6000 | best_R@100 0.693608
2023-10-05 06:25:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 6000 updates
2023-10-05 06:25:06 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_6000.pt
2023-10-05 06:25:12 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_6000.pt
2023-10-05 06:26:29 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_6000.pt (epoch 7 @ 6000 updates, score 0.6936083524318819) (writing took 82.99010396096855 seconds)
2023-10-05 06:26:36 - progress_bar.py[line:272] - INFO: epoch 007:    576 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.2, ups=0.01, wpb=270.3, bsz=96, num_updates=6010, lr=1.38814e-05, gnorm=0.519, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=39822
2023-10-05 06:26:43 - progress_bar.py[line:272] - INFO: epoch 007:    586 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.9, ups=1.5, wpb=269.1, bsz=96, num_updates=6020, lr=1.38169e-05, gnorm=0.445, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=39829
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 06:26:49 - progress_bar.py[line:272] - INFO: epoch 007:    596 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.6, ups=1.49, wpb=269.2, bsz=96, num_updates=6030, lr=1.37524e-05, gnorm=0.73, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=39835
2023-10-05 06:26:56 - progress_bar.py[line:272] - INFO: epoch 007:    606 / 907 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=404.3, ups=1.5, wpb=270.2, bsz=96, num_updates=6040, lr=1.36879e-05, gnorm=0.459, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=39842
2023-10-05 06:27:03 - progress_bar.py[line:272] - INFO: epoch 007:    616 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.5, ups=1.49, wpb=269, bsz=96, num_updates=6050, lr=1.36235e-05, gnorm=0.698, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=39849
2023-10-05 06:27:10 - progress_bar.py[line:272] - INFO: epoch 007:    626 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=267, nsentences=96, sample_size=267, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=384.7, ups=1.44, wpb=267, bsz=96, num_updates=6060, lr=1.3559e-05, gnorm=0.657, clip=10, loss_scale=1024, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=39856
2023-10-05 06:27:16 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-10-05 06:27:17 - progress_bar.py[line:272] - INFO: epoch 007:    637 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=366.9, ups=1.36, wpb=268.9, bsz=96, num_updates=6070, lr=1.34945e-05, gnorm=0.694, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=39863
2023-10-05 06:27:24 - progress_bar.py[line:272] - INFO: epoch 007:    647 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=393.2, ups=1.45, wpb=270.7, bsz=96, num_updates=6080, lr=1.343e-05, gnorm=0.698, clip=20, loss_scale=512, train_wall=7, gb_free=6, ema_decay=0.9999, wall=39870
2023-10-05 06:27:31 - progress_bar.py[line:272] - INFO: epoch 007:    657 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.4, ups=1.45, wpb=269.3, bsz=96, num_updates=6090, lr=1.33656e-05, gnorm=0.545, clip=0, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=39877
2023-10-05 06:27:38 - progress_bar.py[line:272] - INFO: epoch 007:    667 / 907 loss=0.258, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399, ups=1.49, wpb=268.1, bsz=96, num_updates=6100, lr=1.33011e-05, gnorm=0.62, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=39884
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 06:27:44 - progress_bar.py[line:272] - INFO: epoch 007:    677 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.2, ups=1.49, wpb=269.2, bsz=96, num_updates=6110, lr=1.32366e-05, gnorm=0.659, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=39890
2023-10-05 06:27:51 - progress_bar.py[line:272] - INFO: epoch 007:    687 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=381.9, ups=1.41, wpb=270.5, bsz=96, num_updates=6120, lr=1.31721e-05, gnorm=0.481, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=39897
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 06:27:58 - progress_bar.py[line:272] - INFO: epoch 007:    697 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=393.4, ups=1.45, wpb=271, bsz=96, num_updates=6130, lr=1.31077e-05, gnorm=0.495, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=39904
2023-10-05 06:28:05 - progress_bar.py[line:272] - INFO: epoch 007:    707 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=400.6, ups=1.48, wpb=269.9, bsz=96, num_updates=6140, lr=1.30432e-05, gnorm=0.567, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=39911
2023-10-05 06:28:12 - progress_bar.py[line:272] - INFO: epoch 007:    717 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=271.7, nsentences=96, sample_size=271.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=396, ups=1.46, wpb=271.7, bsz=96, num_updates=6150, lr=1.29787e-05, gnorm=0.566, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=39918
2023-10-05 06:28:19 - progress_bar.py[line:272] - INFO: epoch 007:    727 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.2, ups=1.5, wpb=269, bsz=96, num_updates=6160, lr=1.29142e-05, gnorm=0.466, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=39925
2023-10-05 06:28:25 - progress_bar.py[line:272] - INFO: epoch 007:    737 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.4, ups=1.45, wpb=269.8, bsz=96, num_updates=6170, lr=1.28498e-05, gnorm=0.659, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=39931
@@@@ ERROR IN DATA @@@@ play
2023-10-05 06:28:32 - progress_bar.py[line:272] - INFO: epoch 007:    747 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=393.7, ups=1.45, wpb=271.3, bsz=96, num_updates=6180, lr=1.27853e-05, gnorm=0.596, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=39938
2023-10-05 06:28:39 - progress_bar.py[line:272] - INFO: epoch 007:    757 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=392.7, ups=1.45, wpb=271.3, bsz=96, num_updates=6190, lr=1.27208e-05, gnorm=0.581, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=39945
2023-10-05 06:28:46 - progress_bar.py[line:272] - INFO: epoch 007:    767 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.1, ups=1.48, wpb=268.3, bsz=96, num_updates=6200, lr=1.26564e-05, gnorm=0.539, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=39952
2023-10-05 06:28:46 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 06:28:48 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 06:28:48 - train.py[line:550] - INFO: load:1.90 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 06:28:48 - trainer.py[line:1414] - WARNING: OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 2.98 GiB (GPU 1; 23.70 GiB total capacity; 6.61 GiB already allocated; 2.17 GiB free; 20.14 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-10-05 06:28:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 06:28:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 1                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 4            |        cudaMalloc retries: 29        |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   6771 MiB |   7387 MiB |   4518 TiB |   4518 TiB |
|       from large pool |   6627 MiB |   7242 MiB |   4492 TiB |   4492 TiB |
|       from small pool |    144 MiB |    157 MiB |     26 TiB |     26 TiB |
|---------------------------------------------------------------------------|
| Active memory         |   6771 MiB |   7387 MiB |   4518 TiB |   4518 TiB |
|       from large pool |   6627 MiB |   7242 MiB |   4492 TiB |   4492 TiB |
|       from small pool |    144 MiB |    157 MiB |     26 TiB |     26 TiB |
|---------------------------------------------------------------------------|
| Requested memory      |   6723 MiB |   7340 MiB |   4512 TiB |   4512 TiB |
|       from large pool |   6579 MiB |   7195 MiB |   4486 TiB |   4486 TiB |
|       from small pool |    144 MiB |    157 MiB |     26 TiB |     26 TiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  20626 MiB |  21180 MiB | 152748 MiB | 132122 MiB |
|       from large pool |  20480 MiB |  21018 MiB | 152106 MiB | 131626 MiB |
|       from small pool |    146 MiB |    162 MiB |    642 MiB |    496 MiB |
|---------------------------------------------------------------------------|
| Non-releasable memory |  13854 MiB |  13854 MiB |   4391 TiB |   4391 TiB |
|       from large pool |  13852 MiB |  13852 MiB |   4364 TiB |   4364 TiB |
|       from small pool |      1 MiB |      5 MiB |     26 TiB |     26 TiB |
|---------------------------------------------------------------------------|
| Allocations           |    3567    |    3582    |  291111 K  |  291108 K  |
|       from large pool |     565    |     577    |  115525 K  |  115524 K  |
|       from small pool |    3002    |    3021    |  175586 K  |  175583 K  |
|---------------------------------------------------------------------------|
| Active allocs         |    3567    |    3582    |  291111 K  |  291108 K  |
|       from large pool |     565    |     577    |  115525 K  |  115524 K  |
|       from small pool |    3002    |    3021    |  175586 K  |  175583 K  |
|---------------------------------------------------------------------------|
| GPU reserved segments |     139    |     148    |     579    |     440    |
|       from large pool |      66    |      67    |     258    |     192    |
|       from small pool |      73    |      81    |     321    |     248    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      93    |      99    |  157513 K  |  157513 K  |
|       from large pool |      57    |      57    |   32227 K  |   32227 K  |
|       from small pool |      36    |      47    |  125286 K  |  125286 K  |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 06:28:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 2                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 06:28:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 3                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 06:28:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 4                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 06:28:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 5                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 06:28:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 6                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 06:28:48 - trainer.py[line:1417] - WARNING: |===========================================================================|
|                  PyTorch CUDA memory summary, device ID 7                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |
|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |
|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |
|---------------------------------------------------------------------------|
| Allocations           |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Active allocs         |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| GPU reserved segments |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       0    |       0    |       0    |       0    |
|       from large pool |       0    |       0    |       0    |       0    |
|       from small pool |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

2023-10-05 06:28:48 - trainer.py[line:1162] - WARNING: ran out of memory in validation step, retrying batch
2023-10-05 06:30:25 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 06:30:25 - train.py[line:550] - INFO: load:1.99 valid_run:97.23 task_valid:92.96 collect_output:3.27
2023-10-05 06:32:02 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 06:32:02 - train.py[line:550] - INFO: load:2.07 valid_run:193.77 task_valid:184.90 collect_output:6.93
2023-10-05 06:33:38 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 06:33:38 - train.py[line:550] - INFO: load:2.16 valid_run:289.43 task_valid:273.88 collect_output:12.67
2023-10-05 06:35:13 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 06:35:13 - train.py[line:550] - INFO: load:2.24 valid_run:384.43 task_valid:363.80 collect_output:16.78
2023-10-05 06:36:49 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 06:36:49 - train.py[line:550] - INFO: load:2.32 valid_run:480.28 task_valid:453.75 collect_output:21.70
2023-10-05 06:38:25 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 06:38:25 - train.py[line:550] - INFO: load:2.40 valid_run:575.92 task_valid:543.26 collect_output:26.87
2023-10-05 06:39:59 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 06:39:59 - train.py[line:550] - INFO: load:2.49 valid_run:670.47 task_valid:633.56 collect_output:30.14
2023-10-05 06:41:35 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 06:41:35 - train.py[line:550] - INFO: load:2.58 valid_run:766.13 task_valid:725.74 collect_output:32.65
2023-10-05 06:43:11 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 06:43:11 - train.py[line:550] - INFO: load:2.66 valid_run:862.14 task_valid:816.35 collect_output:37.11
2023-10-05 06:44:47 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 06:44:47 - train.py[line:550] - INFO: load:2.75 valid_run:957.79 task_valid:907.88 collect_output:40.28
2023-10-05 06:46:23 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 06:46:23 - train.py[line:550] - INFO: load:2.83 valid_run:1053.09 task_valid:999.24 collect_output:43.19

====================================================================================================
SGG eval:     R @ 50: 0.6418;     R @ 100: 0.6936;     R @ 500: 0.7230;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4400;    mR @ 100: 0.4883;    mR @ 500: 0.5355;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6418;     R @ 100: 0.6936;     R @ 500: 0.7230;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4400;    mR @ 100: 0.4883;    mR @ 500: 0.5355;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6418;     R @ 100: 0.6936;     R @ 500: 0.7230;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4400;    mR @ 100: 0.4883;    mR @ 500: 0.5355;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6418;     R @ 100: 0.6936;     R @ 500: 0.7230;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4400;    mR @ 100: 0.4883;    mR @ 500: 0.5355;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6418;     R @ 100: 0.6936;     R @ 500: 0.7230;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4400;    mR @ 100: 0.4883;    mR @ 500: 0.5355;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6418;     R @ 100: 0.6936;     R @ 500: 0.7230;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4400;    mR @ 100: 0.4883;    mR @ 500: 0.5355;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================

2023-10-05 06:47:38 - train.py[line:487] - INFO: 0.6936416857652152

====================================================================================================
SGG eval:     R @ 50: 0.6418;     R @ 100: 0.6936;     R @ 500: 0.7230;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4400;    mR @ 100: 0.4883;    mR @ 500: 0.5355;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================

2023-10-05 06:47:39 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 06:47:39 - progress_bar.py[line:282] - INFO: epoch 007 | valid on 'valid' subset | loss 0.237 | loss_v1 0 | loss_v2 0 | nll_loss 0.067 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.693642 | ppl 1.05 | vqa_score 0.4932 | wps 396.9 | wpb 191.9 | bsz 64 | num_updates 6200 | best_R@100 0.693642
2023-10-05 06:47:39 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 7 @ 6200 updates
2023-10-05 06:47:39 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_6200.pt

====================================================================================================
SGG eval:     R @ 50: 0.6418;     R @ 100: 0.6936;     R @ 500: 0.7230;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4400;    mR @ 100: 0.4883;    mR @ 500: 0.5355;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1429) (eating:0.7647) (flying in:0.9091) (growing on:0.3750) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================

2023-10-05 06:47:44 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_6200.pt
2023-10-05 06:48:48 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_7_6200.pt (epoch 7 @ 6200 updates, score 0.6936416857652152) (writing took 69.70973087893799 seconds)
2023-10-05 06:48:55 - progress_bar.py[line:272] - INFO: epoch 007:    777 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.2, ups=0.01, wpb=269.6, bsz=96, num_updates=6210, lr=1.25919e-05, gnorm=0.615, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=41161
2023-10-05 06:49:02 - progress_bar.py[line:272] - INFO: epoch 007:    787 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.4, ups=1.5, wpb=268.3, bsz=96, num_updates=6220, lr=1.25274e-05, gnorm=0.579, clip=0, loss_scale=512, train_wall=7, gb_free=6.1, ema_decay=0.9999, wall=41168
2023-10-05 06:49:08 - progress_bar.py[line:272] - INFO: epoch 007:    797 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.3, ups=1.5, wpb=268.9, bsz=96, num_updates=6230, lr=1.24629e-05, gnorm=0.63, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=41174
@@@@ ERROR IN DATA @@@@ play
2023-10-05 06:49:15 - progress_bar.py[line:272] - INFO: epoch 007:    807 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=271.6, nsentences=96, sample_size=271.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=406.3, ups=1.5, wpb=271.6, bsz=96, num_updates=6240, lr=1.23985e-05, gnorm=0.457, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=41181
2023-10-05 06:49:22 - progress_bar.py[line:272] - INFO: epoch 007:    817 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=402.8, ups=1.49, wpb=270.3, bsz=96, num_updates=6250, lr=1.2334e-05, gnorm=0.467, clip=0, loss_scale=512, train_wall=7, gb_free=6.6, ema_decay=0.9999, wall=41188
2023-10-05 06:49:29 - progress_bar.py[line:272] - INFO: epoch 007:    827 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=381.4, ups=1.42, wpb=268, bsz=96, num_updates=6260, lr=1.22695e-05, gnorm=0.661, clip=10, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=41195
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 06:49:35 - progress_bar.py[line:272] - INFO: epoch 007:    837 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.2, ups=1.49, wpb=269.4, bsz=96, num_updates=6270, lr=1.2205e-05, gnorm=0.58, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=41202
2023-10-05 06:49:42 - progress_bar.py[line:272] - INFO: epoch 007:    847 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.5, ups=1.5, wpb=269.8, bsz=96, num_updates=6280, lr=1.21406e-05, gnorm=0.519, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=41208
2023-10-05 06:49:49 - progress_bar.py[line:272] - INFO: epoch 007:    857 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.8, ups=1.49, wpb=268.4, bsz=96, num_updates=6290, lr=1.20761e-05, gnorm=0.549, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=41215
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 06:49:56 - progress_bar.py[line:272] - INFO: epoch 007:    867 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.2, ups=1.49, wpb=270.5, bsz=96, num_updates=6300, lr=1.20116e-05, gnorm=0.527, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=41222
2023-10-05 06:50:02 - progress_bar.py[line:272] - INFO: epoch 007:    877 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.3, ups=1.5, wpb=269.6, bsz=96, num_updates=6310, lr=1.19471e-05, gnorm=0.491, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=41228
2023-10-05 06:50:09 - progress_bar.py[line:272] - INFO: epoch 007:    887 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=273.7, nsentences=96, sample_size=273.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.3, ups=1.46, wpb=273.7, bsz=96, num_updates=6320, lr=1.18827e-05, gnorm=0.636, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=41235
2023-10-05 06:50:16 - progress_bar.py[line:272] - INFO: epoch 007:    897 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.5, ups=1.45, wpb=269.5, bsz=96, num_updates=6330, lr=1.18182e-05, gnorm=0.58, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=41242
2023-10-05 06:50:22 - progress_bar.py[line:272] - INFO: epoch 007:    907 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=247.8, nsentences=88.2, sample_size=247.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=393.3, ups=1.59, wpb=247.8, bsz=88.2, num_updates=6340, lr=1.17537e-05, gnorm=0.616, clip=0, loss_scale=512, train_wall=6, gb_free=16.2, ema_decay=0.9999, wall=41248
2023-10-05 06:50:22 - train.py[line:339] - INFO: end of epoch 7 (average epoch stats below)
2023-10-05 06:50:22 - progress_bar.py[line:282] - INFO: epoch 007 | loss 0.249 | loss_v1 0 | loss_v2 0 | nll_loss 0.068 | ntokens 269.259 | nsentences 95.914 | sample_size 269.259 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.05 | wps 44.6 | ups 0.17 | wpb 269.3 | bsz 95.9 | num_updates 6340 | lr 1.17537e-05 | gnorm 0.568 | clip 6.1 | loss_scale 512 | train_wall 615 | gb_free 16.2 | ema_decay 0.9999 | wall 41248
2023-10-05 06:50:22 - trainer.py[line:694] - INFO: loading train data for epoch 8
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv slice_id 6 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv slice_id 4 row count 10874 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv slice_id 1 row count 10875 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv slice_id 3 row count 10874 total row count 86994


file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv slice_id 7 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv slice_id 5 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv slice_id 2 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E7.tsv slice_id 0 row count 10875 total row count 86994
2023-10-05 06:50:22 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 06:50:23 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
2023-10-05 06:50:23 - trainer.py[line:758] - INFO: begin training epoch 8
2023-10-05 06:50:23 - train.py[line:312] - INFO: Start iterating over samples
2023-10-05 06:50:34 - progress_bar.py[line:272] - INFO: epoch 008:     10 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=237.2, ups=0.89, wpb=268, bsz=96, num_updates=6350, lr=1.16892e-05, gnorm=0.411, clip=10, loss_scale=512, train_wall=8, gb_free=6.4, ema_decay=0.9999, wall=41260
2023-10-05 06:50:41 - progress_bar.py[line:272] - INFO: epoch 008:     20 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=388, ups=1.44, wpb=269.5, bsz=96, num_updates=6360, lr=1.16248e-05, gnorm=0.45, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=41267
2023-10-05 06:50:48 - progress_bar.py[line:272] - INFO: epoch 008:     30 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=374.5, ups=1.39, wpb=269.7, bsz=96, num_updates=6370, lr=1.15603e-05, gnorm=0.522, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=41274
2023-10-05 06:50:55 - progress_bar.py[line:272] - INFO: epoch 008:     40 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.6, ups=1.49, wpb=270.8, bsz=96, num_updates=6380, lr=1.14958e-05, gnorm=0.689, clip=20, loss_scale=512, train_wall=7, gb_free=6, ema_decay=0.9999, wall=41281
2023-10-05 06:51:01 - progress_bar.py[line:272] - INFO: epoch 008:     50 / 907 loss=0.256, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.7, ups=1.49, wpb=270.3, bsz=96, num_updates=6390, lr=1.14313e-05, gnorm=0.591, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=41287
2023-10-05 06:51:08 - progress_bar.py[line:272] - INFO: epoch 008:     60 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=390, ups=1.45, wpb=269.4, bsz=96, num_updates=6400, lr=1.13669e-05, gnorm=0.524, clip=0, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=41294
2023-10-05 06:51:08 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 06:51:10 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 06:51:10 - train.py[line:550] - INFO: load:2.03 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 06:52:48 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 06:52:48 - train.py[line:550] - INFO: load:2.12 valid_run:97.71 task_valid:93.10 collect_output:3.61
2023-10-05 06:54:24 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 06:54:24 - train.py[line:550] - INFO: load:2.20 valid_run:193.75 task_valid:184.94 collect_output:6.86
2023-10-05 06:56:01 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 06:56:01 - train.py[line:550] - INFO: load:2.30 valid_run:290.05 task_valid:274.13 collect_output:12.97
2023-10-05 06:57:36 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 06:57:36 - train.py[line:550] - INFO: load:2.38 valid_run:385.17 task_valid:364.22 collect_output:17.07
2023-10-05 06:59:12 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 06:59:12 - train.py[line:550] - INFO: load:2.46 valid_run:481.11 task_valid:454.36 collect_output:21.88
2023-10-05 07:00:48 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 07:00:48 - train.py[line:550] - INFO: load:2.55 valid_run:577.21 task_valid:544.04 collect_output:27.29
2023-10-05 07:02:23 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 07:02:23 - train.py[line:550] - INFO: load:2.64 valid_run:672.18 task_valid:634.35 collect_output:30.96
2023-10-05 07:04:00 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 07:04:00 - train.py[line:550] - INFO: load:2.72 valid_run:768.09 task_valid:726.59 collect_output:33.68
2023-10-05 07:05:35 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 07:05:35 - train.py[line:550] - INFO: load:2.80 valid_run:863.93 task_valid:817.49 collect_output:37.67
2023-10-05 07:07:12 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 07:07:12 - train.py[line:550] - INFO: load:2.88 valid_run:959.92 task_valid:909.22 collect_output:40.98
2023-10-05 07:08:47 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 07:08:47 - train.py[line:550] - INFO: load:2.97 valid_run:1055.60 task_valid:1000.65 collect_output:44.25

====================================================================================================
SGG eval:     R @ 50: 0.6417;     R @ 100: 0.6912;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4408;    mR @ 100: 0.4834;    mR @ 500: 0.5366;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1714) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6417;     R @ 100: 0.6912;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4408;    mR @ 100: 0.4834;    mR @ 500: 0.5366;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1714) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6417;     R @ 100: 0.6912;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4408;    mR @ 100: 0.4834;    mR @ 500: 0.5366;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1714) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6417;     R @ 100: 0.6912;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4408;    mR @ 100: 0.4834;    mR @ 500: 0.5366;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1714) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6417;     R @ 100: 0.6912;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4408;    mR @ 100: 0.4834;    mR @ 500: 0.5366;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1714) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6417;     R @ 100: 0.6912;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4408;    mR @ 100: 0.4834;    mR @ 500: 0.5366;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1714) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================

2023-10-05 07:10:03 - train.py[line:487] - INFO: 0.6911783804430863

====================================================================================================
SGG eval:     R @ 50: 0.6417;     R @ 100: 0.6912;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4408;    mR @ 100: 0.4834;    mR @ 500: 0.5366;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1714) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6417;     R @ 100: 0.6912;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4408;    mR @ 100: 0.4834;    mR @ 500: 0.5366;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.1714) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4516) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7109) (standing on:0.5793) (using:0.5000) (walking in:0.0000) (walking on:0.4865) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================

2023-10-05 07:10:04 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 07:10:04 - progress_bar.py[line:282] - INFO: epoch 008 | valid on 'valid' subset | loss 0.233 | loss_v1 0 | loss_v2 0 | nll_loss 0.064 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.691178 | ppl 1.05 | vqa_score 0.4955 | wps 396 | wpb 191.9 | bsz 64 | num_updates 6400 | best_R@100 0.693642
2023-10-05 07:10:04 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 6400 updates
2023-10-05 07:10:04 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_6400.pt
2023-10-05 07:10:10 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_6400.pt
2023-10-05 07:10:53 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_6400.pt (epoch 8 @ 6400 updates, score 0.6911783804430863) (writing took 49.3879535747692 seconds)
@@@@ ERROR IN DATA @@@@ play
2023-10-05 07:11:00 - progress_bar.py[line:272] - INFO: epoch 008:     70 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.3, ups=0.01, wpb=268.6, bsz=96, num_updates=6410, lr=1.13024e-05, gnorm=0.554, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=42486
2023-10-05 07:11:07 - progress_bar.py[line:272] - INFO: epoch 008:     80 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=389.5, ups=1.45, wpb=268.6, bsz=96, num_updates=6420, lr=1.12379e-05, gnorm=0.391, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=42493
2023-10-05 07:11:13 - progress_bar.py[line:272] - INFO: epoch 008:     90 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.4, ups=1.5, wpb=269, bsz=96, num_updates=6430, lr=1.11734e-05, gnorm=0.564, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=42499
2023-10-05 07:11:20 - progress_bar.py[line:272] - INFO: epoch 008:    100 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=404.1, ups=1.49, wpb=270.7, bsz=96, num_updates=6440, lr=1.1109e-05, gnorm=0.632, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=42506
2023-10-05 07:11:27 - progress_bar.py[line:272] - INFO: epoch 008:    110 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=402.4, ups=1.5, wpb=268.9, bsz=96, num_updates=6450, lr=1.10445e-05, gnorm=0.534, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=42513
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 07:11:33 - progress_bar.py[line:272] - INFO: epoch 008:    120 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.4, ups=1.49, wpb=269.2, bsz=96, num_updates=6460, lr=1.098e-05, gnorm=0.574, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=42519
2023-10-05 07:11:40 - progress_bar.py[line:272] - INFO: epoch 008:    130 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.073, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.1, ups=1.49, wpb=268.9, bsz=96, num_updates=6470, lr=1.09155e-05, gnorm=0.536, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=42526
2023-10-05 07:11:47 - progress_bar.py[line:272] - INFO: epoch 008:    140 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.3, ups=1.49, wpb=269.2, bsz=96, num_updates=6480, lr=1.08511e-05, gnorm=0.586, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=42533
2023-10-05 07:11:54 - progress_bar.py[line:272] - INFO: epoch 008:    150 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=271.8, nsentences=96, sample_size=271.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=395.3, ups=1.45, wpb=271.8, bsz=96, num_updates=6490, lr=1.07866e-05, gnorm=0.563, clip=0, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=42540
2023-10-05 07:12:00 - progress_bar.py[line:272] - INFO: epoch 008:    160 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.9, ups=1.49, wpb=268.7, bsz=96, num_updates=6500, lr=1.07221e-05, gnorm=0.632, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=42546
2023-10-05 07:12:07 - progress_bar.py[line:272] - INFO: epoch 008:    170 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.1, ups=1.49, wpb=270, bsz=96, num_updates=6510, lr=1.06576e-05, gnorm=0.485, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=42553
2023-10-05 07:12:14 - progress_bar.py[line:272] - INFO: epoch 008:    180 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=389.6, ups=1.44, wpb=270.2, bsz=96, num_updates=6520, lr=1.05932e-05, gnorm=0.624, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=42560
2023-10-05 07:12:21 - progress_bar.py[line:272] - INFO: epoch 008:    190 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=267.5, nsentences=96, sample_size=267.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.4, ups=1.46, wpb=267.5, bsz=96, num_updates=6530, lr=1.05287e-05, gnorm=0.56, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=42567
2023-10-05 07:12:28 - progress_bar.py[line:272] - INFO: epoch 008:    200 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.7, ups=1.49, wpb=269.6, bsz=96, num_updates=6540, lr=1.04642e-05, gnorm=0.392, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=42574
@@@@ ERROR IN DATA @@@@ stand on
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 07:12:34 - progress_bar.py[line:272] - INFO: epoch 008:    210 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.2, ups=1.49, wpb=269.6, bsz=96, num_updates=6550, lr=1.03997e-05, gnorm=0.484, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=42580
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 07:12:41 - progress_bar.py[line:272] - INFO: epoch 008:    220 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=382.5, ups=1.41, wpb=270.6, bsz=96, num_updates=6560, lr=1.03353e-05, gnorm=0.496, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=42587
2023-10-05 07:12:48 - progress_bar.py[line:272] - INFO: epoch 008:    230 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.8, ups=1.49, wpb=268.4, bsz=96, num_updates=6570, lr=1.02708e-05, gnorm=0.643, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=42594
2023-10-05 07:12:55 - progress_bar.py[line:272] - INFO: epoch 008:    240 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.2, ups=1.45, wpb=270.7, bsz=96, num_updates=6580, lr=1.02063e-05, gnorm=0.634, clip=20, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=42601
2023-10-05 07:12:58 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 07:13:02 - progress_bar.py[line:272] - INFO: epoch 008:    251 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=369.3, ups=1.37, wpb=269.4, bsz=96, num_updates=6590, lr=1.01418e-05, gnorm=0.816, clip=30, loss_scale=512, train_wall=7, gb_free=6, ema_decay=0.9999, wall=42608
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 07:13:09 - progress_bar.py[line:272] - INFO: epoch 008:    261 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=268.1, nsentences=96, sample_size=268.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.2, ups=1.45, wpb=268.1, bsz=96, num_updates=6600, lr=1.00774e-05, gnorm=0.487, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=42615
2023-10-05 07:13:09 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 07:13:12 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 07:13:12 - train.py[line:550] - INFO: load:2.33 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 07:14:50 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 07:14:50 - train.py[line:550] - INFO: load:2.42 valid_run:97.84 task_valid:93.21 collect_output:3.55
2023-10-05 07:16:26 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 07:16:26 - train.py[line:550] - INFO: load:2.50 valid_run:194.09 task_valid:185.00 collect_output:7.03
2023-10-05 07:18:02 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 07:18:02 - train.py[line:550] - INFO: load:2.59 valid_run:290.30 task_valid:274.07 collect_output:13.16
2023-10-05 07:19:38 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 07:19:38 - train.py[line:550] - INFO: load:2.66 valid_run:385.91 task_valid:364.02 collect_output:17.90
2023-10-05 07:21:15 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 07:21:15 - train.py[line:550] - INFO: load:2.75 valid_run:482.42 task_valid:454.23 collect_output:23.17
2023-10-05 07:22:51 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 07:22:51 - train.py[line:550] - INFO: load:2.84 valid_run:578.35 task_valid:543.78 collect_output:28.57
2023-10-05 07:24:26 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 07:24:26 - train.py[line:550] - INFO: load:2.93 valid_run:673.02 task_valid:633.96 collect_output:32.07
2023-10-05 07:26:01 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 07:26:01 - train.py[line:550] - INFO: load:3.01 valid_run:768.75 task_valid:726.13 collect_output:34.67
2023-10-05 07:27:37 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 07:27:37 - train.py[line:550] - INFO: load:3.10 valid_run:864.53 task_valid:816.74 collect_output:38.90
2023-10-05 07:29:14 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 07:29:14 - train.py[line:550] - INFO: load:3.18 valid_run:960.72 task_valid:908.14 collect_output:42.70
2023-10-05 07:30:49 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 07:30:49 - train.py[line:550] - INFO: load:3.26 valid_run:1056.10 task_valid:999.40 collect_output:45.88

====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6952;     R @ 500: 0.7205;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4392;    mR @ 100: 0.4879;    mR @ 500: 0.5364;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4194) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7117) (standing on:0.5860) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6952;     R @ 500: 0.7205;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4392;    mR @ 100: 0.4879;    mR @ 500: 0.5364;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4194) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7117) (standing on:0.5860) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6952;     R @ 500: 0.7205;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4392;    mR @ 100: 0.4879;    mR @ 500: 0.5364;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4194) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7117) (standing on:0.5860) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6952;     R @ 500: 0.7205;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4392;    mR @ 100: 0.4879;    mR @ 500: 0.5364;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4194) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7117) (standing on:0.5860) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6952;     R @ 500: 0.7205;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4392;    mR @ 100: 0.4879;    mR @ 500: 0.5364;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4194) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7117) (standing on:0.5860) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================

2023-10-05 07:32:05 - train.py[line:487] - INFO: 0.6951974280621339

====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6952;     R @ 500: 0.7205;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4392;    mR @ 100: 0.4879;    mR @ 500: 0.5364;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4194) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7117) (standing on:0.5860) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6952;     R @ 500: 0.7205;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4392;    mR @ 100: 0.4879;    mR @ 500: 0.5364;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4194) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7117) (standing on:0.5860) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6406;     R @ 100: 0.6952;     R @ 500: 0.7205;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4392;    mR @ 100: 0.4879;    mR @ 500: 0.5364;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.4194) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9265) (says:0.0000) (sitting on:0.7117) (standing on:0.5860) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6528) 
--------------------------------------------------------
====================================================================================================

2023-10-05 07:32:05 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 07:32:05 - progress_bar.py[line:282] - INFO: epoch 008 | valid on 'valid' subset | loss 0.234 | loss_v1 0 | loss_v2 0 | nll_loss 0.064 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.695197 | ppl 1.05 | vqa_score 0.4977 | wps 395.9 | wpb 191.9 | bsz 64 | num_updates 6600 | best_R@100 0.695197
2023-10-05 07:32:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 6600 updates
2023-10-05 07:32:05 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_6600.pt
2023-10-05 07:32:12 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_6600.pt
2023-10-05 07:32:56 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_6600.pt (epoch 8 @ 6600 updates, score 0.6951974280621339) (writing took 50.897195945028216 seconds)
2023-10-05 07:33:03 - progress_bar.py[line:272] - INFO: epoch 008:    271 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.2, ups=0.01, wpb=268.6, bsz=96, num_updates=6610, lr=1.00129e-05, gnorm=0.479, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43809
2023-10-05 07:33:10 - progress_bar.py[line:272] - INFO: epoch 008:    281 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.3, ups=1.49, wpb=270.1, bsz=96, num_updates=6620, lr=9.94842e-06, gnorm=0.465, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43816
2023-10-05 07:33:17 - progress_bar.py[line:272] - INFO: epoch 008:    291 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=397.3, ups=1.47, wpb=270.3, bsz=96, num_updates=6630, lr=9.88395e-06, gnorm=0.412, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43823
2023-10-05 07:33:23 - progress_bar.py[line:272] - INFO: epoch 008:    301 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=404.3, ups=1.49, wpb=270.6, bsz=96, num_updates=6640, lr=9.81947e-06, gnorm=0.573, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43829
2023-10-05 07:33:30 - progress_bar.py[line:272] - INFO: epoch 008:    311 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.9, ups=1.49, wpb=270.8, bsz=96, num_updates=6650, lr=9.755e-06, gnorm=0.464, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43836
2023-10-05 07:33:37 - progress_bar.py[line:272] - INFO: epoch 008:    321 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.1, ups=1.49, wpb=268.9, bsz=96, num_updates=6660, lr=9.69052e-06, gnorm=0.75, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=43843
2023-10-05 07:33:43 - progress_bar.py[line:272] - INFO: epoch 008:    331 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=397.7, ups=1.48, wpb=268, bsz=96, num_updates=6670, lr=9.62605e-06, gnorm=0.656, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43850
2023-10-05 07:33:50 - progress_bar.py[line:272] - INFO: epoch 008:    341 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=267.6, nsentences=96, sample_size=267.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=388.8, ups=1.45, wpb=267.6, bsz=96, num_updates=6680, lr=9.56157e-06, gnorm=0.547, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=43856
2023-10-05 07:33:57 - progress_bar.py[line:272] - INFO: epoch 008:    351 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.5, ups=1.48, wpb=271, bsz=96, num_updates=6690, lr=9.4971e-06, gnorm=0.496, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43863
2023-10-05 07:34:04 - progress_bar.py[line:272] - INFO: epoch 008:    361 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.3, ups=1.49, wpb=270.4, bsz=96, num_updates=6700, lr=9.43262e-06, gnorm=0.659, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=43870
2023-10-05 07:34:11 - progress_bar.py[line:272] - INFO: epoch 008:    371 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.3, ups=1.49, wpb=270.9, bsz=96, num_updates=6710, lr=9.36815e-06, gnorm=0.499, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43877
@@@@ ERROR IN DATA @@@@ ride
@@@@ ERROR IN DATA @@@@ watch
2023-10-05 07:34:17 - progress_bar.py[line:272] - INFO: epoch 008:    381 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.7, ups=1.45, wpb=269.4, bsz=96, num_updates=6720, lr=9.30368e-06, gnorm=0.481, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43883
2023-10-05 07:34:24 - progress_bar.py[line:272] - INFO: epoch 008:    391 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.2, ups=1.49, wpb=268.4, bsz=96, num_updates=6730, lr=9.2392e-06, gnorm=0.575, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43890
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 07:34:31 - progress_bar.py[line:272] - INFO: epoch 008:    401 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=379.5, ups=1.4, wpb=270.5, bsz=96, num_updates=6740, lr=9.17473e-06, gnorm=0.448, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43897
@@@@ ERROR IN DATA @@@@ play
2023-10-05 07:34:38 - progress_bar.py[line:272] - INFO: epoch 008:    411 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=402.1, ups=1.49, wpb=270.2, bsz=96, num_updates=6750, lr=9.11025e-06, gnorm=0.42, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43904
2023-10-05 07:34:45 - progress_bar.py[line:272] - INFO: epoch 008:    421 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=400.6, ups=1.49, wpb=269.2, bsz=96, num_updates=6760, lr=9.04578e-06, gnorm=0.457, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43911
2023-10-05 07:34:52 - progress_bar.py[line:272] - INFO: epoch 008:    431 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=364.3, ups=1.35, wpb=270.6, bsz=96, num_updates=6770, lr=8.9813e-06, gnorm=0.527, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43918
2023-10-05 07:34:59 - progress_bar.py[line:272] - INFO: epoch 008:    441 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.2, ups=1.49, wpb=269.1, bsz=96, num_updates=6780, lr=8.91683e-06, gnorm=0.566, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43925
2023-10-05 07:35:06 - progress_bar.py[line:272] - INFO: epoch 008:    451 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=400.3, ups=1.49, wpb=268.4, bsz=96, num_updates=6790, lr=8.85235e-06, gnorm=0.534, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=43932
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 07:35:12 - progress_bar.py[line:272] - INFO: epoch 008:    461 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=394.3, ups=1.46, wpb=270.8, bsz=96, num_updates=6800, lr=8.78788e-06, gnorm=0.573, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=43938
2023-10-05 07:35:12 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 07:35:15 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 07:35:15 - train.py[line:550] - INFO: load:2.24 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 07:36:53 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 07:36:53 - train.py[line:550] - INFO: load:2.33 valid_run:98.07 task_valid:93.23 collect_output:3.76
2023-10-05 07:38:30 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 07:38:30 - train.py[line:550] - INFO: load:2.42 valid_run:194.42 task_valid:184.86 collect_output:7.54
2023-10-05 07:40:05 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 07:40:05 - train.py[line:550] - INFO: load:2.50 valid_run:290.10 task_valid:273.64 collect_output:13.50
2023-10-05 07:41:41 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 07:41:41 - train.py[line:550] - INFO: load:2.58 valid_run:385.33 task_valid:363.52 collect_output:17.87
2023-10-05 07:43:17 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 07:43:17 - train.py[line:550] - INFO: load:2.66 valid_run:481.48 task_valid:453.33 collect_output:23.28
2023-10-05 07:44:53 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 07:44:53 - train.py[line:550] - INFO: load:2.75 valid_run:577.28 task_valid:542.75 collect_output:28.72
2023-10-05 07:46:28 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 07:46:28 - train.py[line:550] - INFO: load:2.83 valid_run:672.64 task_valid:633.08 collect_output:32.78
2023-10-05 07:48:04 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 07:48:04 - train.py[line:550] - INFO: load:2.94 valid_run:768.44 task_valid:725.48 collect_output:35.20
2023-10-05 07:49:40 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 07:49:40 - train.py[line:550] - INFO: load:3.02 valid_run:864.20 task_valid:816.09 collect_output:39.42
2023-10-05 07:51:16 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 07:51:16 - train.py[line:550] - INFO: load:3.11 valid_run:960.36 task_valid:907.67 collect_output:43.07
2023-10-05 07:52:52 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 07:52:52 - train.py[line:550] - INFO: load:3.18 valid_run:1055.72 task_valid:998.96 collect_output:46.22

====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6956;     R @ 500: 0.7215;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4422;    mR @ 100: 0.4887;    mR @ 500: 0.5413;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7168) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6956;     R @ 500: 0.7215;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4422;    mR @ 100: 0.4887;    mR @ 500: 0.5413;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7168) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6956;     R @ 500: 0.7215;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4422;    mR @ 100: 0.4887;    mR @ 500: 0.5413;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7168) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6956;     R @ 500: 0.7215;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4422;    mR @ 100: 0.4887;    mR @ 500: 0.5413;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7168) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6956;     R @ 500: 0.7215;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4422;    mR @ 100: 0.4887;    mR @ 500: 0.5413;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7168) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================

2023-10-05 07:54:08 - train.py[line:487] - INFO: 0.6956150751209575

====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6956;     R @ 500: 0.7215;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4422;    mR @ 100: 0.4887;    mR @ 500: 0.5413;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7168) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6956;     R @ 500: 0.7215;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4422;    mR @ 100: 0.4887;    mR @ 500: 0.5413;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7168) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================

2023-10-05 07:54:08 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6956;     R @ 500: 0.7215;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4422;    mR @ 100: 0.4887;    mR @ 500: 0.5413;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7168) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================

2023-10-05 07:54:08 - progress_bar.py[line:282] - INFO: epoch 008 | valid on 'valid' subset | loss 0.235 | loss_v1 0 | loss_v2 0 | nll_loss 0.066 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.695615 | ppl 1.05 | vqa_score 0.5011 | wps 396.2 | wpb 191.9 | bsz 64 | num_updates 6800 | best_R@100 0.695615
2023-10-05 07:54:08 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 6800 updates
2023-10-05 07:54:08 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_6800.pt
2023-10-05 07:54:14 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_6800.pt
2023-10-05 07:55:01 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_6800.pt (epoch 8 @ 6800 updates, score 0.6956150751209575) (writing took 52.96615519979969 seconds)
2023-10-05 07:55:08 - progress_bar.py[line:272] - INFO: epoch 008:    471 / 907 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=271.5, nsentences=96, sample_size=271.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=2.3, ups=0.01, wpb=271.5, bsz=96, num_updates=6810, lr=8.7234e-06, gnorm=0.629, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45134
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 07:55:15 - progress_bar.py[line:272] - INFO: epoch 008:    481 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=270.6, nsentences=96, sample_size=270.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=379.5, ups=1.4, wpb=270.6, bsz=96, num_updates=6820, lr=8.65893e-06, gnorm=0.656, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=45141
2023-10-05 07:55:22 - progress_bar.py[line:272] - INFO: epoch 008:    491 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.3, ups=1.49, wpb=269.4, bsz=96, num_updates=6830, lr=8.59446e-06, gnorm=0.569, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45148
2023-10-05 07:55:29 - progress_bar.py[line:272] - INFO: epoch 008:    501 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.2, ups=1.49, wpb=270.1, bsz=96, num_updates=6840, lr=8.52998e-06, gnorm=0.47, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45155
2023-10-05 07:55:35 - progress_bar.py[line:272] - INFO: epoch 008:    511 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.074, ntokens=272.3, nsentences=96, sample_size=272.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=393.4, ups=1.44, wpb=272.3, bsz=96, num_updates=6850, lr=8.46551e-06, gnorm=0.598, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45161
2023-10-05 07:55:42 - progress_bar.py[line:272] - INFO: epoch 008:    521 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.069, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.3, ups=1.49, wpb=269.1, bsz=96, num_updates=6860, lr=8.40103e-06, gnorm=0.511, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45168
2023-10-05 07:55:49 - progress_bar.py[line:272] - INFO: epoch 008:    531 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.076, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.5, ups=1.5, wpb=268.2, bsz=96, num_updates=6870, lr=8.33656e-06, gnorm=0.745, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=45175
2023-10-05 07:55:56 - progress_bar.py[line:272] - INFO: epoch 008:    541 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=267.2, nsentences=96, sample_size=267.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.4, ups=1.49, wpb=267.2, bsz=96, num_updates=6880, lr=8.27208e-06, gnorm=0.427, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45182
2023-10-05 07:56:02 - progress_bar.py[line:272] - INFO: epoch 008:    551 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.6, ups=1.49, wpb=268, bsz=96, num_updates=6890, lr=8.20761e-06, gnorm=0.435, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45188
2023-10-05 07:56:09 - progress_bar.py[line:272] - INFO: epoch 008:    561 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=402.7, ups=1.49, wpb=270.2, bsz=96, num_updates=6900, lr=8.14313e-06, gnorm=0.494, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=45195
2023-10-05 07:56:16 - progress_bar.py[line:272] - INFO: epoch 008:    571 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=369.6, ups=1.37, wpb=269.5, bsz=96, num_updates=6910, lr=8.07866e-06, gnorm=0.435, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45202
2023-10-05 07:56:23 - progress_bar.py[line:272] - INFO: epoch 008:    581 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=266.6, nsentences=96, sample_size=266.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=386.1, ups=1.45, wpb=266.6, bsz=96, num_updates=6920, lr=8.01418e-06, gnorm=0.576, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=45209
2023-10-05 07:56:30 - progress_bar.py[line:272] - INFO: epoch 008:    591 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391, ups=1.46, wpb=268.7, bsz=96, num_updates=6930, lr=7.94971e-06, gnorm=0.484, clip=0, loss_scale=512, train_wall=7, gb_free=6, ema_decay=0.9999, wall=45216
2023-10-05 07:56:37 - progress_bar.py[line:272] - INFO: epoch 008:    601 / 907 loss=0.254, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.5, ups=1.45, wpb=269.2, bsz=96, num_updates=6940, lr=7.88524e-06, gnorm=0.521, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=45223
2023-10-05 07:56:44 - progress_bar.py[line:272] - INFO: epoch 008:    611 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=393.2, ups=1.45, wpb=270.5, bsz=96, num_updates=6950, lr=7.82076e-06, gnorm=0.531, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45230
2023-10-05 07:56:51 - progress_bar.py[line:272] - INFO: epoch 008:    621 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402, ups=1.49, wpb=270.1, bsz=96, num_updates=6960, lr=7.75629e-06, gnorm=0.731, clip=30, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45237
2023-10-05 07:56:57 - progress_bar.py[line:272] - INFO: epoch 008:    631 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.2, ups=1.49, wpb=270, bsz=96, num_updates=6970, lr=7.69181e-06, gnorm=0.634, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=45243
2023-10-05 07:57:04 - progress_bar.py[line:272] - INFO: epoch 008:    641 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.6, ups=1.45, wpb=269.8, bsz=96, num_updates=6980, lr=7.62734e-06, gnorm=0.577, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=45250
2023-10-05 07:57:11 - progress_bar.py[line:272] - INFO: epoch 008:    651 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=267.1, nsentences=96, sample_size=267.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.4, ups=1.49, wpb=267.1, bsz=96, num_updates=6990, lr=7.56286e-06, gnorm=0.507, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45257
2023-10-05 07:57:18 - progress_bar.py[line:272] - INFO: epoch 008:    661 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=392.6, ups=1.45, wpb=270, bsz=96, num_updates=7000, lr=7.49839e-06, gnorm=0.477, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=45264
2023-10-05 07:57:18 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 07:57:20 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 07:57:20 - train.py[line:550] - INFO: load:1.80 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 07:58:59 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 07:58:59 - train.py[line:550] - INFO: load:1.88 valid_run:98.66 task_valid:92.89 collect_output:4.80
2023-10-05 08:00:35 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 08:00:35 - train.py[line:550] - INFO: load:1.96 valid_run:195.29 task_valid:184.79 collect_output:8.59
2023-10-05 08:02:12 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 08:02:12 - train.py[line:550] - INFO: load:2.04 valid_run:291.41 task_valid:273.45 collect_output:15.09
2023-10-05 08:03:47 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 08:03:47 - train.py[line:550] - INFO: load:2.12 valid_run:386.66 task_valid:363.31 collect_output:19.54
2023-10-05 08:05:23 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 08:05:23 - train.py[line:550] - INFO: load:2.21 valid_run:482.43 task_valid:453.11 collect_output:24.59
2023-10-05 08:06:59 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 08:06:59 - train.py[line:550] - INFO: load:2.28 valid_run:578.16 task_valid:542.41 collect_output:30.11
2023-10-05 08:08:33 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 08:08:33 - train.py[line:550] - INFO: load:2.36 valid_run:672.75 task_valid:632.70 collect_output:33.50
2023-10-05 08:10:09 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 08:10:09 - train.py[line:550] - INFO: load:2.45 valid_run:768.30 task_valid:724.83 collect_output:35.98
2023-10-05 08:11:45 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 08:11:45 - train.py[line:550] - INFO: load:2.54 valid_run:864.26 task_valid:815.34 collect_output:40.48
2023-10-05 08:13:21 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 08:13:21 - train.py[line:550] - INFO: load:2.62 valid_run:960.25 task_valid:906.86 collect_output:44.00
2023-10-05 08:14:57 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 08:14:57 - train.py[line:550] - INFO: load:2.70 valid_run:1055.71 task_valid:998.12 collect_output:47.25

====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6961;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4425;    mR @ 100: 0.4888;    mR @ 500: 0.5342;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6961;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4425;    mR @ 100: 0.4888;    mR @ 500: 0.5342;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6961;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4425;    mR @ 100: 0.4888;    mR @ 500: 0.5342;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6961;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4425;    mR @ 100: 0.4888;    mR @ 500: 0.5342;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6961;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4425;    mR @ 100: 0.4888;    mR @ 500: 0.5342;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6961;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4425;    mR @ 100: 0.4888;    mR @ 500: 0.5342;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================

2023-10-05 08:16:12 - train.py[line:487] - INFO: 0.6961150751209575

====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6961;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4425;    mR @ 100: 0.4888;    mR @ 500: 0.5342;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================

2023-10-05 08:16:13 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])

====================================================================================================
SGG eval:     R @ 50: 0.6434;     R @ 100: 0.6961;     R @ 500: 0.7213;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4425;    mR @ 100: 0.4888;    mR @ 500: 0.5342;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2000) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5000) (walking in:0.0000) (walking on:0.5135) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================

2023-10-05 08:16:13 - progress_bar.py[line:282] - INFO: epoch 008 | valid on 'valid' subset | loss 0.233 | loss_v1 0 | loss_v2 0 | nll_loss 0.064 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.696115 | ppl 1.05 | vqa_score 0.5011 | wps 396.7 | wpb 191.9 | bsz 64 | num_updates 7000 | best_R@100 0.696115
2023-10-05 08:16:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 7000 updates
2023-10-05 08:16:13 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_7000.pt
2023-10-05 08:16:18 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_7000.pt
2023-10-05 08:17:02 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_7000.pt (epoch 8 @ 7000 updates, score 0.6961150751209575) (writing took 49.11369334626943 seconds)
2023-10-05 08:17:08 - progress_bar.py[line:272] - INFO: epoch 008:    671 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=2.3, ups=0.01, wpb=270.5, bsz=96, num_updates=7010, lr=7.43391e-06, gnorm=0.534, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46454
2023-10-05 08:17:15 - progress_bar.py[line:272] - INFO: epoch 008:    681 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=406.8, ups=1.5, wpb=271.2, bsz=96, num_updates=7020, lr=7.36944e-06, gnorm=0.585, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=46461
2023-10-05 08:17:22 - progress_bar.py[line:272] - INFO: epoch 008:    691 / 907 loss=0.259, loss_v1=0, loss_v2=0, nll_loss=0.077, ntokens=266.8, nsentences=96, sample_size=266.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.6, ups=1.49, wpb=266.8, bsz=96, num_updates=7030, lr=7.30496e-06, gnorm=0.61, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=46468
2023-10-05 08:17:28 - progress_bar.py[line:272] - INFO: epoch 008:    701 / 907 loss=0.252, loss_v1=0, loss_v2=0, nll_loss=0.071, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.1, ups=1.5, wpb=268, bsz=96, num_updates=7040, lr=7.24049e-06, gnorm=0.567, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46475
2023-10-05 08:17:35 - progress_bar.py[line:272] - INFO: epoch 008:    711 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=270.8, nsentences=96, sample_size=270.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=396, ups=1.46, wpb=270.8, bsz=96, num_updates=7050, lr=7.17602e-06, gnorm=0.601, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46481
2023-10-05 08:17:42 - progress_bar.py[line:272] - INFO: epoch 008:    721 / 907 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=404.3, ups=1.49, wpb=270.9, bsz=96, num_updates=7060, lr=7.11154e-06, gnorm=0.518, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=46488
2023-10-05 08:17:49 - progress_bar.py[line:272] - INFO: epoch 008:    731 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=267.9, nsentences=96, sample_size=267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.5, ups=1.49, wpb=267.9, bsz=96, num_updates=7070, lr=7.04707e-06, gnorm=0.52, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46495
2023-10-05 08:17:55 - progress_bar.py[line:272] - INFO: epoch 008:    741 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=402, ups=1.5, wpb=268.7, bsz=96, num_updates=7080, lr=6.98259e-06, gnorm=0.5, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46501
2023-10-05 08:18:02 - progress_bar.py[line:272] - INFO: epoch 008:    751 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=383.2, ups=1.42, wpb=270.4, bsz=96, num_updates=7090, lr=6.91812e-06, gnorm=0.509, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46509
2023-10-05 08:18:09 - progress_bar.py[line:272] - INFO: epoch 008:    761 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=266.5, nsentences=96, sample_size=266.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.4, ups=1.49, wpb=266.5, bsz=96, num_updates=7100, lr=6.85364e-06, gnorm=0.614, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46515
2023-10-05 08:18:16 - progress_bar.py[line:272] - INFO: epoch 008:    771 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=402.1, ups=1.49, wpb=269.6, bsz=96, num_updates=7110, lr=6.78917e-06, gnorm=0.501, clip=0, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=46522
2023-10-05 08:18:20 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-10-05 08:18:23 - progress_bar.py[line:272] - INFO: epoch 008:    782 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=269.5, nsentences=96, sample_size=269.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=369.3, ups=1.37, wpb=269.5, bsz=96, num_updates=7120, lr=6.72469e-06, gnorm=0.597, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46529
2023-10-05 08:18:30 - progress_bar.py[line:272] - INFO: epoch 008:    792 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.3, ups=1.49, wpb=269.2, bsz=96, num_updates=7130, lr=6.66022e-06, gnorm=0.62, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46536
2023-10-05 08:18:37 - progress_bar.py[line:272] - INFO: epoch 008:    802 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.9, ups=1.5, wpb=270, bsz=96, num_updates=7140, lr=6.59574e-06, gnorm=0.584, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46543
2023-10-05 08:18:43 - progress_bar.py[line:272] - INFO: epoch 008:    812 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=399.8, ups=1.49, wpb=269.1, bsz=96, num_updates=7150, lr=6.53127e-06, gnorm=0.551, clip=10, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=46549
2023-10-05 08:18:51 - progress_bar.py[line:272] - INFO: epoch 008:    822 / 907 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=375.5, ups=1.39, wpb=270.9, bsz=96, num_updates=7160, lr=6.4668e-06, gnorm=0.412, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=46557
2023-10-05 08:18:57 - progress_bar.py[line:272] - INFO: epoch 008:    832 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=389.7, ups=1.45, wpb=269.2, bsz=96, num_updates=7170, lr=6.40232e-06, gnorm=0.486, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=46563
2023-10-05 08:19:04 - progress_bar.py[line:272] - INFO: epoch 008:    842 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.9, ups=1.49, wpb=270.7, bsz=96, num_updates=7180, lr=6.33785e-06, gnorm=0.555, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46570
2023-10-05 08:19:11 - progress_bar.py[line:272] - INFO: epoch 008:    852 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=367.6, ups=1.37, wpb=269.2, bsz=96, num_updates=7190, lr=6.27337e-06, gnorm=0.566, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=46578
2023-10-05 08:19:18 - progress_bar.py[line:272] - INFO: epoch 008:    862 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=268.8, nsentences=96, sample_size=268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=400.8, ups=1.49, wpb=268.8, bsz=96, num_updates=7200, lr=6.2089e-06, gnorm=0.439, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=46584
2023-10-05 08:19:18 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 08:19:20 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 08:19:20 - train.py[line:550] - INFO: load:1.94 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 08:20:58 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 08:20:58 - train.py[line:550] - INFO: load:2.03 valid_run:97.12 task_valid:93.03 collect_output:3.10
2023-10-05 08:22:34 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 08:22:34 - train.py[line:550] - INFO: load:2.12 valid_run:193.29 task_valid:184.86 collect_output:6.46
2023-10-05 08:24:10 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 08:24:10 - train.py[line:550] - INFO: load:2.20 valid_run:289.03 task_valid:273.79 collect_output:12.33
2023-10-05 08:25:45 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 08:25:45 - train.py[line:550] - INFO: load:2.29 valid_run:384.19 task_valid:363.93 collect_output:16.37
2023-10-05 08:27:21 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 08:27:21 - train.py[line:550] - INFO: load:2.37 valid_run:480.02 task_valid:453.85 collect_output:21.34
2023-10-05 08:28:57 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 08:28:57 - train.py[line:550] - INFO: load:2.46 valid_run:576.23 task_valid:543.68 collect_output:26.79
2023-10-05 08:30:32 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 08:30:32 - train.py[line:550] - INFO: load:2.54 valid_run:671.17 task_valid:634.11 collect_output:30.34
2023-10-05 08:32:08 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 08:32:08 - train.py[line:550] - INFO: load:2.63 valid_run:766.92 task_valid:726.53 collect_output:32.73
2023-10-05 08:33:45 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 08:33:45 - train.py[line:550] - INFO: load:2.71 valid_run:863.28 task_valid:817.38 collect_output:37.31
2023-10-05 08:35:21 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 08:35:21 - train.py[line:550] - INFO: load:2.79 valid_run:959.33 task_valid:909.06 collect_output:40.73
2023-10-05 08:36:56 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 08:36:56 - train.py[line:550] - INFO: load:2.88 valid_run:1054.56 task_valid:1000.46 collect_output:43.60

====================================================================================================
SGG eval:     R @ 50: 0.6442;     R @ 100: 0.6959;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4443;    mR @ 100: 0.4893;    mR @ 500: 0.5375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5500) (walking in:0.0000) (walking on:0.5045) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6442;     R @ 100: 0.6959;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4443;    mR @ 100: 0.4893;    mR @ 500: 0.5375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5500) (walking in:0.0000) (walking on:0.5045) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6442;     R @ 100: 0.6959;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4443;    mR @ 100: 0.4893;    mR @ 500: 0.5375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5500) (walking in:0.0000) (walking on:0.5045) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6442;     R @ 100: 0.6959;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4443;    mR @ 100: 0.4893;    mR @ 500: 0.5375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5500) (walking in:0.0000) (walking on:0.5045) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6442;     R @ 100: 0.6959;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4443;    mR @ 100: 0.4893;    mR @ 500: 0.5375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5500) (walking in:0.0000) (walking on:0.5045) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6442;     R @ 100: 0.6959;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4443;    mR @ 100: 0.4893;    mR @ 500: 0.5375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5500) (walking in:0.0000) (walking on:0.5045) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6442;     R @ 100: 0.6959;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4443;    mR @ 100: 0.4893;    mR @ 500: 0.5375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5500) (walking in:0.0000) (walking on:0.5045) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================

2023-10-05 08:38:12 - train.py[line:487] - INFO: 0.6959007894066718

====================================================================================================
SGG eval:     R @ 50: 0.6442;     R @ 100: 0.6959;     R @ 500: 0.7221;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4443;    mR @ 100: 0.4893;    mR @ 500: 0.5375;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.4792) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5880) (using:0.5500) (walking in:0.0000) (walking on:0.5045) (watching:0.6944) 
--------------------------------------------------------
====================================================================================================

2023-10-05 08:38:12 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 08:38:12 - progress_bar.py[line:282] - INFO: epoch 008 | valid on 'valid' subset | loss 0.235 | loss_v1 0 | loss_v2 0 | nll_loss 0.066 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.695901 | ppl 1.05 | vqa_score 0.5 | wps 396.5 | wpb 191.9 | bsz 64 | num_updates 7200 | best_R@100 0.696115
2023-10-05 08:38:12 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 8 @ 7200 updates
2023-10-05 08:38:12 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_7200.pt
2023-10-05 08:38:18 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_7200.pt
2023-10-05 08:38:53 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_8_7200.pt (epoch 8 @ 7200 updates, score 0.6959007894066718) (writing took 40.48471444519237 seconds)
2023-10-05 08:38:59 - progress_bar.py[line:272] - INFO: epoch 008:    872 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.3, ups=0.01, wpb=268, bsz=96, num_updates=7210, lr=6.14442e-06, gnorm=0.507, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=47765
2023-10-05 08:39:06 - progress_bar.py[line:272] - INFO: epoch 008:    882 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=407, ups=1.5, wpb=271.3, bsz=96, num_updates=7220, lr=6.07995e-06, gnorm=0.467, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=47772
2023-10-05 08:39:13 - progress_bar.py[line:272] - INFO: epoch 008:    892 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=408.7, ups=1.51, wpb=271.2, bsz=96, num_updates=7230, lr=6.01547e-06, gnorm=0.633, clip=10, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=47779
2023-10-05 08:39:19 - progress_bar.py[line:272] - INFO: epoch 008:    902 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=267.4, nsentences=96, sample_size=267.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.4, ups=1.49, wpb=267.4, bsz=96, num_updates=7240, lr=5.951e-06, gnorm=0.586, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=47785
2023-10-05 08:39:22 - train.py[line:339] - INFO: end of epoch 8 (average epoch stats below)
2023-10-05 08:39:22 - progress_bar.py[line:282] - INFO: epoch 008 | loss 0.246 | loss_v1 0 | loss_v2 0 | nll_loss 0.065 | ntokens 269.262 | nsentences 95.914 | sample_size 269.262 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.05 | wps 37.3 | ups 0.14 | wpb 269.3 | bsz 95.9 | num_updates 7245 | lr 5.91876e-06 | gnorm 0.544 | clip 4.8 | loss_scale 512 | train_wall 613 | gb_free 16.3 | ema_decay 0.9999 | wall 47788
2023-10-05 08:39:22 - trainer.py[line:694] - INFO: loading train data for epoch 9
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv slice_id 3 row count 10874 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv slice_id 6 row count 10874 total row count 86994

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv slice_id 1 row count 10875 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv slice_id 4 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv slice_id 2 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv slice_id 7 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv slice_id 5 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E8.tsv slice_id 0 row count 10875 total row count 86994
2023-10-05 08:39:23 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
2023-10-05 08:39:23 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 08:39:23 - trainer.py[line:758] - INFO: begin training epoch 9
2023-10-05 08:39:23 - train.py[line:312] - INFO: Start iterating over samples
2023-10-05 08:39:30 - progress_bar.py[line:272] - INFO: epoch 009:      5 / 907 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=250.3, nsentences=88.2, sample_size=250.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=237.8, ups=0.95, wpb=250.3, bsz=88.2, num_updates=7250, lr=5.88652e-06, gnorm=0.464, clip=10, loss_scale=512, train_wall=8, gb_free=6.5, ema_decay=0.9999, wall=47796
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 08:39:37 - progress_bar.py[line:272] - INFO: epoch 009:     15 / 907 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=271, nsentences=96, sample_size=271, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=376.9, ups=1.39, wpb=271, bsz=96, num_updates=7260, lr=5.82205e-06, gnorm=0.453, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=47803
2023-10-05 08:39:44 - progress_bar.py[line:272] - INFO: epoch 009:     25 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=399.7, ups=1.48, wpb=269.7, bsz=96, num_updates=7270, lr=5.75758e-06, gnorm=0.472, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=47810
2023-10-05 08:39:51 - progress_bar.py[line:272] - INFO: epoch 009:     35 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=400.2, ups=1.48, wpb=269.8, bsz=96, num_updates=7280, lr=5.6931e-06, gnorm=0.456, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=47817
2023-10-05 08:39:57 - progress_bar.py[line:272] - INFO: epoch 009:     45 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400, ups=1.49, wpb=268.7, bsz=96, num_updates=7290, lr=5.62863e-06, gnorm=0.624, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=47823
2023-10-05 08:40:04 - progress_bar.py[line:272] - INFO: epoch 009:     55 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=397.5, ups=1.48, wpb=268.4, bsz=96, num_updates=7300, lr=5.56415e-06, gnorm=0.457, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=47830
2023-10-05 08:40:11 - progress_bar.py[line:272] - INFO: epoch 009:     65 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.8, ups=1.48, wpb=269.7, bsz=96, num_updates=7310, lr=5.49968e-06, gnorm=0.565, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=47837
2023-10-05 08:40:18 - progress_bar.py[line:272] - INFO: epoch 009:     75 / 907 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=272.4, nsentences=96, sample_size=272.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=406.3, ups=1.49, wpb=272.4, bsz=96, num_updates=7320, lr=5.4352e-06, gnorm=0.394, clip=0, loss_scale=512, train_wall=7, gb_free=6, ema_decay=0.9999, wall=47844
2023-10-05 08:40:24 - progress_bar.py[line:272] - INFO: epoch 009:     85 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=392.5, ups=1.45, wpb=269.8, bsz=96, num_updates=7330, lr=5.37073e-06, gnorm=0.563, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=47850
2023-10-05 08:40:31 - progress_bar.py[line:272] - INFO: epoch 009:     95 / 907 loss=0.25, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=383.9, ups=1.43, wpb=268, bsz=96, num_updates=7340, lr=5.30625e-06, gnorm=0.741, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=47857
2023-10-05 08:40:38 - progress_bar.py[line:272] - INFO: epoch 009:    105 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.6, ups=1.49, wpb=269.6, bsz=96, num_updates=7350, lr=5.24178e-06, gnorm=0.41, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=47864
2023-10-05 08:40:45 - progress_bar.py[line:272] - INFO: epoch 009:    115 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=390.4, ups=1.45, wpb=268.7, bsz=96, num_updates=7360, lr=5.1773e-06, gnorm=0.516, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=47871
2023-10-05 08:40:52 - progress_bar.py[line:272] - INFO: epoch 009:    125 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.3, ups=1.49, wpb=270.7, bsz=96, num_updates=7370, lr=5.11283e-06, gnorm=0.437, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=47878
2023-10-05 08:40:59 - progress_bar.py[line:272] - INFO: epoch 009:    135 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=388.3, ups=1.44, wpb=269.2, bsz=96, num_updates=7380, lr=5.04836e-06, gnorm=0.491, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=47885
2023-10-05 08:41:05 - progress_bar.py[line:272] - INFO: epoch 009:    145 / 907 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=271.3, nsentences=96, sample_size=271.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403, ups=1.49, wpb=271.3, bsz=96, num_updates=7390, lr=4.98388e-06, gnorm=0.554, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=47891
2023-10-05 08:41:12 - progress_bar.py[line:272] - INFO: epoch 009:    155 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=399.7, ups=1.49, wpb=268.3, bsz=96, num_updates=7400, lr=4.91941e-06, gnorm=0.669, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=47898
2023-10-05 08:41:12 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 08:41:14 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 08:41:14 - train.py[line:550] - INFO: load:1.44 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 08:42:52 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 08:42:52 - train.py[line:550] - INFO: load:1.53 valid_run:98.13 task_valid:93.37 collect_output:3.70
2023-10-05 08:44:28 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 08:44:28 - train.py[line:550] - INFO: load:1.62 valid_run:194.37 task_valid:185.25 collect_output:7.06
2023-10-05 08:46:05 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 08:46:05 - train.py[line:550] - INFO: load:1.70 valid_run:290.32 task_valid:274.17 collect_output:13.17
2023-10-05 08:47:40 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 08:47:40 - train.py[line:550] - INFO: load:1.78 valid_run:385.29 task_valid:364.39 collect_output:16.98
2023-10-05 08:49:15 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 08:49:15 - train.py[line:550] - INFO: load:1.87 valid_run:480.93 task_valid:454.56 collect_output:21.49
2023-10-05 08:50:51 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 08:50:51 - train.py[line:550] - INFO: load:1.96 valid_run:576.79 task_valid:544.28 collect_output:26.65
2023-10-05 08:52:26 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 08:52:26 - train.py[line:550] - INFO: load:2.04 valid_run:671.50 task_valid:634.83 collect_output:29.85
2023-10-05 08:54:02 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 08:54:02 - train.py[line:550] - INFO: load:2.13 valid_run:767.12 task_valid:727.16 collect_output:32.13
2023-10-05 08:55:38 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 08:55:38 - train.py[line:550] - INFO: load:2.23 valid_run:863.02 task_valid:818.02 collect_output:36.20
2023-10-05 08:57:14 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 08:57:14 - train.py[line:550] - INFO: load:2.32 valid_run:958.68 task_valid:909.80 collect_output:39.11
2023-10-05 08:58:49 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 08:58:49 - train.py[line:550] - INFO: load:2.41 valid_run:1054.13 task_valid:1001.29 collect_output:42.06

====================================================================================================
SGG eval:     R @ 50: 0.6449;     R @ 100: 0.6989;     R @ 500: 0.7248;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4446;    mR @ 100: 0.4959;    mR @ 500: 0.5383;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4955) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6449;     R @ 100: 0.6989;     R @ 500: 0.7248;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4446;    mR @ 100: 0.4959;    mR @ 500: 0.5383;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4955) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6449;     R @ 100: 0.6989;     R @ 500: 0.7248;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4446;    mR @ 100: 0.4959;    mR @ 500: 0.5383;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4955) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6449;     R @ 100: 0.6989;     R @ 500: 0.7248;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4446;    mR @ 100: 0.4959;    mR @ 500: 0.5383;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4955) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================

2023-10-05 09:00:05 - train.py[line:487] - INFO: 0.6988531703590527

====================================================================================================
SGG eval:     R @ 50: 0.6449;     R @ 100: 0.6989;     R @ 500: 0.7248;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4446;    mR @ 100: 0.4959;    mR @ 500: 0.5383;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4955) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6449;     R @ 100: 0.6989;     R @ 500: 0.7248;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4446;    mR @ 100: 0.4959;    mR @ 500: 0.5383;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4955) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================

2023-10-05 09:00:06 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 09:00:06 - progress_bar.py[line:282] - INFO: epoch 009 | valid on 'valid' subset | loss 0.235 | loss_v1 0 | loss_v2 0 | nll_loss 0.066 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.698853 | ppl 1.05 | vqa_score 0.4989 | wps 396.7 | wpb 191.9 | bsz 64 | num_updates 7400 | best_R@100 0.698853
2023-10-05 09:00:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 7400 updates
2023-10-05 09:00:06 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_7400.pt

====================================================================================================
SGG eval:     R @ 50: 0.6449;     R @ 100: 0.6989;     R @ 500: 0.7248;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4446;    mR @ 100: 0.4959;    mR @ 500: 0.5383;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4955) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6449;     R @ 100: 0.6989;     R @ 500: 0.7248;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4446;    mR @ 100: 0.4959;    mR @ 500: 0.5383;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9255) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4955) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================

2023-10-05 09:00:12 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_7400.pt
2023-10-05 09:00:57 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_7400.pt (epoch 9 @ 7400 updates, score 0.6988531703590527) (writing took 51.71714289486408 seconds)
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 09:01:04 - progress_bar.py[line:272] - INFO: epoch 009:    165 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=2.3, ups=0.01, wpb=270.1, bsz=96, num_updates=7410, lr=4.85493e-06, gnorm=0.541, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49090
2023-10-05 09:01:11 - progress_bar.py[line:272] - INFO: epoch 009:    175 / 907 loss=0.236, loss_v1=0, loss_v2=0, nll_loss=0.054, ntokens=271.2, nsentences=96, sample_size=271.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=405.3, ups=1.49, wpb=271.2, bsz=96, num_updates=7420, lr=4.79046e-06, gnorm=0.398, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=49097
2023-10-05 09:01:18 - progress_bar.py[line:272] - INFO: epoch 009:    185 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=402.9, ups=1.49, wpb=270, bsz=96, num_updates=7430, lr=4.72598e-06, gnorm=0.401, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49104
2023-10-05 09:01:24 - progress_bar.py[line:272] - INFO: epoch 009:    195 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.1, ups=1.49, wpb=269.7, bsz=96, num_updates=7440, lr=4.66151e-06, gnorm=0.457, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49110
2023-10-05 09:01:31 - progress_bar.py[line:272] - INFO: epoch 009:    205 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=271.1, nsentences=96, sample_size=271.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=405.5, ups=1.5, wpb=271.1, bsz=96, num_updates=7450, lr=4.59703e-06, gnorm=0.473, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49117
2023-10-05 09:01:38 - progress_bar.py[line:272] - INFO: epoch 009:    215 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=271.5, nsentences=96, sample_size=271.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=395, ups=1.45, wpb=271.5, bsz=96, num_updates=7460, lr=4.53256e-06, gnorm=0.681, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49124
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 09:01:45 - progress_bar.py[line:272] - INFO: epoch 009:    225 / 907 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=269.6, nsentences=96, sample_size=269.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.6, ups=1.5, wpb=269.6, bsz=96, num_updates=7470, lr=4.46809e-06, gnorm=0.48, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49131
2023-10-05 09:01:51 - progress_bar.py[line:272] - INFO: epoch 009:    235 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=267.4, nsentences=96, sample_size=267.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=398.3, ups=1.49, wpb=267.4, bsz=96, num_updates=7480, lr=4.40361e-06, gnorm=0.522, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49137
2023-10-05 09:01:58 - progress_bar.py[line:272] - INFO: epoch 009:    245 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=269.7, nsentences=96, sample_size=269.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=389.8, ups=1.45, wpb=269.7, bsz=96, num_updates=7490, lr=4.33914e-06, gnorm=0.527, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=49144
2023-10-05 09:02:05 - progress_bar.py[line:272] - INFO: epoch 009:    255 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=372.5, ups=1.38, wpb=269, bsz=96, num_updates=7500, lr=4.27466e-06, gnorm=0.547, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49151
2023-10-05 09:02:12 - progress_bar.py[line:272] - INFO: epoch 009:    265 / 907 loss=0.237, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=271.4, nsentences=96, sample_size=271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=405.2, ups=1.49, wpb=271.4, bsz=96, num_updates=7510, lr=4.21019e-06, gnorm=0.462, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49158
2023-10-05 09:02:19 - progress_bar.py[line:272] - INFO: epoch 009:    275 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.7, ups=1.49, wpb=270.3, bsz=96, num_updates=7520, lr=4.14571e-06, gnorm=0.569, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=49165
2023-10-05 09:02:26 - progress_bar.py[line:272] - INFO: epoch 009:    285 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.7, ups=1.49, wpb=269, bsz=96, num_updates=7530, lr=4.08124e-06, gnorm=0.488, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=49172
2023-10-05 09:02:32 - progress_bar.py[line:272] - INFO: epoch 009:    295 / 907 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=271.5, nsentences=96, sample_size=271.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=394, ups=1.45, wpb=271.5, bsz=96, num_updates=7540, lr=4.01676e-06, gnorm=0.619, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=49178
2023-10-05 09:02:39 - progress_bar.py[line:272] - INFO: epoch 009:    305 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=389.5, ups=1.45, wpb=268.3, bsz=96, num_updates=7550, lr=3.95229e-06, gnorm=0.517, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49185
2023-10-05 09:02:46 - progress_bar.py[line:272] - INFO: epoch 009:    315 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.2, ups=1.49, wpb=269.2, bsz=96, num_updates=7560, lr=3.88781e-06, gnorm=0.623, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49192
2023-10-05 09:02:53 - progress_bar.py[line:272] - INFO: epoch 009:    325 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.3, ups=1.48, wpb=270.4, bsz=96, num_updates=7570, lr=3.82334e-06, gnorm=0.546, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=49199
2023-10-05 09:03:00 - progress_bar.py[line:272] - INFO: epoch 009:    335 / 907 loss=0.238, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=378.7, ups=1.41, wpb=269.3, bsz=96, num_updates=7580, lr=3.75887e-06, gnorm=0.382, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=49206
@@@@ ERROR IN DATA @@@@ play
2023-10-05 09:03:07 - progress_bar.py[line:272] - INFO: epoch 009:    345 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=266.3, nsentences=96, sample_size=266.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=387, ups=1.45, wpb=266.3, bsz=96, num_updates=7590, lr=3.69439e-06, gnorm=0.558, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=49213
2023-10-05 09:03:14 - progress_bar.py[line:272] - INFO: epoch 009:    355 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=385.3, ups=1.42, wpb=270.7, bsz=96, num_updates=7600, lr=3.62992e-06, gnorm=0.508, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=49220
2023-10-05 09:03:14 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 09:03:16 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 09:03:16 - train.py[line:550] - INFO: load:1.86 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 09:04:53 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 09:04:53 - train.py[line:550] - INFO: load:1.96 valid_run:97.40 task_valid:93.06 collect_output:3.38
2023-10-05 09:06:30 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 09:06:30 - train.py[line:550] - INFO: load:2.04 valid_run:193.46 task_valid:184.85 collect_output:6.70
2023-10-05 09:08:06 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 09:08:06 - train.py[line:550] - INFO: load:2.13 valid_run:289.55 task_valid:273.89 collect_output:12.81
2023-10-05 09:09:41 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 09:09:41 - train.py[line:550] - INFO: load:2.21 valid_run:384.53 task_valid:363.81 collect_output:16.92
2023-10-05 09:11:17 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 09:11:17 - train.py[line:550] - INFO: load:2.30 valid_run:480.21 task_valid:453.74 collect_output:21.72
2023-10-05 09:12:53 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 09:12:53 - train.py[line:550] - INFO: load:2.38 valid_run:576.13 task_valid:543.25 collect_output:27.20
2023-10-05 09:14:27 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 09:14:27 - train.py[line:550] - INFO: load:2.47 valid_run:670.69 task_valid:633.60 collect_output:30.49
2023-10-05 09:16:03 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 09:16:03 - train.py[line:550] - INFO: load:2.56 valid_run:766.20 task_valid:725.74 collect_output:32.87
2023-10-05 09:17:39 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 09:17:39 - train.py[line:550] - INFO: load:2.65 valid_run:862.06 task_valid:816.40 collect_output:37.10
2023-10-05 09:19:15 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 09:19:15 - train.py[line:550] - INFO: load:2.73 valid_run:958.28 task_valid:908.00 collect_output:40.76
2023-10-05 09:20:51 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 09:20:51 - train.py[line:550] - INFO: load:2.82 valid_run:1053.58 task_valid:999.28 collect_output:43.78

====================================================================================================
SGG eval:     R @ 50: 0.6460;     R @ 100: 0.6998;     R @ 500: 0.7267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4433;    mR @ 100: 0.4958;    mR @ 500: 0.5389;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5901) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6460;     R @ 100: 0.6998;     R @ 500: 0.7267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4433;    mR @ 100: 0.4958;    mR @ 500: 0.5389;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5901) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6460;     R @ 100: 0.6998;     R @ 500: 0.7267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4433;    mR @ 100: 0.4958;    mR @ 500: 0.5389;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5901) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6460;     R @ 100: 0.6998;     R @ 500: 0.7267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4433;    mR @ 100: 0.4958;    mR @ 500: 0.5389;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5901) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6460;     R @ 100: 0.6998;     R @ 500: 0.7267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4433;    mR @ 100: 0.4958;    mR @ 500: 0.5389;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5901) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6460;     R @ 100: 0.6998;     R @ 500: 0.7267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4433;    mR @ 100: 0.4958;    mR @ 500: 0.5389;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5901) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================

2023-10-05 09:22:07 - train.py[line:487] - INFO: 0.6997817417876242

====================================================================================================
SGG eval:     R @ 50: 0.6460;     R @ 100: 0.6998;     R @ 500: 0.7267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4433;    mR @ 100: 0.4958;    mR @ 500: 0.5389;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5901) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6460;     R @ 100: 0.6998;     R @ 500: 0.7267;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4433;    mR @ 100: 0.4958;    mR @ 500: 0.5389;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.8235) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5901) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================

2023-10-05 09:22:07 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 09:22:07 - progress_bar.py[line:282] - INFO: epoch 009 | valid on 'valid' subset | loss 0.232 | loss_v1 0 | loss_v2 0 | nll_loss 0.063 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.699782 | ppl 1.04 | vqa_score 0.4966 | wps 396.9 | wpb 191.9 | bsz 64 | num_updates 7600 | best_R@100 0.699782
2023-10-05 09:22:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 7600 updates
2023-10-05 09:22:07 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_7600.pt
2023-10-05 09:22:13 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_7600.pt
2023-10-05 09:22:55 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_7600.pt (epoch 9 @ 7600 updates, score 0.6997817417876242) (writing took 47.995799923315644 seconds)
2023-10-05 09:23:02 - progress_bar.py[line:272] - INFO: epoch 009:    365 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=2.3, ups=0.01, wpb=269.8, bsz=96, num_updates=7610, lr=3.56544e-06, gnorm=0.758, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=50408
2023-10-05 09:23:08 - progress_bar.py[line:272] - INFO: epoch 009:    375 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=406.1, ups=1.5, wpb=270.7, bsz=96, num_updates=7620, lr=3.50097e-06, gnorm=0.576, clip=20, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=50414
@@@@ ERROR IN DATA @@@@ play
2023-10-05 09:23:15 - progress_bar.py[line:272] - INFO: epoch 009:    385 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=271.7, nsentences=96, sample_size=271.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=408.4, ups=1.5, wpb=271.7, bsz=96, num_updates=7630, lr=3.43649e-06, gnorm=0.499, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=50421
2023-10-05 09:23:22 - progress_bar.py[line:272] - INFO: epoch 009:    395 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=405.2, ups=1.5, wpb=270.5, bsz=96, num_updates=7640, lr=3.37202e-06, gnorm=0.496, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=50428
2023-10-05 09:23:28 - progress_bar.py[line:272] - INFO: epoch 009:    405 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.8, ups=1.5, wpb=268.4, bsz=96, num_updates=7650, lr=3.30754e-06, gnorm=0.542, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=50434
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 09:23:35 - progress_bar.py[line:272] - INFO: epoch 009:    415 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=391.3, ups=1.46, wpb=268.7, bsz=96, num_updates=7660, lr=3.24307e-06, gnorm=0.543, clip=0, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=50441
2023-10-05 09:23:42 - progress_bar.py[line:272] - INFO: epoch 009:    425 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=270.9, nsentences=96, sample_size=270.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=395.6, ups=1.46, wpb=270.9, bsz=96, num_updates=7670, lr=3.17859e-06, gnorm=0.581, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=50448
2023-10-05 09:23:49 - progress_bar.py[line:272] - INFO: epoch 009:    435 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=270.2, nsentences=96, sample_size=270.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=392.7, ups=1.45, wpb=270.2, bsz=96, num_updates=7680, lr=3.11412e-06, gnorm=0.488, clip=10, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=50455
2023-10-05 09:23:56 - progress_bar.py[line:272] - INFO: epoch 009:    445 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=268.8, nsentences=96, sample_size=268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.2, ups=1.49, wpb=268.8, bsz=96, num_updates=7690, lr=3.04965e-06, gnorm=0.514, clip=0, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=50462
2023-10-05 09:24:03 - progress_bar.py[line:272] - INFO: epoch 009:    455 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=266.7, nsentences=96, sample_size=266.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=377.2, ups=1.41, wpb=266.7, bsz=96, num_updates=7700, lr=2.98517e-06, gnorm=0.357, clip=0, loss_scale=1024, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=50469
2023-10-05 09:24:10 - progress_bar.py[line:272] - INFO: epoch 009:    465 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=390.1, ups=1.44, wpb=270, bsz=96, num_updates=7710, lr=2.9207e-06, gnorm=0.514, clip=10, loss_scale=1024, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=50476
2023-10-05 09:24:13 - trainer.py[line:1006] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 512.0
2023-10-05 09:24:17 - progress_bar.py[line:272] - INFO: epoch 009:    476 / 907 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=269.1, nsentences=96, sample_size=269.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=360.6, ups=1.34, wpb=269.1, bsz=96, num_updates=7720, lr=2.85622e-06, gnorm=0.529, clip=10, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=50483
2023-10-05 09:24:24 - progress_bar.py[line:272] - INFO: epoch 009:    486 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=399.1, ups=1.49, wpb=268.5, bsz=96, num_updates=7730, lr=2.79175e-06, gnorm=0.457, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=50490
2023-10-05 09:24:31 - progress_bar.py[line:272] - INFO: epoch 009:    496 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=400.5, ups=1.49, wpb=268.5, bsz=96, num_updates=7740, lr=2.72727e-06, gnorm=0.497, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=50497
2023-10-05 09:24:37 - progress_bar.py[line:272] - INFO: epoch 009:    506 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=270.3, nsentences=96, sample_size=270.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.6, ups=1.49, wpb=270.3, bsz=96, num_updates=7750, lr=2.6628e-06, gnorm=0.519, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=50503
@@@@ ERROR IN DATA @@@@ ride
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 09:24:44 - progress_bar.py[line:272] - INFO: epoch 009:    516 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=268.8, nsentences=96, sample_size=268.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.1, ups=1.49, wpb=268.8, bsz=96, num_updates=7760, lr=2.59832e-06, gnorm=0.528, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=50510
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 09:24:51 - progress_bar.py[line:272] - INFO: epoch 009:    526 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=381.4, ups=1.42, wpb=268, bsz=96, num_updates=7770, lr=2.53385e-06, gnorm=0.593, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=50517
2023-10-05 09:24:58 - progress_bar.py[line:272] - INFO: epoch 009:    536 / 907 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.056, ntokens=268.4, nsentences=96, sample_size=268.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=377.9, ups=1.41, wpb=268.4, bsz=96, num_updates=7780, lr=2.46937e-06, gnorm=0.37, clip=0, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=50524
2023-10-05 09:25:05 - progress_bar.py[line:272] - INFO: epoch 009:    546 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=392, ups=1.45, wpb=270.4, bsz=96, num_updates=7790, lr=2.4049e-06, gnorm=0.571, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=50531
2023-10-05 09:25:12 - progress_bar.py[line:272] - INFO: epoch 009:    556 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=388.6, ups=1.45, wpb=267.8, bsz=96, num_updates=7800, lr=2.34043e-06, gnorm=0.376, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=50538
2023-10-05 09:25:12 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 09:25:14 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 09:25:14 - train.py[line:550] - INFO: load:2.04 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 09:26:51 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 09:26:51 - train.py[line:550] - INFO: load:2.13 valid_run:96.86 task_valid:92.96 collect_output:2.93
2023-10-05 09:28:28 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 09:28:28 - train.py[line:550] - INFO: load:2.20 valid_run:193.43 task_valid:184.86 collect_output:6.65
2023-10-05 09:30:04 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 09:30:04 - train.py[line:550] - INFO: load:2.29 valid_run:289.24 task_valid:273.62 collect_output:12.74
2023-10-05 09:31:39 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 09:31:39 - train.py[line:550] - INFO: load:2.36 valid_run:384.15 task_valid:363.56 collect_output:16.78
2023-10-05 09:33:15 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 09:33:15 - train.py[line:550] - INFO: load:2.45 valid_run:479.83 task_valid:453.54 collect_output:21.55
2023-10-05 09:34:50 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 09:34:50 - train.py[line:550] - INFO: load:2.54 valid_run:575.53 task_valid:543.09 collect_output:26.74
2023-10-05 09:36:25 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 09:36:25 - train.py[line:550] - INFO: load:2.62 valid_run:670.41 task_valid:633.43 collect_output:30.31
2023-10-05 09:38:02 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 09:38:02 - train.py[line:550] - INFO: load:2.71 valid_run:766.42 task_valid:725.72 collect_output:33.04
2023-10-05 09:39:38 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 09:39:38 - train.py[line:550] - INFO: load:2.79 valid_run:862.38 task_valid:816.31 collect_output:37.42
2023-10-05 09:41:14 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 09:41:14 - train.py[line:550] - INFO: load:2.88 valid_run:958.20 task_valid:907.95 collect_output:40.63
2023-10-05 09:42:49 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 09:42:49 - train.py[line:550] - INFO: load:2.97 valid_run:1053.47 task_valid:999.22 collect_output:43.68

====================================================================================================
SGG eval:     R @ 50: 0.6445;     R @ 100: 0.6964;     R @ 500: 0.7253;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4430;    mR @ 100: 0.4925;    mR @ 500: 0.5385;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5830) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6445;     R @ 100: 0.6964;     R @ 500: 0.7253;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4430;    mR @ 100: 0.4925;    mR @ 500: 0.5385;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5830) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6445;     R @ 100: 0.6964;     R @ 500: 0.7253;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4430;    mR @ 100: 0.4925;    mR @ 500: 0.5385;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5830) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6445;     R @ 100: 0.6964;     R @ 500: 0.7253;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4430;    mR @ 100: 0.4925;    mR @ 500: 0.5385;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5830) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6445;     R @ 100: 0.6964;     R @ 500: 0.7253;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4430;    mR @ 100: 0.4925;    mR @ 500: 0.5385;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5830) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6445;     R @ 100: 0.6964;     R @ 500: 0.7253;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4430;    mR @ 100: 0.4925;    mR @ 500: 0.5385;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5830) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6445;     R @ 100: 0.6964;     R @ 500: 0.7253;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4430;    mR @ 100: 0.4925;    mR @ 500: 0.5385;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5830) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================

2023-10-05 09:44:05 - train.py[line:487] - INFO: 0.6963531703590526

====================================================================================================
SGG eval:     R @ 50: 0.6445;     R @ 100: 0.6964;     R @ 500: 0.7253;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4430;    mR @ 100: 0.4925;    mR @ 500: 0.5385;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7439) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3871) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5830) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================

2023-10-05 09:44:05 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 09:44:05 - progress_bar.py[line:282] - INFO: epoch 009 | valid on 'valid' subset | loss 0.233 | loss_v1 0 | loss_v2 0 | nll_loss 0.063 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.696353 | ppl 1.04 | vqa_score 0.4955 | wps 396.8 | wpb 191.9 | bsz 64 | num_updates 7800 | best_R@100 0.699782
2023-10-05 09:44:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 7800 updates
2023-10-05 09:44:05 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_7800.pt
2023-10-05 09:44:11 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_7800.pt
2023-10-05 09:44:46 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_7800.pt (epoch 9 @ 7800 updates, score 0.6963531703590526) (writing took 40.914388498757035 seconds)
@@@@ ERROR IN DATA @@@@ watch
2023-10-05 09:44:53 - progress_bar.py[line:272] - INFO: epoch 009:    566 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=268.5, nsentences=96, sample_size=268.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=2.3, ups=0.01, wpb=268.5, bsz=96, num_updates=7810, lr=2.27595e-06, gnorm=0.705, clip=20, loss_scale=512, train_wall=7, gb_free=5.9, ema_decay=0.9999, wall=51719
2023-10-05 09:45:00 - progress_bar.py[line:272] - INFO: epoch 009:    576 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=267.6, nsentences=96, sample_size=267.6, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=390.6, ups=1.46, wpb=267.6, bsz=96, num_updates=7820, lr=2.21148e-06, gnorm=0.491, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=51726
2023-10-05 09:45:06 - progress_bar.py[line:272] - INFO: epoch 009:    586 / 907 loss=0.239, loss_v1=0, loss_v2=0, nll_loss=0.057, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=402.8, ups=1.49, wpb=270.4, bsz=96, num_updates=7830, lr=2.147e-06, gnorm=0.479, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=51732
2023-10-05 09:45:13 - progress_bar.py[line:272] - INFO: epoch 009:    596 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=397, ups=1.47, wpb=270.5, bsz=96, num_updates=7840, lr=2.08253e-06, gnorm=0.469, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=51739
2023-10-05 09:45:20 - progress_bar.py[line:272] - INFO: epoch 009:    606 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=404.3, ups=1.5, wpb=270, bsz=96, num_updates=7850, lr=2.01805e-06, gnorm=0.399, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=51746
2023-10-05 09:45:26 - progress_bar.py[line:272] - INFO: epoch 009:    616 / 907 loss=0.245, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=401.4, ups=1.49, wpb=269.8, bsz=96, num_updates=7860, lr=1.95358e-06, gnorm=0.54, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=51753
2023-10-05 09:45:33 - progress_bar.py[line:272] - INFO: epoch 009:    626 / 907 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=271.7, nsentences=96, sample_size=271.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=396.9, ups=1.46, wpb=271.7, bsz=96, num_updates=7870, lr=1.8891e-06, gnorm=0.512, clip=10, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=51759
2023-10-05 09:45:40 - progress_bar.py[line:272] - INFO: epoch 009:    636 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.6, ups=1.49, wpb=270.1, bsz=96, num_updates=7880, lr=1.82463e-06, gnorm=0.582, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=51766
2023-10-05 09:45:47 - progress_bar.py[line:272] - INFO: epoch 009:    646 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=270, nsentences=96, sample_size=270, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=396.1, ups=1.47, wpb=270, bsz=96, num_updates=7890, lr=1.76015e-06, gnorm=0.559, clip=10, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=51773
2023-10-05 09:45:54 - progress_bar.py[line:272] - INFO: epoch 009:    656 / 907 loss=0.253, loss_v1=0, loss_v2=0, nll_loss=0.072, ntokens=269, nsentences=96, sample_size=269, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400.4, ups=1.49, wpb=269, bsz=96, num_updates=7900, lr=1.69568e-06, gnorm=0.669, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=51780
2023-10-05 09:46:00 - progress_bar.py[line:272] - INFO: epoch 009:    666 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=270.1, nsentences=96, sample_size=270.1, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=403.8, ups=1.49, wpb=270.1, bsz=96, num_updates=7910, lr=1.63121e-06, gnorm=0.588, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=51786
@@@@ ERROR IN DATA @@@@ stand on
2023-10-05 09:46:08 - progress_bar.py[line:272] - INFO: epoch 009:    676 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=371.9, ups=1.38, wpb=269.3, bsz=96, num_updates=7920, lr=1.56673e-06, gnorm=0.75, clip=20, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=51794
2023-10-05 09:46:15 - progress_bar.py[line:272] - INFO: epoch 009:    686 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.061, ntokens=269.8, nsentences=96, sample_size=269.8, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=383.5, ups=1.42, wpb=269.8, bsz=96, num_updates=7930, lr=1.50226e-06, gnorm=0.455, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=51801
2023-10-05 09:46:21 - progress_bar.py[line:272] - INFO: epoch 009:    696 / 907 loss=0.255, loss_v1=0, loss_v2=0, nll_loss=0.075, ntokens=269.9, nsentences=96, sample_size=269.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=402.4, ups=1.49, wpb=269.9, bsz=96, num_updates=7940, lr=1.43778e-06, gnorm=0.831, clip=40, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=51807
2023-10-05 09:46:28 - progress_bar.py[line:272] - INFO: epoch 009:    706 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=270.4, nsentences=96, sample_size=270.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.9, ups=1.49, wpb=270.4, bsz=96, num_updates=7950, lr=1.37331e-06, gnorm=0.558, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=51814
2023-10-05 09:46:35 - progress_bar.py[line:272] - INFO: epoch 009:    716 / 907 loss=0.251, loss_v1=0, loss_v2=0, nll_loss=0.07, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=398.2, ups=1.49, wpb=267.8, bsz=96, num_updates=7960, lr=1.30883e-06, gnorm=0.554, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=51821
2023-10-05 09:46:41 - progress_bar.py[line:272] - INFO: epoch 009:    726 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=405.2, ups=1.5, wpb=270.7, bsz=96, num_updates=7970, lr=1.24436e-06, gnorm=0.609, clip=0, loss_scale=512, train_wall=7, gb_free=6.2, ema_decay=0.9999, wall=51827
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 09:46:48 - progress_bar.py[line:272] - INFO: epoch 009:    736 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=267.9, nsentences=96, sample_size=267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=388.6, ups=1.45, wpb=267.9, bsz=96, num_updates=7980, lr=1.17988e-06, gnorm=0.436, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=51834
@@@@ ERROR IN DATA @@@@ ride
2023-10-05 09:46:55 - progress_bar.py[line:272] - INFO: epoch 009:    746 / 907 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=269.3, nsentences=96, sample_size=269.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.1, ups=1.49, wpb=269.3, bsz=96, num_updates=7990, lr=1.11541e-06, gnorm=0.416, clip=0, loss_scale=512, train_wall=7, gb_free=6.6, ema_decay=0.9999, wall=51841
2023-10-05 09:47:02 - progress_bar.py[line:272] - INFO: epoch 009:    756 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=268.3, nsentences=96, sample_size=268.3, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=372.9, ups=1.39, wpb=268.3, bsz=96, num_updates=8000, lr=1.05093e-06, gnorm=0.451, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=51848
2023-10-05 09:47:02 - train.py[line:506] - INFO: begin validation on "valid" subset
2023-10-05 09:47:04 - train.py[line:549] - INFO: 0 / 2338
2023-10-05 09:47:04 - train.py[line:550] - INFO: load:1.44 valid_run:0.00 task_valid:0.00 collect_output:0.00
2023-10-05 09:48:41 - train.py[line:549] - INFO: 200 / 2338
2023-10-05 09:48:41 - train.py[line:550] - INFO: load:1.52 valid_run:97.48 task_valid:93.16 collect_output:3.37
2023-10-05 09:50:18 - train.py[line:549] - INFO: 400 / 2338
2023-10-05 09:50:18 - train.py[line:550] - INFO: load:1.61 valid_run:193.63 task_valid:184.60 collect_output:7.13
2023-10-05 09:51:54 - train.py[line:549] - INFO: 600 / 2338
2023-10-05 09:51:54 - train.py[line:550] - INFO: load:1.69 valid_run:289.68 task_valid:273.32 collect_output:13.53
2023-10-05 09:53:29 - train.py[line:549] - INFO: 800 / 2338
2023-10-05 09:53:29 - train.py[line:550] - INFO: load:1.77 valid_run:384.42 task_valid:363.19 collect_output:17.45
2023-10-05 09:55:04 - train.py[line:549] - INFO: 1000 / 2338
2023-10-05 09:55:04 - train.py[line:550] - INFO: load:1.86 valid_run:479.92 task_valid:453.05 collect_output:22.15
2023-10-05 09:56:40 - train.py[line:549] - INFO: 1200 / 2338
2023-10-05 09:56:40 - train.py[line:550] - INFO: load:1.95 valid_run:575.70 task_valid:542.47 collect_output:27.56
2023-10-05 09:58:15 - train.py[line:549] - INFO: 1400 / 2338
2023-10-05 09:58:15 - train.py[line:550] - INFO: load:2.03 valid_run:670.21 task_valid:632.59 collect_output:31.03
2023-10-05 09:59:50 - train.py[line:549] - INFO: 1600 / 2338
2023-10-05 09:59:50 - train.py[line:550] - INFO: load:2.11 valid_run:765.64 task_valid:724.60 collect_output:33.55
2023-10-05 10:01:26 - train.py[line:549] - INFO: 1800 / 2338
2023-10-05 10:01:26 - train.py[line:550] - INFO: load:2.19 valid_run:861.31 task_valid:815.10 collect_output:37.77
2023-10-05 10:03:02 - train.py[line:549] - INFO: 2000 / 2338
2023-10-05 10:03:02 - train.py[line:550] - INFO: load:2.27 valid_run:957.05 task_valid:906.50 collect_output:41.14
2023-10-05 10:04:38 - train.py[line:549] - INFO: 2200 / 2338
2023-10-05 10:04:38 - train.py[line:550] - INFO: load:2.35 valid_run:1052.61 task_valid:997.96 collect_output:44.26

====================================================================================================
SGG eval:     R @ 50: 0.6430;     R @ 100: 0.6960;     R @ 500: 0.7239;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4416;    mR @ 100: 0.4914;    mR @ 500: 0.5358;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3806) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6430;     R @ 100: 0.6960;     R @ 500: 0.7239;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4416;    mR @ 100: 0.4914;    mR @ 500: 0.5358;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3806) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6430;     R @ 100: 0.6960;     R @ 500: 0.7239;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4416;    mR @ 100: 0.4914;    mR @ 500: 0.5358;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3806) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================

2023-10-05 10:05:53 - train.py[line:487] - INFO: 0.6959531703590528

====================================================================================================
SGG eval:     R @ 50: 0.6430;     R @ 100: 0.6960;     R @ 500: 0.7239;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4416;    mR @ 100: 0.4914;    mR @ 500: 0.5358;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3806) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6430;     R @ 100: 0.6960;     R @ 500: 0.7239;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4416;    mR @ 100: 0.4914;    mR @ 500: 0.5358;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3806) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6430;     R @ 100: 0.6960;     R @ 500: 0.7239;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4416;    mR @ 100: 0.4914;    mR @ 500: 0.5358;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3806) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================


====================================================================================================
SGG eval:     R @ 50: 0.6430;     R @ 100: 0.6960;     R @ 500: 0.7239;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4416;    mR @ 100: 0.4914;    mR @ 500: 0.5358;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3806) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================

2023-10-05 10:05:54 - train.py[line:579] - INFO: logits:torch.Size([149614, 21]) sample_ids:torch.Size([149614])
2023-10-05 10:05:54 - progress_bar.py[line:282] - INFO: epoch 009 | valid on 'valid' subset | loss 0.231 | loss_v1 0 | loss_v2 0 | nll_loss 0.062 | ntokens 191.853 | nsentences 63.992 | sample_size 191.853 | sample_size_v1 0 | sample_size_v2 0 | R@100 0.695953 | ppl 1.04 | vqa_score 0.4921 | wps 397.3 | wpb 191.9 | bsz 64 | num_updates 8000 | best_R@100 0.699782
2023-10-05 10:05:54 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 9 @ 8000 updates
2023-10-05 10:05:54 - trainer.py[line:472] - INFO: Saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_8000.pt

====================================================================================================
SGG eval:     R @ 50: 0.6430;     R @ 100: 0.6960;     R @ 500: 0.7239;  for mode=predcls, type=Recall(Main).
SGG eval:    mR @ 50: 0.4416;    mR @ 100: 0.4914;    mR @ 500: 0.5358;  for mode=predcls, type=Mean Recall.
----------------------- Details ------------------------
(carrying:0.7195) (covered in:0.5417) (covering:0.2286) (eating:0.7647) (flying in:0.9091) (growing on:0.2500) (hanging from:0.3806) (lying on:0.4000) (mounted on:0.1429) (painted on:0.5000) (parked on:1.0000) (playing:0.0000) (riding:0.9353) (says:0.0000) (sitting on:0.7185) (standing on:0.5930) (using:0.5500) (walking in:0.0000) (walking on:0.4865) (watching:0.7083) 
--------------------------------------------------------
====================================================================================================

2023-10-05 10:05:59 - trainer.py[line:482] - INFO: Finished saving checkpoint to ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_8000.pt
2023-10-05 10:06:34 - checkpoint_utils.py[line:133] - INFO: Saved checkpoint ./../../vqa_checkpoints/20_way_caption_five_filtered/1_B12_A1_E9_0.05_5e-5_480/checkpoint_9_8000.pt (epoch 9 @ 8000 updates, score 0.6959531703590528) (writing took 40.208709484897554 seconds)
2023-10-05 10:06:41 - progress_bar.py[line:272] - INFO: epoch 009:    766 / 907 loss=0.24, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=2.3, ups=0.01, wpb=268, bsz=96, num_updates=8010, lr=9.8646e-07, gnorm=0.445, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=53027
2023-10-05 10:06:47 - progress_bar.py[line:272] - INFO: epoch 009:    776 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=270.7, nsentences=96, sample_size=270.7, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=394.2, ups=1.46, wpb=270.7, bsz=96, num_updates=8020, lr=9.21986e-07, gnorm=0.457, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=53033
2023-10-05 10:06:54 - progress_bar.py[line:272] - INFO: epoch 009:    786 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.063, ntokens=271.4, nsentences=96, sample_size=271.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=407.3, ups=1.5, wpb=271.4, bsz=96, num_updates=8030, lr=8.57511e-07, gnorm=0.707, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=53040
2023-10-05 10:07:01 - progress_bar.py[line:272] - INFO: epoch 009:    796 / 907 loss=0.243, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=270.5, nsentences=96, sample_size=270.5, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=403.4, ups=1.49, wpb=270.5, bsz=96, num_updates=8040, lr=7.93037e-07, gnorm=0.661, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=53047
2023-10-05 10:07:08 - progress_bar.py[line:272] - INFO: epoch 009:    806 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.059, ntokens=268, nsentences=96, sample_size=268, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=391.7, ups=1.46, wpb=268, bsz=96, num_updates=8050, lr=7.28562e-07, gnorm=0.476, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=53054
2023-10-05 10:07:14 - progress_bar.py[line:272] - INFO: epoch 009:    816 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.06, ntokens=269.4, nsentences=96, sample_size=269.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=401.2, ups=1.49, wpb=269.4, bsz=96, num_updates=8060, lr=6.64088e-07, gnorm=0.455, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=53060
2023-10-05 10:07:21 - progress_bar.py[line:272] - INFO: epoch 009:    826 / 907 loss=0.244, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=271.6, nsentences=96, sample_size=271.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=393.7, ups=1.45, wpb=271.6, bsz=96, num_updates=8070, lr=5.99613e-07, gnorm=0.656, clip=20, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=53067
2023-10-05 10:07:28 - progress_bar.py[line:272] - INFO: epoch 009:    836 / 907 loss=0.242, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=267.9, nsentences=96, sample_size=267.9, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=399.3, ups=1.49, wpb=267.9, bsz=96, num_updates=8080, lr=5.35139e-07, gnorm=0.421, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=53074
2023-10-05 10:07:35 - progress_bar.py[line:272] - INFO: epoch 009:    846 / 907 loss=0.248, loss_v1=0, loss_v2=0, nll_loss=0.066, ntokens=268.6, nsentences=96, sample_size=268.6, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=388.6, ups=1.45, wpb=268.6, bsz=96, num_updates=8090, lr=4.70664e-07, gnorm=0.553, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=53081
2023-10-05 10:07:42 - progress_bar.py[line:272] - INFO: epoch 009:    856 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.062, ntokens=267.4, nsentences=96, sample_size=267.4, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=397.7, ups=1.49, wpb=267.4, bsz=96, num_updates=8100, lr=4.0619e-07, gnorm=0.441, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=53088
2023-10-05 10:07:48 - progress_bar.py[line:272] - INFO: epoch 009:    866 / 907 loss=0.246, loss_v1=0, loss_v2=0, nll_loss=0.064, ntokens=267.8, nsentences=96, sample_size=267.8, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=397.1, ups=1.48, wpb=267.8, bsz=96, num_updates=8110, lr=3.41715e-07, gnorm=0.564, clip=10, loss_scale=512, train_wall=7, gb_free=6.3, ema_decay=0.9999, wall=53094
2023-10-05 10:07:55 - progress_bar.py[line:272] - INFO: epoch 009:    876 / 907 loss=0.247, loss_v1=0, loss_v2=0, nll_loss=0.065, ntokens=268.2, nsentences=96, sample_size=268.2, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=400, ups=1.49, wpb=268.2, bsz=96, num_updates=8120, lr=2.7724e-07, gnorm=0.459, clip=0, loss_scale=512, train_wall=7, gb_free=6.4, ema_decay=0.9999, wall=53101
2023-10-05 10:08:02 - progress_bar.py[line:272] - INFO: epoch 009:    886 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.068, ntokens=268.9, nsentences=96, sample_size=268.9, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=387.5, ups=1.44, wpb=268.9, bsz=96, num_updates=8130, lr=2.12766e-07, gnorm=0.46, clip=10, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=53108
2023-10-05 10:08:09 - progress_bar.py[line:272] - INFO: epoch 009:    896 / 907 loss=0.249, loss_v1=0, loss_v2=0, nll_loss=0.067, ntokens=268.7, nsentences=96, sample_size=268.7, sample_size_v1=0, sample_size_v2=0, ppl=1.05, wps=406.4, ups=1.51, wpb=268.7, bsz=96, num_updates=8140, lr=1.48291e-07, gnorm=0.505, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=53115
2023-10-05 10:08:16 - progress_bar.py[line:272] - INFO: epoch 009:    906 / 907 loss=0.241, loss_v1=0, loss_v2=0, nll_loss=0.058, ntokens=269.2, nsentences=96, sample_size=269.2, sample_size_v1=0, sample_size_v2=0, ppl=1.04, wps=389.6, ups=1.45, wpb=269.2, bsz=96, num_updates=8150, lr=8.38169e-08, gnorm=0.416, clip=0, loss_scale=512, train_wall=7, gb_free=6.5, ema_decay=0.9999, wall=53122
2023-10-05 10:08:16 - train.py[line:339] - INFO: end of epoch 9 (average epoch stats below)
2023-10-05 10:08:16 - progress_bar.py[line:282] - INFO: epoch 009 | loss 0.244 | loss_v1 0 | loss_v2 0 | nll_loss 0.062 | ntokens 269.256 | nsentences 95.914 | sample_size 269.256 | sample_size_v1 0 | sample_size_v2 0 | ppl 1.04 | wps 45.7 | ups 0.17 | wpb 269.3 | bsz 95.9 | num_updates 8151 | lr 7.73694e-08 | gnorm 0.523 | clip 6.5 | loss_scale 512 | train_wall 614 | gb_free 16.3 | ema_decay 0.9999 | wall 53122
2023-10-05 10:08:16 - trainer.py[line:694] - INFO: loading train data for epoch 10
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv slice_id 6 row count 10874 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv slice_id 0 row count 10875 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv slice_id 4 row count 10874 total row count 86994

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv slice_id 5 row count 10874 total row count 86994

file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv slice_id 2 row count 10874 total row count 86994
2023-10-05 10:08:16 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/COCO/b64_feat.lineidx
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv slice_id 3 row count 10874 total row count 86994
file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv slice_id 7 row count 10874 total row count 86994file /data/cminus/datasets/OFA_data/sgg/20_way_caption_five_filtered/query_combine_coco_vg_train_NA1_E9.tsv slice_id 1 row count 10875 total row count 86994

2023-10-05 10:08:16 - tsv_file.py[line:93] - INFO: loading lineidx: /data/cminus/ofa/data/mm_data/../../../datasets/VisualGenome/b64_feat.lineidx
2023-10-05 10:08:16 - train.py[line:221] - INFO: done training in 53115.1 seconds
